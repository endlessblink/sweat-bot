{
  "id": "e248af91-8430-4c20-bb56-11fa88dc1ed9",
  "url": "https://api.firecrawl.dev/v2/crawl/e248af91-8430-4c20-bb56-11fa88dc1ed9",
  "startedAt": "2025-08-23T20:41:19.055Z",
  "endedAt": "2025-08-23T20:41:20.647Z",
  "endpoint": "crawl",
  "formState": {
    "extractSetupCompleted": false,
    "urls": [],
    "extractSchema": {
      "type": "object",
      "required": [],
      "properties": {
        "company_mission": {
          "type": "string"
        },
        "supports_sso": {
          "type": "boolean"
        },
        "is_open_source": {
          "type": "boolean"
        },
        "is_in_yc": {
          "type": "boolean"
        }
      }
    },
    "extractPrompt": "Extract the company details, following the schema.",
    "enableWebSearch": false,
    "options": {
      "onlyMainContent": true,
      "parsePDF": true,
      "stealthMode": false,
      "excludeTags": [],
      "includeTags": [],
      "waitFor": "",
      "timeout": "",
      "maxAge": "2 days",
      "ignoreSitemap": false,
      "crawlEntireDomain": false,
      "sitemap": "include",
      "limit": "100",
      "maxDepth": "",
      "excludePaths": [],
      "includePaths": [],
      "includeSubdomains": false,
      "search": "",
      "scrapeContentFromSearchResults": true,
      "timeBasedSearch": "",
      "location": "",
      "prompt": ""
    },
    "formats": [
      "markdown"
    ],
    "sources": [
      "web"
    ],
    "jsonSchema": {
      "type": "object",
      "required": [],
      "properties": {
        "company_name": {
          "type": "string"
        },
        "company_description": {
          "type": "string"
        }
      }
    },
    "agent": {},
    "url": "voltagent.dev/docs/",
    "endpoint": "crawl"
  },
  "status": "success",
  "version": "5oGtIHTA-yoCHS3PnuXyD",
  "data": [
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n### What is VoltAgent? [â€‹](https://voltagent.dev/docs/\\#what-is-voltagent \"Direct link to What is VoltAgent?\")\n\nThink of VoltAgent as a powerful toolkit for developers who want to build applications with AI smarts. If you've ever wanted to create your own chatbot, a helpful virtual assistant, or any software that needs to think, learn, or interact intelligently, VoltAgent makes it much easier.\n\nInstead of building everything from scratch, VoltAgent provides ready-made building blocks. Here's what makes it special:\n\n- **Core Engine ( `@voltagent/core`)**: This is the heart of VoltAgent, providing the fundamental brainpower and capabilities for any AI agent you build.\n- **Automate with Workflows**: Go beyond simple chatbots. VoltAgent includes a powerful workflow engine to create multi-step automations that can process data, call APIs, run tasks in parallel, and execute conditional logic.\n- **Add Special Features**: Need your AI to talk? Add the `@voltagent/voice` package. It's modular, like adding apps to your phone.\n- **Connect to Anything**: VoltAgent helps your AI connect to other websites, tools, or data sources, allowing it to perform real tasks.\n- **Memory**: It helps the AI remember past conversations and learn, making interactions more natural and helpful.\n- **Works with Many AI Brains**: You're not locked into one AI provider. VoltAgent can work with popular AI models from OpenAI (like ChatGPT), Google, Anthropic, and others.\n- **Quick Start Tools ( `create-voltagent-app`, `@voltagent/cli`)**: Helpers to get developers up and running with a new AI project quickly. The create-voltagent-app CLI provides an interactive setup with AI provider selection, automatic dependency installation, and IDE configuration.\n\nTo easily monitor and manage the agents you build with VoltAgent, there's a complementary tool called **[VoltOps LLM Observability Platform](https://console.voltagent.dev/)** (available separately). It provides a user-friendly interface, bridging the gap between coding flexibility and no-code convenience.\n\n- Core Framework\n- Workflow Engine\n- VoltOps Platform\n\n```codeBlockLines_e6Vv\nimport { VoltAgent, Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\n\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  name: \"my-voltagent-app\",\n  instructions: \"A helpful assistant that answers questions without using tools\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n});\n\n```\n\nIn short, VoltAgent helps developers build sophisticated AI applications faster and more reliably, without getting bogged down in repetitive setup or being limited by overly simple tools.\n\n### Why VoltAgent? [â€‹](https://voltagent.dev/docs/\\#why-voltagent \"Direct link to Why VoltAgent?\")\n\nCreating smart AI applications can be tricky. Developers often face two choices:\n\n1. **Build Everything Themselves:** Using the basic tools provided by AI companies (like OpenAI or Google). This gives lots of control but can quickly become messy, hard to manage, and requires re-building the same features over and over for different projects.\n2. **Use Simple \"No-Code\" Builders:** These tools are easier to start with but often limit what you can build. You might get stuck with features you can't change, be forced to use only one company's AI, or find it impossible to create truly unique or complex AI assistants.\n\nVoltAgent offers a better way, finding the sweet spot between these two extremes. It provides helpful structure and ready-made components without boxing developers in. Here's why it's a great choice:\n\n- **Build Faster:** Get your AI application up and running much quicker than starting from scratch.\n- **Build Sophisticated Automations:** It's not just for chat. The workflow engine lets you build complex, multi-step processes for tasks like data analysis pipelines, automated content generation, or intelligent decision-making systems.\n- **Keep Things Tidy:** VoltAgent encourages organized code, making applications easier to update and fix later.\n- **Grow Easily:** Start with a simple chatbot and scale up to handle more complex tasks or multiple AI agents working together.\n- **Stay Flexible:** You have full control to customize how your AI looks, behaves, and interacts.\n- **Avoid Getting Stuck:** VoltAgent doesn't lock you into a specific AI provider. You can switch if needed, protecting your work.\n- **Save Costs:** Smart features help reduce how much you spend on using the underlying AI services.\n- **Monitor and Debug Visually:** The separate [VoltOps LLM Observability Platform](https://console.voltagent.dev/) provides a visual interface to easily track performance, understand behavior, and fix issues in your VoltAgent applications.\n\nEssentially, VoltAgent helps developers build the exact AI application they imagine â€“ from simple helpers to sophisticated systems â€“ more efficiently and with less frustration, complemented by powerful monitoring tools.\n\n### Table of Contents\n\n- [What is VoltAgent?](https://voltagent.dev/docs/#what-is-voltagent)\n- [Why VoltAgent?](https://voltagent.dev/docs/#why-voltagent)",
      "metadata": {
        "docsearch:docusaurus_tag": "docs-default-current",
        "viewport": "width=device-width, initial-scale=1.0",
        "og:locale": "en",
        "title": "Overview | VoltAgent",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "generator": "Docusaurus v3.1.1",
        "twitter:card": "summary_large_image",
        "ogUrl": "https://voltagent.dev/docs/",
        "ogLocale": "en",
        "docusaurus_locale": "en",
        "ogDescription": "What is VoltAgent?",
        "docusaurus_tag": "docs-default-current",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "docsearch:version": "current",
        "language": "en",
        "docsearch:language": "en",
        "docusaurus_version": "current",
        "description": "What is VoltAgent?",
        "og:image": "https://voltagent.dev/img/social3.png",
        "og:description": "What is VoltAgent?",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "og:url": "https://voltagent.dev/docs/",
        "ogTitle": "Overview | VoltAgent",
        "og:title": "Overview | VoltAgent",
        "scrapeId": "c95a24e5-382e-440c-9fca-c4c58ca9f407",
        "sourceURL": "http://voltagent.dev/docs/",
        "url": "https://voltagent.dev/docs/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:19.121Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/providers/overview/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Providers Overview\n\nIn VoltAgent, **Providers** (implementing the `LLMProvider` interface) are the essential components that bridge the gap between your `Agent` and the underlying Large Language Models (LLMs) or AI services. They handle the specifics of interacting with different APIs, managing authentication, formatting requests, and parsing responses.\n\nThis allows you to build your agent logic independently of the specific LLM service you choose initially, making it easy to switch models or services later.\n\nRecommended Approach\n\n**We strongly recommend using the Vercel AI SDK providers** through our `@voltagent/vercel-ai` integration. This gives you access to 30+ providers with consistent APIs, automatic updates, and a vibrant community ecosystem.\n\n**[View all available providers and models](https://voltagent.dev/docs/getting-started/providers-models/)**\n\n## Available Providers [â€‹](https://voltagent.dev/docs/providers/overview/\\#available-providers \"Direct link to Available Providers\")\n\nVoltAgent offers several providers, with our recommended approach being the Vercel AI SDK integration:\n\n### Recommended Provider [â€‹](https://voltagent.dev/docs/providers/overview/\\#recommended-provider \"Direct link to Recommended Provider\")\n\n- **[`@voltagent/vercel-ai`](https://voltagent.dev/docs/providers/vercel-ai/):** **RECOMMENDED**\n  - Leverages the versatile [Vercel AI SDK](https://sdk.vercel.ai/docs) for broad compatibility with 30+ LLM providers\n  - Access to OpenAI, Anthropic, Google, Groq, Mistral, Amazon Bedrock, Azure, and many more through a single interface\n  - Consistent API across all providers with automatic updates for new models\n  - Active community ecosystem with regular updates\n\n### Lightweight Alternative [â€‹](https://voltagent.dev/docs/providers/overview/\\#lightweight-alternative \"Direct link to Lightweight Alternative\")\n\n- **[`@voltagent/xsai`](https://voltagent.dev/docs/providers/xsai/):**\n  - Uses the lightweight `xsai` library to connect to any OpenAI-compatible API endpoint\n  - Ideal for flexibility and when targeting environments sensitive to bundle size (like edge functions)\n  - Works with OpenAI, Groq, Together AI, Anyscale, Mistral, and local models via Ollama/LM Studio\n\n### Legacy Providers (Deprecated) [â€‹](https://voltagent.dev/docs/providers/overview/\\#legacy-providers-deprecated \"Direct link to Legacy Providers (Deprecated)\")\n\nDeprecated Packages\n\nThe following providers are deprecated in favor of the Vercel AI SDK providers. They will continue to work but will not receive new features or model updates.\n\n- **[`@voltagent/google-ai`](https://voltagent.dev/docs/providers/google-ai/):** **DEPRECATED**\n  - Legacy integration for Google's Generative AI models (Gemini)\n  - **Migrate to:** `@ai-sdk/google` or `@ai-sdk/google-vertex` with `@voltagent/vercel-ai`\n- **[`@voltagent/groq-ai`](https://voltagent.dev/docs/providers/groq-ai/):** **DEPRECATED**\n  - Legacy integration for Groq API\n  - **Migrate to:** `@ai-sdk/groq` with `@voltagent/vercel-ai`\n- **[`@voltagent/anthropic-ai`](https://voltagent.dev/docs/providers/anthropic-ai/):** **DEPRECATED**\n  - Legacy integration for Anthropic's Claude models\n  - **Migrate to:** `@ai-sdk/anthropic` with `@voltagent/vercel-ai`\n\n## Custom Provider Implementation [â€‹](https://voltagent.dev/docs/providers/overview/\\#custom-provider-implementation \"Direct link to Custom Provider Implementation\")\n\nVoltAgent supports creating **custom providers** for advanced use cases that require more control than what the Vercel AI SDK offers.\n\n### When to Use Custom Providers [â€‹](https://voltagent.dev/docs/providers/overview/\\#when-to-use-custom-providers \"Direct link to When to Use Custom Providers\")\n\n**Consider a custom provider when you need:**\n\n- Integration with proprietary or internal LLM services\n- Advanced control over API request/response handling\n- Custom authentication or authorization mechanisms\n- Specialized retry logic or rate limiting strategies\n- Integration with legacy systems that don't follow standard APIs\n\n### When to Use Vercel AI SDK (Recommended for Most Cases) [â€‹](https://voltagent.dev/docs/providers/overview/\\#when-to-use-vercel-ai-sdk-recommended-for-most-cases \"Direct link to When to Use Vercel AI SDK (Recommended for Most Cases)\")\n\n**The Vercel AI SDK providers are sufficient for most use cases:**\n\n- Access to 30+ popular AI providers out of the box\n- Consistent, well-tested implementations\n- Regular updates with new models and features\n- Active community support and contributions\n- Standardized interfaces for streaming, tool calling, and structured outputs\n- OpenAI-compatible provider for custom endpoints\n\n### Implementing a Custom Provider [â€‹](https://voltagent.dev/docs/providers/overview/\\#implementing-a-custom-provider \"Direct link to Implementing a Custom Provider\")\n\nTo create a custom provider, implement the `LLMProvider` interface from `@voltagent/core`:\n\n```codeBlockLines_e6Vv\nimport { LLMProvider } from \"@voltagent/core\";\n\nexport class MyCustomProvider implements LLMProvider {\n  // Implement required methods\n  async generateText(/* ... */) {\n    /* ... */\n  }\n  async streamText(/* ... */) {\n    /* ... */\n  }\n  async generateObject(/* ... */) {\n    /* ... */\n  }\n  // ... other required methods\n}\n\n```\n\n> **Pro Tip:** Before building a custom provider, check if the [OpenAI-compatible provider](https://ai-sdk.dev/providers/openai-compatible-providers) can work with your custom endpoint. Many LLM services follow the OpenAI API specification, making integration much simpler.\n\nSelect the provider that best fits the LLM service or API you intend to use. See the individual provider pages linked above for detailed installation, configuration, and usage instructions.\n\n### Table of Contents\n\n- [Available Providers](https://voltagent.dev/docs/providers/overview/#available-providers)\n  - [Recommended Provider](https://voltagent.dev/docs/providers/overview/#recommended-provider)\n  - [Lightweight Alternative](https://voltagent.dev/docs/providers/overview/#lightweight-alternative)\n  - [Legacy Providers (Deprecated)](https://voltagent.dev/docs/providers/overview/#legacy-providers-deprecated)\n- [Custom Provider Implementation](https://voltagent.dev/docs/providers/overview/#custom-provider-implementation)\n  - [When to Use Custom Providers](https://voltagent.dev/docs/providers/overview/#when-to-use-custom-providers)\n  - [When to Use Vercel AI SDK (Recommended for Most Cases)](https://voltagent.dev/docs/providers/overview/#when-to-use-vercel-ai-sdk-recommended-for-most-cases)\n  - [Implementing a Custom Provider](https://voltagent.dev/docs/providers/overview/#implementing-a-custom-provider)",
      "metadata": {
        "generator": "Docusaurus v3.1.1",
        "docusaurus_version": "current",
        "og:description": "In VoltAgent, Providers (implementing the LLMProvider interface) are the essential components that bridge the gap between your Agent and the underlying Large Language Models (LLMs) or AI services. They handle the specifics of interacting with different APIs, managing authentication, formatting requests, and parsing responses.",
        "ogLocale": "en",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "og:locale": "en",
        "og:image": "https://voltagent.dev/img/social3.png",
        "og:title": "Providers Overview | VoltAgent",
        "ogUrl": "https://voltagent.dev/docs/providers/overview/",
        "docusaurus_tag": "docs-default-current",
        "title": "Providers Overview | VoltAgent",
        "viewport": "width=device-width, initial-scale=1.0",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "twitter:card": "summary_large_image",
        "docsearch:version": "current",
        "og:url": "https://voltagent.dev/docs/providers/overview/",
        "docsearch:docusaurus_tag": "docs-default-current",
        "docsearch:language": "en",
        "description": "In VoltAgent, Providers (implementing the LLMProvider interface) are the essential components that bridge the gap between your Agent and the underlying Large Language Models (LLMs) or AI services. They handle the specifics of interacting with different APIs, managing authentication, formatting requests, and parsing responses.",
        "docusaurus_locale": "en",
        "ogTitle": "Providers Overview | VoltAgent",
        "ogDescription": "In VoltAgent, Providers (implementing the LLMProvider interface) are the essential components that bridge the gap between your Agent and the underlying Large Language Models (LLMs) or AI services. They handle the specifics of interacting with different APIs, managing authentication, formatting requests, and parsing responses.",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "language": "en",
        "scrapeId": "06be36f5-d2a0-4633-bca1-eb2d1fa8180d",
        "sourceURL": "https://voltagent.dev/docs/providers/overview/",
        "url": "https://voltagent.dev/docs/providers/overview/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:24.074Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/agents/prompts/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Prompt Management\n\n## Overview [â€‹](https://voltagent.dev/docs/agents/prompts/\\#overview \"Direct link to Overview\")\n\nVoltAgent provides a three-tier prompt management system that scales from simple prototypes to enterprise-grade production deployments. Choose the approach that best fits your current needs and easily migrate as your requirements grow.\n\n### The Three Approaches [â€‹](https://voltagent.dev/docs/agents/prompts/\\#the-three-approaches \"Direct link to The Three Approaches\")\n\n| Approach | Best For | Setup Time | Team Size | Flexibility |\n| --- | --- | --- | --- | --- |\n| **Static Instructions** | Prototypes, simple tools | 0 minutes | 1-2 developers | Low |\n| **Dynamic Instructions** | Context-aware apps | 5 minutes | 2-5 developers | High |\n| **VoltOps Management** | Production teams | 15 minutes | 3+ team members | Enterprise |\n\n## 1\\. Basic Static Instructions [â€‹](https://voltagent.dev/docs/agents/prompts/\\#1-basic-static-instructions \"Direct link to 1. Basic Static Instructions\")\n\n**Basic agent setup:**\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst weatherAgent = new Agent({\n  name: \"WeatherAgent\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  instructions:\n    \"You are a customer support agent. Help users with their questions politely and efficiently.\",\n});\n\n```\n\n### What it is [â€‹](https://voltagent.dev/docs/agents/prompts/\\#what-it-is \"Direct link to What it is\")\n\nSimple string-based instructions that remain constant throughout your agent's lifecycle. This is the most straightforward approach where you hardcode your agent's behavior directly in your application code.\n\n**Real-world example**: A documentation chatbot that always behaves the same way regardless of user, time, or context.\n\n### When to use [â€‹](https://voltagent.dev/docs/agents/prompts/\\#when-to-use \"Direct link to When to use\")\n\n**âœ… Perfect for:**\n\n- **MVP/Prototyping**: Getting your agent working quickly without infrastructure overhead\n- **Simple task-specific agents**: Email summarizers, code formatters, static content generators\n- **Educational projects**: Learning VoltAgent basics without complexity\n- **Single-purpose tools**: Agents that perform one specific task consistently\n\n**âŒ Avoid when:**\n\n- You need different behavior for different users\n- Your agent needs to adapt based on time, location, or context\n- Multiple team members need to edit prompts\n- You're planning to A/B test different approaches\n- Your application serves multiple customer segments\n\n### Pros & Cons [â€‹](https://voltagent.dev/docs/agents/prompts/\\#pros--cons \"Direct link to Pros & Cons\")\n\n| Pros | Cons |\n| --- | --- |\n| Simple and straightforward | No runtime flexibility |\n| No external dependencies | No version control |\n| Perfect for getting started | Hard to update in production |\n| Immediate deployment | No analytics or monitoring |\n\n## 2\\. Dynamic Instructions with UserContext [â€‹](https://voltagent.dev/docs/agents/prompts/\\#2-dynamic-instructions-with-usercontext \"Direct link to 2. Dynamic Instructions with UserContext\")\n\n**Function-based instructions with userTier:**\n\n```codeBlockLines_e6Vv\nconst supportAgent = new Agent({\n  name: \"SupportAgent\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  instructions: async ({ userContext }) => {\n    const userTier = userContext.get(\"userTier\") || \"basic\";\n\n    if (userTier === \"premium\") {\n      return \"You are a premium customer support agent. Provide detailed explanations, offer multiple solutions, and prioritize this customer's requests. Be thorough and professional.\";\n    } else {\n      return \"You are a customer support agent. Provide helpful but concise answers to user questions. Be friendly and efficient.\";\n    }\n  },\n});\n\n```\n\n**Using the agent with userContext:**\n\n```codeBlockLines_e6Vv\n// Premium user gets different treatment\nconst premiumContext = new Map();\npremiumContext.set(\"userTier\", \"premium\");\n\nconst premiumResponse = await supportAgent.generateText(\"I need help with my order\", {\n  userContext: premiumContext,\n});\n\n// Basic user gets standard support\nconst basicContext = new Map();\nbasicContext.set(\"userTier\", \"basic\");\n\nconst basicResponse = await supportAgent.generateText(\"I need help with my order\", {\n  userContext: basicContext,\n});\n\n```\n\n### What it is [â€‹](https://voltagent.dev/docs/agents/prompts/\\#what-it-is-1 \"Direct link to What it is\")\n\nFunction-based instructions that generate prompts dynamically based on runtime context, user data, and application state. Your agent's behavior adapts in real-time without external dependencies.\n\n**Real-world examples**:\n\n- E-commerce support agent that behaves differently for VIP vs. regular customers\n- Educational tutor that adjusts complexity based on student level\n- Multi-tenant SaaS agent that uses different brand voices per customer\n\n### When to use [â€‹](https://voltagent.dev/docs/agents/prompts/\\#when-to-use-1 \"Direct link to When to use\")\n\n**âœ… Perfect for:**\n\n- **User-specific experiences**: Different prompt behavior per user tier, role, or preferences\n- **Context-dependent logic**: Time-sensitive responses, location-based customization\n- **Multi-tenant applications**: Different behavior per customer/organization\n- **A/B testing setup**: Conditional prompt logic for experimentation\n- **Privacy-conscious applications**: No external prompt management needed\n\n**âŒ Consider alternatives when:**\n\n- Multiple non-technical team members need to edit prompts\n- You need detailed prompt analytics and version history\n- Your team needs collaborative prompt development\n- You want to update prompts without code deployments\n- Complex prompt templates that would benefit from a visual editor\n\n### Pros & Cons [â€‹](https://voltagent.dev/docs/agents/prompts/\\#pros--cons-1 \"Direct link to Pros & Cons\")\n\n| Pros | Cons |\n| --- | --- |\n| Full runtime flexibility | More complex code |\n| Access to user context and application state | Harder to debug prompts |\n| Conditional prompt logic | No centralized prompt management |\n| No external dependencies | No built-in analytics |\n| Immediate updates |  |\n\n## 3\\. VoltOps Prompt Management [â€‹](https://voltagent.dev/docs/agents/prompts/\\#3-voltops-prompt-management \"Direct link to 3. VoltOps Prompt Management\")\n\nVoltOps provides a complete prompt management platform with version control, team collaboration, and analytics. Let's walk through setting it up step by step.\n\n### Step 1: Sign Up and Get API Keys [â€‹](https://voltagent.dev/docs/agents/prompts/\\#step-1-sign-up-and-get-api-keys \"Direct link to Step 1: Sign Up and Get API Keys\")\n\n1. **Sign up** at [console.voltagent.dev](https://console.voltagent.dev/)\n2. **Create a project** or select an existing one\n3. **Get your API keys** from Settings â†’ [Projects](https://console.voltagent.dev/settings/projects)\n4. **Add to your .env file**:\n\n```codeBlockLines_e6Vv\nVOLTOPS_PUBLIC_KEY=pk_your_public_key_here\nVOLTOPS_SECRET_KEY=sk_your_secret_key_here\n\n```\n\n### Step 2: Create Your First Prompt [â€‹](https://voltagent.dev/docs/agents/prompts/\\#step-2-create-your-first-prompt \"Direct link to Step 2: Create Your First Prompt\")\n\n![VoltOps Prompt Management](https://cdn.voltagent.dev/docs/create-prompt-demo.gif)\n\nLet's create a customer support prompt step by step:\n\n1. **Navigate to Prompts**: Go to [`https://console.voltagent.dev/prompts`](https://console.voltagent.dev/prompts)\n\n2. **Click \"Create Prompt\"** button in the top right\n\n3. **Fill in the prompt details**:\n\n\n   - **Name**: `customer-support-prompt`\n   - **Description**: `Customer support agent prompt for handling user inquiries`\n   - **Type**: Select `Text` (we'll explore chat type later)\n   - **Content**:\n\n```codeBlockLines_e6Vv\nYou are a helpful customer support agent for {{companyName}}.\n\nYour role is to assist customers with their questions and concerns in a {{tone}} manner.\n\nCurrent support level: {{supportLevel}}\n\nGuidelines:\n- Always be polite and professional\n- If you cannot help, escalate to human support\n- Use the company name when appropriate\n\n```\n\n4. **Add template variables** (these will be auto-detected):\n   - `companyName`\n   - `tone`\n   - `supportLevel`\n5. **Set initial labels**: Add `development` label\n\n6. **Click \"Create Prompt\"**\n\n\n### Step 3: Use the Prompt in Your Code [â€‹](https://voltagent.dev/docs/agents/prompts/\\#step-3-use-the-prompt-in-your-code \"Direct link to Step 3: Use the Prompt in Your Code\")\n\n![VoltOps Prompt Playground Demo](https://cdn.voltagent.dev/docs/voltops-prompt-playground.gif)\n\nNow let's integrate this prompt into your VoltAgent application:\n\n**Setup VoltOps Client:**\n\n```codeBlockLines_e6Vv\nimport { Agent, VoltAgent, VoltOpsClient } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst voltOpsClient = new VoltOpsClient({\n  publicKey: process.env.VOLTOPS_PUBLIC_KEY,\n  secretKey: process.env.VOLTOPS_SECRET_KEY,\n  prompts: true,\n  promptCache: {\n    enabled: true,\n    ttl: 300, // 5 minutes\n  },\n});\n\nconst supportAgent = new Agent({\n  name: \"SupportAgent\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  instructions: async ({ prompts }) => {\n    return await prompts.getPrompt({\n      promptName: \"customer-support-prompt\",\n      variables: {\n        companyName: \"VoltAgent Corp\",\n        tone: \"friendly and professional\",\n        supportLevel: \"premium\",\n      },\n    });\n  },\n});\n\n// Initialize VoltAgent with agents and VoltOps client\nconst voltAgent = new VoltAgent({\n  agents: {\n    supportAgent,\n  },\n  voltOpsClient: voltOpsClient,\n});\n\n// Test your agent\nconst response = await supportAgent.generateText(\"I'm having trouble with my order\");\nconsole.log(response.text);\n\n```\n\nAlternative: Direct VoltOpsClient on Agent\n\nYou can also pass the VoltOpsClient directly to individual agents:\n\n```codeBlockLines_e6Vv\nconst supportAgent = new Agent({\n  name: \"SupportAgent\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  instructions: async ({ prompts }) => {\n    return await prompts.getPrompt({\n      promptName: \"customer-support-prompt\",\n      variables: {\n        companyName: \"VoltAgent Corp\",\n        tone: \"friendly and professional\",\n        supportLevel: \"premium\",\n      },\n    });\n  },\n  voltOpsClient: voltOpsClient, // Direct client assignment\n});\n\n```\n\nThis approach is useful when you have agents with different VoltOps configurations or when you need fine-grained control over client settings per agent.\n\n**ðŸ’¡ Tip**: You can also find complete usage examples in the prompt's **Usage tab** in the console interface, with copy-ready code snippets for different scenarios.\n\nDirect VoltOpsClient Access\n\nYou can also access prompts directly from the VoltOpsClient outside of agent instructions, which is useful for testing and debugging:\n\n```codeBlockLines_e6Vv\n// Direct access for testing or utility functions\nconst voltOpsClient = new VoltOpsClient({\n  publicKey: process.env.VOLTOPS_PUBLIC_KEY,\n  secretKey: process.env.VOLTOPS_SECRET_KEY,\n});\n\n// Get prompt directly\nconst promptContent = await voltOpsClient.prompts.getPrompt({\n  promptName: \"customer-support-prompt\",\n  variables: {\n    companyName: \"VoltAgent Corp\",\n    tone: \"friendly and professional\",\n    supportLevel: \"premium\",\n  },\n});\n\nconsole.log(\"Prompt content:\", promptContent);\n\n```\n\nThis approach is perfect for:\n\n- Testing prompts independently\n- Building prompt preview tools\n- Dynamic prompt selection logic\n- Utility functions that need prompt access\n\n### Step 4: Create a New Version [â€‹](https://voltagent.dev/docs/agents/prompts/\\#step-4-create-a-new-version \"Direct link to Step 4: Create a New Version\")\n\n![VoltOps Prompt Versioning](https://cdn.voltagent.dev/docs/create-new-version-prompt.gif)\n\nAs your application evolves, you'll want to improve your prompts. Let's create a new version:\n\n1. **Go to your prompt detail page**\n\n2. **Click \"New Version\"** button\n\n3. **Modify the prompt content**:\n\n\n\n\n\n```codeBlockLines_e6Vv\nYou are an expert customer support agent for {{companyName}}.\n\nYour mission is to provide exceptional service and resolve customer issues efficiently.\n\nSupport tier: {{supportLevel}}\nCommunication style: {{tone}}\n\nEnhanced guidelines:\n- Always acknowledge the customer's concern first\n- Provide clear, step-by-step solutions\n- Offer alternative solutions when possible\n- Follow up to ensure satisfaction\n- Escalate complex technical issues to our technical team\n\nRemember: Every interaction is an opportunity to create a loyal customer.\n\n```\n\n4. **Add a commit message**: \"Enhanced support guidelines and improved structure\"\n\n5. **Click \"Create Version\"**\n\n\n### Step 5: Test with Cache Behavior [â€‹](https://voltagent.dev/docs/agents/prompts/\\#step-5-test-with-cache-behavior \"Direct link to Step 5: Test with Cache Behavior\")\n\nNow let's test our updated prompt:\n\n```codeBlockLines_e6Vv\n// Run your agent again\nconst response = await supportAgent.generateText(\"I'm having trouble with my order\");\n\n```\n\n**You might notice the old prompt is still being used!** This is because of caching.\n\n### Understanding Cache Behavior [â€‹](https://voltagent.dev/docs/agents/prompts/\\#understanding-cache-behavior \"Direct link to Understanding Cache Behavior\")\n\nVoltOps uses caching to reduce latency and improve performance. There are two levels of cache configuration:\n\n**1\\. Global VoltOps Client Cache:**\n\n```codeBlockLines_e6Vv\nconst voltOpsClient = new VoltOpsClient({\n// ... other options\npromptCache: {\n    enabled: true,\n    ttl: 300, // 5 minutes - cached prompts expire after this time\n    maxSize: 100, // Maximum number of prompts to cache\n},\n});\n\n```\n\n**2\\. Per-Prompt Cache Override:**\n\n```codeBlockLines_e6Vv\ninstructions: async ({ prompts }) => {\nreturn await prompts.getPrompt({\n    promptName: \"customer-support-prompt\",\n    promptCache: {\n      enabled: false, // Disable cache for this specific prompt\n    },\n    variables: {\n      companyName: \"VoltAgent Corp\",\n      tone: \"friendly and professional\",\n      supportLevel: \"premium\",\n    },\n});\n};\n\n```\n\n**To test your new version immediately:**\n\n```codeBlockLines_e6Vv\n// Option 1: Disable cache temporarily\npromptCache: {\nenabled: false;\n}\n\n// Option 2: Clear cache and test\nvoltOpsClient.prompts.clearCache();\n\n// Option 3: Wait for TTL to expire (5 minutes by default)\n\n```\n\n### Step 6: Using Labels for Environment Management [â€‹](https://voltagent.dev/docs/agents/prompts/\\#step-6-using-labels-for-environment-management \"Direct link to Step 6: Using Labels for Environment Management\")\n\n![Promote to Production](https://cdn.voltagent.dev/docs/prompt-promoting.gif)\n\nLabels help you manage different versions across environments. Let's promote your new version to production:\n\n1. **Go to your prompt detail page**\n2. **Find version 2** in the version history sidebar\n3. **Click the \"â‹¯\" menu** next to the version\n4. **Select \"Promote to Production\"**\n5. **Confirm the promotion**\n\nNow you can target specific environments in your code:\n\n**Development Environment:**\n\n```codeBlockLines_e6Vv\ninstructions: async ({ prompts }) => {\nreturn await prompts.getPrompt({\n    promptName: \"customer-support-prompt\",\n    label: \"development\", // Uses development version\n    variables: {\n      /* ... */\n    },\n});\n};\n\n```\n\n**Production Environment:**\n\n```codeBlockLines_e6Vv\ninstructions: async ({ prompts }) => {\nreturn await prompts.getPrompt({\n    promptName: \"customer-support-prompt\",\n    label: \"production\", // Uses production version\n    variables: {\n      /* ... */\n    },\n});\n};\n\n```\n\n**Environment-based Selection:**\n\n```codeBlockLines_e6Vv\ninstructions: async ({ prompts }) => {\nconst label = process.env.NODE_ENV === \"production\" ? \"production\" : \"development\";\n\nreturn await prompts.getPrompt({\n    promptName: \"customer-support-prompt\",\n    label: label,\n    variables: {\n      /* ... */\n    },\n});\n};\n\n```\n\n### Step 7: Chat Type Prompts [â€‹](https://voltagent.dev/docs/agents/prompts/\\#step-7-chat-type-prompts \"Direct link to Step 7: Chat Type Prompts\")\n\nFor more complex conversational agents, you can use chat-type prompts that define multiple message roles:\n\n**Creating a Chat Prompt:**\n\n1. **Click \"Create Prompt\"**\n2. **Select \"Chat\" type**\n3. **Add multiple messages**:\n\n\n\n\n\n```codeBlockLines_e6Vv\n[\\\n     {\\\n       \"role\": \"system\",\\\n       \"content\": \"You are {{agentRole}} for {{companyName}}. Always maintain a {{tone}} tone.\"\\\n     },\\\n     {\\\n       \"role\": \"user\",\\\n       \"content\": \"Hello, I need help with my account.\"\\\n     },\\\n     {\\\n       \"role\": \"assistant\",\\\n       \"content\": \"Hello! I'd be happy to help you with your account. Could you please provide more details about the specific issue you're experiencing?\"\\\n     }\\\n]\n\n```\n\n\n**Using Chat Prompts:**\n\n```codeBlockLines_e6Vv\nconst chatAgent = new Agent({\nname: \"ChatSupportAgent\",\nllm: new VercelAIProvider(),\nmodel: openai(\"gpt-4o-mini\"),\ninstructions: async ({ prompts }) => {\n    return await prompts.getPrompt({\n      promptName: \"chat-support-prompt\",\n      variables: {\n        agentRole: \"customer support specialist\",\n        companyName: \"VoltAgent Corp\",\n        tone: \"friendly and professional\",\n      },\n    });\n},\nvoltOpsClient: voltOpsClient,\n});\n\n```\n\nChat prompts are perfect for:\n\n- Multi-turn conversations\n- Setting conversation context\n- Providing example interactions\n- Fine-tuning response patterns\n\n### What it is [â€‹](https://voltagent.dev/docs/agents/prompts/\\#what-it-is-2 \"Direct link to What it is\")\n\nEnterprise-grade prompt management platform that separates prompt content from your application code. Think of it as \"GitHub for prompts\" with built-in analytics, team collaboration, and deployment pipelines.\n\n**Real-world examples**:\n\n- **Large development teams**: Product managers can edit prompts without touching code\n- **Enterprise applications**: Compliance teams can review prompt changes before production\n- **SaaS platforms**: Different prompt versions for different customer tiers managed centrally\n- **AI-first companies**: Data scientists can optimize prompts based on performance analytics\n\n### When to use [â€‹](https://voltagent.dev/docs/agents/prompts/\\#when-to-use-2 \"Direct link to When to use\")\n\n**âœ… Essential for:**\n\n- **Team collaboration**: Non-technical stakeholders need to edit prompts\n- **Production environments**: You need audit trails, rollback capabilities, and change approval workflows\n- **Multiple environments**: Different prompt versions for dev/staging/production\n- **Performance optimization**: You need analytics on prompt effectiveness and costs\n- **Compliance requirements**: Audit trails and approval processes for prompt changes\n- **Scale operations**: Managing 10+ different prompts across multiple agents\n\n### Pros & Cons [â€‹](https://voltagent.dev/docs/agents/prompts/\\#pros--cons-2 \"Direct link to Pros & Cons\")\n\n| Pros | Cons |\n| --- | --- |\n| Complete version control | External dependency |\n| Team collaboration features | Requires setup |\n| Environment-specific labels | Network requests |\n| Template variables with validation | Learning curve |\n| Built-in analytics and monitoring |  |\n| Performance caching |  |\n| Chat and text prompt support |  |\n\n## 5\\. Best Practices [â€‹](https://voltagent.dev/docs/agents/prompts/\\#5-best-practices \"Direct link to 5. Best Practices\")\n\n### Prompt Versioning Strategies [â€‹](https://voltagent.dev/docs/agents/prompts/\\#prompt-versioning-strategies \"Direct link to Prompt Versioning Strategies\")\n\n**Follow semantic versioning principles:**\n\n```codeBlockLines_e6Vv\n// Bad: Vague commit messages\n\"updated prompt\";\n\"fixed issues\";\n\n// Good: Descriptive commit messages\n\"Add persona consistency guidelines for customer support\";\n\"Reduce hallucination by adding explicit knowledge boundaries\";\n\"Optimize for 20% faster response times based on analytics\";\n\n```\n\n**Environment promotion workflow:**\n\n```codeBlockLines_e6Vv\n// 1. Develop and test in development\nconst devPrompt = await prompts.getPrompt({\npromptName: \"support-agent\",\nlabel: \"development\",\n});\n\n// 2. Promote to staging for integration testing\n// (Done via VoltOps console)\n\n// 3. After approval, promote to production\nconst prodPrompt = await prompts.getPrompt({\npromptName: \"support-agent\",\nlabel: \"production\",\n});\n\n```\n\n### Error Handling & Resilience [â€‹](https://voltagent.dev/docs/agents/prompts/\\#error-handling--resilience \"Direct link to Error Handling & Resilience\")\n\n**Always implement fallback strategies:**\n\n```codeBlockLines_e6Vv\ninstructions: async ({ prompts }) => {\ntry {\n    return await prompts.getPrompt({\n      promptName: \"primary-prompt\",\n      timeout: 5000, // 5 second timeout\n    });\n} catch (error) {\n    console.error(\"Prompt fetch failed, using fallback:\", error);\n\n    // Fallback to static prompt\n    return \"You are a helpful assistant. Please help the user with their question.\";\n}\n};\n\n```\n\n### Performance Optimization [â€‹](https://voltagent.dev/docs/agents/prompts/\\#performance-optimization \"Direct link to Performance Optimization\")\n\n**Strategic caching configuration:**\n\n```codeBlockLines_e6Vv\n// High-frequency prompts: Short TTL\nconst frequentPrompt = await prompts.getPrompt({\npromptName: \"chat-greeting\",\npromptCache: { ttl: 60, enabled: true }, // 1 minute\n});\n\n// Stable prompts: Long TTL\nconst stablePrompt = await prompts.getPrompt({\npromptName: \"system-instructions\",\npromptCache: { ttl: 3600, enabled: true }, // 1 hour\n});\n\n// Dynamic prompts: No cache\nconst dynamicPrompt = await prompts.getPrompt({\npromptName: \"personalized-prompt\",\npromptCache: { enabled: false },\nvariables: { userId: dynamicUserId },\n});\n\n```\n\n**Preload critical prompts:**\n\n```codeBlockLines_e6Vv\n// Preload during application startup\nconst criticalPrompts = [\"welcome-message\", \"error-handler\", \"fallback-response\"];\n\nawait Promise.all(criticalPrompts.map((name) => prompts.getPrompt({ promptName: name })));\n\n```\n\n### Security Best Practices [â€‹](https://voltagent.dev/docs/agents/prompts/\\#security-best-practices \"Direct link to Security Best Practices\")\n\n**Input sanitization for template variables:**\n\n```codeBlockLines_e6Vv\ninstructions: async ({ prompts, userContext }) => {\n// Sanitize user input\nconst sanitizedUserName =\n    userContext\n      .get(\"userName\")\n      ?.replace(/[<>]/g, \"\") // Remove potential HTML\n      ?.substring(0, 50) || \"Guest\"; // Limit length\n\nreturn await prompts.getPrompt({\n    promptName: \"personalized-greeting\",\n    variables: {\n      userName: sanitizedUserName,\n      // Never pass raw user input directly\n    },\n});\n};\n\n```\n\n## 6\\. Troubleshooting [â€‹](https://voltagent.dev/docs/agents/prompts/\\#6-troubleshooting \"Direct link to 6. Troubleshooting\")\n\n### Common Issues [â€‹](https://voltagent.dev/docs/agents/prompts/\\#common-issues \"Direct link to Common Issues\")\n\n**Prompt not found error:**\n\n```codeBlockLines_e6Vv\n// Problem: Prompt name doesn't exist\nError: Prompt 'weather-prompt' not found\n\n// Solution: Check prompt name spelling and ensure it exists in VoltOps\ninstructions: async ({ prompts }) => {\ntry {\n    return await prompts.getPrompt({ promptName: \"weather-prompt\" });\n} catch (error) {\n    console.error(\"Prompt fetch failed:\", error);\n    return \"Fallback instructions here\";\n}\n}\n\n```\n\n**Template variable errors:**\n\n```codeBlockLines_e6Vv\n// Problem: Missing required variables\nTemplate error: Variable 'userName' not found\n\n// Solution: Provide all required variables\nreturn await prompts.getPrompt({\npromptName: \"greeting-prompt\",\nvariables: {\n    userName: userContext.get('userName') || 'Guest', // Provide default\n    currentTime: new Date().toISOString()\n}\n});\n\n```\n\n**Cache issues:**\n\n```codeBlockLines_e6Vv\n// Problem: Stale prompts due to caching\n// Solution: Clear cache or adjust TTL\nvoltOpsClient.clearCache(); // Clear all cached prompts\n\n// Or disable caching temporarily\nreturn await prompts.getPrompt({\npromptName: \"urgent-prompt\",\npromptCache: { enabled: false },\n});\n\n```\n\n**Authentication errors:**\n\n```codeBlockLines_e6Vv\n// Problem: Invalid API keys\nError: Authentication failed\n\n// Solution: Verify environment variables\nconsole.log(\"Public Key:\", process.env.VOLTOPS_PUBLIC_KEY?.substring(0, 8) + \"...\");\nconsole.log(\"Secret Key:\", process.env.VOLTOPS_SECRET_KEY ? \"Set\" : \"Missing\");\n\n```\n\n### Debug Tips [â€‹](https://voltagent.dev/docs/agents/prompts/\\#debug-tips \"Direct link to Debug Tips\")\n\n**Test prompt fetching independently:**\n\n```codeBlockLines_e6Vv\n// Test VoltOps connection outside of agent\nconst voltOpsClient = new VoltOpsClient({\npublicKey: process.env.VOLTOPS_PUBLIC_KEY,\nsecretKey: process.env.VOLTOPS_SECRET_KEY,\n});\n\nconst promptManager = voltOpsClient.prompts;\n\ntry {\nconst prompt = await promptManager.getPrompt({\n    promptName: \"test-prompt\",\n});\nconsole.log(\"Prompt fetch successful:\", prompt);\n} catch (error) {\nconsole.error(\"Prompt fetch failed:\", error);\n}\n\n```\n\n## 7\\. Choosing the Right Approach [â€‹](https://voltagent.dev/docs/agents/prompts/\\#7-choosing-the-right-approach \"Direct link to 7. Choosing the Right Approach\")\n\n### At a Glance Comparison [â€‹](https://voltagent.dev/docs/agents/prompts/\\#at-a-glance-comparison \"Direct link to At a Glance Comparison\")\n\n| Feature | Static Instructions | Dynamic Instructions | VoltOps Management |\n| --- | --- | --- | --- |\n| **Setup Time** | 0 minutes | 5 minutes | 15 minutes |\n| **Runtime Performance** | Fastest | Fast | Good (with caching) |\n| **Context Awareness** | âŒ | âœ… | âœ… |\n| **Team Collaboration** | âŒ | Limited | âœ… |\n| **Version Control** | Code-based | Code-based | Built-in |\n| **Non-technical Editing** | âŒ | âŒ | âœ… |\n| **Analytics** | Manual | Manual | Built-in |\n| **A/B Testing** | Manual | Code-based | Built-in |\n| **Offline Support** | âœ… | âœ… | âŒ |\n| **Cost** | Free | Free | Paid service |\n\n### Real-World Scenarios [â€‹](https://voltagent.dev/docs/agents/prompts/\\#real-world-scenarios \"Direct link to Real-World Scenarios\")\n\n**Scenario 1: Solo Developer Building a Personal Tool**\n\n```codeBlockLines_e6Vv\n// Use Static Instructions\nconst agent = new Agent({\ninstructions: \"You are a helpful code reviewer. Focus on security and performance.\",\n// ... other options\n});\n\n```\n\n**Why**: No team collaboration needed, behavior is consistent, setup is instant.\n\n**Scenario 2: SaaS Platform with Different User Tiers**\n\n```codeBlockLines_e6Vv\n// Use Dynamic Instructions\nconst agent = new Agent({\ninstructions: async ({ userContext }) => {\n    const tier = userContext.get(\"tier\");\n    return tier === \"premium\"\n      ? \"You are a dedicated premium support agent with deep technical expertise.\"\n      : \"You are a helpful support agent providing efficient solutions.\";\n},\n});\n\n```\n\n**Why**: Behavior changes based on user context, but you don't need external prompt management.\n\n**Scenario 3: Enterprise Team with Product Managers**\n\n```codeBlockLines_e6Vv\n// Use VoltOps Management\nconst agent = new Agent({\ninstructions: async ({ prompts }) => {\n    return await prompts.getPrompt({\n      promptName: \"customer-support-agent\",\n      label: process.env.NODE_ENV === \"production\" ? \"production\" : \"development\",\n    });\n},\nvoltOpsClient: voltOpsClient,\n});\n\n```\n\n**Why**: Non-technical team members need to edit prompts, you need approval workflows, and analytics are important.\n\n### Quick Start Recommendations [â€‹](https://voltagent.dev/docs/agents/prompts/\\#quick-start-recommendations \"Direct link to Quick Start Recommendations\")\n\n1. **Just starting with VoltAgent?** â†’ Start with Static Instructions\n2. **Need user-specific behavior?** â†’ Use Dynamic Instructions\n3. **Working with a team?** â†’ Evaluate VoltOps Management\n4. **Building for production?** â†’ Plan migration path to VoltOps\n\nRemember: You can always start simple and migrate to more sophisticated approaches as your needs grow. The key is choosing the right level of complexity for your current requirements.\n\n### Table of Contents\n\n- [Overview](https://voltagent.dev/docs/agents/prompts/#overview)\n  - [The Three Approaches](https://voltagent.dev/docs/agents/prompts/#the-three-approaches)\n- [1\\. Basic Static Instructions](https://voltagent.dev/docs/agents/prompts/#1-basic-static-instructions)\n  - [What it is](https://voltagent.dev/docs/agents/prompts/#what-it-is)\n  - [When to use](https://voltagent.dev/docs/agents/prompts/#when-to-use)\n  - [Pros & Cons](https://voltagent.dev/docs/agents/prompts/#pros--cons)\n- [2\\. Dynamic Instructions with UserContext](https://voltagent.dev/docs/agents/prompts/#2-dynamic-instructions-with-usercontext)\n  - [What it is](https://voltagent.dev/docs/agents/prompts/#what-it-is-1)\n  - [When to use](https://voltagent.dev/docs/agents/prompts/#when-to-use-1)\n  - [Pros & Cons](https://voltagent.dev/docs/agents/prompts/#pros--cons-1)\n- [3\\. VoltOps Prompt Management](https://voltagent.dev/docs/agents/prompts/#3-voltops-prompt-management)\n  - [Step 1: Sign Up and Get API Keys](https://voltagent.dev/docs/agents/prompts/#step-1-sign-up-and-get-api-keys)\n  - [Step 2: Create Your First Prompt](https://voltagent.dev/docs/agents/prompts/#step-2-create-your-first-prompt)\n  - [Step 3: Use the Prompt in Your Code](https://voltagent.dev/docs/agents/prompts/#step-3-use-the-prompt-in-your-code)\n  - [Step 4: Create a New Version](https://voltagent.dev/docs/agents/prompts/#step-4-create-a-new-version)\n  - [Step 5: Test with Cache Behavior](https://voltagent.dev/docs/agents/prompts/#step-5-test-with-cache-behavior)\n  - [Understanding Cache Behavior](https://voltagent.dev/docs/agents/prompts/#understanding-cache-behavior)\n  - [Step 6: Using Labels for Environment Management](https://voltagent.dev/docs/agents/prompts/#step-6-using-labels-for-environment-management)\n  - [Step 7: Chat Type Prompts](https://voltagent.dev/docs/agents/prompts/#step-7-chat-type-prompts)\n  - [What it is](https://voltagent.dev/docs/agents/prompts/#what-it-is-2)\n  - [When to use](https://voltagent.dev/docs/agents/prompts/#when-to-use-2)\n  - [Pros & Cons](https://voltagent.dev/docs/agents/prompts/#pros--cons-2)\n- [5\\. Best Practices](https://voltagent.dev/docs/agents/prompts/#5-best-practices)\n  - [Prompt Versioning Strategies](https://voltagent.dev/docs/agents/prompts/#prompt-versioning-strategies)\n  - [Error Handling & Resilience](https://voltagent.dev/docs/agents/prompts/#error-handling--resilience)\n  - [Performance Optimization](https://voltagent.dev/docs/agents/prompts/#performance-optimization)\n  - [Security Best Practices](https://voltagent.dev/docs/agents/prompts/#security-best-practices)\n- [6\\. Troubleshooting](https://voltagent.dev/docs/agents/prompts/#6-troubleshooting)\n  - [Common Issues](https://voltagent.dev/docs/agents/prompts/#common-issues)\n  - [Debug Tips](https://voltagent.dev/docs/agents/prompts/#debug-tips)\n- [7\\. Choosing the Right Approach](https://voltagent.dev/docs/agents/prompts/#7-choosing-the-right-approach)\n  - [At a Glance Comparison](https://voltagent.dev/docs/agents/prompts/#at-a-glance-comparison)\n  - [Real-World Scenarios](https://voltagent.dev/docs/agents/prompts/#real-world-scenarios)\n  - [Quick Start Recommendations](https://voltagent.dev/docs/agents/prompts/#quick-start-recommendations)",
      "metadata": {
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "ogTitle": "Prompt Management | VoltAgent",
        "viewport": "width=device-width, initial-scale=1.0",
        "ogDescription": "Overview",
        "og:description": "Overview",
        "og:locale": "en",
        "docusaurus_locale": "en",
        "title": "Prompt Management | VoltAgent",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "docusaurus_version": "current",
        "language": "en",
        "ogLocale": "en",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "docsearch:language": "en",
        "docusaurus_tag": "docs-default-current",
        "docsearch:version": "current",
        "twitter:card": "summary_large_image",
        "og:url": "https://voltagent.dev/docs/agents/prompts/",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:title": "Prompt Management | VoltAgent",
        "ogUrl": "https://voltagent.dev/docs/agents/prompts/",
        "description": "Overview",
        "og:image": "https://voltagent.dev/img/social3.png",
        "generator": "Docusaurus v3.1.1",
        "scrapeId": "c6e65f27-ced4-4f93-8a6a-b1473652798b",
        "sourceURL": "https://voltagent.dev/docs/agents/prompts/",
        "url": "https://voltagent.dev/docs/agents/prompts/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:41:03.574Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/rag/qdrant/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# VoltAgent with Qdrant\n\n[Qdrant](https://qdrant.tech/) is an open-source vector database designed for scalable, high-performance semantic search and retrieval. It supports REST and gRPC APIs, advanced filtering, and is easy to self-host or use as a managed service.\n\n## Prerequisites [â€‹](https://voltagent.dev/docs/rag/qdrant/\\#prerequisites \"Direct link to Prerequisites\")\n\nBefore starting, ensure you have:\n\n- Node.js 18+ installed\n- Qdrant instance (local or cloud)\n- Qdrant API key (if using cloud)\n- OpenAI API key (for embeddings)\n\n## Installation [â€‹](https://voltagent.dev/docs/rag/qdrant/\\#installation \"Direct link to Installation\")\n\nCreate a new VoltAgent project with Qdrant integration:\n\n```codeBlockLines_e6Vv\nnpm create voltagent-app@latest -- --example with-qdrant\ncd with-qdrant\n\n```\n\nThis creates a complete VoltAgent + Qdrant setup with sample data and two different agent configurations.\n\nInstall the dependencies:\n\n- npm\n- pnpm\n- yarn\n\n```codeBlockLines_e6Vv\nnpm install\n\n```\n\n## Environment Setup [â€‹](https://voltagent.dev/docs/rag/qdrant/\\#environment-setup \"Direct link to Environment Setup\")\n\nCreate a `.env` file with your configuration:\n\n```codeBlockLines_e6Vv\n# Qdrant URL\n# docker run -p 6333:6333 qdrant/qdrant\nQDRANT_URL=http://localhost:6333\n\n# Qdrant API key (Optional)\nQDRANT_API_KEY=your-qdrant-api-key-here\n\n# OpenAI API key for embeddings and LLM\nOPENAI_API_KEY=your-openai-api-key-here\n\n```\n\n## Run Your Application [â€‹](https://voltagent.dev/docs/rag/qdrant/\\#run-your-application \"Direct link to Run Your Application\")\n\nStart your VoltAgent application:\n\n- npm\n- pnpm\n- yarn\n\n```codeBlockLines_e6Vv\nnpm run dev\n\n```\n\nYou'll see:\n\n```codeBlockLines_e6Vv\nðŸš€ VoltAgent with Qdrant is running!\nðŸ“š Two different agents are ready:\n  1ï¸âƒ£ Assistant with Retriever - Automatic semantic search on every interaction\n  2ï¸âƒ£ Assistant with Tools - LLM decides when to search autonomously\n\nðŸ” Try asking questions like:\n  â€¢ 'What is VoltAgent?'\n  â€¢ 'Tell me about vector databases'\n  â€¢ 'How does Qdrant work?'\n  â€¢ 'What is RAG?'\n\nðŸ’¡ The Tools Agent will automatically search when needed!\n\nðŸ“‹ Sources tracking: Both agents track which documents were used\n   Check userContext.get('references') to see sources with IDs and scores\nðŸ“‹ Creating new collection \"voltagent-knowledge-base\"...\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  VOLTAGENT SERVER STARTED SUCCESSFULLY\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  âœ“ HTTP Server:  http://localhost:3141\n  âœ“ Swagger UI:   http://localhost:3141/ui\n\n  Test your agents with VoltOps Console: https://console.voltagent.dev\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nâœ… Collection \"voltagent-knowledge-base\" created successfully\nðŸ“š Populating collection with sample documents...\nâœ… Successfully upserted 5 documents to collection\n\n```\n\n## Interact with Your Agents [â€‹](https://voltagent.dev/docs/rag/qdrant/\\#interact-with-your-agents \"Direct link to Interact with Your Agents\")\n\nYour agents are now running! To interact with them:\n\n1. **Open the Console:** Click the [`https://console.voltagent.dev`](https://console.voltagent.dev/) link in your terminal output (or copy-paste it into your browser).\n2. **Find Your Agents:** On the VoltOps LLM Observability Platform page, you should see both agents listed:\n   - \"Assistant with Retriever\"\n   - \"Assistant with Tools\"\n3. **Open Agent Details:** Click on either agent's name.\n4. **Start Chatting:** On the agent detail page, click the chat icon in the bottom right corner to open the chat window.\n5. **Test RAG Capabilities:** Try questions like:\n   - \"What is VoltAgent?\"\n   - \"Tell me about Qdrant\"\n   - \"How does vector search work?\"\n   - \"What is RAG?\"\n\nYou should receive responses from your AI agents that include relevant information from your Qdrant knowledge base, along with source references showing which documents were used to generate the response.\n\n## How It Works [â€‹](https://voltagent.dev/docs/rag/qdrant/\\#how-it-works \"Direct link to How It Works\")\n\nThe following sections explain how this example is built and how you can customize it.\n\n### Create the Qdrant Retriever [â€‹](https://voltagent.dev/docs/rag/qdrant/\\#create-the-qdrant-retriever \"Direct link to Create the Qdrant Retriever\")\n\nCreate `src/retriever/index.ts`:\n\n```codeBlockLines_e6Vv\nimport { BaseRetriever, type BaseMessage, type RetrieveOptions } from \"@voltagent/core\";\nimport { QdrantClient } from \"@qdrant/js-client-rest\";\n\n// Initialize Qdrant client\nconst qdrant = new QdrantClient({\n  url: process.env.QDRANT_URL || \"http://localhost:6333\",\n  apiKey: process.env.QDRANT_API_KEY,\n});\n\nconst collectionName = \"voltagent-knowledge-base\";\n\n```\n\n**Key Components Explained**:\n\n- **Qdrant Client**: Connects to Qdrant's REST API\n- **Collection**: A named container for your vectors in Qdrant\n- **Open Source & Cloud**: Use locally or as a managed service\n\n### Initialize Collection and Sample Data [â€‹](https://voltagent.dev/docs/rag/qdrant/\\#initialize-collection-and-sample-data \"Direct link to Initialize Collection and Sample Data\")\n\nThe example automatically creates and populates your Qdrant collection:\n\n```codeBlockLines_e6Vv\nasync function initializeCollection() {\n  try {\n    // Check if collection exists\n    let exists = false;\n    try {\n      await qdrant.getCollection(collectionName);\n      exists = true;\n      console.log(`ðŸ“‹ Collection \"${collectionName}\" already exists`);\n    } catch (error) {\n      console.log(`ðŸ“‹ Creating new collection \"${collectionName}\"...`);\n    }\n\n    // Create collection if it doesn't exist\n    if (!exists) {\n      await qdrant.createCollection(collectionName, {\n        vectors: { size: 1536, distance: \"Cosine\" },\n      });\n      console.log(`âœ… Collection \"${collectionName}\" created successfully`);\n    }\n\n    // Check if we need to populate with sample data\n    const stats = await qdrant.count(collectionName);\n    if (stats.count === 0) {\n      console.log(\"ðŸ“š Populating collection with sample documents...\");\n      // Generate embeddings for sample documents using OpenAI\n      const OpenAI = await import(\"openai\");\n      const openai = new OpenAI.default({\n        apiKey: process.env.OPENAI_API_KEY!,\n      });\n      const points = [];\n      for (const record of sampleRecords) {\n        try {\n          const embeddingResponse = await openai.embeddings.create({\n            model: \"text-embedding-3-small\",\n            input: record.payload.text,\n          });\n          points.push({\n            id: record.id,\n            vector: embeddingResponse.data[0].embedding,\n            payload: record.payload,\n          });\n        } catch (error) {\n          console.error(`Error generating embedding for ${record.id}:`, error);\n        }\n      }\n      if (points.length > 0) {\n        await qdrant.upsert(collectionName, { points });\n        console.log(`âœ… Successfully upserted ${points.length} documents to collection`);\n      }\n    } else {\n      console.log(`ðŸ“Š Collection already contains ${stats.count} documents`);\n    }\n  } catch (error) {\n    console.error(\"Error initializing Qdrant collection:\", error);\n  }\n}\n\n```\n\n**What This Does**:\n\n- Creates a Qdrant collection with cosine similarity\n- Generates embeddings using OpenAI's API\n- Adds the embeddings and payloads to Qdrant\n\n### Implement the Retriever Class [â€‹](https://voltagent.dev/docs/rag/qdrant/\\#implement-the-retriever-class \"Direct link to Implement the Retriever Class\")\n\nCreate the main retriever class:\n\n```codeBlockLines_e6Vv\n// Retriever function\nasync function retrieveDocuments(query: string, topK = 3) {\n  try {\n    // Generate embedding for the query\n    const OpenAI = await import(\"openai\");\n    const openai = new OpenAI.default({\n      apiKey: process.env.OPENAI_API_KEY!,\n    });\n    const embeddingResponse = await openai.embeddings.create({\n      model: \"text-embedding-3-small\",\n      input: query,\n    });\n    const queryVector = embeddingResponse.data[0].embedding;\n    // Perform search in Qdrant\n    const searchResults = (\n      await qdrant.query(collectionName, {\n        query: queryVector,\n        limit: topK,\n        with_payload: true,\n      })\n    ).points;\n    // Format results\n    return (\n      searchResults.map((match: any) => ({\n        content: match.payload?.text || \"\",\n        metadata: match.payload || {},\n        score: match.score || 0,\n        id: match.id,\n      })) || []\n    );\n  } catch (error) {\n    console.error(\"Error retrieving documents from Qdrant:\", error);\n    return [];\n  }\n}\n\n/**\n * Qdrant-based retriever implementation for VoltAgent\n */\nexport class QdrantRetriever extends BaseRetriever {\n  /**\n   * Retrieve documents from Qdrant based on semantic similarity\n   * @param input - The input to use for retrieval (string or BaseMessage[])\n   * @param options - Configuration and context for the retrieval\n   * @returns Promise resolving to a formatted context string\n   */\n  async retrieve(input: string | BaseMessage[], options: RetrieveOptions): Promise<string> {\n    // Convert input to searchable string\n    let searchText = \"\";\n    if (typeof input === \"string\") {\n      searchText = input;\n    } else if (Array.isArray(input) && input.length > 0) {\n      const lastMessage = input[input.length - 1];\n      if (Array.isArray(lastMessage.content)) {\n        const textParts = lastMessage.content\n          .filter((part: any) => part.type === \"text\")\n          .map((part: any) => part.text);\n        searchText = textParts.join(\" \");\n      } else {\n        searchText = lastMessage.content as string;\n      }\n    }\n    // Perform semantic search using Qdrant\n    const results = await retrieveDocuments(searchText, 3);\n    // Add references to userContext if available\n    if (options.userContext && results.length > 0) {\n      const references = results.map((doc: any, index: number) => ({\n        id: doc.id,\n        title: doc.metadata.topic || `Document ${index + 1}`,\n        source: \"Qdrant Knowledge Base\",\n        score: doc.score,\n        category: doc.metadata.category,\n      }));\n      options.userContext.set(\"references\", references);\n    }\n    // Return the concatenated content for the LLM\n    if (results.length === 0) {\n      return \"No relevant documents found in the knowledge base.\";\n    }\n    return results\n      .map(\n        (doc: any, index: number) =>\n          `Document ${index + 1} (ID: ${doc.id}, Score: ${doc.score.toFixed(4)}, Category: ${doc.metadata.category}):\\n${doc.content}`\n      )\n      .join(\"\\n\\n---\\n\\n\");\n  }\n}\n\n// Create retriever instance\nexport const retriever = new QdrantRetriever();\n\n```\n\n### Create Your Agents [â€‹](https://voltagent.dev/docs/rag/qdrant/\\#create-your-agents \"Direct link to Create Your Agents\")\n\nNow create agents using different retrieval patterns in `src/index.ts`:\n\n```codeBlockLines_e6Vv\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent, VoltAgent } from \"@voltagent/core\";\nimport { createPinoLogger } from \"@voltagent/logger\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\n\nimport { retriever } from \"./retriever/index.js\";\n\n// Agent 1: Using retriever directly\nconst agentWithRetriever = new Agent({\n  name: \"Assistant with Retriever\",\n  description:\n    \"A helpful assistant that can retrieve information from the Qdrant knowledge base using semantic search to provide better answers. I automatically search for relevant information when needed.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  retriever: retriever,\n});\n\n// Agent 2: Using retriever as tool\nconst agentWithTools = new Agent({\n  name: \"Assistant with Tools\",\n  description:\n    \"A helpful assistant that can search the Qdrant knowledge base using tools. The agent will decide when to search for information based on user questions.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  tools: [retriever.tool],\n});\n\n// Create logger\nconst logger = createPinoLogger({\n  name: \"with-qdrant\",\n  level: \"info\",\n});\n\nnew VoltAgent({\n  agents: {\n    agentWithRetriever,\n    agentWithTools,\n  },\n  logger,\n});\n\n```\n\n### Table of Contents\n\n- [Prerequisites](https://voltagent.dev/docs/rag/qdrant/#prerequisites)\n- [Installation](https://voltagent.dev/docs/rag/qdrant/#installation)\n- [Environment Setup](https://voltagent.dev/docs/rag/qdrant/#environment-setup)\n- [Run Your Application](https://voltagent.dev/docs/rag/qdrant/#run-your-application)\n- [Interact with Your Agents](https://voltagent.dev/docs/rag/qdrant/#interact-with-your-agents)\n- [How It Works](https://voltagent.dev/docs/rag/qdrant/#how-it-works)\n  - [Create the Qdrant Retriever](https://voltagent.dev/docs/rag/qdrant/#create-the-qdrant-retriever)\n  - [Initialize Collection and Sample Data](https://voltagent.dev/docs/rag/qdrant/#initialize-collection-and-sample-data)\n  - [Implement the Retriever Class](https://voltagent.dev/docs/rag/qdrant/#implement-the-retriever-class)\n  - [Create Your Agents](https://voltagent.dev/docs/rag/qdrant/#create-your-agents)",
      "metadata": {
        "docsearch:language": "en",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "ogLocale": "en",
        "og:image": "https://voltagent.dev/img/social3.png",
        "og:title": "VoltAgent",
        "ogUrl": "https://voltagent.dev/docs/rag/qdrant/",
        "docusaurus_tag": "default",
        "generator": "Docusaurus v3.1.1",
        "og:locale": "en",
        "docsearch:docusaurus_tag": "default",
        "twitter:card": "summary_large_image",
        "docusaurus_locale": "en",
        "language": "en",
        "title": "VoltAgent",
        "ogTitle": "VoltAgent",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "og:url": "https://voltagent.dev/docs/rag/qdrant/",
        "viewport": "width=device-width, initial-scale=1.0",
        "scrapeId": "d3543b7c-3510-42db-9d9d-0871514aed8c",
        "sourceURL": "https://voltagent.dev/docs/rag/qdrant/",
        "url": "https://voltagent.dev/docs/rag/qdrant/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:14.180Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/quick-start/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Quick Start\n\nThere are two ways to create a VoltAgent application: Automatic setup or manual setup. While both work, the automatic setup provides the smoothest experience, especially for new users.\n\n### Automatic Setup (Recommended) [â€‹](https://voltagent.dev/docs/quick-start/\\#automatic-setup-recommended \"Direct link to Automatic Setup (Recommended)\")\n\nYou can quickly create a new project using the `create-voltagent-app` CLI tool:\n\n- npm\n- yarn\n- pnpm\n\n```codeBlockLines_e6Vv\nnpm create voltagent-app@latest my-agent-app\n\n```\n\nAfter running the command, you'll see the VoltAgent Generator welcome screen:\n\n```codeBlockLines_e6Vv\n _    __      ____  ___                    __\n| |  / /___  / / /_/   | ____ ____  ____  / /_\n| | / / __ \\/ / __/ /| |/ __ `/ _ \\/ __ \\/ __/\n| |/ / /_/ / / /_/ ___ / /_/ /  __/ / / / /_\n|___/\\____/_/\\__/_/  |_\\__, /\\___/_/ /_/\\__/\n                      /____/\n\n   â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n   â”‚                                               â”‚\n   â”‚   Welcome to VoltAgent Generator!             â”‚\n   â”‚                                               â”‚\n   â”‚   Create powerful AI agents with VoltAgent.   â”‚\n   â”‚                                               â”‚\n   â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n\nLet's create your next AI application...\n\n? What is your project named? (my-voltagent-app) _\n\n```\n\nThe CLI will guide you through the setup process:\n\n1. **Project Name**: Choose a name for your project\n2. **AI Provider**: Select from OpenAI, Anthropic, Google, Groq, Mistral, or Ollama (local)\n3. **API Key** (optional): Enter your API key or skip to add it later\n4. **Package Manager**: Choose from installed package managers (npm, yarn, or pnpm)\n5. **IDE Configuration**: Optionally configure MCP Docs Server for your IDE\n\nThe tool will automatically:\n\n- Create project files and structure\n- Generate a `.env` file with your API key (if provided)\n- Initialize a git repository\n- Install dependencies Once the setup is complete, navigate to your project directory:\n\n```codeBlockLines_e6Vv\ncd my-voltagent-app\n\n```\n\n### Add Your API Key [â€‹](https://voltagent.dev/docs/quick-start/\\#add-your-api-key \"Direct link to Add Your API Key\")\n\nIf you skipped API key entry during setup, create or edit the `.env` file in your project root and add your API key:\n\n```codeBlockLines_e6Vv\n# For OpenAI\nOPENAI_API_KEY=your-api-key-here\n\n# For Anthropic\nANTHROPIC_API_KEY=your-api-key-here\n\n# For Google\nGOOGLE_GENERATIVE_AI_API_KEY=your-api-key-here\n\n# For Groq\nGROQ_API_KEY=your-api-key-here\n\n# For Mistral\nMISTRAL_API_KEY=your-api-key-here\n\n# For Ollama (no API key needed, runs locally)\n# Make sure Ollama is installed and running\n\n```\n\n> **Get your API key:**\n>\n> - **OpenAI**: [platform.openai.com/api-keys](https://platform.openai.com/api-keys)\n> - **Anthropic**: [console.anthropic.com/settings/keys](https://console.anthropic.com/settings/keys)\n> - **Google**: [aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)\n> - **Groq**: [console.groq.com/keys](https://console.groq.com/keys)\n> - **Mistral**: [console.mistral.ai/api-keys](https://console.mistral.ai/api-keys)\n> - **Ollama**: [ollama.com/download](https://ollama.com/download)\n\n### Start Your Application [â€‹](https://voltagent.dev/docs/quick-start/\\#start-your-application \"Direct link to Start Your Application\")\n\n- npm\n- yarn\n- pnpm\n\n```codeBlockLines_e6Vv\nnpm run dev\n\n```\n\nWhen you run the `dev` command, `tsx` will compile and run your code. You should see the VoltAgent server startup message in your terminal:\n\n```codeBlockLines_e6Vv\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  VOLTAGENT SERVER STARTED SUCCESSFULLY\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  âœ“ HTTP Server: http://localhost:3141\n\n  VoltOps Platform:    https://console.voltagent.dev\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n[VoltAgent] All packages are up to date\n\n```\n\nYour agent is now running! To interact with it:\n\n1. **Open the Console:** Click the [`https://console.voltagent.dev`](https://console.voltagent.dev/) link in your terminal output (or copy-paste it into your browser).\n2. **Find Your Agent:** On the VoltOps LLM Observability Platform page, you should see your agent listed (e.g., \"my-agent\").\n3. **Open Agent Details:** Click on your agent's name.\n4. **Start Chatting:** On the agent detail page, click the chat icon in the bottom right corner to open the chat window.\n5. **Send a Message:** Type a message like \"Hello\" and press Enter.\n\n![VoltOps LLM Observability Platform](https://cdn.voltagent.dev/readme/demo.gif)\n\nYou should receive a response from your AI agent in the chat window. This confirms that your VoltAgent application is set up correctly and communicating with the LLM.\n\nThe `dev` script uses `tsx watch`, so it will automatically restart if you make changes to your code in the `src` directory. Press `Ctrl+C` in the terminal to stop the agent.\n\n### Explore and Run Your Workflow from the Console [â€‹](https://voltagent.dev/docs/quick-start/\\#explore-and-run-your-workflow-from-the-console \"Direct link to Explore and Run Your Workflow from the Console\")\n\nYour new project isn't just an agent; it's a powerful automation engine. We've included an expense approval workflow example to get you started, and you can run it directly from the VoltOps console.\n\nThis workflow demonstrates how to chain together all the core steps of VoltAgent:\n\n- **Data Transformation** ( `andThen`)\n- **AI Agent Calls** ( `andAgent`)\n- **Parallel Processing** ( `andAll`)\n- **Racing Operations** ( `andRace`)\n- **Conditional Logic** ( `andWhen`)\n\n#### How to Run the Workflow [â€‹](https://voltagent.dev/docs/quick-start/\\#how-to-run-the-workflow \"Direct link to How to Run the Workflow\")\n\n![VoltOps Workflow Observability](https://cdn.voltagent.dev/docs/workflow-observability-demo.gif)\n\n1. **Go to the Workflows Page:** After starting your server, go directly to the [Workflows page](https://console.voltagent.dev/workflows).\n2. **Select Your Project:** Use the project selector on the page to choose your newly created project (e.g., \"my-agent-app\").\n3. **Find and Run the Workflow:** You will see **\"Expense Approval Workflow\"** listed. Click on it to open the detail page, then click the **\"Run\"** button.\n4. **Provide Input:** An input form will appear. The workflow expects a JSON object with expense details. Try one of the following inputs to see how it works:\n\n   - For automatic approval (under $100):\n\n```codeBlockLines_e6Vv\n{\n  \"amount\": 75,\n  \"category\": \"office supplies\",\n  \"description\": \"Notebooks and pens for team meeting\"\n}\n\n```\n\n- For manual review (over $100):\n\n```codeBlockLines_e6Vv\n{\n  \"amount\": 450,\n  \"category\": \"equipment\",\n  \"description\": \"New monitor for development workstation\"\n}\n\n```\n\n5. **View the Results:** After execution, you can inspect the detailed logs for each step and see the final output directly in the console.\n\nThis interactive experience is a great way to understand how to build and test complex automations with VoltAgent without needing to modify your code for every run.\n\n## Next Steps [â€‹](https://voltagent.dev/docs/quick-start/\\#next-steps \"Direct link to Next Steps\")\n\nReady to build real AI agents? Follow our step-by-step tutorial:\n\n- **[Start the Tutorial](https://voltagent.dev/tutorial/introduction/)** \\- Learn to build agents with tools, memory, and real-world integrations\n\nOr explore specific topics:\n\n- Explore [Agent](https://voltagent.dev/docs/agents/overview/) options\n- Learn about [Memory](https://voltagent.dev/docs/agents/memory/overview/)\n- Check out [Tool Creation](https://voltagent.dev/docs/agents/tools/) for more advanced use cases\n\n### Manual Setup [â€‹](https://voltagent.dev/docs/quick-start/\\#manual-setup \"Direct link to Manual Setup\")\n\nFollow these steps to create a new TypeScript project and add VoltAgent:\n\nCreate a new project directory:\n\n```codeBlockLines_e6Vv\nmkdir my-voltagent-project\ncd my-voltagent-project\n\n```\n\nInitialize a new npm project:\n\n```codeBlockLines_e6Vv\nnpm init -y\n\n```\n\nCreate a basic TypeScript configuration file (tsconfig.json):\n\n```codeBlockLines_e6Vv\n{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"module\": \"ES2022\",\n    \"moduleResolution\": \"bundler\",\n    \"esModuleInterop\": true,\n    \"outDir\": \"dist\",\n    \"strict\": true\n  },\n  \"include\": [\"src\"]\n}\n\n```\n\n#### Install Dependencies [â€‹](https://voltagent.dev/docs/quick-start/\\#install-dependencies \"Direct link to Install Dependencies\")\n\n- npm\n- yarn\n- pnpm\n\n```codeBlockLines_e6Vv\n# Install development dependencies\nnpm install --save-dev typescript tsx @types/node @voltagent/cli\n\n# Install dependencies\nnpm install @voltagent/core @voltagent/vercel-ai @ai-sdk/openai zod@^3.25.0\n\n```\n\nCreate a source directory:\n\n```codeBlockLines_e6Vv\nmkdir src\n\n```\n\nCreate a basic agent in `src/index.ts`:\n\n```codeBlockLines_e6Vv\nimport { VoltAgent, Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\"; // Example provider\nimport { openai } from \"@ai-sdk/openai\"; // Example model\n\n// Define a simple agent\nconst agent = new Agent({\n  name: \"my-agent\",\n  instructions: \"A helpful assistant that answers questions without using tools\",\n  // Note: You can swap VercelAIProvider and openai with other supported providers/models\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n});\n\n// Initialize VoltAgent with your agent(s)\nnew VoltAgent({\n  agents: {\n    agent,\n  },\n});\n\n```\n\nCreate a `.env` file and add your OpenAI API key:\n\n```codeBlockLines_e6Vv\n# Make sure to replace 'your_openai_api_key' with your actual key\nOPENAI_API_KEY=your_openai_api_key\n\n```\n\nAdd the following to your package.json:\n\n```codeBlockLines_e6Vv\n\"type\": \"module\",\n\"scripts\": {\n  \"build\": \"tsc\",\n  \"dev\": \"tsx watch --env-file=.env ./src\",\n  \"start\": \"node dist/index.js\",\n  \"volt\": \"volt\" // Requires @voltagent/cli\n}\n\n```\n\nYour project structure should now look like this:\n\n```codeBlockLines_e6Vv\nmy-voltagent-project/\nâ”œâ”€â”€ node_modules/\nâ”œâ”€â”€ src/\nâ”‚   â””â”€â”€ index.ts\nâ”œâ”€â”€ package.json\nâ”œâ”€â”€ tsconfig.json\nâ”œâ”€â”€ .env\nâ””â”€â”€ .voltagent/ (created automatically when you run the agent)\n\n```\n\n#### Run Your Agent [â€‹](https://voltagent.dev/docs/quick-start/\\#run-your-agent \"Direct link to Run Your Agent\")\n\n- npm\n- yarn\n- pnpm\n\n```codeBlockLines_e6Vv\nnpm run dev\n\n```\n\nWhen you run the `dev` command, `tsx` will compile and run your code. You should see the VoltAgent server startup message in your terminal:\n\n```codeBlockLines_e6Vv\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  VOLTAGENT SERVER STARTED SUCCESSFULLY\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  âœ“ HTTP Server: http://localhost:3141\n\n  VoltOps Platform:    https://console.voltagent.dev\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n[VoltAgent] All packages are up to date\n\n```\n\nYour agent is now running! To interact with it:\n\n1. **Open the Console:** Click the `https://console.voltagent.dev` link in your terminal output (or copy-paste it into your browser).\n2. **Find Your Agent:** On the VoltOps LLM Observability Platform page, you should see your agent listed (e.g., \"my-agent\").\n3. **Open Agent Details:** Click on your agent's name.\n4. **Start Chatting:** On the agent detail page, click the chat icon in the bottom right corner to open the chat window.\n5. **Send a Message:** Type a message like \"Hello\" and press Enter.\n\n_\\[Placeholder for GIF showing Console interaction: Finding agent, clicking chat, sending message\\]_\n\nYou should receive a response from your AI agent in the chat window. This confirms that your VoltAgent application is set up correctly and communicating with the LLM.\n\nThe `dev` script uses `tsx watch`, so it will automatically restart if you make changes to your code in the `src` directory. Press `Ctrl+C` in the terminal to stop the agent.\n\n## Next Steps [â€‹](https://voltagent.dev/docs/quick-start/\\#next-steps-1 \"Direct link to Next Steps\")\n\nReady to build real AI agents? Follow our step-by-step tutorial:\n\n- **[Start the Tutorial](https://voltagent.dev/tutorial/introduction/)** \\- Learn to build agents with tools, memory, and real-world integrations\n\nOr explore specific topics:\n\n- Explore [Agent](https://voltagent.dev/docs/agents/overview/) options\n- Learn about [Memory](https://voltagent.dev/docs/agents/memory/overview/)\n- Check out [Tool Creation](https://voltagent.dev/docs/agents/tools/) for more advanced use cases\n\n### Table of Contents\n\n- [Automatic Setup (Recommended)](https://voltagent.dev/docs/quick-start/#automatic-setup-recommended)\n- [Add Your API Key](https://voltagent.dev/docs/quick-start/#add-your-api-key)\n- [Start Your Application](https://voltagent.dev/docs/quick-start/#start-your-application)\n- [Explore and Run Your Workflow from the Console](https://voltagent.dev/docs/quick-start/#explore-and-run-your-workflow-from-the-console)\n- [Next Steps](https://voltagent.dev/docs/quick-start/#next-steps)\n  - [Manual Setup](https://voltagent.dev/docs/quick-start/#manual-setup)\n- [Next Steps](https://voltagent.dev/docs/quick-start/#next-steps-1)",
      "metadata": {
        "og:title": "Quick Start | VoltAgent",
        "docsearch:version": "current",
        "docsearch:docusaurus_tag": "docs-default-current",
        "generator": "Docusaurus v3.1.1",
        "ogUrl": "https://voltagent.dev/docs/quick-start/",
        "title": "Quick Start | VoltAgent",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "docsearch:language": "en",
        "twitter:card": "summary_large_image",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "og:locale": "en",
        "ogLocale": "en",
        "language": "en",
        "docusaurus_locale": "en",
        "docusaurus_version": "current",
        "og:url": "https://voltagent.dev/docs/quick-start/",
        "og:description": "There are two ways to create a VoltAgent application: Automatic setup or manual setup. While both work, the automatic setup provides the smoothest experience, especially for new users.",
        "ogDescription": "There are two ways to create a VoltAgent application: Automatic setup or manual setup. While both work, the automatic setup provides the smoothest experience, especially for new users.",
        "og:image": "https://voltagent.dev/img/social3.png",
        "docusaurus_tag": "docs-default-current",
        "description": "There are two ways to create a VoltAgent application: Automatic setup or manual setup. While both work, the automatic setup provides the smoothest experience, especially for new users.",
        "viewport": "width=device-width, initial-scale=1.0",
        "ogTitle": "Quick Start | VoltAgent",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "scrapeId": "7f964c80-7c27-464b-86ab-d58f18e30151",
        "sourceURL": "https://voltagent.dev/docs/quick-start/",
        "url": "https://voltagent.dev/docs/quick-start/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:41.531Z",
        "creditsUsed": 1
      },
      "warning": "This scrape job was throttled at your current concurrency limit. If you'd like to scrape faster, you can upgrade your plan."
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/agents/context/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Operation Context ( `userContext`)\n\n`userContext` allows you to pass custom data throughout a single agent operation. Think of it as a shared bag of information that all components (hooks, tools, retrievers, sub-agents) can access during one agent task.\n\n## Basic Concept [â€‹](https://voltagent.dev/docs/agents/context/\\#basic-concept \"Direct link to Basic Concept\")\n\nHere's how `userContext` flows through an agent operation:\n\n```codeBlockLines_e6Vv\nYou â†’ Agent â†’ Hooks â†’ Tools â†’ Retrievers â†’ Sub-Agents\n     â†‘                                              â†“\n     â† â† â† â† â† userContext flows everywhere â† â† â† â† â†\n\n```\n\nLet's see this in action with simple examples:\n\n## Initialize userContext [â€‹](https://voltagent.dev/docs/agents/context/\\#initialize-usercontext \"Direct link to Initialize userContext\")\n\nYou can provide initial data in two ways:\n\n### Method 1: Set Default Context in Constructor [â€‹](https://voltagent.dev/docs/agents/context/\\#method-1-set-default-context-in-constructor \"Direct link to Method 1: Set Default Context in Constructor\")\n\nYou can set default `userContext` when creating the agent, which will be used for all operations unless overridden:\n\n```codeBlockLines_e6Vv\nimport { Agent, VercelAIProvider } from \"@voltagent/core\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Set default context at agent creation\nconst defaultContext = new Map();\ndefaultContext.set(\"environment\", \"production\");\ndefaultContext.set(\"projectId\", \"my-project\");\n\nconst agent = new Agent({\n  name: \"SimpleAgent\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  instructions: \"You are a helpful assistant.\",\n  userContext: defaultContext, // Default context for all operations\n});\n\n// Uses default context automatically\nconst response1 = await agent.generateText(\"Hello!\");\nconsole.log(\"Environment:\", response1.userContext?.get(\"environment\")); // \"production\"\n\n// Override with execution context (replaces default completely)\nconst response2 = await agent.generateText(\"Debug this\", {\n  userContext: new Map([\\\n    [\"environment\", \"development\"],\\\n    [\"projectId\", \"my-project\"],\\\n  ]),\n});\nconsole.log(\"Environment:\", response2.userContext?.get(\"environment\")); // \"development\"\nconsole.log(\"Project ID:\", response2.userContext?.get(\"projectId\")); // \"my-project\"\n\n```\n\n### Method 2: Pass Context During Execution [â€‹](https://voltagent.dev/docs/agents/context/\\#method-2-pass-context-during-execution \"Direct link to Method 2: Pass Context During Execution\")\n\nYou can also pass `userContext` only when calling the agent:\n\n```codeBlockLines_e6Vv\nconst agent = new Agent({\n  name: \"SimpleAgent\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  instructions: \"You are a helpful assistant.\",\n});\n\n// Pass userContext when calling the agent\nconst executionContext = new Map();\nexecutionContext.set(\"language\", \"English\");\n\nconst response = await agent.generateText(\"Hello!\", {\n  userContext: executionContext,\n});\n\n// Now you can access the data from the response\nconsole.log(\"Language:\", response.userContext?.get(\"language\"));\n\n```\n\n## Hooks Access userContext [â€‹](https://voltagent.dev/docs/agents/context/\\#hooks-access-usercontext \"Direct link to Hooks Access userContext\")\n\nHooks can read and write to `userContext`:\n\n```codeBlockLines_e6Vv\nimport { createHooks } from \"@voltagent/core\";\n\nconst agent = new Agent({\n  name: \"HookAgent\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  hooks: createHooks({\n    onStart: ({ context }) => {\n      // Read data that was passed in\n      const language = context.userContext.get(\"language\");\n      console.log(`Starting operation for language: ${language}`);\n\n      // Add new data\n      context.userContext.set(\"requestId\", `req-${Date.now()}`);\n      context.userContext.set(\"startTime\", new Date().toISOString());\n    },\n    onEnd: ({ context }) => {\n      // Read data from context\n      const requestId = context.userContext.get(\"requestId\");\n      const startTime = context.userContext.get(\"startTime\");\n      console.log(`Request ${requestId} completed (started at ${startTime})`);\n    },\n  }),\n  instructions: \"You are a helpful assistant.\",\n});\n\n// Usage\nconst context = new Map();\ncontext.set(\"language\", \"English\");\n\nawait agent.generateText(\"Hello!\", { userContext: context });\n\n```\n\n## Tools Access userContext [â€‹](https://voltagent.dev/docs/agents/context/\\#tools-access-usercontext \"Direct link to Tools Access userContext\")\n\nTools can read and write to `userContext` through their options:\n\n```codeBlockLines_e6Vv\nimport { createTool } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\nconst loggerTool = createTool({\n  name: \"log_message\",\n  description: \"Logs a message with user context\",\n  parameters: z.object({\n    message: z.string(),\n  }),\n  execute: async ({ message }, options) => {\n    // Read from userContext\n    const language = options?.operationContext?.userContext?.get(\"language\");\n    const requestId = options?.operationContext?.userContext?.get(\"requestId\");\n\n    console.log(`[${requestId}] Language ${language}: ${message}`);\n\n    // Write to userContext\n    const userContext = options?.operationContext?.userContext;\n    if (userContext) {\n      const logs = userContext.get(\"logs\") || [];\n      logs.push({ message, timestamp: new Date().toISOString() });\n      userContext.set(\"logs\", logs);\n    }\n\n    return `Message logged for language ${language}`;\n  },\n});\n\nconst agentWithTool = new Agent({\n  name: \"ToolAgent\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  tools: [loggerTool],\n  instructions: \"Use the log_message tool to log what the user says.\",\n});\n\n// Usage\nconst context = new Map();\ncontext.set(\"language\", \"English\");\ncontext.set(\"requestId\", \"req-456\");\n\nconst response = await agentWithTool.generateText(\"Log this: Hello world!\", {\n  userContext: context,\n});\n\n// Check what was logged\nconst logs = response.userContext?.get(\"logs\");\nconsole.log(\"All logs:\", logs);\n\n```\n\n## Retrievers Store References [â€‹](https://voltagent.dev/docs/agents/context/\\#retrievers-store-references \"Direct link to Retrievers Store References\")\n\nRetrievers can store source information in `userContext`:\n\n```codeBlockLines_e6Vv\nimport { BaseRetriever } from \"@voltagent/core\";\n\nclass SimpleRetriever extends BaseRetriever {\n  async retrieve(input, options) {\n    // Simulate finding documents\n    const foundDocs = [\\\n      { title: \"VoltAgent Guide\", url: \"https://docs.example.com\" },\\\n      { title: \"Agent Tutorial\", url: \"https://tutorial.example.com\" },\\\n    ];\n\n    // Store references in userContext\n    if (options?.userContext) {\n      options.userContext.set(\"references\", foundDocs);\n      options.userContext.set(\"searchQuery\", input);\n    }\n\n    // Return content for LLM\n    return foundDocs.map((doc) => `${doc.title}: Some helpful content...`).join(\"\\n\");\n  }\n}\n\nconst agentWithRetriever = new Agent({\n  name: \"RetrievalAgent\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  retriever: new SimpleRetriever(),\n  instructions: \"Answer using retrieved information.\",\n});\n\n// Usage\nconst response = await agentWithRetriever.generateText(\"How do I use VoltAgent?\");\n\nconsole.log(\"Answer:\", response.text);\nconsole.log(\"Search query:\", response.userContext?.get(\"searchQuery\"));\nconsole.log(\"References:\", response.userContext?.get(\"references\"));\n\n```\n\n## Sub-Agents Automatically Inherit Context [â€‹](https://voltagent.dev/docs/agents/context/\\#sub-agents-automatically-inherit-context \"Direct link to Sub-Agents Automatically Inherit Context\")\n\nWhen a supervisor delegates to sub-agents, the complete operation context is automatically passed, including `userContext` and conversation history:\n\n```codeBlockLines_e6Vv\n// Worker agent - automatically receives supervisor's context\nconst workerAgent = new Agent({\n  name: \"WorkerAgent\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  hooks: createHooks({\n    onStart: ({ context }) => {\n      // Automatically gets userContext from supervisor\n      const projectId = context.userContext.get(\"projectId\");\n      const language = context.userContext.get(\"language\");\n      console.log(`Worker starting for project ${projectId}, language ${language}`);\n\n      // Can add its own data too\n      context.userContext.set(\"workerStartTime\", new Date().toISOString());\n    },\n  }),\n  instructions: \"You are a worker that processes tasks.\",\n});\n\n// Supervisor agent\nconst supervisorAgent = new Agent({\n  name: \"SupervisorAgent\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  subAgents: [workerAgent],\n  hooks: createHooks({\n    onStart: ({ context }) => {\n      // Set up project context\n      context.userContext.set(\"projectId\", `project-${Date.now()}`);\n      context.userContext.set(\"supervisorId\", \"supervisor-001\");\n    },\n  }),\n  instructions: \"You supervise tasks. Delegate work to WorkerAgent when needed.\",\n});\n\n// Usage\nconst initialContext = new Map();\ninitialContext.set(\"language\", \"English\");\ninitialContext.set(\"priority\", \"high\");\n\nconst response = await supervisorAgent.generateText(\"Please delegate this task to the worker\", {\n  userContext: initialContext,\n});\n\n// Final context includes data from both supervisor and worker\nconsole.log(\"Project ID:\", response.userContext?.get(\"projectId\"));\nconsole.log(\"Worker start time:\", response.userContext?.get(\"workerStartTime\"));\n\n```\n\n### Key Benefits [â€‹](https://voltagent.dev/docs/agents/context/\\#key-benefits \"Direct link to Key Benefits\")\n\n- **Automatic Inheritance**: No manual context passing required\n- **Shared History**: All agents contribute to the same conversation steps\n- **Bidirectional Updates**: Changes made by sub-agents are visible to supervisor\n- **Unified Workflow**: The entire operation appears as one cohesive process\n\nFor more details on sub-agent architecture, see the [Sub-Agents guide](https://voltagent.dev/docs/agents/sub-agents/).\n\n## Complete Flow Example [â€‹](https://voltagent.dev/docs/agents/context/\\#complete-flow-example \"Direct link to Complete Flow Example\")\n\nHere's how all pieces work together:\n\n```codeBlockLines_e6Vv\nimport { Agent, createHooks, createTool, BaseRetriever } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\n// Simple retriever\nclass BasicRetriever extends BaseRetriever {\n  async retrieve(input, options) {\n    if (options.userContext) {\n      options.userContext.set(\"references\", [{ title: \"Document 1\", source: \"knowledge-base\" }]);\n    }\n    return \"Retrieved content about the topic\";\n  }\n}\n\n// Simple tool\nconst counterTool = createTool({\n  name: \"increment_counter\",\n  description: \"Increments a counter\",\n  parameters: z.object({}),\n  execute: async (_, options) => {\n    const userContext = options.operationContext?.userContext;\n    if (userContext) {\n      const count = (userContext.get(\"counter\") || 0) + 1;\n      userContext.set(\"counter\", count);\n      return `Counter is now: ${count}`;\n    }\n    return \"Counter incremented\";\n  },\n});\n\n// Agent with everything\nconst fullAgent = new Agent({\n  name: \"FullAgent\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  retriever: new BasicRetriever(),\n  tools: [counterTool],\n  hooks: createHooks({\n    onStart: ({ context }) => {\n      console.log(\"ðŸš€ Operation started\");\n      context.userContext.set(\"operationId\", `op-${Date.now()}`);\n    },\n    onEnd: ({ context }) => {\n      const opId = context.userContext.get(\"operationId\");\n      const counter = context.userContext.get(\"counter\");\n      const references = context.userContext.get(\"references\");\n\n      console.log(\"âœ… Operation completed\");\n      console.log(`Operation ID: ${opId}`);\n      console.log(`Counter final value: ${counter}`);\n      console.log(`References found: ${references?.length || 0}`);\n    },\n  }),\n  instructions: \"Use tools and retrieval to help users. Always increment the counter.\",\n});\n\n// Usage showing the complete flow\nasync function demonstrateFlow() {\n  const initialContext = new Map();\n  initialContext.set(\"language\", \"English\");\n\n  const response = await fullAgent.generateText(\n    \"Use the increment tool and search for information\",\n    { userContext: initialContext }\n  );\n\n  console.log(\"Text:\", response.text);\n  const finalContext = response.userContext;\n  for (const [key, value] of finalContext.entries()) {\n    console.log(`${String(key)}: ${JSON.stringify(value)}`);\n  }\n}\n\n```\n\n## Key Points [â€‹](https://voltagent.dev/docs/agents/context/\\#key-points \"Direct link to Key Points\")\n\n1. **Initialization**:\n\n   - Set default context in constructor: `new Agent({ userContext: defaultMap })`\n   - Override per call: `agent.generateText(\"...\", { userContext: callMap })`\n2. **Hooks**: Access via `context.userContext` in `onStart`/ `onEnd`\n3. **Tools**: Access via `options.operationContext.userContext` in `execute`\n4. **Retrievers**: Access via `options.userContext` in `retrieve`\n5. **Sub-Agents**: Automatically get a copy of supervisor's `userContext`\n6. **Response**: Access final state via `response.userContext`\n7. **Dynamic Values**: Constructor context is available in dynamic instructions, model, and tools functions\n\nEach component can read existing data and add new data. The `userContext` travels through the entire operation, making it easy to share state and track information across all parts of your agent system.\n\n### Context Priority [â€‹](https://voltagent.dev/docs/agents/context/\\#context-priority \"Direct link to Context Priority\")\n\nWhen both constructor and execution contexts are provided:\n\n- Execution context completely replaces constructor context (no automatic merging)\n- Constructor context serves as the default when no execution context is provided\n- Dynamic values (instructions, model, tools) receive whichever context is active\n\ntip\n\nTo extend rather than replace the default context, create a new Map from it:\n\n```codeBlockLines_e6Vv\nconst extendedContext = new Map(defaultContext);\nextendedContext.set(\"environment\", \"development\"); // Override specific values\n\n```\n\n### Table of Contents\n\n- [Basic Concept](https://voltagent.dev/docs/agents/context/#basic-concept)\n- [Initialize userContext](https://voltagent.dev/docs/agents/context/#initialize-usercontext)\n  - [Method 1: Set Default Context in Constructor](https://voltagent.dev/docs/agents/context/#method-1-set-default-context-in-constructor)\n  - [Method 2: Pass Context During Execution](https://voltagent.dev/docs/agents/context/#method-2-pass-context-during-execution)\n- [Hooks Access userContext](https://voltagent.dev/docs/agents/context/#hooks-access-usercontext)\n- [Tools Access userContext](https://voltagent.dev/docs/agents/context/#tools-access-usercontext)\n- [Retrievers Store References](https://voltagent.dev/docs/agents/context/#retrievers-store-references)\n- [Sub-Agents Automatically Inherit Context](https://voltagent.dev/docs/agents/context/#sub-agents-automatically-inherit-context)\n  - [Key Benefits](https://voltagent.dev/docs/agents/context/#key-benefits)\n- [Complete Flow Example](https://voltagent.dev/docs/agents/context/#complete-flow-example)\n- [Key Points](https://voltagent.dev/docs/agents/context/#key-points)\n  - [Context Priority](https://voltagent.dev/docs/agents/context/#context-priority)",
      "metadata": {
        "ogImage": "https://voltagent.dev/img/social3.png",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_version": "current",
        "og:description": "Pass custom data through agent operations using userContext.",
        "language": "en",
        "ogUrl": "https://voltagent.dev/docs/agents/context/",
        "og:url": "https://voltagent.dev/docs/agents/context/",
        "docusaurus_tag": "docs-default-current",
        "og:title": "Operation Context (userContext) | VoltAgent",
        "docsearch:language": "en",
        "title": "Operation Context (userContext) | VoltAgent",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "ogTitle": "Operation Context (userContext) | VoltAgent",
        "docsearch:docusaurus_tag": "docs-default-current",
        "twitter:card": "summary_large_image",
        "og:image": "https://voltagent.dev/img/social3.png",
        "og:locale": "en",
        "generator": "Docusaurus v3.1.1",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "docsearch:version": "current",
        "description": "Pass custom data through agent operations using userContext.",
        "ogDescription": "Pass custom data through agent operations using userContext.",
        "ogLocale": "en",
        "docusaurus_locale": "en",
        "scrapeId": "db85eba8-13e5-45f6-acbe-9828a2563af8",
        "sourceURL": "https://voltagent.dev/docs/agents/context/",
        "url": "https://voltagent.dev/docs/agents/context/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:30.569Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/agents/providers/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Using LLM Providers with Agents\n\nIn VoltAgent, **Providers** are the connection layer between your `Agent` and the underlying Large Language Model (LLM) or AI service. They implement the `LLMProvider` interface and handle the complexities of specific APIs, such as authentication, request formatting, and response parsing.\n\nThis abstraction allows you to build agents that are **model agnostic**. You can easily switch the underlying LLM (e.g., from OpenAI to Groq, or from a cloud service to a local model) often just by changing the provider configuration, without needing to modify your core agent logic.\n\n## Available Providers [â€‹](https://voltagent.dev/docs/agents/providers/\\#available-providers \"Direct link to Available Providers\")\n\nVoltAgent offers built-in providers for various popular services and SDKs. This allows you to connect your agents to different LLMs with minimal code changes.\n\n- **[Vercel AI Provider](https://voltagent.dev/docs/providers/vercel-ai/):** Integrates with the Vercel AI SDK, allowing you to use various models supported by Vercel.\n- **[Google AI Provider](https://voltagent.dev/docs/providers/google-ai/):** Connects to Google's AI models, including Gemini and Vertex AI, via their official SDK.\n- **[Groq AI Provider](https://voltagent.dev/docs/providers/groq-ai/):** Leverages the Groq API for extremely fast inference on supported models like Llama and Mixtral.\n- **[Anthropic AI Provider](https://voltagent.dev/docs/providers/anthropic-ai/):** Connects directly to Anthropic's AI models (Claude) using the official Anthropic AI SDK.\n- **[xsAI (OpenAI-Compatible) Provider](https://voltagent.dev/docs/providers/xsai/):** Provides compatibility with any OpenAI-compatible API endpoint, including self-hosted models or other third-party services.\n\nChoose the provider that best suits the LLM or service you want to use. Detailed configuration and usage instructions can be found on each provider's specific documentation page linked above.\n\nFor a general overview of all available providers, see the [Providers Overview](https://voltagent.dev/docs/providers/overview/).\n\n## Configuring an Agent with a Provider [â€‹](https://voltagent.dev/docs/agents/providers/\\#configuring-an-agent-with-a-provider \"Direct link to Configuring an Agent with a Provider\")\n\nWhen you create an `Agent` instance, you assign a configured provider instance to the `llm` property and specify the desired model identifier using the `model` property.\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\n\n// 1. Import your chosen provider\n// Example: using the VercelAIProvider\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\n// Import the model definition from the Vercel AI SDK\nimport { openai } from \"@ai-sdk/openai\";\n\n// 2. Instantiate and configure the provider\n// VercelAIProvider often requires no constructor arguments (relies on env vars)\nconst myProvider = new VercelAIProvider();\n\n// 3. Create the Agent, passing the provider and model ID\nconst agent = new Agent({\n  name: \"My Configured Agent\",\n  instructions: \"An agent ready to interact via the specified provider\",\n  llm: myProvider, // Assign the provider instance\n  model: openai(\"gpt-4o-mini\"), // Pass the model object from Vercel AI SDK\n});\n\n// 4. Now you can use the agent's methods (generateText, streamText, etc.)\nasync function run() {\n  const response = await agent.generateText(\"How does the provider architecture help?\");\n  console.log(response.text);\n}\n\nrun();\n\n```\n\n## The `model` Parameter [â€‹](https://voltagent.dev/docs/agents/providers/\\#the-model-parameter \"Direct link to the-model-parameter\")\n\nIt's important to understand that the value you provide for the `model` parameter is interpreted _by the specific `llm` provider_ you have configured for the agent.\n\n- Some providers (like `@voltagent/xsai`, `@voltagent/google-ai`, `@voltagent/groq-ai`, `@voltagent/anthropic-ai`) expect a **string** identifier (e.g., `'gpt-4o-mini'`, `'gemini-1.5-pro'`, `'llama3-70b-8192'`) that corresponds to a model available on the target API.\n- Other providers (like `@voltagent/vercel-ai`) expect a **model object** imported from their corresponding SDK (e.g., `openai('gpt-4o')`, `anthropic('claude-3-5-sonnet-20240620')`).\n\nAlways refer to the documentation for the specific provider you are using to know what format is expected for the `model` parameter.\n\n### Table of Contents\n\n- [Available Providers](https://voltagent.dev/docs/agents/providers/#available-providers)\n- [Configuring an Agent with a Provider](https://voltagent.dev/docs/agents/providers/#configuring-an-agent-with-a-provider)\n- [The `model` Parameter](https://voltagent.dev/docs/agents/providers/#the-model-parameter)",
      "metadata": {
        "docusaurus_locale": "en",
        "og:description": "In VoltAgent, Providers are the connection layer between your Agent and the underlying Large Language Model (LLM) or AI service. They implement the LLMProvider interface and handle the complexities of specific APIs, such as authentication, request formatting, and response parsing.",
        "ogUrl": "https://voltagent.dev/docs/agents/providers/",
        "generator": "Docusaurus v3.1.1",
        "twitter:card": "summary_large_image",
        "description": "In VoltAgent, Providers are the connection layer between your Agent and the underlying Large Language Model (LLM) or AI service. They implement the LLMProvider interface and handle the complexities of specific APIs, such as authentication, request formatting, and response parsing.",
        "og:url": "https://voltagent.dev/docs/agents/providers/",
        "og:title": "Using LLM Providers | VoltAgent",
        "ogLocale": "en",
        "ogDescription": "In VoltAgent, Providers are the connection layer between your Agent and the underlying Large Language Model (LLM) or AI service. They implement the LLMProvider interface and handle the complexities of specific APIs, such as authentication, request formatting, and response parsing.",
        "og:image": "https://voltagent.dev/img/social3.png",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "docsearch:version": "current",
        "docusaurus_version": "current",
        "language": "en",
        "ogTitle": "Using LLM Providers | VoltAgent",
        "og:locale": "en",
        "viewport": "width=device-width, initial-scale=1.0",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "docusaurus_tag": "docs-default-current",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "title": "Using LLM Providers | VoltAgent",
        "docsearch:language": "en",
        "docsearch:docusaurus_tag": "docs-default-current",
        "scrapeId": "40c9b434-3901-49cd-a111-587b471ef614",
        "sourceURL": "https://voltagent.dev/docs/agents/providers/",
        "url": "https://voltagent.dev/docs/agents/providers/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:54.595Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/workflows/schemas/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Schemas\n\n> Validate your data at every step. Catch errors early, not in production.\n\n## What are Schemas? [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#what-are-schemas \"Direct link to What are Schemas?\")\n\nA schema is a blueprint for your data. It defines what shape your data should have.\n\n```codeBlockLines_e6Vv\n// Without schema - anything goes\nconst data = { name: \"John\", age: \"twenty\" }; // Wrong type!\n\n// With schema - enforced structure\nconst schema = z.object({\n  name: z.string(),\n  age: z.number(),\n});\nconst data = schema.parse({ name: \"John\", age: 20 }); // Valid!\n\n```\n\n## Types of Workflow Schemas [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#types-of-workflow-schemas \"Direct link to Types of Workflow Schemas\")\n\n### 1\\. Input Schema [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#1-input-schema \"Direct link to 1. Input Schema\")\n\nValidates data when workflow starts.\n\n```codeBlockLines_e6Vv\nconst workflow = createWorkflowChain({\n  id: \"process-order\",\n  input: z.object({\n    orderId: z.string(),\n    amount: z.number().positive(),\n  }),\n  // ...\n});\n\n// This will work\nawait workflow.run({ orderId: \"123\", amount: 99.99 });\n\n// This will fail with clear error\nawait workflow.run({ orderId: 123, amount: -5 }); // Type error!\n\n```\n\n### 2\\. Result Schema [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#2-result-schema \"Direct link to 2. Result Schema\")\n\nValidates final workflow output.\n\n```codeBlockLines_e6Vv\nconst workflow = createWorkflowChain({\n  id: \"generate-report\",\n  input: z.object({ data: z.array(z.number()) }),\n  result: z.object({\n    average: z.number(),\n    summary: z.string(),\n  }),\n}).andThen({\n  id: \"calculate\",\n  execute: async ({ data }) => ({\n    average: data.reduce((a, b) => a + b, 0) / data.length,\n    summary: `Processed ${data.length} items`,\n  }),\n});\n\n```\n\n### 3\\. Suspend Schema [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#3-suspend-schema \"Direct link to 3. Suspend Schema\")\n\nValidates data saved when workflow pauses.\n\n```codeBlockLines_e6Vv\nconst workflow = createWorkflowChain({\n  id: \"approval-flow\",\n  suspendSchema: z.object({\n    requestId: z.string(),\n    amount: z.number(),\n    requestedBy: z.string(),\n  }),\n}).andThen({\n  id: \"check-approval\",\n  execute: async ({ data }, { suspend }) => {\n    if (data.amount > 1000) {\n      // Suspend with validated data\n      suspend({\n        requestId: data.id,\n        amount: data.amount,\n        requestedBy: data.user,\n      });\n    }\n    return data;\n  },\n});\n\n```\n\n### 4\\. Resume Schema [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#4-resume-schema \"Direct link to 4. Resume Schema\")\n\nValidates data when workflow continues after suspension.\n\n```codeBlockLines_e6Vv\nconst workflow = createWorkflowChain({\n  id: \"approval-flow\",\n  resumeSchema: z.object({\n    approved: z.boolean(),\n    approvedBy: z.string().email(),\n    comments: z.string().optional(),\n  }),\n}).andThen({\n  id: \"process-approval\",\n  execute: async ({ data, resumeData }) => {\n    // resumeData is typed and validated\n    if (resumeData?.approved) {\n      return { ...data, status: \"approved\", approver: resumeData.approvedBy };\n    }\n    return { ...data, status: \"rejected\" };\n  },\n});\n\n// Resume with validated data\nawait workflow.resume(executionId, {\n  approved: true,\n  approvedBy: \"manager@company.com\",\n  comments: \"Looks good\",\n});\n\n```\n\n## Step-Level Schemas [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#step-level-schemas \"Direct link to Step-Level Schemas\")\n\nSteps can define their own schemas that override workflow defaults:\n\n```codeBlockLines_e6Vv\nconst workflow = createWorkflowChain({\n  id: \"multi-step\",\n  input: z.object({ userId: z.string() }),\n  resumeSchema: z.object({ continue: z.boolean() }), // Default\n}).andThen({\n  id: \"step-with-custom-resume\",\n  resumeSchema: z.object({\n    verified: z.boolean(),\n    verificationCode: z.string(),\n  }), // This step needs different resume data\n  execute: async ({ data, resumeData }) => {\n    // Uses step's resumeSchema, not workflow's\n    if (resumeData?.verified) {\n      return { ...data, verified: true };\n    }\n    return data;\n  },\n});\n\n```\n\n## Why Use Schemas? [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#why-use-schemas \"Direct link to Why Use Schemas?\")\n\n### 1\\. Catch Errors Early [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#1-catch-errors-early \"Direct link to 1. Catch Errors Early\")\n\n```codeBlockLines_e6Vv\n// Without schema - error happens in production\n.andThen({\n  execute: async ({ data }) => {\n    // Crashes if data.email is undefined\n    return await sendEmail(data.email);\n  }\n})\n\n// With schema - error caught immediately\ninput: z.object({ email: z.string().email() })\n\n```\n\n### 2\\. Better Developer Experience [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#2-better-developer-experience \"Direct link to 2. Better Developer Experience\")\n\n```codeBlockLines_e6Vv\n// TypeScript knows exactly what data looks like\n.andThen({\n  execute: async ({ data }) => {\n    // Auto-complete works perfectly\n    data.email // TypeScript knows this exists\n    data.phone // TypeScript error: property doesn't exist\n  }\n})\n\n```\n\n### 3\\. Clear Documentation [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#3-clear-documentation \"Direct link to 3. Clear Documentation\")\n\nSchemas serve as documentation for your workflow:\n\n```codeBlockLines_e6Vv\n// Anyone can see what this workflow expects\nconst workflow = createWorkflowChain({\n  input: z.object({\n    customer: z.object({\n      id: z.string(),\n      email: z.string().email(),\n      tier: z.enum([\"free\", \"pro\", \"enterprise\"]),\n    }),\n    items: z.array(\n      z.object({\n        sku: z.string(),\n        quantity: z.number().int().positive(),\n      })\n    ),\n  }),\n});\n\n```\n\n## Schema Patterns [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#schema-patterns \"Direct link to Schema Patterns\")\n\n### Optional Fields [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#optional-fields \"Direct link to Optional Fields\")\n\n```codeBlockLines_e6Vv\nz.object({\n  required: z.string(),\n  optional: z.string().optional(),\n  withDefault: z.string().default(\"default value\"),\n});\n\n```\n\n### Union Types [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#union-types \"Direct link to Union Types\")\n\n```codeBlockLines_e6Vv\n// Accept multiple formats\nresumeSchema: z.union([\\\n  z.object({ approved: z.literal(true), approvedBy: z.string() }),\\\n  z.object({ approved: z.literal(false), reason: z.string() }),\\\n]);\n\n```\n\n### Nested Validation [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#nested-validation \"Direct link to Nested Validation\")\n\n```codeBlockLines_e6Vv\ninput: z.object({\n  user: z.object({\n    name: z.string().min(1),\n    age: z.number().int().min(18),\n  }),\n  preferences: z.record(z.string(), z.any()).optional(),\n});\n\n```\n\n## Common Mistakes [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#common-mistakes \"Direct link to Common Mistakes\")\n\n### 1\\. Forgetting Resume Schema [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#1-forgetting-resume-schema \"Direct link to 1. Forgetting Resume Schema\")\n\n```codeBlockLines_e6Vv\n// Bad - no validation on resume\n.andThen({\n  execute: async ({ resumeData }) => {\n    // resumeData could be anything!\n    return resumeData.approved; // Might crash\n  }\n})\n\n// Good - validated resume data\nresumeSchema: z.object({ approved: z.boolean() })\n\n```\n\n### 2\\. Too Strict Schemas [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#2-too-strict-schemas \"Direct link to 2. Too Strict Schemas\")\n\n```codeBlockLines_e6Vv\n// Bad - too restrictive\nresult: z.object({\n  data: z.string().length(100), // Must be exactly 100 chars\n});\n\n// Good - flexible but safe\nresult: z.object({\n  data: z.string().min(1).max(1000),\n});\n\n```\n\n## Next Steps [â€‹](https://voltagent.dev/docs/workflows/schemas/\\#next-steps \"Direct link to Next Steps\")\n\n- Learn about [Suspend & Resume](https://voltagent.dev/docs/workflows/suspend-resume/) patterns with schemas\n- See schemas in action with [Step Types](https://voltagent.dev/docs/workflows/steps/and-then/)\n- Explore [Workflow Hooks](https://voltagent.dev/docs/workflows/hooks/) for schema validation events\n- Execute workflows via [REST API](https://voltagent.dev/docs/api/overview/#workflow-endpoints) with type-safe schemas\n\n### Table of Contents\n\n- [What are Schemas?](https://voltagent.dev/docs/workflows/schemas/#what-are-schemas)\n- [Types of Workflow Schemas](https://voltagent.dev/docs/workflows/schemas/#types-of-workflow-schemas)\n  - [1\\. Input Schema](https://voltagent.dev/docs/workflows/schemas/#1-input-schema)\n  - [2\\. Result Schema](https://voltagent.dev/docs/workflows/schemas/#2-result-schema)\n  - [3\\. Suspend Schema](https://voltagent.dev/docs/workflows/schemas/#3-suspend-schema)\n  - [4\\. Resume Schema](https://voltagent.dev/docs/workflows/schemas/#4-resume-schema)\n- [Step-Level Schemas](https://voltagent.dev/docs/workflows/schemas/#step-level-schemas)\n- [Why Use Schemas?](https://voltagent.dev/docs/workflows/schemas/#why-use-schemas)\n  - [1\\. Catch Errors Early](https://voltagent.dev/docs/workflows/schemas/#1-catch-errors-early)\n  - [2\\. Better Developer Experience](https://voltagent.dev/docs/workflows/schemas/#2-better-developer-experience)\n  - [3\\. Clear Documentation](https://voltagent.dev/docs/workflows/schemas/#3-clear-documentation)\n- [Schema Patterns](https://voltagent.dev/docs/workflows/schemas/#schema-patterns)\n  - [Optional Fields](https://voltagent.dev/docs/workflows/schemas/#optional-fields)\n  - [Union Types](https://voltagent.dev/docs/workflows/schemas/#union-types)\n  - [Nested Validation](https://voltagent.dev/docs/workflows/schemas/#nested-validation)\n- [Common Mistakes](https://voltagent.dev/docs/workflows/schemas/#common-mistakes)\n  - [1\\. Forgetting Resume Schema](https://voltagent.dev/docs/workflows/schemas/#1-forgetting-resume-schema)\n  - [2\\. Too Strict Schemas](https://voltagent.dev/docs/workflows/schemas/#2-too-strict-schemas)\n- [Next Steps](https://voltagent.dev/docs/workflows/schemas/#next-steps)",
      "metadata": {
        "twitter:card": "summary_large_image",
        "docsearch:language": "en",
        "ogDescription": "Validate your data at every step. Catch errors early, not in production.",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "generator": "Docusaurus v3.1.1",
        "ogUrl": "https://voltagent.dev/docs/workflows/schemas/",
        "docsearch:docusaurus_tag": "docs-default-current",
        "description": "Validate your data at every step. Catch errors early, not in production.",
        "og:url": "https://voltagent.dev/docs/workflows/schemas/",
        "docusaurus_locale": "en",
        "og:description": "Validate your data at every step. Catch errors early, not in production.",
        "og:image": "https://voltagent.dev/img/social3.png",
        "docusaurus_tag": "docs-default-current",
        "ogLocale": "en",
        "title": "Schemas | VoltAgent",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "og:locale": "en",
        "docsearch:version": "current",
        "ogTitle": "Schemas | VoltAgent",
        "og:title": "Schemas | VoltAgent",
        "language": "en",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_version": "current",
        "scrapeId": "45f4197b-0008-44db-8126-d7f5eadfe23c",
        "sourceURL": "https://voltagent.dev/docs/workflows/schemas/",
        "url": "https://voltagent.dev/docs/workflows/schemas/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:09.317Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/workflows/steps/and-tap/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# andTap\n\n> Look at your data without touching it. Perfect for logging, debugging, and analytics.\n\n## Quick Start [â€‹](https://voltagent.dev/docs/workflows/steps/and-tap/\\#quick-start \"Direct link to Quick Start\")\n\n```codeBlockLines_e6Vv\nimport { createWorkflowChain } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\nconst workflow = createWorkflowChain({\n  id: \"process-order\",\n  input: z.object({ orderId: z.string() }),\n})\n  .andThen({\n    id: \"calculate-total\",\n    execute: async ({ data }) => ({\n      ...data,\n      total: 100,\n    }),\n  })\n  .andTap({\n    id: \"log-total\",\n    execute: ({ data }) => {\n      console.log(`Order ${data.orderId} total: $${data.total}`);\n    },\n  })\n  .andThen({\n    id: \"charge-customer\",\n    execute: async ({ data }) => ({\n      ...data,\n      charged: true,\n    }),\n  });\n\n// Console: \"Order 123 total: $100\"\n// Result: { orderId: \"123\", total: 100, charged: true }\n\n```\n\n## How It Works [â€‹](https://voltagent.dev/docs/workflows/steps/and-tap/\\#how-it-works \"Direct link to How It Works\")\n\n`andTap` = See but don't touch:\n\n```codeBlockLines_e6Vv\n.andTap({\n  execute: ({ data }) => {\n    // Look at data\n    console.log(data);\n    // Return value is ignored\n    return \"this is ignored\";\n  }\n})\n// Next step gets original data unchanged\n\n```\n\nKey points:\n\n- **Never changes data** \\- Original data passes through untouched\n- **Can't break your workflow** \\- Errors are caught and logged\n- **Return value ignored** \\- Whatever you return doesn't matter\n\n## Common Patterns [â€‹](https://voltagent.dev/docs/workflows/steps/and-tap/\\#common-patterns \"Direct link to Common Patterns\")\n\n### Debug Your Workflow [â€‹](https://voltagent.dev/docs/workflows/steps/and-tap/\\#debug-your-workflow \"Direct link to Debug Your Workflow\")\n\n```codeBlockLines_e6Vv\n.andThen({ id: \"step1\", execute: async () => ({ value: 42 }) })\n.andTap({\n  id: \"debug\",\n  execute: ({ data }) => console.log(\"Current data:\", data)\n})\n.andThen({ id: \"step2\", execute: async ({ data }) => data })\n\n```\n\n### Send Analytics [â€‹](https://voltagent.dev/docs/workflows/steps/and-tap/\\#send-analytics \"Direct link to Send Analytics\")\n\n```codeBlockLines_e6Vv\n.andTap({\n  id: \"track-event\",\n  execute: async ({ data }) => {\n    await analytics.track(\"OrderProcessed\", {\n      orderId: data.orderId,\n      amount: data.total\n    });\n  }\n})\n\n```\n\n### Log to External Services [â€‹](https://voltagent.dev/docs/workflows/steps/and-tap/\\#log-to-external-services \"Direct link to Log to External Services\")\n\n```codeBlockLines_e6Vv\n.andTap({\n  id: \"log-to-datadog\",\n  execute: async ({ data, state }) => {\n    await logger.info(\"Workflow progress\", {\n      workflowId: state.workflowId,\n      step: \"payment\",\n      data\n    });\n  }\n})\n\n```\n\n## andTap vs andThen [â€‹](https://voltagent.dev/docs/workflows/steps/and-tap/\\#andtap-vs-andthen \"Direct link to andTap vs andThen\")\n\n| What | andTap | andThen |\n| --- | --- | --- |\n| Purpose | Look at data | Change data |\n| Returns | Ignored | Merged into data |\n| Errors | Caught (workflow continues) | Thrown (workflow stops) |\n| Use for | Logging, analytics | Business logic |\n\n## Error Handling [â€‹](https://voltagent.dev/docs/workflows/steps/and-tap/\\#error-handling \"Direct link to Error Handling\")\n\nErrors in `andTap` don't stop your workflow:\n\n```codeBlockLines_e6Vv\n.andTap({\n  id: \"might-fail\",\n  execute: async ({ data }) => {\n    throw new Error(\"This error is caught!\");\n  }\n})\n.andThen({\n  id: \"still-runs\",\n  execute: async ({ data }) => {\n    // This runs even though andTap threw an error\n    return { ...data, success: true };\n  }\n})\n\n```\n\n## Best Practices [â€‹](https://voltagent.dev/docs/workflows/steps/and-tap/\\#best-practices \"Direct link to Best Practices\")\n\n1. **Use for side effects only** \\- Don't try to modify data\n2. **Keep it simple** \\- Complex logic belongs in `andThen`\n3. **Don't depend on execution** \\- Workflow should work even if tap fails\n4. **Perfect for debugging** \\- Add/remove without affecting logic\n\n## Schema Support [â€‹](https://voltagent.dev/docs/workflows/steps/and-tap/\\#schema-support \"Direct link to Schema Support\")\n\n```codeBlockLines_e6Vv\n.andTap({\n  id: \"validate-logging\",\n  inputSchema: z.object({\n    orderId: z.string(),\n    total: z.number()\n  }),\n  execute: ({ data }) => {\n    // TypeScript knows data shape\n    console.log(`Order ${data.orderId}: $${data.total}`);\n  }\n})\n\n```\n\n## Next Steps [â€‹](https://voltagent.dev/docs/workflows/steps/and-tap/\\#next-steps \"Direct link to Next Steps\")\n\n- Learn about [andThen](https://voltagent.dev/docs/workflows/steps/and-then/) for data transformation\n- Explore [andWhen](https://voltagent.dev/docs/workflows/steps/and-when/) for conditional logic\n- See [andAgent](https://voltagent.dev/docs/workflows/steps/and-agent/) for AI integration\n- Execute workflows via [REST API](https://voltagent.dev/docs/api/overview/#workflow-endpoints)\n\n> **Remember**: `andTap` is read-only. Use it to observe, not to change.\n\n### Table of Contents\n\n- [Quick Start](https://voltagent.dev/docs/workflows/steps/and-tap/#quick-start)\n- [How It Works](https://voltagent.dev/docs/workflows/steps/and-tap/#how-it-works)\n- [Common Patterns](https://voltagent.dev/docs/workflows/steps/and-tap/#common-patterns)\n  - [Debug Your Workflow](https://voltagent.dev/docs/workflows/steps/and-tap/#debug-your-workflow)\n  - [Send Analytics](https://voltagent.dev/docs/workflows/steps/and-tap/#send-analytics)\n  - [Log to External Services](https://voltagent.dev/docs/workflows/steps/and-tap/#log-to-external-services)\n- [andTap vs andThen](https://voltagent.dev/docs/workflows/steps/and-tap/#andtap-vs-andthen)\n- [Error Handling](https://voltagent.dev/docs/workflows/steps/and-tap/#error-handling)\n- [Best Practices](https://voltagent.dev/docs/workflows/steps/and-tap/#best-practices)\n- [Schema Support](https://voltagent.dev/docs/workflows/steps/and-tap/#schema-support)\n- [Next Steps](https://voltagent.dev/docs/workflows/steps/and-tap/#next-steps)",
      "metadata": {
        "docsearch:docusaurus_tag": "docs-default-current",
        "docsearch:version": "current",
        "og:image": "https://voltagent.dev/img/social3.png",
        "og:locale": "en",
        "twitter:card": "summary_large_image",
        "ogLocale": "en",
        "docusaurus_locale": "en",
        "docusaurus_version": "current",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "viewport": "width=device-width, initial-scale=1.0",
        "og:title": "andTap | VoltAgent",
        "title": "andTap | VoltAgent",
        "docusaurus_tag": "docs-default-current",
        "og:description": "Look at your data without touching it. Perfect for logging, debugging, and analytics.",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "ogDescription": "Look at your data without touching it. Perfect for logging, debugging, and analytics.",
        "generator": "Docusaurus v3.1.1",
        "og:url": "https://voltagent.dev/docs/workflows/steps/and-tap/",
        "docsearch:language": "en",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "ogUrl": "https://voltagent.dev/docs/workflows/steps/and-tap/",
        "language": "en",
        "description": "Look at your data without touching it. Perfect for logging, debugging, and analytics.",
        "ogTitle": "andTap | VoltAgent",
        "scrapeId": "545ad7b0-4605-4be2-831a-45e99e0558e6",
        "sourceURL": "https://voltagent.dev/docs/workflows/steps/and-tap/",
        "url": "https://voltagent.dev/docs/workflows/steps/and-tap/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:54.133Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/agents/dynamic-agents/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Dynamic Agents\n\nDynamic Agents allow you to create adaptive AI agents that change their behavior, capabilities, and configuration based on runtime context. Instead of having fixed instructions, models, or tools, you can define functions that dynamically determine these properties based on user context, request parameters, or any other runtime information.\n\n## Why Use Dynamic Agents? [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#why-use-dynamic-agents \"Direct link to Why Use Dynamic Agents?\")\n\n**Why?** To create personalized, context-aware AI experiences that adapt to different users, roles, subscription tiers, languages, or any other runtime conditions without creating separate agent instances.\n\nDynamic agents are perfect for:\n\n- **Multi-tenant applications** where different users need different capabilities\n- **Role-based access control** where admins get different tools than regular users\n- **Subscription tiers** where premium users get access to better models\n- **Internationalization** where responses adapt to user's language\n- **A/B testing** where different users get different model configurations\n\n## Basic Dynamic Agent [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#basic-dynamic-agent \"Direct link to Basic Dynamic Agent\")\n\nHere's a simple example of a dynamic agent that changes its behavior based on user role:\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst dynamicAgent = new Agent({\n  name: \"Adaptive Assistant\",\n\n  // Dynamic instructions based on user context\n  instructions: ({ userContext }) => {\n    const role = (userContext.get(\"role\") as string) || \"user\";\n    const language = (userContext.get(\"language\") as string) || \"English\";\n\n    if (role === \"admin\") {\n      return `You are an admin assistant with special privileges. Respond in ${language}.`;\n    } else {\n      return `You are a helpful assistant. Respond in ${language}.`;\n    }\n  },\n\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n});\n\n```\n\n## Dynamic Properties [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#dynamic-properties \"Direct link to Dynamic Properties\")\n\nDynamic agents support three main dynamic properties:\n\n### Dynamic Instructions [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#dynamic-instructions \"Direct link to Dynamic Instructions\")\n\n**Why?** To personalize the agent's personality, capabilities, and behavior based on user context.\n\n```codeBlockLines_e6Vv\nconst agent = new Agent({\n  name: \"Multilingual Support Agent\",\n\n  instructions: ({ userContext }) => {\n    const language = (userContext.get(\"language\") as string) || \"English\";\n    const supportTier = (userContext.get(\"supportTier\") as string) || \"basic\";\n\n    let baseInstructions = `You are a customer support agent. Respond in ${language}.`;\n\n    if (supportTier === \"premium\") {\n      baseInstructions += \" You can offer advanced troubleshooting and priority support.\";\n    } else {\n      baseInstructions += \" Provide standard support within basic guidelines.\";\n    }\n\n    return baseInstructions;\n  },\n\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n});\n\n```\n\n### Dynamic Models [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#dynamic-models \"Direct link to Dynamic Models\")\n\n**Why?** To allocate different AI models based on user subscription, request complexity, or cost considerations.\n\n```codeBlockLines_e6Vv\nconst agent = new Agent({\n  name: \"Tier-Based Assistant\",\n  instructions: \"You are a helpful assistant.\",\n\n  // Different models for different subscription tiers\n  model: ({ userContext }) => {\n    const tier = (userContext.get(\"tier\") as string) || \"free\";\n\n    switch (tier) {\n      case \"premium\":\n        return openai(\"gpt-4o\");\n      case \"pro\":\n        return openai(\"gpt-4o-mini\");\n      default:\n        return openai(\"gpt-3.5-turbo\");\n    }\n  },\n\n  llm: new VercelAIProvider(),\n});\n\n```\n\n### Dynamic Tools [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#dynamic-tools \"Direct link to Dynamic Tools\")\n\n**Why?** To provide different capabilities based on user permissions, roles, or subscription levels.\n\n```codeBlockLines_e6Vv\nimport { createTool } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\n// Regular user tool\nconst basicTool = createTool({\n  name: \"get_help\",\n  description: \"Get basic help information\",\n  parameters: z.object({\n    topic: z.string().describe(\"Help topic\"),\n  }),\n  execute: async ({ topic }) => {\n    return `Here's basic help about ${topic}`;\n  },\n});\n\n// Admin-only tool\nconst adminTool = createTool({\n  name: \"admin_action\",\n  description: \"Perform administrative actions\",\n  parameters: z.object({\n    action: z.string().describe(\"Admin action to perform\"),\n  }),\n  execute: async ({ action }) => {\n    return `Admin action performed: ${action}`;\n  },\n});\n\nconst agent = new Agent({\n  name: \"Role-Based Agent\",\n  instructions: \"You are an assistant with role-based capabilities.\",\n\n  // Different tools based on user role\n  tools: ({ userContext }) => {\n    const role = (userContext.get(\"role\") as string) || \"user\";\n\n    if (role === \"admin\") {\n      return [basicTool, adminTool]; // Admins get both tools\n    } else {\n      return [basicTool]; // Regular users get basic tools only\n    }\n  },\n\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n});\n\n```\n\n## Using Dynamic Agents [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#using-dynamic-agents \"Direct link to Using Dynamic Agents\")\n\nTo use a dynamic agent, pass the `userContext` when calling generation methods:\n\n```codeBlockLines_e6Vv\n// Create user context with relevant information\nconst userContext = new Map<string, unknown>();\nuserContext.set(\"role\", \"admin\");\nuserContext.set(\"language\", \"Spanish\");\nuserContext.set(\"tier\", \"premium\");\nuserContext.set(\"company\", \"TechCorp\");\n\n// Generate response with context\nconst response = await dynamicAgent.generateText(\"Help me manage the system settings\", {\n  userContext: userContext,\n});\n\nconsole.log(response.text);\n// The agent will respond in Spanish, with admin capabilities,\n// using the premium model, and have access to admin tools\n\n```\n\nYou can also use it with streaming:\n\n```codeBlockLines_e6Vv\nconst streamResponse = await dynamicAgent.streamText(\"What products are available?\", {\n  userContext: new Map([\\\n    [\"role\", \"customer\"],\\\n    [\"language\", \"French\"],\\\n    [\"tier\", \"basic\"],\\\n  ]),\n});\n\nfor await (const chunk of streamResponse.textStream) {\n  process.stdout.write(chunk);\n}\n\n```\n\n## REST API Usage [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#rest-api-usage \"Direct link to REST API Usage\")\n\nDynamic agents can also be used via the VoltAgent REST API by passing `userContext` in the request options. This is perfect for web frontends, mobile apps, or any system that needs to interact with dynamic agents over HTTP.\n\n### API Request Format [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#api-request-format \"Direct link to API Request Format\")\n\nPass the `userContext` object within the `options` field of your API request:\n\n```codeBlockLines_e6Vv\n{\n  \"input\": \"Your message to the agent\",\n  \"options\": {\n    \"userContext\": {\n      \"role\": \"admin\",\n      \"language\": \"Spanish\",\n      \"tier\": \"premium\"\n    },\n    \"temperature\": 0.7,\n    \"maxTokens\": 500\n  }\n}\n\n```\n\n### REST API Examples [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#rest-api-examples \"Direct link to REST API Examples\")\n\n**Basic Text Generation:**\n\n```codeBlockLines_e6Vv\n# Admin user requesting help in Spanish\ncurl -X POST http://localhost:3141/agents/YOUR_AGENT_NAME/text \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"input\": \"I need to update system settings\",\n       \"options\": {\n         \"userContext\": {\n           \"role\": \"admin\",\n           \"language\": \"Spanish\",\n           \"tier\": \"enterprise\"\n         }\n       }\n     }'\n\n```\n\n**Streaming with Real-time Context:**\n\n```codeBlockLines_e6Vv\n# Stream response for different user roles\ncurl -N -X POST http://localhost:3141/agents/YOUR_AGENT_NAME/stream \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"input\": \"Write a summary of our quarterly results\",\n       \"options\": {\n         \"userContext\": {\n           \"role\": \"manager\",\n           \"department\": \"finance\",\n           \"accessLevel\": \"confidential\",\n           \"language\": \"English\"\n         }\n       }\n     }'\n\n```\n\n## VoltOps Integration [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#voltops-integration \"Direct link to VoltOps Integration\")\n\n**Using Dynamic Agents with VoltOps Dashboard**\n\nVoltOps provides a user-friendly interface for testing and monitoring dynamic agents. You can easily pass different userContext values and see how your agent adapts in real-time.\n\n![VoltOps Dynamic Agents Demo](https://cdn.voltagent.dev/docs/user-context-demo.gif)\n\nThe VoltOps interface allows you to:\n\n- Set userContext values through a visual form\n- Test different user roles and configurations\n- Monitor how dynamic properties change based on context\n- Debug and optimize your dynamic agent logic\n\n## Best Practices [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#best-practices \"Direct link to Best Practices\")\n\n### Context Validation [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#context-validation \"Direct link to Context Validation\")\n\nAlways validate and provide defaults for userContext values:\n\n```codeBlockLines_e6Vv\ninstructions: ({ userContext }) => {\n  // Always provide defaults and validate types\n  const role = (userContext.get(\"role\") as string) || \"user\";\n  const language = (userContext.get(\"language\") as string) || \"English\";\n\n  // Validate known values\n  const validRoles = [\"admin\", \"support\", \"customer\"];\n  const actualRole = validRoles.includes(role) ? role : \"customer\";\n\n  return `You are a ${actualRole} assistant. Respond in ${language}.`;\n};\n\n```\n\n### Performance Considerations [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#performance-considerations \"Direct link to Performance Considerations\")\n\nDynamic functions are called for every request, so keep them lightweight:\n\n```codeBlockLines_e6Vv\n// âœ… Good - Simple and fast\nmodel: ({ userContext }) => {\n  const tier = userContext.get('tier') as string;\n  return tier === 'premium' ? openai('gpt-4o') : openai('gpt-3.5-turbo');\n},\n\n// âŒ Avoid - Heavy computation in dynamic functions\nmodel: async ({ userContext }) => {\n  // Don't make API calls or heavy computations here\n  const userProfile = await fetchUserFromDatabase(userContext.get('userId'));\n  return determineModelFromProfile(userProfile); // This will slow down every request\n}\n\n```\n\n### Security [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#security \"Direct link to Security\")\n\nBe careful with user-provided context values:\n\n```codeBlockLines_e6Vv\ninstructions: ({ userContext }) => {\n  const role = userContext.get(\"role\") as string;\n\n  // âœ… Use allowlists for security-sensitive operations\n  const allowedRoles = [\"admin\", \"support\", \"customer\"];\n  const safeRole = allowedRoles.includes(role) ? role : \"customer\";\n\n  return `You are a ${safeRole} assistant.`;\n};\n\n```\n\n### Context Structure [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#context-structure \"Direct link to Context Structure\")\n\nUse consistent context key naming across your application:\n\n```codeBlockLines_e6Vv\n// âœ… Consistent naming convention\nconst createUserContext = (user: User) => {\n  const context = new Map<string, unknown>();\n  context.set(\"user.id\", user.id);\n  context.set(\"user.role\", user.role);\n  context.set(\"user.tier\", user.subscriptionTier);\n  context.set(\"user.language\", user.preferredLanguage);\n  context.set(\"request.timestamp\", Date.now());\n  return context;\n};\n\n```\n\n## Advanced Patterns [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#advanced-patterns \"Direct link to Advanced Patterns\")\n\n### Conditional Dynamic Properties [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#conditional-dynamic-properties \"Direct link to Conditional Dynamic Properties\")\n\nYou can make properties dynamic only when needed:\n\n```codeBlockLines_e6Vv\nconst agent = new Agent({\n  name: \"Conditionally Dynamic Agent\",\n\n  // Static instructions most of the time\n  instructions: \"You are a helpful assistant.\",\n\n  // But dynamic model when user context is provided\n  model: ({ userContext }) => {\n    // If no tier specified, use default static model\n    if (!userContext.has(\"tier\")) {\n      return openai(\"gpt-4o-mini\"); // Default model\n    }\n\n    // Otherwise, choose based on tier\n    const tier = userContext.get(\"tier\") as string;\n    return tier === \"premium\" ? openai(\"gpt-4o\") : openai(\"gpt-3.5-turbo\");\n  },\n\n  llm: new VercelAIProvider(),\n});\n\n```\n\n### Context Inheritance [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#context-inheritance \"Direct link to Context Inheritance\")\n\nPass context between related operations:\n\n```codeBlockLines_e6Vv\n// Main agent with context\nconst parentResponse = await dynamicAgent.generateText(\"Create a summary\", {\n  userContext: myContext,\n});\n\n// Sub-agent inherits the same context\nconst detailResponse = await detailAgent.generateText(\n  \"Provide more details\",\n  { userContext: myContext } // Same context for consistency\n);\n\n```\n\n## Error Handling [â€‹](https://voltagent.dev/docs/agents/dynamic-agents/\\#error-handling \"Direct link to Error Handling\")\n\nHandle errors gracefully in dynamic functions:\n\n```codeBlockLines_e6Vv\nmodel: ({ userContext }) => {\n  try {\n    const tier = userContext.get(\"tier\") as string;\n\n    if (tier === \"premium\") {\n      return openai(\"gpt-4o\");\n    }\n    return openai(\"gpt-3.5-turbo\");\n  } catch (error) {\n    console.warn(\"Error in dynamic model selection:\", error);\n    // Fallback to safe default\n    return openai(\"gpt-3.5-turbo\");\n  }\n};\n\n```\n\n### Table of Contents\n\n- [Why Use Dynamic Agents?](https://voltagent.dev/docs/agents/dynamic-agents/#why-use-dynamic-agents)\n- [Basic Dynamic Agent](https://voltagent.dev/docs/agents/dynamic-agents/#basic-dynamic-agent)\n- [Dynamic Properties](https://voltagent.dev/docs/agents/dynamic-agents/#dynamic-properties)\n  - [Dynamic Instructions](https://voltagent.dev/docs/agents/dynamic-agents/#dynamic-instructions)\n  - [Dynamic Models](https://voltagent.dev/docs/agents/dynamic-agents/#dynamic-models)\n  - [Dynamic Tools](https://voltagent.dev/docs/agents/dynamic-agents/#dynamic-tools)\n- [Using Dynamic Agents](https://voltagent.dev/docs/agents/dynamic-agents/#using-dynamic-agents)\n- [REST API Usage](https://voltagent.dev/docs/agents/dynamic-agents/#rest-api-usage)\n  - [API Request Format](https://voltagent.dev/docs/agents/dynamic-agents/#api-request-format)\n  - [REST API Examples](https://voltagent.dev/docs/agents/dynamic-agents/#rest-api-examples)\n- [VoltOps Integration](https://voltagent.dev/docs/agents/dynamic-agents/#voltops-integration)\n- [Best Practices](https://voltagent.dev/docs/agents/dynamic-agents/#best-practices)\n  - [Context Validation](https://voltagent.dev/docs/agents/dynamic-agents/#context-validation)\n  - [Performance Considerations](https://voltagent.dev/docs/agents/dynamic-agents/#performance-considerations)\n  - [Security](https://voltagent.dev/docs/agents/dynamic-agents/#security)\n  - [Context Structure](https://voltagent.dev/docs/agents/dynamic-agents/#context-structure)\n- [Advanced Patterns](https://voltagent.dev/docs/agents/dynamic-agents/#advanced-patterns)\n  - [Conditional Dynamic Properties](https://voltagent.dev/docs/agents/dynamic-agents/#conditional-dynamic-properties)\n  - [Context Inheritance](https://voltagent.dev/docs/agents/dynamic-agents/#context-inheritance)\n- [Error Handling](https://voltagent.dev/docs/agents/dynamic-agents/#error-handling)",
      "metadata": {
        "ogLocale": "en",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "og:title": "Dynamic Agents | VoltAgent",
        "language": "en",
        "og:description": "Dynamic Agents allow you to create adaptive AI agents that change their behavior, capabilities, and configuration based on runtime context. Instead of having fixed instructions, models, or tools, you can define functions that dynamically determine these properties based on user context, request parameters, or any other runtime information.",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "docsearch:language": "en",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_version": "current",
        "generator": "Docusaurus v3.1.1",
        "og:locale": "en",
        "twitter:card": "summary_large_image",
        "og:url": "https://voltagent.dev/docs/agents/dynamic-agents/",
        "og:image": "https://voltagent.dev/img/social3.png",
        "docusaurus_locale": "en",
        "docusaurus_tag": "docs-default-current",
        "docsearch:version": "current",
        "docsearch:docusaurus_tag": "docs-default-current",
        "ogTitle": "Dynamic Agents | VoltAgent",
        "ogDescription": "Dynamic Agents allow you to create adaptive AI agents that change their behavior, capabilities, and configuration based on runtime context. Instead of having fixed instructions, models, or tools, you can define functions that dynamically determine these properties based on user context, request parameters, or any other runtime information.",
        "title": "Dynamic Agents | VoltAgent",
        "description": "Dynamic Agents allow you to create adaptive AI agents that change their behavior, capabilities, and configuration based on runtime context. Instead of having fixed instructions, models, or tools, you can define functions that dynamically determine these properties based on user context, request parameters, or any other runtime information.",
        "ogUrl": "https://voltagent.dev/docs/agents/dynamic-agents/",
        "scrapeId": "bdb48885-9179-467f-b46e-d0b0788b434a",
        "sourceURL": "https://voltagent.dev/docs/agents/dynamic-agents/",
        "url": "https://voltagent.dev/docs/agents/dynamic-agents/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:26.067Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/rag/custom-retrievers/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Build Your Own Retriever\n\nWant to connect your AI agent to your own database, API, or files? Here's how to build a custom retriever in 5 minutes.\n\n## The Pattern (Copy & Paste) [â€‹](https://voltagent.dev/docs/rag/custom-retrievers/\\#the-pattern-copy--paste \"Direct link to The Pattern (Copy & Paste)\")\n\nEvery retriever follows the same simple pattern:\n\n```codeBlockLines_e6Vv\nimport { BaseRetriever } from \"@voltagent/core\";\n\nclass MyRetriever extends BaseRetriever {\n  async retrieve(input, options) {\n    // 1. Get the user's question\n    const question = typeof input === \"string\" ? input : input[input.length - 1].content;\n\n    // 2. Search your data source\n    const results = await this.searchMyData(question);\n\n    // 3. Return formatted results\n    return results.join(\"\\n\\n\");\n  }\n\n  async searchMyData(query) {\n    // Replace this with your actual search logic\n    return [\"Sample result 1\", \"Sample result 2\"];\n  }\n}\n\n```\n\n## Real Examples [â€‹](https://voltagent.dev/docs/rag/custom-retrievers/\\#real-examples \"Direct link to Real Examples\")\n\n### Search Local Files [â€‹](https://voltagent.dev/docs/rag/custom-retrievers/\\#search-local-files \"Direct link to Search Local Files\")\n\n```codeBlockLines_e6Vv\nimport { BaseRetriever } from \"@voltagent/core\";\nimport fs from \"fs\";\nimport path from \"path\";\n\nclass FileRetriever extends BaseRetriever {\n  constructor(docsPath = \"./docs\") {\n    super({\n      toolName: \"search_files\",\n      toolDescription: \"Search through local documentation files\",\n    });\n    this.docsPath = docsPath;\n  }\n\n  async retrieve(input, options) {\n    const query = typeof input === \"string\" ? input : input[input.length - 1].content;\n\n    // Read all .md files\n    const files = fs.readdirSync(this.docsPath).filter((file) => file.endsWith(\".md\"));\n\n    const results = [];\n    for (const file of files) {\n      const content = fs.readFileSync(path.join(this.docsPath, file), \"utf8\");\n      if (content.toLowerCase().includes(query.toLowerCase())) {\n        results.push(`File: ${file}\\n${content.slice(0, 500)}...`);\n      }\n    }\n\n    return results.length > 0 ? results.join(\"\\n\\n---\\n\\n\") : \"No relevant files found.\";\n  }\n}\n\n```\n\n### Search PostgreSQL Database [â€‹](https://voltagent.dev/docs/rag/custom-retrievers/\\#search-postgresql-database \"Direct link to Search PostgreSQL Database\")\n\n```codeBlockLines_e6Vv\nimport { BaseRetriever } from \"@voltagent/core\";\nimport { Pool } from \"pg\";\n\nclass PostgreSQLRetriever extends BaseRetriever {\n  constructor(connectionString) {\n    super({\n      toolName: \"search_database\",\n      toolDescription: \"Search the company knowledge database\",\n    });\n    this.pool = new Pool({ connectionString });\n  }\n\n  async retrieve(input, options) {\n    const query = typeof input === \"string\" ? input : input[input.length - 1].content;\n\n    // Search using PostgreSQL full-text search\n    const result = await this.pool.query(\n      `\n      SELECT title, content, ts_rank(search_vector, plainto_tsquery($1)) as rank\n      FROM documents\n      WHERE search_vector @@ plainto_tsquery($1)\n      ORDER BY rank DESC\n      LIMIT 5\n    `,\n      [query]\n    );\n\n    return result.rows.map((row) => `${row.title}: ${row.content}`).join(\"\\n\\n---\\n\\n\");\n  }\n}\n\n```\n\n### Call External API [â€‹](https://voltagent.dev/docs/rag/custom-retrievers/\\#call-external-api \"Direct link to Call External API\")\n\n```codeBlockLines_e6Vv\nimport { BaseRetriever } from \"@voltagent/core\";\n\nclass APIRetriever extends BaseRetriever {\n  constructor(apiKey) {\n    super({\n      toolName: \"search_api\",\n      toolDescription: \"Search external knowledge API\",\n    });\n    this.apiKey = apiKey;\n  }\n\n  async retrieve(input, options) {\n    const query = typeof input === \"string\" ? input : input[input.length - 1].content;\n\n    const response = await fetch(\"https://api.example.com/search\", {\n      method: \"POST\",\n      headers: {\n        Authorization: `Bearer ${this.apiKey}`,\n        \"Content-Type\": \"application/json\",\n      },\n      body: JSON.stringify({ query, limit: 5 }),\n    });\n\n    const data = await response.json();\n\n    return data.results.map((item) => `${item.title}: ${item.summary}`).join(\"\\n\\n---\\n\\n\");\n  }\n}\n\n```\n\n## Track Sources (Optional) [â€‹](https://voltagent.dev/docs/rag/custom-retrievers/\\#track-sources-optional \"Direct link to Track Sources (Optional)\")\n\nWant to show users where the information came from? Use `userContext` to track sources:\n\n```codeBlockLines_e6Vv\nclass SourceTrackingRetriever extends BaseRetriever {\n  async retrieve(input, options) {\n    const query = typeof input === \"string\" ? input : input[input.length - 1].content;\n\n    // Your search logic here\n    const results = await this.searchData(query);\n\n    // Save sources for later reference\n    if (options.userContext && results.length > 0) {\n      const sources = results.map((r) => ({\n        title: r.title,\n        url: r.url,\n        score: r.score,\n      }));\n\n      options.userContext.set(\"sources\", sources);\n    }\n\n    return results.map((r) => r.content).join(\"\\n\\n\");\n  }\n}\n\n// Use it\nconst response = await agent.generateText(\"How do I deploy?\");\nconsole.log(\"Answer:\", response.text);\n\n// Check what sources were used\nconst sources = response.userContext?.get(\"sources\");\nsources?.forEach((s) => console.log(`Source: ${s.title} (${s.url})`));\n\n```\n\n**Why track sources?**\n\n- Show users where info came from\n- Debug what the retriever found\n- Compliance and audit trails\n- Better user experience\n\n## How to Use Your Retriever [â€‹](https://voltagent.dev/docs/rag/custom-retrievers/\\#how-to-use-your-retriever \"Direct link to How to Use Your Retriever\")\n\nYou can use your retriever in two ways:\n\n### Option 1: Always Search [â€‹](https://voltagent.dev/docs/rag/custom-retrievers/\\#option-1-always-search \"Direct link to Option 1: Always Search\")\n\n```codeBlockLines_e6Vv\nconst agent = new Agent({\n  name: \"Support Bot\",\n  retriever: new MyRetriever(), // Searches before every response\n  // ... other config\n});\n\n```\n\n**When to use:** Support bots, Q&A systems where you always want context\n\n### Option 2: Search When Needed [â€‹](https://voltagent.dev/docs/rag/custom-retrievers/\\#option-2-search-when-needed \"Direct link to Option 2: Search When Needed\")\n\n```codeBlockLines_e6Vv\nconst retriever = new MyRetriever({\n  toolName: \"search_docs\",\n  toolDescription: \"Search company documentation\",\n});\n\nconst agent = new Agent({\n  name: \"Smart Assistant\",\n  tools: [retriever.tool], // LLM decides when to search\n  // ... other config\n});\n\n```\n\n**When to use:** General assistants where you want the LLM to decide when to search\n\n## Quick Decision Guide [â€‹](https://voltagent.dev/docs/rag/custom-retrievers/\\#quick-decision-guide \"Direct link to Quick Decision Guide\")\n\n| Use Case | Method | Why |\n| --- | --- | --- |\n| Support bot | `agent.retriever` | Always needs context |\n| Q&A system | `agent.retriever` | Every question needs search |\n| General assistant | `agent.tools` | Let LLM decide when to search |\n| Multi-tool agent | `agent.tools` | Mix with other tools |\n\n## Pro Tips [â€‹](https://voltagent.dev/docs/rag/custom-retrievers/\\#pro-tips \"Direct link to Pro Tips\")\n\n**Format your results clearly:**\n\n```codeBlockLines_e6Vv\n// âŒ Hard to parse\nreturn results.join(\" \");\n\n// âœ… Easy to parse\nreturn results.map((r) => `Source: ${r.title}\\n${r.content}`).join(\"\\n\\n---\\n\\n\");\n\n```\n\n**Handle errors gracefully:**\n\n```codeBlockLines_e6Vv\nasync retrieve(input, options) {\n  try {\n    const results = await this.searchData(input);\n    return results.length > 0 ? results.join('\\n\\n') : \"No results found.\";\n  } catch (error) {\n    console.error('Search failed:', error);\n    return \"Search temporarily unavailable.\";\n  }\n}\n\n```\n\n**Make it fast:**\n\n```codeBlockLines_e6Vv\n// Add timeouts and limits\nconst results = await Promise.race([\\\n  this.searchData(query),\\\n  new Promise((_, reject) => setTimeout(() => reject(new Error(\"Timeout\")), 5000)),\\\n]);\n\n```\n\n**Good tool descriptions:**\n\n```codeBlockLines_e6Vv\n// âŒ Vague\ntoolDescription: \"Searches stuff\";\n\n// âœ… Specific\ntoolDescription: \"Search company documentation, policies, and FAQ. Use when user asks about company procedures, benefits, or policies.\";\n\n```\n\n## Learn More [â€‹](https://voltagent.dev/docs/rag/custom-retrievers/\\#learn-more \"Direct link to Learn More\")\n\n- **[RAG Overview â†’](https://voltagent.dev/docs/rag/overview/)** \\- Complete guide to Retrieval-Augmented Generation\n- **[Chroma Integration â†’](https://voltagent.dev/docs/rag/chroma/)** \\- Working example with Chroma vector database\n- **[Examples â†’](https://github.com/voltagent/voltagent/tree/main/examples)** \\- See retriever implementations in action\n\n### Table of Contents\n\n- [The Pattern (Copy & Paste)](https://voltagent.dev/docs/rag/custom-retrievers/#the-pattern-copy--paste)\n- [Real Examples](https://voltagent.dev/docs/rag/custom-retrievers/#real-examples)\n  - [Search Local Files](https://voltagent.dev/docs/rag/custom-retrievers/#search-local-files)\n  - [Search PostgreSQL Database](https://voltagent.dev/docs/rag/custom-retrievers/#search-postgresql-database)\n  - [Call External API](https://voltagent.dev/docs/rag/custom-retrievers/#call-external-api)\n- [Track Sources (Optional)](https://voltagent.dev/docs/rag/custom-retrievers/#track-sources-optional)\n- [How to Use Your Retriever](https://voltagent.dev/docs/rag/custom-retrievers/#how-to-use-your-retriever)\n  - [Option 1: Always Search](https://voltagent.dev/docs/rag/custom-retrievers/#option-1-always-search)\n  - [Option 2: Search When Needed](https://voltagent.dev/docs/rag/custom-retrievers/#option-2-search-when-needed)\n- [Quick Decision Guide](https://voltagent.dev/docs/rag/custom-retrievers/#quick-decision-guide)\n- [Pro Tips](https://voltagent.dev/docs/rag/custom-retrievers/#pro-tips)\n- [Learn More](https://voltagent.dev/docs/rag/custom-retrievers/#learn-more)",
      "metadata": {
        "ogDescription": "Want to connect your AI agent to your own database, API, or files? Here's how to build a custom retriever in 5 minutes.",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_version": "current",
        "ogTitle": "Build Your Own Retriever | VoltAgent",
        "twitter:card": "summary_large_image",
        "og:image": "https://voltagent.dev/img/social3.png",
        "language": "en",
        "docsearch:version": "current",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "ogLocale": "en",
        "generator": "Docusaurus v3.1.1",
        "og:title": "Build Your Own Retriever | VoltAgent",
        "description": "Want to connect your AI agent to your own database, API, or files? Here's how to build a custom retriever in 5 minutes.",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "docsearch:language": "en",
        "docusaurus_locale": "en",
        "og:url": "https://voltagent.dev/docs/rag/custom-retrievers/",
        "docsearch:docusaurus_tag": "docs-default-current",
        "title": "Build Your Own Retriever | VoltAgent",
        "docusaurus_tag": "docs-default-current",
        "og:description": "Want to connect your AI agent to your own database, API, or files? Here's how to build a custom retriever in 5 minutes.",
        "ogUrl": "https://voltagent.dev/docs/rag/custom-retrievers/",
        "og:locale": "en",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "scrapeId": "e37f51bc-91f0-4f6f-8247-eed04c5730a6",
        "sourceURL": "https://voltagent.dev/docs/rag/custom-retrievers/",
        "url": "https://voltagent.dev/docs/rag/custom-retrievers/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:11.450Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/workflows/steps/and-all/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# andAll\n\n> Run multiple steps in parallel and wait for all to complete. Perfect for batch processing, multiple API calls, or any operations that can run simultaneously.\n\n## Quick Start [â€‹](https://voltagent.dev/docs/workflows/steps/and-all/\\#quick-start \"Direct link to Quick Start\")\n\nRun three operations at the same time:\n\n```codeBlockLines_e6Vv\nimport { createWorkflowChain, andThen, andAll } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\nconst workflow = createWorkflowChain({\n  id: \"fetch-user-data\",\n  input: z.object({ userId: z.string() }),\n}).andAll({\n  id: \"fetch-user-data-steps\",\n  steps: [\\\n    // All three API calls run at the same time\\\n    andThen({\\\n      id: \"fetch-profile\",\\\n      execute: async ({ data }) => {\\\n        const profile = await fetchUserProfile(data.userId);\\\n        return { profile };\\\n      },\\\n    }),\\\n    andThen({\\\n      id: \"fetch-posts\",\\\n      execute: async ({ data }) => {\\\n        const posts = await fetchUserPosts(data.userId);\\\n        return { posts };\\\n      },\\\n    }),\\\n    andThen({\\\n      id: \"fetch-stats\",\\\n      execute: async ({ data }) => {\\\n        const stats = await fetchUserStats(data.userId);\\\n        return { stats };\\\n      },\\\n    }),\\\n  ],\n});\n\n// All three requests happen in parallel\nconst result = await workflow.run({ userId: \"user-123\" });\n// Result: { profile: {...}, posts: [...], stats: {...} }\n\n```\n\n## How It Works [â€‹](https://voltagent.dev/docs/workflows/steps/and-all/\\#how-it-works \"Direct link to How It Works\")\n\n1. All steps start at the same time\n2. Each step gets the same input data\n3. Waits for ALL steps to finish\n4. Merges all results into one object\n5. If any step fails, the whole thing fails\n\nThink of it like ordering from multiple restaurants at once - you wait for all deliveries before eating.\n\n## Function Signature [â€‹](https://voltagent.dev/docs/workflows/steps/and-all/\\#function-signature \"Direct link to Function Signature\")\n\n```codeBlockLines_e6Vv\n.andAll({\n  id: string,\n  steps: Array<Step>,\n  name?: string,           // Optional\n  purpose?: string         // Optional\n})\n\n```\n\n## Common Patterns [â€‹](https://voltagent.dev/docs/workflows/steps/and-all/\\#common-patterns \"Direct link to Common Patterns\")\n\n### Parallel API Calls [â€‹](https://voltagent.dev/docs/workflows/steps/and-all/\\#parallel-api-calls \"Direct link to Parallel API Calls\")\n\n```codeBlockLines_e6Vv\n.andAll({\n  id: \"parallel-api-calls\",\n  steps: [\\\n    andThen({\\\n      id: \"api-1\",\\\n      execute: async ({ data }) => {\\\n        const result = await fetch(`/api/service1/${data.id}`);\\\n        return { service1: await result.json() };\\\n      }\\\n    }),\\\n    andThen({\\\n      id: \"api-2\",\\\n      execute: async ({ data }) => {\\\n        const result = await fetch(`/api/service2/${data.id}`);\\\n        return { service2: await result.json() };\\\n      }\\\n    })\\\n  ]\n})\n\n```\n\n### Parallel AI Agents [â€‹](https://voltagent.dev/docs/workflows/steps/and-all/\\#parallel-ai-agents \"Direct link to Parallel AI Agents\")\n\n```codeBlockLines_e6Vv\n.andAll({\n  id: \"parallel-ai-analysis\",\n  steps: [\\\n    andAgent(\\\n      ({ data }) => `Summarize: ${data.text}`,\\\n      summaryAgent,\\\n      { schema: z.object({ summary: z.string() }) }\\\n    ),\\\n    andAgent(\\\n      ({ data }) => `Extract keywords from: ${data.text}`,\\\n      keywordAgent,\\\n      { schema: z.object({ keywords: z.array(z.string()) }) }\\\n    ),\\\n    andAgent(\\\n      ({ data }) => `Analyze sentiment: ${data.text}`,\\\n      sentimentAgent,\\\n      { schema: z.object({ sentiment: z.string() }) }\\\n    )\\\n  ]\n})\n\n```\n\n### Batch Processing [â€‹](https://voltagent.dev/docs/workflows/steps/and-all/\\#batch-processing \"Direct link to Batch Processing\")\n\n```codeBlockLines_e6Vv\nconst items = [\"item1\", \"item2\", \"item3\"];\n\n.andAll({\n  id: \"batch-processing\",\n  steps: items.map(item =>\n    andThen({\n      id: `process-${item}`,\n      execute: async () => {\n        const result = await processItem(item);\n        return { [item]: result };\n      }\n    })\n  )\n})\n\n```\n\n## Error Handling [â€‹](https://voltagent.dev/docs/workflows/steps/and-all/\\#error-handling \"Direct link to Error Handling\")\n\nIf any step fails, `andAll` fails immediately:\n\n```codeBlockLines_e6Vv\n.andAll({\n  id: \"mixed-success-failure\",\n  steps: [\\\n    andThen({\\\n      id: \"will-succeed\",\\\n      execute: async () => ({ success: true })\\\n    }),\\\n    andThen({\\\n      id: \"will-fail\",\\\n      execute: async () => {\\\n        throw new Error(\"Failed!\");\\\n      }\\\n    }),\\\n    andThen({\\\n      id: \"also-succeeds\",\\\n      execute: async () => ({ alsoSuccess: true })\\\n    })\\\n  ]\n})\n// Workflow stops here - error thrown\n\n```\n\nTo handle failures gracefully, catch errors in individual steps:\n\n```codeBlockLines_e6Vv\n.andAll({\n  id: \"safe-parallel-calls\",\n  steps: [\\\n    andThen({\\\n      id: \"safe-api-call\",\\\n      execute: async ({ data }) => {\\\n        try {\\\n          const result = await riskyApiCall(data.id);\\\n          return { apiResult: result };\\\n        } catch (error) {\\\n          return { apiResult: null, error: error.message };\\\n        }\\\n      }\\\n    })\\\n  ]\n})\n\n```\n\n## Suspend & Resume [â€‹](https://voltagent.dev/docs/workflows/steps/and-all/\\#suspend--resume \"Direct link to Suspend & Resume\")\n\n`andAll` supports suspension - if any step suspends, the entire parallel operation suspends:\n\n```codeBlockLines_e6Vv\n.andAll({\n  id: \"approval-workflow\",\n  steps: [\\\n    andThen({\\\n      id: \"auto-process\",\\\n      execute: async ({ data }) => ({ processed: true })\\\n    }),\\\n    andThen({\\\n      id: \"needs-approval\",\\\n      execute: async ({ data, suspend, resumeData }) => {\\\n        if (resumeData) {\\\n          return { approved: resumeData.approved };\\\n        }\\\n        await suspend(\"Needs approval\");\\\n      }\\\n    })\\\n  ]\n})\n\n```\n\n## Performance Tips [â€‹](https://voltagent.dev/docs/workflows/steps/and-all/\\#performance-tips \"Direct link to Performance Tips\")\n\n### Sequential vs Parallel [â€‹](https://voltagent.dev/docs/workflows/steps/and-all/\\#sequential-vs-parallel \"Direct link to Sequential vs Parallel\")\n\n```codeBlockLines_e6Vv\n// Sequential: 3 seconds total\n.andThen({ execute: async () => await api1() }) // 1s\n.andThen({ execute: async () => await api2() }) // 1s\n.andThen({ execute: async () => await api3() }) // 1s\n\n// Parallel: 1 second total\n.andAll({\n  id: \"parallel-api-calls\",\n  steps: [\\\n    andThen({ execute: async () => await api1() }), // 1s\\\n    andThen({ execute: async () => await api2() }), // 1s\\\n    andThen({ execute: async () => await api3() })  // 1s\\\n  ]\n})\n\n```\n\n### Best Practices [â€‹](https://voltagent.dev/docs/workflows/steps/and-all/\\#best-practices \"Direct link to Best Practices\")\n\n1. **Only parallelize independent operations**\n\n\n\n\n\n```codeBlockLines_e6Vv\n// Good: No dependencies\n.andAll({\n     id: \"independent-fetches\",\n     steps: [fetchUser(), fetchPosts(), fetchComments()]\n})\n\n// Bad: Second depends on first\n.andAll({\n     id: \"dependent-operations\",\n     steps: [createUser(), assignUserRole()]\n})\n\n```\n\n2. **Limit parallelism**\n\n\n\n\n\n```codeBlockLines_e6Vv\n// Good: Reasonable number\n.andAll({\n     id: \"reasonable-parallel\",\n     steps: [api1(), api2(), api3()]\n})\n\n// Bad: Too many\n.andAll({\n     id: \"too-many-parallel\",\n     steps: hundredsOfApiCalls\n})\n\n```\n\n3. **Handle errors appropriately**\n\n\n\n\n\n```codeBlockLines_e6Vv\n// Wrap risky operations\n.andAll({\n     id: \"safe-operations\",\n     steps: [\\\n       safeWrapper(riskyOperation1),\\\n       safeWrapper(riskyOperation2)\\\n     ]\n})\n\n```\n\n\n## Comparison with andRace [â€‹](https://voltagent.dev/docs/workflows/steps/and-all/\\#comparison-with-andrace \"Direct link to Comparison with andRace\")\n\n| Feature | andAll | andRace |\n| --- | --- | --- |\n| Waits for | All steps | First step |\n| Use case | Need all results | Need fastest result |\n| Failure | Fails if any fail | Succeeds if any succeed |\n| Result | Merged from all | From first complete |\n\n## Next Steps [â€‹](https://voltagent.dev/docs/workflows/steps/and-all/\\#next-steps \"Direct link to Next Steps\")\n\n- Learn about [andRace](https://voltagent.dev/docs/workflows/steps/and-race/) for \"first wins\" scenarios\n- Explore [andThen](https://voltagent.dev/docs/workflows/steps/and-then/) for sequential processing\n- See [andWhen](https://voltagent.dev/docs/workflows/steps/and-when/) for conditional execution\n- Execute workflows via [REST API](https://voltagent.dev/docs/api/overview/#workflow-endpoints)\n\n### Table of Contents\n\n- [Quick Start](https://voltagent.dev/docs/workflows/steps/and-all/#quick-start)\n- [How It Works](https://voltagent.dev/docs/workflows/steps/and-all/#how-it-works)\n- [Function Signature](https://voltagent.dev/docs/workflows/steps/and-all/#function-signature)\n- [Common Patterns](https://voltagent.dev/docs/workflows/steps/and-all/#common-patterns)\n  - [Parallel API Calls](https://voltagent.dev/docs/workflows/steps/and-all/#parallel-api-calls)\n  - [Parallel AI Agents](https://voltagent.dev/docs/workflows/steps/and-all/#parallel-ai-agents)\n  - [Batch Processing](https://voltagent.dev/docs/workflows/steps/and-all/#batch-processing)\n- [Error Handling](https://voltagent.dev/docs/workflows/steps/and-all/#error-handling)\n- [Suspend & Resume](https://voltagent.dev/docs/workflows/steps/and-all/#suspend--resume)\n- [Performance Tips](https://voltagent.dev/docs/workflows/steps/and-all/#performance-tips)\n  - [Sequential vs Parallel](https://voltagent.dev/docs/workflows/steps/and-all/#sequential-vs-parallel)\n  - [Best Practices](https://voltagent.dev/docs/workflows/steps/and-all/#best-practices)\n- [Comparison with andRace](https://voltagent.dev/docs/workflows/steps/and-all/#comparison-with-andrace)\n- [Next Steps](https://voltagent.dev/docs/workflows/steps/and-all/#next-steps)",
      "metadata": {
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "generator": "Docusaurus v3.1.1",
        "twitter:card": "summary_large_image",
        "og:locale": "en",
        "docusaurus_version": "current",
        "ogUrl": "https://voltagent.dev/docs/workflows/steps/and-all/",
        "docsearch:docusaurus_tag": "docs-default-current",
        "description": "Run multiple steps in parallel and wait for all to complete. Perfect for batch processing, multiple API calls, or any operations that can run simultaneously.",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "viewport": "width=device-width, initial-scale=1.0",
        "docsearch:version": "current",
        "og:url": "https://voltagent.dev/docs/workflows/steps/and-all/",
        "og:title": "andAll | VoltAgent",
        "ogDescription": "Run multiple steps in parallel and wait for all to complete. Perfect for batch processing, multiple API calls, or any operations that can run simultaneously.",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "og:description": "Run multiple steps in parallel and wait for all to complete. Perfect for batch processing, multiple API calls, or any operations that can run simultaneously.",
        "og:image": "https://voltagent.dev/img/social3.png",
        "docusaurus_locale": "en",
        "ogTitle": "andAll | VoltAgent",
        "language": "en",
        "docusaurus_tag": "docs-default-current",
        "ogLocale": "en",
        "title": "andAll | VoltAgent",
        "docsearch:language": "en",
        "scrapeId": "80e061b9-f683-4188-968a-410c606d49f4",
        "sourceURL": "https://voltagent.dev/docs/workflows/steps/and-all/",
        "url": "https://voltagent.dev/docs/workflows/steps/and-all/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:39.500Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/integrations/nextjs/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Integrating VoltAgent with Next.js\n\nThis guide walks you through setting up VoltAgent in a Next.js application. We'll build a simple AI calculator example using Server Actions and the Vercel AI SDK.\n\n## Quick Start with Example [â€‹](https://voltagent.dev/docs/integrations/nextjs/\\#quick-start-with-example \"Direct link to Quick Start with Example\")\n\nIf you prefer to start directly with the completed example project, you can create it using the following command:\n\n```codeBlockLines_e6Vv\nnpm create voltagent-app@latest -- --example with-nextjs\n\n```\n\nThis command will scaffold the entire Next.js example project described in this guide.\n\n## Create a New Next.js Project [â€‹](https://voltagent.dev/docs/integrations/nextjs/\\#create-a-new-nextjs-project \"Direct link to Create a New Next.js Project\")\n\nStart by creating a new Next.js project using the latest version:\n\n```codeBlockLines_e6Vv\nnpx create-next-app@latest my-voltagent-app\ncd my-voltagent-app\n\n```\n\nFollow the prompts, selecting TypeScript and App Router.\n\n## Install VoltAgent Dependencies [â€‹](https://voltagent.dev/docs/integrations/nextjs/\\#install-voltagent-dependencies \"Direct link to Install VoltAgent Dependencies\")\n\nInstall the necessary VoltAgent packages and the Vercel AI SDK provider:\n\n```codeBlockLines_e6Vv\nnpm install @voltagent/core @voltagent/vercel-ai @voltagent/cli @ai-sdk/openai zod@^3.25.0\n\n```\n\n- `@voltagent/core`: The core VoltAgent library.\n- `@voltagent/vercel-ai`: Integrates VoltAgent with the Vercel AI SDK.\n- `@ai-sdk/openai`: The AI SDK provider for OpenAI (or your preferred LLM provider).\n- `@voltagent/cli`: The command-line interface for VoltAgent tasks (e.g., managing updates).\n- `zod`: Required by the Vercel AI SDK for schema validation.\n\n## Configure `next.config.js` [â€‹](https://voltagent.dev/docs/integrations/nextjs/\\#configure-nextconfigjs \"Direct link to configure-nextconfigjs\")\n\nNext.js might try to bundle server-side packages by default. To prevent issues with VoltAgent, you need to mark its packages as external in your `next.config.mjs` (or `.js` / `.ts`) file:\n\nnext.config.mjs // or next.config.ts\n\n```codeBlockLines_e6Vv\nimport type { NextConfig } from \"next\";\n\nconst nextConfig: NextConfig = {\n  experimental: {\n    // Mark VoltAgent packages as external\n    serverComponentsExternalPackages: [\"@voltagent/*\"],\n    // If using other packages that need to run externally (like npm-check-updates in the example)\n    // add them here too.\n    // serverComponentsExternalPackages: [\"@voltagent/*\", \"another-package\"],\n  },\n};\n\nexport default nextConfig;\n\n```\n\n**Note:** The property was `serverExternalPackages` in older Next.js versions, but changed to `experimental.serverComponentsExternalPackages`. Ensure you use the correct one for your Next.js version.\n\n## Initialize VoltAgent [â€‹](https://voltagent.dev/docs/integrations/nextjs/\\#initialize-voltagent \"Direct link to Initialize VoltAgent\")\n\nCreate a file to initialize the VoltAgent agent, for example, `voltagent/index.ts` in your project root:\n\nvoltagent/index.ts\n\n```codeBlockLines_e6Vv\nimport { VoltAgent } from \"@voltagent/core\";\nimport { VercelAIManager } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\"; // Or your preferred provider\n\nexport const agent = new VoltAgent({\n  provider: \"vercel-ai\", // Specify the Vercel AI provider\n  manager: new VercelAIManager({\n    model: openai(\"gpt-4o\"), // Configure your desired model\n  }),\n  functions: [\\\n    // Add any VoltAgent functions/tools here if needed\\\n  ],\n});\n\n```\n\nRemember to set up your environment variables (e.g., `OPENAI_API_KEY`) in a `.env.local` file.\nCreate a `.env.local` file in your project root if it doesn't exist, and add your necessary API keys:\n\n.env.local\n\n```codeBlockLines_e6Vv\nOPENAI_API_KEY=\"your-openai-api-key-here\"\n# Add other environment variables if needed\n\n```\n\n## Create a Server Action [â€‹](https://voltagent.dev/docs/integrations/nextjs/\\#create-a-server-action \"Direct link to Create a Server Action\")\n\nDefine a Server Action to interact with the VoltAgent agent. Create `app/actions.ts`:\n\napp/actions.ts\n\n```codeBlockLines_e6Vv\n\"use server\";\n\nimport { agent } from \"@/voltagent\"; // Adjust path if needed\n\nexport async function calculateExpression(expression: string) {\n  const result = await agent.generateText(\n    `Calculate ${expression}. Only respond with the numeric result.`\n  );\n\n  return result.text;\n}\n\n```\n\n## Build the UI Component [â€‹](https://voltagent.dev/docs/integrations/nextjs/\\#build-the-ui-component \"Direct link to Build the UI Component\")\n\nCreate a client component to take user input and display the result. Create `app/components/calculator.tsx`:\n\napp/components/calculator.tsx\n\n```codeBlockLines_e6Vv\n\"use client\";\n\nimport { useState } from \"react\";\nimport { calculateExpression } from \"../actions\";\n\nexport function Calculator() {\n  const [result, setResult] = useState<string | null>(null);\n  const [loading, setLoading] = useState(false);\n  const [expression, setExpression] = useState(\"\");\n\n  async function handleSubmit(formData: FormData) {\n    const expr = formData.get(\"expression\") as string;\n    if (!expr.trim()) return;\n\n    setLoading(true);\n    try {\n      const calcResult = await calculateExpression(expr);\n      setResult(calcResult);\n      setExpression(expr);\n    } catch (error) {\n      console.error(\"Calculation error:\", error);\n      setResult(\"Error calculating expression\");\n    } finally {\n      setLoading(false);\n    }\n  }\n\n  return (\n    <div>\n      <h2>AI Calculator</h2>\n      <form action={handleSubmit}>\n        <label htmlFor=\"expression\">Enter calculation:</label>\n        <input\n          id=\"expression\"\n          name=\"expression\"\n          type=\"text\"\n          placeholder=\"E.g. (5 + 3) * 2\"\n          required\n        />\n        <button type=\"submit\" disabled={loading}>\n          {loading ? \"Calculating...\" : \"Calculate\"}\n        </button>\n      </form>\n\n      {result && (\n        <div>\n          <h3>Result:</h3>\n          <p>{expression} = {result}</p>\n        </div>\n      )}\n    </div>\n  );\n}\n\n```\n\n_(Styling omitted for brevity. Refer to the example project for full styling)_\n\n## Use the Component [â€‹](https://voltagent.dev/docs/integrations/nextjs/\\#use-the-component \"Direct link to Use the Component\")\n\nFinally, import and use the `Calculator` component in your main page ( `app/page.tsx`):\n\napp/page.tsx\n\n```codeBlockLines_e6Vv\nimport { Calculator } from \"./components/calculator\";\n\nexport default function HomePage() {\n  return (\n    <main>\n      <h1>VoltAgent Next.js Example</h1>\n      <Calculator />\n    </main>\n  );\n}\n\n```\n\nNow you can run your Next.js development server ( `npm run dev`) and test the AI calculator! This demonstrates a basic integration of VoltAgent within a Next.js application using Server Actions.\n\n### Table of Contents\n\n- [Quick Start with Example](https://voltagent.dev/docs/integrations/nextjs/#quick-start-with-example)\n- [Create a New Next.js Project](https://voltagent.dev/docs/integrations/nextjs/#create-a-new-nextjs-project)\n- [Install VoltAgent Dependencies](https://voltagent.dev/docs/integrations/nextjs/#install-voltagent-dependencies)\n- [Configure `next.config.js`](https://voltagent.dev/docs/integrations/nextjs/#configure-nextconfigjs)\n- [Initialize VoltAgent](https://voltagent.dev/docs/integrations/nextjs/#initialize-voltagent)\n- [Create a Server Action](https://voltagent.dev/docs/integrations/nextjs/#create-a-server-action)\n- [Build the UI Component](https://voltagent.dev/docs/integrations/nextjs/#build-the-ui-component)\n- [Use the Component](https://voltagent.dev/docs/integrations/nextjs/#use-the-component)",
      "metadata": {
        "ogUrl": "https://voltagent.dev/docs/integrations/nextjs/",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_version": "current",
        "generator": "Docusaurus v3.1.1",
        "twitter:card": "summary_large_image",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "og:url": "https://voltagent.dev/docs/integrations/nextjs/",
        "docsearch:language": "en",
        "og:description": "This guide walks you through setting up VoltAgent in a Next.js application. We'll build a simple AI calculator example using Server Actions and the Vercel AI SDK.",
        "ogDescription": "This guide walks you through setting up VoltAgent in a Next.js application. We'll build a simple AI calculator example using Server Actions and the Vercel AI SDK.",
        "og:title": "Next.js | VoltAgent",
        "docusaurus_tag": "docs-default-current",
        "docsearch:docusaurus_tag": "docs-default-current",
        "ogTitle": "Next.js | VoltAgent",
        "docusaurus_locale": "en",
        "docsearch:version": "current",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "og:locale": "en",
        "language": "en",
        "ogLocale": "en",
        "title": "Next.js | VoltAgent",
        "og:image": "https://voltagent.dev/img/social3.png",
        "description": "This guide walks you through setting up VoltAgent in a Next.js application. We'll build a simple AI calculator example using Server Actions and the Vercel AI SDK.",
        "scrapeId": "64190665-69b6-4514-8e26-c67200282873",
        "sourceURL": "https://voltagent.dev/docs/integrations/nextjs/",
        "url": "https://voltagent.dev/docs/integrations/nextjs/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:07.522Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/agents/hooks/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Hooks\n\nHooks provide points within the agent's execution lifecycle where you can inject custom logic. They allow you to run code before an agent starts processing, after it finishes, before and after it uses a tool, or when tasks are handed off between agents in a multi-agent system.\n\nThis is useful for logging, monitoring, adding validation, managing resources, or modifying behavior.\n\n## Creating and Using Hooks [â€‹](https://voltagent.dev/docs/agents/hooks/\\#creating-and-using-hooks \"Direct link to Creating and Using Hooks\")\n\nThe recommended way to define hooks is using the `createHooks` helper function. This creates a typed hooks object that can be passed to one or more agents during initialization.\n\n```codeBlockLines_e6Vv\nimport {\n  Agent,\n  createHooks,\n  messageHelpers,\n  type AgentTool,\n  type AgentOperationOutput, // Unified success output type\n  type VoltAgentError, // Standardized error type\n  type ChatMessage, // Vercel AI SDK compatible message format\n  type OnStartHookArgs, // Argument types for hooks\n  type OnEndHookArgs,\n  type OnPrepareMessagesHookArgs,\n  type OnToolStartHookArgs,\n  type OnToolEndHookArgs,\n  type OnHandoffHookArgs,\n} from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Define a collection of hooks using the helper\nconst myAgentHooks = createHooks({\n  /**\n   * Called before the agent starts processing a request.\n   */\n  onStart: async (args: OnStartHookArgs) => {\n    const { agent, context } = args;\n    console.log(`[Hook] Agent ${agent.name} starting interaction at ${new Date().toISOString()}`);\n    console.log(`[Hook] Operation ID: ${context.operationId}`);\n  },\n\n  /**\n   * Called before messages are sent to the LLM. Allows transformation of messages.\n   */\n  onPrepareMessages: async (args: OnPrepareMessagesHookArgs) => {\n    const { messages, context } = args;\n    console.log(`[Hook] Preparing ${messages.length} messages for LLM`);\n\n    // Example: Add timestamps to user messages\n    const timestamp = new Date().toLocaleTimeString();\n    const enhanced = messages.map((msg) => messageHelpers.addTimestampToMessage(msg, timestamp));\n\n    // Return transformed messages (or nothing to keep original)\n    return { messages: enhanced };\n  },\n\n  /**\n   * Called after the agent finishes processing a request, successfully or with an error.\n   */\n  onEnd: async (args: OnEndHookArgs) => {\n    const { agent, output, error, messages, context } = args;\n    if (error) {\n      console.error(`[Hook] Agent ${agent.name} finished with error:`, error.message);\n      console.log(`[Hook] User input was:`, messages[0]?.content);\n      // Log detailed error info\n      console.error(`[Hook] Error Details:`, JSON.stringify(error, null, 2));\n    } else if (output) {\n      console.log(`[Hook] Agent ${agent.name} finished successfully.`);\n      console.log(`[Hook] Conversation turn:`, {\n        userInput: messages[0]?.content,\n        assistantResponse: messages[1]?.content,\n      });\n\n      // Example: Log usage or analyze the result based on output type\n      if (\"usage\" in output && output.usage) {\n        console.log(`[Hook] Token Usage: ${output.usage.totalTokens}`);\n      }\n      if (\"text\" in output && output.text) {\n        console.log(`[Hook] Final text length: ${output.text.length}`);\n      }\n      if (\"object\" in output && output.object) {\n        console.log(`[Hook] Final object keys: ${Object.keys(output.object).join(\", \")}`);\n      }\n    }\n  },\n\n  /**\n   * Called just before a tool's execute function is called.\n   */\n  onToolStart: async (args: OnToolStartHookArgs) => {\n    const { agent, tool, context } = args;\n    console.log(`[Hook] Agent ${agent.name} starting tool: ${tool.name}`);\n    // Example: Validate tool inputs or log intent\n  },\n\n  /**\n   * Called after a tool's execute function completes or throws.\n   */\n  onToolEnd: async (args: OnToolEndHookArgs) => {\n    const { agent, tool, output, error, context } = args;\n    if (error) {\n      console.error(`[Hook] Tool ${tool.name} failed with error:`, error.message);\n      // Log detailed tool error\n      console.error(`[Hook] Tool Error Details:`, JSON.stringify(error, null, 2));\n    } else {\n      console.log(`[Hook] Tool ${tool.name} completed successfully with result:`, output);\n      // Example: Log tool output or trigger follow-up actions\n    }\n  },\n\n  /**\n   * Called when a task is handed off from a source agent to this agent (in sub-agent scenarios).\n   */\n  onHandoff: async (args: OnHandoffHookArgs) => {\n    const { agent, sourceAgent } = args;\n    console.log(`[Hook] Task handed off from ${sourceAgent.name} to ${agent.name}`);\n    // Example: Track collaboration flow in multi-agent systems\n  },\n});\n\n// Define a placeholder provider for the example\nconst provider = new VercelAIProvider();\n\n// Assign the hooks when creating an agent\nconst agentWithHooks = new Agent({\n  name: \"My Agent with Hooks\",\n  instructions: \"An assistant demonstrating hooks\",\n  llm: provider,\n  model: openai(\"gpt-4o\"),\n  // Pass the hooks object during initialization\n  hooks: myAgentHooks,\n});\n\n// Alternatively, define hooks inline (less reusable)\nconst agentWithInlineHooks = new Agent({\n  name: \"Inline Hooks Agent\",\n  instructions: \"Another assistant\",\n  llm: provider,\n  model: openai(\"gpt-4o\"),\n  hooks: {\n    onStart: async ({ agent, context }) => {\n      // Use object destructuring\n      /* ... */\n    },\n    onEnd: async ({ agent, output, error, context }) => {\n      /* ... */\n    },\n    // ... other inline hooks ...\n  },\n});\n\n```\n\n## Passing hooks to generate methods [â€‹](https://voltagent.dev/docs/agents/hooks/\\#passing-hooks-to-generate-methods \"Direct link to Passing hooks to generate methods\")\n\nYou can pass hooks to the `generateText`, `streamText`, `generateObject`, and `streamObject` methods, directly to run the hooks only on that invocation.\n\nwarning\n\nThis will NOT override the hooks passed to the agent during initialization.\n\n```codeBlockLines_e6Vv\nconst agent = new Agent({\n  name: \"My Agent with Hooks\",\n  instructions: \"An assistant demonstrating hooks\",\n  llm: provider,\n  model: openai(\"gpt-4o\"),\n  hooks: myAgentHooks,\n});\n\nawait agent.generateText(\"Hello, how are you?\", {\n  hooks: {\n    onEnd: async ({ context }) => {\n      console.log(\"End of generation but only on this invocation!\");\n    },\n  },\n});\n\n```\n\nAn example of this is you may want to only store the conversation history for a specific invocation, but not for all usages of the agent:\n\n```codeBlockLines_e6Vv\nconst agent = new Agent({\n  name: \"Translation Agent\",\n  instructions: \"A translation agent that translates text from English to French\",\n  llm: provider,\n  model: openai(\"gpt-4o\"),\n});\n\n// for the translate endpoint, we don't want to store the conversation history\napp.post(\"/api/translate\", async (req, res) => {\n  const result = await agent.generateText(req.body.text);\n  return result;\n});\n\n// for the chat endpoint, we want to store the conversation history\napp.post(\"/api/translate/chat\", async (req, res) => {\n  const result = await agent.streamText(req.body.text, {\n    hooks: {\n      onEnd: async ({ context }) => {\n        await chatStore.save({\n          conversationId: context.conversationId,\n          messages: context.steps,\n        });\n      },\n    },\n  });\n\n  return result.textStream;\n});\n\n```\n\n## Available Hooks [â€‹](https://voltagent.dev/docs/agents/hooks/\\#available-hooks \"Direct link to Available Hooks\")\n\nAll hooks receive a single argument object containing relevant information.\n\n### `onStart` [â€‹](https://voltagent.dev/docs/agents/hooks/\\#onstart \"Direct link to onstart\")\n\n- **Triggered:** Before the agent begins processing a request ( `generateText`, `streamText`, etc.).\n- **Argument Object ( `OnStartHookArgs`):** `{ agent: Agent, context: OperationContext }`\n- **Use Cases:** Initialization logic, request logging, setting up request-scoped resources.\n\n```codeBlockLines_e6Vv\n// Example: Log the start of an operation\nonStart: async ({ agent, context }) => {\n  console.log(`Agent ${agent.name} starting operation ${context.operationId}`);\n};\n\n```\n\n### `onPrepareMessages` [â€‹](https://voltagent.dev/docs/agents/hooks/\\#onpreparemessages \"Direct link to onpreparemessages\")\n\n- **Triggered:** After messages are loaded from memory but before they are sent to the LLM.\n- **Argument Object ( `OnPrepareMessagesHookArgs`):** `{ messages: BaseMessage[], context: OperationContext }`\n- **Use Cases:** Transform messages (add timestamps, context), filter sensitive data (PII, credentials), inject dynamic system prompts, remove duplicate messages, add user-specific context.\n- **Return:** `{ messages: BaseMessage[] }` with transformed messages, or nothing to keep original messages.\n- **Note:** This hook runs on every LLM call and receives all messages including system prompt and memory messages.\n\n```codeBlockLines_e6Vv\n// Example: Add timestamps and filter sensitive data\nonPrepareMessages: async ({ messages, context }) => {\n  const timestamp = new Date().toLocaleTimeString();\n\n  // Transform messages using message helpers\n  const enhanced = messages.map((msg) => {\n    // Add timestamp to user messages\n    let transformed = messageHelpers.addTimestampToMessage(msg, timestamp);\n\n    // Filter sensitive data from all messages\n    transformed = messageHelpers.mapMessageContent(transformed, (text) =>\n      text.replace(/\\b\\d{3}-\\d{2}-\\d{4}\\b/g, \"[SSN-REDACTED]\")\n    );\n\n    return transformed;\n  });\n\n  return { messages: enhanced };\n};\n\n```\n\n### `onEnd` [â€‹](https://voltagent.dev/docs/agents/hooks/\\#onend \"Direct link to onend\")\n\n- **Triggered:** After the agent finishes processing a request, either successfully or with an error.\n- **Argument Object ( `OnEndHookArgs`):** `{ agent: Agent, output: AgentOperationOutput | undefined, error: VoltAgentError | undefined, conversationId: string, context: OperationContext }`\n- **Use Cases:** Cleanup logic, logging completion status and results (success or failure), analyzing final output or error details, recording usage statistics, storing conversation history.\n- **Note:** The `output` object's specific structure within the `AgentOperationOutput` union depends on the agent method called. Check for specific fields ( `text`, `object`) or use type guards. `error` will contain the structured `VoltAgentError` on failure.\n\n```codeBlockLines_e6Vv\n// Example: Log the outcome of an operation and store conversation history\nonEnd: async ({ agent, output, error, conversationId, context }) => {\n  if (error) {\n    console.error(`Agent ${agent.name} operation ${context.operationId} failed: ${error.message}`);\n    console.log(`User input: \"${context.historyEntry.input}\"`);\n    // Only user input available on error (no assistant response)\n  } else {\n    // Check output type if needed\n    if (output && \"text\" in output) {\n      console.log(\n        `Agent ${agent.name} operation ${context.operationId} succeeded with text output.`\n      );\n    } else if (output && \"object\" in output) {\n      console.log(\n        `Agent ${agent.name} operation ${context.operationId} succeeded with object output.`\n      );\n    } else {\n      console.log(`Agent ${agent.name} operation ${context.operationId} succeeded.`);\n    }\n\n    // Log the complete conversation flow\n    console.log(`Conversation flow:`, {\n      user: context.historyEntry.input,\n      assistant: context.steps, // the assistant steps\n      totalMessages: context.steps.length,\n      toolInteractions: context.steps.flatMap((s) => s.toolInvocations || []).length,\n      toolsUsed: context.steps.flatMap((s) => s.toolInvocations || []).map((t) => t.toolName),\n    });\n\n    // Log usage if available\n    if (output?.usage) {\n      console.log(`  Usage: ${output.usage.totalTokens} tokens`);\n    }\n  }\n};\n\n```\n\n### `onToolStart` [â€‹](https://voltagent.dev/docs/agents/hooks/\\#ontoolstart \"Direct link to ontoolstart\")\n\n- **Triggered:** Just before an agent executes a specific tool.\n- **Argument Object ( `OnToolStartHookArgs`):** `{ agent: Agent, tool: AgentTool, context: OperationContext }`\n- **Use Cases:** Logging tool usage intent, validating tool inputs (though typically handled by Zod schema), modifying tool arguments (use with caution).\n\n```codeBlockLines_e6Vv\n// Example: Log when a tool is about to be used\nonToolStart: async ({ agent, tool, context }) => {\n  console.log(\n    `Agent ${agent.name} invoking tool '${tool.name}' for operation ${context.operationId}`\n  );\n};\n\n```\n\n### `onToolEnd` [â€‹](https://voltagent.dev/docs/agents/hooks/\\#ontoolend \"Direct link to ontoolend\")\n\n- **Triggered:** After a tool's `execute` function successfully completes or fails.\n- **Argument Object ( `OnToolEndHookArgs`):** `{ agent: Agent, tool: AgentTool, output: unknown | undefined, error: VoltAgentError | undefined, context: OperationContext }`\n- **Use Cases:** Logging tool results or errors, post-processing tool output, triggering subsequent actions based on tool success or failure.\n\n```codeBlockLines_e6Vv\n// Example: Log the result or error of a tool execution\nonToolEnd: async ({ agent, tool, output, error, context }) => {\n  if (error) {\n    console.error(\n      `Tool '${tool.name}' failed in operation ${context.operationId}: ${error.message}`\n    );\n  } else {\n    console.log(\n      `Tool '${tool.name}' succeeded in operation ${context.operationId}. Result:`,\n      output\n    );\n  }\n};\n\n```\n\n### `onHandoff` [â€‹](https://voltagent.dev/docs/agents/hooks/\\#onhandoff \"Direct link to onhandoff\")\n\n- **Triggered:** When one agent delegates a task to another agent (using the `delegate_task` tool in a sub-agent setup).\n- **Argument Object ( `OnHandoffHookArgs`):** `{ agent: Agent, sourceAgent: Agent }`\n- **Use Cases:** Tracking and visualizing workflow in multi-agent systems, adding context during agent collaboration.\n\n```codeBlockLines_e6Vv\n// Example: Log agent handoffs\nonHandoff: async ({ agent, sourceAgent }) => {\n  console.log(`Task handed off from agent '${sourceAgent.name}' to agent '${agent.name}'`);\n};\n\n```\n\n## Asynchronous Hooks and Error Handling [â€‹](https://voltagent.dev/docs/agents/hooks/\\#asynchronous-hooks-and-error-handling \"Direct link to Asynchronous Hooks and Error Handling\")\n\n- **Async Nature:** Hooks can be defined as `async` functions. VoltAgent will `await` the completion of each hook before proceeding. Be mindful that long-running asynchronous operations within hooks can add latency to the overall agent response time.\n- **Error Handling:** If an error is thrown _inside_ a hook function and not caught within the hook itself, it may interrupt the agent's execution flow. It's recommended to handle potential errors within your hook logic using `try...catch` if necessary, or ensure hooks are designed to be reliable.\n\n## Common Use Cases [â€‹](https://voltagent.dev/docs/agents/hooks/\\#common-use-cases \"Direct link to Common Use Cases\")\n\nHooks enable a variety of powerful patterns:\n\n1. **Logging & Observability**: Track agent execution steps, timings, inputs, outputs, and errors for monitoring and debugging.\n2. **Analytics**: Collect detailed usage data (token counts, tool usage frequency, success/error rates) for analysis.\n3. **Request/Response Modification**: (Use with caution) Modify inputs before processing or outputs after generation.\n4. **State Management**: Initialize or clean up request-specific state or resources.\n5. **Workflow Orchestration**: Trigger external actions or notifications based on agent events (e.g., notify on tool failure or successful completion with specific output).\n6. **UI Integration**: You can leverage the `@voltagent/vercel-ui` package to convert the `OperationContext` to a list of messages that can be used with the Vercel AI SDK (see below example).\n\n## Examples [â€‹](https://voltagent.dev/docs/agents/hooks/\\#examples \"Direct link to Examples\")\n\n### Message Transformation with onPrepareMessages [â€‹](https://voltagent.dev/docs/agents/hooks/\\#message-transformation-with-onpreparemessages \"Direct link to Message Transformation with onPrepareMessages\")\n\nHere's an example using `onPrepareMessages` with message helpers to enhance messages before they reach the LLM:\n\n```codeBlockLines_e6Vv\nimport { Agent, createHooks, messageHelpers } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst enhancedHooks = createHooks({\n  onPrepareMessages: async ({ messages, context }) => {\n    // Use message helpers for cleaner transformations\n    const enhanced = messages.map((msg) => {\n      // Add timestamps to user messages\n      if (msg.role === \"user\") {\n        const timestamp = new Date().toLocaleTimeString();\n        msg = messageHelpers.addTimestampToMessage(msg, timestamp);\n      }\n\n      // Filter sensitive data from all messages\n      msg = messageHelpers.mapMessageContent(msg, (text) => {\n        // Redact SSN patterns\n        text = text.replace(/\\b\\d{3}-\\d{2}-\\d{4}\\b/g, \"[SSN-REDACTED]\");\n        // Redact credit card patterns\n        text = text.replace(/\\b\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}\\b/g, \"[CC-REDACTED]\");\n        return text;\n      });\n\n      return msg;\n    });\n\n    // Add dynamic context based on user\n    if (context.userContext?.userId) {\n      const systemContext = {\n        role: \"system\" as const,\n        content: `User ID: ${context.userContext.userId}. Provide personalized responses.`,\n      };\n      enhanced.unshift(systemContext);\n    }\n\n    return { messages: enhanced };\n  },\n\n  onEnd: async ({ output, context }) => {\n    // Log what transformations were applied\n    console.log(`Messages processed for operation ${context.operationId}`);\n    if (output?.usage) {\n      console.log(`Tokens used: ${output.usage.totalTokens}`);\n    }\n  },\n});\n\nconst agent = new Agent({\n  name: \"Privacy-Aware Assistant\",\n  instructions: \"A helpful assistant that protects user privacy\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  hooks: enhancedHooks,\n});\n\n// User message: \"My SSN is 123-45-6789\"\n// LLM receives: \"[10:30:45] My SSN is [SSN-REDACTED]\"\n\n```\n\n### Vercel UI Integration Example [â€‹](https://voltagent.dev/docs/agents/hooks/\\#vercel-ui-integration-example \"Direct link to Vercel UI Integration Example\")\n\nHere's an example of how you can use the `@voltagent/vercel-ui` package to convert the `OperationContext` to a list of messages that can be used with the Vercel AI SDK:\n\n```codeBlockLines_e6Vv\nimport { convertToUIMessages } from \"@voltagent/vercel-ui\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { Agent } from \"@voltagent/core\";\n\nconst agent = new Agent({\n  id: \"assistant\",\n  name: \"Assistant\",\n  purpose: \"A helpful assistant that can answer questions and help with tasks.\",\n  instructions: \"You are a helpful assistant that can answer questions and help with tasks.\",\n  model: \"gpt-4.1-mini\",\n  llm: new VercelAIProvider(),\n  hooks: {\n    onEnd: async (result) => {\n      await chatStore.save({\n        conversationId: result.conversationId,\n        messages: convertToUIMessages(result.operationContext),\n      });\n    },\n  },\n});\n\nconst result = await agent.generateText(\"Hello, how are you?\");\n\n// You can now fetch the messages from your custom chat store and return to the UI to provide a\n// history of the conversation.\n\napp.get(\"/api/chats/:id\", async ({ req }) => {\n  const conversation = await chatStore.read(req.param(\"id\"));\n  return Response.json(conversation.messages);\n});\n\n```\n\n### Full Conversation Flow Example [â€‹](https://voltagent.dev/docs/agents/hooks/\\#full-conversation-flow-example \"Direct link to Full Conversation Flow Example\")\n\nHere's an example showing how the `messages` parameter includes complete conversation flow with tool interactions:\n\n```codeBlockLines_e6Vv\nconst conversationHooks = createHooks({\n  onEnd: async ({ agent, output, error, messages, context }) => {\n    // Example messages array for a successful operation with tool usage (ChatMessage format):\n    // [\\\n    //   {\\\n    //     id: \"msg_1\",\\\n    //     role: \"user\",\\\n    //     content: \"What's the weather in San Francisco?\",\\\n    //     createdAt: new Date()\\\n    //   },\\\n    //   {\\\n    //     id: \"msg_2\",\\\n    //     role: \"assistant\",\\\n    //     content: \"The weather in San Francisco is 8Â°C and rainy with 86% humidity.\",\\\n    //     createdAt: new Date(),\\\n    //     toolInvocations: [\\\n    //       {\\\n    //         toolCallId: \"call_mmZhyZwnheCjZQCRxFPR14pF\",\\\n    //         toolName: \"getWeather\",\\\n    //         args: { location: \"San Francisco\" },\\\n    //         result: {\\\n    //           weather: { location: \"San Francisco\", temperature: 8, condition: \"Rainy\", humidity: 86, windSpeed: 14 },\\\n    //           message: \"Current weather in San Francisco: 8Â°C and rainy with 86% humidity.\"\\\n    //         },\\\n    //         state: \"result\",\\\n    //         step: 0\\\n    //       }\\\n    //     ]\\\n    //   }\\\n    // ]\n\n    if (!error && output) {\n      // Store complete conversation including tool interactions\n      await storeConversation({\n        operationId: context.operationId,\n        messages: messages, // Full conversation flow\n        usage: output.usage,\n        timestamp: new Date(),\n      });\n\n      // Check if tools were used\n      const toolInteractions = messages.flatMap((m) => m.toolInvocations || []);\n      if (toolInteractions.length > 0) {\n        console.log(`Operation used ${toolInteractions.length} tool(s)`);\n        toolInteractions.forEach((tool, i) => {\n          console.log(`  Tool ${i + 1}: ${tool.toolName} (${tool.state})`);\n        });\n      }\n    }\n  },\n});\n\n```\n\n### Table of Contents\n\n- [Creating and Using Hooks](https://voltagent.dev/docs/agents/hooks/#creating-and-using-hooks)\n- [Passing hooks to generate methods](https://voltagent.dev/docs/agents/hooks/#passing-hooks-to-generate-methods)\n- [Available Hooks](https://voltagent.dev/docs/agents/hooks/#available-hooks)\n  - [`onStart`](https://voltagent.dev/docs/agents/hooks/#onstart)\n  - [`onPrepareMessages`](https://voltagent.dev/docs/agents/hooks/#onpreparemessages)\n  - [`onEnd`](https://voltagent.dev/docs/agents/hooks/#onend)\n  - [`onToolStart`](https://voltagent.dev/docs/agents/hooks/#ontoolstart)\n  - [`onToolEnd`](https://voltagent.dev/docs/agents/hooks/#ontoolend)\n  - [`onHandoff`](https://voltagent.dev/docs/agents/hooks/#onhandoff)\n- [Asynchronous Hooks and Error Handling](https://voltagent.dev/docs/agents/hooks/#asynchronous-hooks-and-error-handling)\n- [Common Use Cases](https://voltagent.dev/docs/agents/hooks/#common-use-cases)\n- [Examples](https://voltagent.dev/docs/agents/hooks/#examples)\n  - [Message Transformation with onPrepareMessages](https://voltagent.dev/docs/agents/hooks/#message-transformation-with-onpreparemessages)\n  - [Vercel UI Integration Example](https://voltagent.dev/docs/agents/hooks/#vercel-ui-integration-example)\n  - [Full Conversation Flow Example](https://voltagent.dev/docs/agents/hooks/#full-conversation-flow-example)",
      "metadata": {
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "language": "en",
        "docsearch:language": "en",
        "twitter:card": "summary_large_image",
        "docsearch:docusaurus_tag": "docs-default-current",
        "ogDescription": "Hooks provide points within the agent's execution lifecycle where you can inject custom logic. They allow you to run code before an agent starts processing, after it finishes, before and after it uses a tool, or when tasks are handed off between agents in a multi-agent system.",
        "ogUrl": "https://voltagent.dev/docs/agents/hooks/",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "title": "Hooks | VoltAgent",
        "ogLocale": "en",
        "og:title": "Hooks | VoltAgent",
        "docusaurus_tag": "docs-default-current",
        "description": "Hooks provide points within the agent's execution lifecycle where you can inject custom logic. They allow you to run code before an agent starts processing, after it finishes, before and after it uses a tool, or when tasks are handed off between agents in a multi-agent system.",
        "og:description": "Hooks provide points within the agent's execution lifecycle where you can inject custom logic. They allow you to run code before an agent starts processing, after it finishes, before and after it uses a tool, or when tasks are handed off between agents in a multi-agent system.",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "docusaurus_version": "current",
        "og:image": "https://voltagent.dev/img/social3.png",
        "ogTitle": "Hooks | VoltAgent",
        "generator": "Docusaurus v3.1.1",
        "viewport": "width=device-width, initial-scale=1.0",
        "og:locale": "en",
        "og:url": "https://voltagent.dev/docs/agents/hooks/",
        "docusaurus_locale": "en",
        "docsearch:version": "current",
        "scrapeId": "b1a8db36-935c-4e25-91cf-780f4c794aca",
        "sourceURL": "https://voltagent.dev/docs/agents/hooks/",
        "url": "https://voltagent.dev/docs/agents/hooks/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:50.312Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/utils/message-helpers/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Message Helpers\n\nMessage helpers are utility functions for working with `BaseMessage` content in VoltAgent. Message content can be either a string or an array of content parts (text, image, or file), and these helpers provide type-safe operations for both formats.\n\n## Import [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#import \"Direct link to Import\")\n\n```codeBlockLines_e6Vv\nimport { messageHelpers } from \"@voltagent/core\";\n// Or import individual functions\nimport { isTextContent, extractText, MessageContentBuilder } from \"@voltagent/core/utils\";\n\n```\n\n## Type Guards [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#type-guards \"Direct link to Type Guards\")\n\nType guards determine the format of message content and enable type-safe operations.\n\n### `isTextContent()` [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#istextcontent \"Direct link to istextcontent\")\n\nChecks if content is a string.\n\n```codeBlockLines_e6Vv\nimport { isTextContent } from \"@voltagent/core/utils\";\n\nconst stringContent = \"Hello world\";\nconst arrayContent = [{ type: \"text\", text: \"Hello\" }];\n\nconsole.log(isTextContent(stringContent)); // true\nconsole.log(isTextContent(arrayContent)); // false\n\n```\n\n### `isStructuredContent()` [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#isstructuredcontent \"Direct link to isstructuredcontent\")\n\nChecks if content is an array of content parts.\n\n```codeBlockLines_e6Vv\nimport { isStructuredContent } from \"@voltagent/core/utils\";\n\nconst stringContent = \"Hello world\";\nconst arrayContent = [\\\n  { type: \"text\", text: \"Hello\" },\\\n  { type: \"image\", image: \"data:image/png;base64...\" },\\\n];\n\nconsole.log(isStructuredContent(stringContent)); // false\nconsole.log(isStructuredContent(arrayContent)); // true\n\n```\n\n### `hasTextPart()` [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#hastextpart \"Direct link to hastextpart\")\n\nChecks if content contains any text, regardless of format.\n\n```codeBlockLines_e6Vv\nimport { hasTextPart } from \"@voltagent/core/utils\";\n\nconst stringContent = \"Hello\";\nconst mixedContent = [\\\n  { type: \"text\", text: \"Description\" },\\\n  { type: \"image\", image: \"data...\" },\\\n];\nconst imageOnlyContent = [{ type: \"image\", image: \"data...\" }];\n\nconsole.log(hasTextPart(stringContent)); // true\nconsole.log(hasTextPart(mixedContent)); // true\nconsole.log(hasTextPart(imageOnlyContent)); // false\n\n```\n\n### `hasImagePart()` and `hasFilePart()` [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#hasimagepart-and-hasfilepart \"Direct link to hasimagepart-and-hasfilepart\")\n\nCheck for specific content part types.\n\n```codeBlockLines_e6Vv\nimport { hasImagePart, hasFilePart } from \"@voltagent/core/utils\";\n\nconst content = [\\\n  { type: \"text\", text: \"Check this image:\" },\\\n  { type: \"image\", image: \"data:image/png;base64...\" },\\\n  { type: \"file\", data: \"file content\", mimeType: \"text/plain\" },\\\n];\n\nconsole.log(hasImagePart(content)); // true\nconsole.log(hasFilePart(content)); // true\nconsole.log(hasImagePart(\"text\")); // false\n\n```\n\n## Extractors [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#extractors \"Direct link to Extractors\")\n\nExtractors retrieve specific content types from messages.\n\n### `extractText()` [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#extracttext \"Direct link to extracttext\")\n\nExtracts all text from content, concatenating multiple text parts.\n\n```codeBlockLines_e6Vv\nimport { extractText } from \"@voltagent/core/utils\";\n\n// From string content\nconst text1 = extractText(\"Hello world\");\nconsole.log(text1); // \"Hello world\"\n\n// From structured content\nconst content = [\\\n  { type: \"text\", text: \"Hello \" },\\\n  { type: \"image\", image: \"data...\" },\\\n  { type: \"text\", text: \"world\" },\\\n];\nconst text2 = extractText(content);\nconsole.log(text2); // \"Hello world\"\n\n// From non-text content\nconst imageOnly = [{ type: \"image\", image: \"data...\" }];\nconst text3 = extractText(imageOnly);\nconsole.log(text3); // \"\"\n\n```\n\n### `extractTextParts()` [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#extracttextparts \"Direct link to extracttextparts\")\n\nReturns all text parts as an array, preserving structure.\n\n```codeBlockLines_e6Vv\nimport { extractTextParts } from \"@voltagent/core/utils\";\n\nconst content = [\\\n  { type: \"text\", text: \"First paragraph\" },\\\n  { type: \"image\", image: \"data...\" },\\\n  { type: \"text\", text: \"Second paragraph\" },\\\n];\n\nconst textParts = extractTextParts(content);\nconsole.log(textParts);\n// [\\\n//   { type: \"text\", text: \"First paragraph\" },\\\n//   { type: \"text\", text: \"Second paragraph\" }\\\n// ]\n\n// String content returns array format\nconst stringParts = extractTextParts(\"Hello\");\nconsole.log(stringParts);\n// [{ type: \"text\", text: \"Hello\" }]\n\n```\n\n### `extractImageParts()` and `extractFileParts()` [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#extractimageparts-and-extractfileparts \"Direct link to extractimageparts-and-extractfileparts\")\n\nExtract specific content part types.\n\n```codeBlockLines_e6Vv\nimport { extractImageParts, extractFileParts } from \"@voltagent/core/utils\";\n\nconst content = [\\\n  { type: \"text\", text: \"Files:\" },\\\n  { type: \"image\", image: \"image1.png\" },\\\n  { type: \"file\", data: \"doc.pdf\", mimeType: \"application/pdf\" },\\\n  { type: \"image\", image: \"image2.jpg\" },\\\n];\n\nconst images = extractImageParts(content);\nconsole.log(images.length); // 2\nconsole.log(images[0]); // { type: \"image\", image: \"image1.png\" }\n\nconst files = extractFileParts(content);\nconsole.log(files.length); // 1\nconsole.log(files[0]); // { type: \"file\", data: \"doc.pdf\", mimeType: \"application/pdf\" }\n\n```\n\n## Transformers [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#transformers \"Direct link to Transformers\")\n\nTransformers modify message content while preserving structure.\n\n### `transformTextContent()` [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#transformtextcontent \"Direct link to transformtextcontent\")\n\nApplies a transformation function to all text parts.\n\n```codeBlockLines_e6Vv\nimport { transformTextContent } from \"@voltagent/core/utils\";\n\n// Transform string content\nconst upper1 = transformTextContent(\"hello\", (text) => text.toUpperCase());\nconsole.log(upper1); // \"HELLO\"\n\n// Transform structured content\nconst content = [\\\n  { type: \"text\", text: \"hello\" },\\\n  { type: \"image\", image: \"data...\" },\\\n  { type: \"text\", text: \"world\" },\\\n];\n\nconst upper2 = transformTextContent(content, (text) => text.toUpperCase());\nconsole.log(upper2);\n// [\\\n//   { type: \"text\", text: \"HELLO\" },\\\n//   { type: \"image\", image: \"data...\" },\\\n//   { type: \"text\", text: \"WORLD\" }\\\n// ]\n\n```\n\n### `mapMessageContent()` [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#mapmessagecontent \"Direct link to mapmessagecontent\")\n\nTransforms text content within a complete message object.\n\n```codeBlockLines_e6Vv\nimport { mapMessageContent } from \"@voltagent/core/utils\";\nimport type { BaseMessage } from \"@voltagent/core\";\n\nconst message: BaseMessage = {\n  role: \"user\",\n  content: \"hello world\",\n};\n\nconst loudMessage = mapMessageContent(message, (text) => text.toUpperCase());\nconsole.log(loudMessage);\n// { role: \"user\", content: \"HELLO WORLD\" }\n\n// Works with structured content too\nconst complexMessage: BaseMessage = {\n  role: \"assistant\",\n  content: [\\\n    { type: \"text\", text: \"The answer is\" },\\\n    { type: \"text\", text: \"42\" },\\\n  ],\n};\n\nconst emphasized = mapMessageContent(complexMessage, (text) => `**${text}**`);\nconsole.log(emphasized.content);\n// [\\\n//   { type: \"text\", text: \"**The answer is**\" },\\\n//   { type: \"text\", text: \"**42**\" }\\\n// ]\n\n```\n\n### `filterContentParts()` [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#filtercontentparts \"Direct link to filtercontentparts\")\n\nFilters content parts based on a predicate function.\n\n```codeBlockLines_e6Vv\nimport { filterContentParts } from \"@voltagent/core/utils\";\n\nconst content = [\\\n  { type: \"text\", text: \"Keep this\" },\\\n  { type: \"image\", image: \"remove.png\" },\\\n  { type: \"text\", text: \"Keep this too\" },\\\n  { type: \"file\", data: \"remove.pdf\" },\\\n];\n\n// Keep only text parts\nconst textOnly = filterContentParts(content, (part) => part.type === \"text\");\nconsole.log(textOnly);\n// [\\\n//   { type: \"text\", text: \"Keep this\" },\\\n//   { type: \"text\", text: \"Keep this too\" }\\\n// ]\n\n// If only one text part remains, returns string\nconst singleContent = [\\\n  { type: \"text\", text: \"Only text\" },\\\n  { type: \"image\", image: \"img.png\" },\\\n];\nconst filtered = filterContentParts(singleContent, (part) => part.type === \"text\");\nconsole.log(filtered); // \"Only text\"\n\n```\n\n## Normalizers [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#normalizers \"Direct link to Normalizers\")\n\nNormalizers convert between content formats.\n\n### `normalizeToArray()` [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#normalizetoarray \"Direct link to normalizetoarray\")\n\nConverts any content format to array format.\n\n```codeBlockLines_e6Vv\nimport { normalizeToArray } from \"@voltagent/core/utils\";\n\n// String to array\nconst array1 = normalizeToArray(\"Hello\");\nconsole.log(array1);\n// [{ type: \"text\", text: \"Hello\" }]\n\n// Array remains array\nconst content = [\\\n  { type: \"text\", text: \"Hello\" },\\\n  { type: \"image\", image: \"data...\" },\\\n];\nconst array2 = normalizeToArray(content);\nconsole.log(array2 === content); // true (same reference)\n\n```\n\n### `normalizeContent()` [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#normalizecontent \"Direct link to normalizecontent\")\n\nConverts content to the most compact representation.\n\n```codeBlockLines_e6Vv\nimport { normalizeContent } from \"@voltagent/core/utils\";\n\n// Single text part becomes string\nconst content1 = [{ type: \"text\", text: \"Hello\" }];\nconst normalized1 = normalizeContent(content1);\nconsole.log(normalized1); // \"Hello\"\n\n// Empty array becomes empty string\nconst content2 = [];\nconst normalized2 = normalizeContent(content2);\nconsole.log(normalized2); // \"\"\n\n// Multiple parts remain as array\nconst content3 = [\\\n  { type: \"text\", text: \"Hello\" },\\\n  { type: \"image\", image: \"data...\" },\\\n];\nconst normalized3 = normalizeContent(content3);\nconsole.log(Array.isArray(normalized3)); // true\n\n```\n\n## MessageContentBuilder [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#messagecontentbuilder \"Direct link to MessageContentBuilder\")\n\nA builder class for constructing complex message content.\n\n### Basic Usage [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#basic-usage \"Direct link to Basic Usage\")\n\n```codeBlockLines_e6Vv\nimport { MessageContentBuilder } from \"@voltagent/core/utils\";\n\nconst builder = new MessageContentBuilder();\n\n// Build simple text\nconst simple = builder.addText(\"Hello world\").build();\nconsole.log(simple); // \"Hello world\"\n\n// Build complex content\nbuilder.clear(); // Reset the builder\nconst complex = builder\n  .addText(\"Here's an image:\")\n  .addImage(\"data:image/png;base64,...\")\n  .addText(\"And here's a file:\")\n  .addFile(\"document.pdf\", \"application/pdf\")\n  .build();\n\nconsole.log(Array.isArray(complex)); // true\nconsole.log(complex.length); // 4\n\n```\n\n### Builder Methods [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#builder-methods \"Direct link to Builder Methods\")\n\n```codeBlockLines_e6Vv\nconst builder = new MessageContentBuilder();\n\n// Add various content types\nbuilder\n  .addText(\"Step 1\")\n  .addImage(\"screenshot.png\")\n  .addFile(\"data.csv\", \"text/csv\")\n  .addPart({ type: \"custom\", data: \"...\" }); // Custom parts\n\n// Builder state\nconsole.log(builder.length); // 4\n\n// Build as array (always returns array)\nconst asArray = builder.buildAsArray();\nconsole.log(Array.isArray(asArray)); // true\n\n// Clear and reuse\nbuilder.clear();\nconsole.log(builder.length); // 0\n\n```\n\n## Convenience Functions [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#convenience-functions \"Direct link to Convenience Functions\")\n\nPre-built functions for common operations.\n\n### `addTimestampToMessage()` [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#addtimestamptomessage \"Direct link to addtimestamptomessage\")\n\nAdds timestamps to user messages.\n\n```codeBlockLines_e6Vv\nimport { addTimestampToMessage } from \"@voltagent/core/utils\";\nimport type { BaseMessage } from \"@voltagent/core\";\n\nconst userMessage: BaseMessage = {\n  role: \"user\",\n  content: \"What's the weather?\",\n};\n\n// With custom timestamp\nconst stamped1 = addTimestampToMessage(userMessage, \"10:30:00\");\nconsole.log(stamped1.content); // \"[10:30:00] What's the weather?\"\n\n// With automatic timestamp\nconst stamped2 = addTimestampToMessage(userMessage);\nconsole.log(stamped2.content); // \"[14:23:45] What's the weather?\" (current time)\n\n// Non-user messages are unchanged\nconst assistantMessage: BaseMessage = {\n  role: \"assistant\",\n  content: \"The weather is sunny\",\n};\nconst unchanged = addTimestampToMessage(assistantMessage);\nconsole.log(unchanged.content); // \"The weather is sunny\"\n\n```\n\n### `prependToMessage()` and `appendToMessage()` [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#prependtomessage-and-appendtomessage \"Direct link to prependtomessage-and-appendtomessage\")\n\nAdd text to the beginning or end of message content.\n\n```codeBlockLines_e6Vv\nimport { prependToMessage, appendToMessage } from \"@voltagent/core/utils\";\nimport type { BaseMessage } from \"@voltagent/core\";\n\nconst message: BaseMessage = {\n  role: \"user\",\n  content: \"Execute this\",\n};\n\nconst withPrefix = prependToMessage(message, \"URGENT: \");\nconsole.log(withPrefix.content); // \"URGENT: Execute this\"\n\nconst withSuffix = appendToMessage(message, \" immediately!\");\nconsole.log(withSuffix.content); // \"Execute this immediately!\"\n\n// Works with structured content\nconst structured: BaseMessage = {\n  role: \"assistant\",\n  content: [\\\n    { type: \"text\", text: \"Result\" },\\\n    { type: \"image\", image: \"graph.png\" },\\\n  ],\n};\n\nconst prefixed = prependToMessage(structured, \"Final \");\nconsole.log(prefixed.content[0]); // { type: \"text\", text: \"Final Result\" }\n\n```\n\n### `hasContent()` and `getContentLength()` [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#hascontent-and-getcontentlength \"Direct link to hascontent-and-getcontentlength\")\n\nUtility functions for content inspection.\n\n```codeBlockLines_e6Vv\nimport { hasContent, getContentLength } from \"@voltagent/core/utils\";\nimport type { BaseMessage } from \"@voltagent/core\";\n\n// Check if message has content\nconst empty: BaseMessage = { role: \"user\", content: \"\" };\nconst withText: BaseMessage = { role: \"user\", content: \"Hello\" };\nconst emptyArray: BaseMessage = { role: \"user\", content: [] };\n\nconsole.log(hasContent(empty)); // false\nconsole.log(hasContent(withText)); // true\nconsole.log(hasContent(emptyArray)); // false\n\n// Get content length\nconsole.log(getContentLength(\"Hello\")); // 5 (string length)\nconsole.log(getContentLength([])); // 0 (array length)\nconsole.log(\n  getContentLength([\\\n    { type: \"text\", text: \"Hi\" },\\\n    { type: \"image\", image: \"...\" },\\\n  ])\n); // 2 (array length)\n\n```\n\n## Using with Hooks [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#using-with-hooks \"Direct link to Using with Hooks\")\n\nMessage helpers integrate with agent hooks for message transformation.\n\n```codeBlockLines_e6Vv\nimport { Agent, messageHelpers } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  name: \"Assistant\",\n  description: \"A helpful assistant\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n\n  hooks: {\n    onPrepareMessages: async ({ messages }) => {\n      const timestamp = new Date().toLocaleTimeString();\n\n      // Transform all user messages\n      const enhanced = messages.map((msg) => messageHelpers.addTimestampToMessage(msg, timestamp));\n\n      return { messages: enhanced };\n    },\n  },\n});\n\n```\n\n## API Reference [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#api-reference \"Direct link to API Reference\")\n\n### Type Guards [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#type-guards-1 \"Direct link to Type Guards\")\n\n```codeBlockLines_e6Vv\nfunction isTextContent(content: MessageContent): content is string;\nfunction isStructuredContent(content: MessageContent): content is Array<any>;\nfunction hasTextPart(content: MessageContent): boolean;\nfunction hasImagePart(content: MessageContent): boolean;\nfunction hasFilePart(content: MessageContent): boolean;\n\n```\n\n### Extractors [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#extractors-1 \"Direct link to Extractors\")\n\n```codeBlockLines_e6Vv\nfunction extractText(content: MessageContent): string;\nfunction extractTextParts(content: MessageContent): Array<{ type: \"text\"; text: string }>;\nfunction extractImageParts(content: MessageContent): Array<any>;\nfunction extractFileParts(content: MessageContent): Array<any>;\n\n```\n\n### Transformers [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#transformers-1 \"Direct link to Transformers\")\n\n```codeBlockLines_e6Vv\nfunction transformTextContent(\n  content: MessageContent,\n  transformer: (text: string) => string\n): MessageContent;\n\nfunction mapMessageContent<T extends BaseMessage>(\n  message: T,\n  transformer: (text: string) => string\n): T;\n\nfunction filterContentParts(\n  content: MessageContent,\n  predicate: (part: any) => boolean\n): MessageContent;\n\n```\n\n### Normalizers [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#normalizers-1 \"Direct link to Normalizers\")\n\n```codeBlockLines_e6Vv\nfunction normalizeToArray(content: MessageContent): Array<any>;\nfunction normalizeContent(content: MessageContent): MessageContent;\n\n```\n\n### Builder [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#builder \"Direct link to Builder\")\n\n```codeBlockLines_e6Vv\nclass MessageContentBuilder {\n  addText(text: string): this;\n  addImage(image: string | Uint8Array): this;\n  addFile(file: string | Uint8Array, mimeType?: string): this;\n  addPart(part: any): this;\n  build(): MessageContent;\n  buildAsArray(): Array<any>;\n  clear(): this;\n  get length(): number;\n}\n\n```\n\n### Convenience Functions [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#convenience-functions-1 \"Direct link to Convenience Functions\")\n\n```codeBlockLines_e6Vv\nfunction addTimestampToMessage(message: BaseMessage, timestamp?: string): BaseMessage;\nfunction prependToMessage(message: BaseMessage, prefix: string): BaseMessage;\nfunction appendToMessage(message: BaseMessage, suffix: string): BaseMessage;\nfunction hasContent(message: BaseMessage): boolean;\nfunction getContentLength(content: MessageContent): number;\n\n```\n\n### Combined Export [â€‹](https://voltagent.dev/docs/utils/message-helpers/\\#combined-export \"Direct link to Combined Export\")\n\nAll functions are available through the `messageHelpers` object:\n\n```codeBlockLines_e6Vv\nimport { messageHelpers } from \"@voltagent/core\";\n\n// Access all functions\nmessageHelpers.isTextContent(content);\nmessageHelpers.extractText(content);\nmessageHelpers.MessageContentBuilder;\n// ... etc\n\n```\n\n### Table of Contents\n\n- [Import](https://voltagent.dev/docs/utils/message-helpers/#import)\n- [Type Guards](https://voltagent.dev/docs/utils/message-helpers/#type-guards)\n  - [`isTextContent()`](https://voltagent.dev/docs/utils/message-helpers/#istextcontent)\n  - [`isStructuredContent()`](https://voltagent.dev/docs/utils/message-helpers/#isstructuredcontent)\n  - [`hasTextPart()`](https://voltagent.dev/docs/utils/message-helpers/#hastextpart)\n  - [`hasImagePart()` and `hasFilePart()`](https://voltagent.dev/docs/utils/message-helpers/#hasimagepart-and-hasfilepart)\n- [Extractors](https://voltagent.dev/docs/utils/message-helpers/#extractors)\n  - [`extractText()`](https://voltagent.dev/docs/utils/message-helpers/#extracttext)\n  - [`extractTextParts()`](https://voltagent.dev/docs/utils/message-helpers/#extracttextparts)\n  - [`extractImageParts()` and `extractFileParts()`](https://voltagent.dev/docs/utils/message-helpers/#extractimageparts-and-extractfileparts)\n- [Transformers](https://voltagent.dev/docs/utils/message-helpers/#transformers)\n  - [`transformTextContent()`](https://voltagent.dev/docs/utils/message-helpers/#transformtextcontent)\n  - [`mapMessageContent()`](https://voltagent.dev/docs/utils/message-helpers/#mapmessagecontent)\n  - [`filterContentParts()`](https://voltagent.dev/docs/utils/message-helpers/#filtercontentparts)\n- [Normalizers](https://voltagent.dev/docs/utils/message-helpers/#normalizers)\n  - [`normalizeToArray()`](https://voltagent.dev/docs/utils/message-helpers/#normalizetoarray)\n  - [`normalizeContent()`](https://voltagent.dev/docs/utils/message-helpers/#normalizecontent)\n- [MessageContentBuilder](https://voltagent.dev/docs/utils/message-helpers/#messagecontentbuilder)\n  - [Basic Usage](https://voltagent.dev/docs/utils/message-helpers/#basic-usage)\n  - [Builder Methods](https://voltagent.dev/docs/utils/message-helpers/#builder-methods)\n- [Convenience Functions](https://voltagent.dev/docs/utils/message-helpers/#convenience-functions)\n  - [`addTimestampToMessage()`](https://voltagent.dev/docs/utils/message-helpers/#addtimestamptomessage)\n  - [`prependToMessage()` and `appendToMessage()`](https://voltagent.dev/docs/utils/message-helpers/#prependtomessage-and-appendtomessage)\n  - [`hasContent()` and `getContentLength()`](https://voltagent.dev/docs/utils/message-helpers/#hascontent-and-getcontentlength)\n- [Using with Hooks](https://voltagent.dev/docs/utils/message-helpers/#using-with-hooks)\n- [API Reference](https://voltagent.dev/docs/utils/message-helpers/#api-reference)\n  - [Type Guards](https://voltagent.dev/docs/utils/message-helpers/#type-guards-1)\n  - [Extractors](https://voltagent.dev/docs/utils/message-helpers/#extractors-1)\n  - [Transformers](https://voltagent.dev/docs/utils/message-helpers/#transformers-1)\n  - [Normalizers](https://voltagent.dev/docs/utils/message-helpers/#normalizers-1)\n  - [Builder](https://voltagent.dev/docs/utils/message-helpers/#builder)\n  - [Convenience Functions](https://voltagent.dev/docs/utils/message-helpers/#convenience-functions-1)\n  - [Combined Export](https://voltagent.dev/docs/utils/message-helpers/#combined-export)",
      "metadata": {
        "language": "en",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "docusaurus_locale": "en",
        "og:image": "https://voltagent.dev/img/social3.png",
        "ogTitle": "Message Helpers | VoltAgent",
        "og:locale": "en",
        "docusaurus_version": "current",
        "og:title": "Message Helpers | VoltAgent",
        "twitter:card": "summary_large_image",
        "title": "Message Helpers | VoltAgent",
        "ogDescription": "Message helpers are utility functions for working with BaseMessage content in VoltAgent. Message content can be either a string or an array of content parts (text, image, or file), and these helpers provide type-safe operations for both formats.",
        "docusaurus_tag": "docs-default-current",
        "ogUrl": "https://voltagent.dev/docs/utils/message-helpers/",
        "docsearch:version": "current",
        "viewport": "width=device-width, initial-scale=1.0",
        "og:url": "https://voltagent.dev/docs/utils/message-helpers/",
        "generator": "Docusaurus v3.1.1",
        "docsearch:docusaurus_tag": "docs-default-current",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "docsearch:language": "en",
        "description": "Message helpers are utility functions for working with BaseMessage content in VoltAgent. Message content can be either a string or an array of content parts (text, image, or file), and these helpers provide type-safe operations for both formats.",
        "og:description": "Message helpers are utility functions for working with BaseMessage content in VoltAgent. Message content can be either a string or an array of content parts (text, image, or file), and these helpers provide type-safe operations for both formats.",
        "ogLocale": "en",
        "scrapeId": "96df6897-1b69-4a0f-9263-8b00a22068ed",
        "sourceURL": "https://voltagent.dev/docs/utils/message-helpers/",
        "url": "https://voltagent.dev/docs/utils/message-helpers/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:41.064Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/workflows/hooks/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Workflow Hooks\n\n> Run code at specific moments in your workflow. Perfect for logging, monitoring, and debugging.\n\n## Quick Start [â€‹](https://voltagent.dev/docs/workflows/hooks/\\#quick-start \"Direct link to Quick Start\")\n\n```codeBlockLines_e6Vv\nimport { createWorkflowChain } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\nconst workflow = createWorkflowChain({\n  id: \"order-processing\",\n  input: z.object({ orderId: z.string(), amount: z.number() }),\n  hooks: {\n    onStart: async (state) => {\n      console.log(`Processing order ${state.data.orderId}`);\n    },\n    onEnd: async (state) => {\n      if (state.status === \"completed\") {\n        console.log(`Order ${state.data.orderId} completed!`);\n      } else {\n        console.error(`Order failed: ${state.error}`);\n      }\n    },\n  },\n})\n  .andThen({\n    id: \"validate-order\",\n    execute: async ({ data }) => ({ ...data, validated: true }),\n  })\n  .andThen({\n    id: \"charge-payment\",\n    execute: async ({ data }) => ({ ...data, charged: true }),\n  });\n\nawait workflow.run({ orderId: \"123\", amount: 99.99 });\n// Console output:\n// Processing order 123\n// Order 123 completed!\n\n```\n\n## The Four Hooks [â€‹](https://voltagent.dev/docs/workflows/hooks/\\#the-four-hooks \"Direct link to The Four Hooks\")\n\n### 1\\. onStart [â€‹](https://voltagent.dev/docs/workflows/hooks/\\#1-onstart \"Direct link to 1. onStart\")\n\nRuns once when workflow begins:\n\n```codeBlockLines_e6Vv\nonStart: async (state) => {\n  // state.data = initial input\n  // state.executionId = unique run ID\n  await logger.info(\"Workflow started\", {\n    workflowId: state.workflowId,\n    executionId: state.executionId,\n  });\n};\n\n```\n\n### 2\\. onEnd [â€‹](https://voltagent.dev/docs/workflows/hooks/\\#2-onend \"Direct link to 2. onEnd\")\n\nRuns once when workflow finishes:\n\n```codeBlockLines_e6Vv\nonEnd: async (state) => {\n  // state.status = \"completed\" or \"error\"\n  // state.result = final data (if completed)\n  // state.error = error details (if failed)\n\n  if (state.status === \"error\") {\n    await alertTeam(`Workflow failed: ${state.error}`);\n  }\n};\n\n```\n\n### 3\\. onStepStart [â€‹](https://voltagent.dev/docs/workflows/hooks/\\#3-onstepstart \"Direct link to 3. onStepStart\")\n\nRuns before each step:\n\n```codeBlockLines_e6Vv\nonStepStart: async (state) => {\n  // state.stepId = current step ID\n  // state.data = data going into step\n\n  console.time(`Step ${state.stepId}`);\n};\n\n```\n\n### 4\\. onStepEnd [â€‹](https://voltagent.dev/docs/workflows/hooks/\\#4-onstepend \"Direct link to 4. onStepEnd\")\n\nRuns after each step succeeds:\n\n```codeBlockLines_e6Vv\nonStepEnd: async (state) => {\n  // state.stepId = current step ID\n  // state.data = data coming out of step\n\n  console.timeEnd(`Step ${state.stepId}`);\n};\n\n```\n\n## Common Patterns [â€‹](https://voltagent.dev/docs/workflows/hooks/\\#common-patterns \"Direct link to Common Patterns\")\n\n### Performance Monitoring [â€‹](https://voltagent.dev/docs/workflows/hooks/\\#performance-monitoring \"Direct link to Performance Monitoring\")\n\n```codeBlockLines_e6Vv\nconst performanceHooks = {\n  onStepStart: async (state) => {\n    state.timings = state.timings || {};\n    state.timings[state.stepId] = Date.now();\n  },\n  onStepEnd: async (state) => {\n    const duration = Date.now() - state.timings[state.stepId];\n    await metrics.recordStepDuration(state.stepId, duration);\n  },\n};\n\n```\n\n### Error Tracking [â€‹](https://voltagent.dev/docs/workflows/hooks/\\#error-tracking \"Direct link to Error Tracking\")\n\n```codeBlockLines_e6Vv\nconst errorHooks = {\n  onEnd: async (state) => {\n    if (state.status === \"error\") {\n      await errorTracker.report({\n        workflowId: state.workflowId,\n        executionId: state.executionId,\n        error: state.error,\n        input: state.data,\n      });\n    }\n  },\n};\n\n```\n\n### Audit Logging [â€‹](https://voltagent.dev/docs/workflows/hooks/\\#audit-logging \"Direct link to Audit Logging\")\n\n```codeBlockLines_e6Vv\nconst auditHooks = {\n  onStart: async (state) => {\n    await auditLog.create({\n      action: \"workflow.started\",\n      workflowId: state.workflowId,\n      userId: state.userContext?.get(\"userId\"),\n      timestamp: new Date(),\n    });\n  },\n  onEnd: async (state) => {\n    await auditLog.create({\n      action: \"workflow.completed\",\n      workflowId: state.workflowId,\n      status: state.status,\n      duration: Date.now() - state.startTime,\n    });\n  },\n};\n\n```\n\n### Development Debugging [â€‹](https://voltagent.dev/docs/workflows/hooks/\\#development-debugging \"Direct link to Development Debugging\")\n\n```codeBlockLines_e6Vv\nconst debugHooks = {\n  onStepStart: async (state) => {\n    console.log(`â†’ ${state.stepId}`, state.data);\n  },\n  onStepEnd: async (state) => {\n    console.log(`â† ${state.stepId}`, state.data);\n  },\n  onEnd: async (state) => {\n    if (state.status === \"error\") {\n      console.error(\"Workflow failed:\", state.error);\n      console.error(\"Last data:\", state.data);\n    }\n  },\n};\n\n```\n\n## Hook Execution Order [â€‹](https://voltagent.dev/docs/workflows/hooks/\\#hook-execution-order \"Direct link to Hook Execution Order\")\n\nHere's what happens when you run a workflow:\n\n```codeBlockLines_e6Vv\n1. onStart\n2. onStepStart (step 1)\n3. [Step 1 executes]\n4. onStepEnd (step 1)\n5. onStepStart (step 2)\n6. [Step 2 executes]\n7. onStepEnd (step 2)\n8. onEnd\n\n```\n\nIf a step fails:\n\n```codeBlockLines_e6Vv\n1. onStart\n2. onStepStart (step 1)\n3. [Step 1 fails with error]\n4. onEnd (with error status)\n\n```\n\nNote: `onStepEnd` is skipped for failed steps.\n\n## Best Practices [â€‹](https://voltagent.dev/docs/workflows/hooks/\\#best-practices \"Direct link to Best Practices\")\n\n1. **Keep hooks fast** \\- They run synchronously and can slow down your workflow\n2. **Handle hook errors** \\- Wrap risky operations in try/catch\n3. **Don't modify state** \\- Hooks should observe, not change data\n4. **Use for cross-cutting concerns** \\- Logging, monitoring, analytics\n\n## Real World Example [â€‹](https://voltagent.dev/docs/workflows/hooks/\\#real-world-example \"Direct link to Real World Example\")\n\n```codeBlockLines_e6Vv\nconst productionWorkflow = createWorkflowChain({\n  id: \"user-onboarding\",\n  input: z.object({ userId: z.string(), email: z.string() }),\n  hooks: {\n    onStart: async (state) => {\n      // Track workflow start\n      await analytics.track(\"onboarding.started\", {\n        userId: state.data.userId,\n      });\n    },\n    onStepEnd: async (state) => {\n      // Track each step completion\n      await analytics.track(\"onboarding.step_completed\", {\n        userId: state.data.userId,\n        step: state.stepId,\n      });\n    },\n    onEnd: async (state) => {\n      if (state.status === \"completed\") {\n        // Send welcome email\n        await emailService.send({\n          to: state.data.email,\n          template: \"welcome\",\n        });\n\n        // Track success\n        await analytics.track(\"onboarding.completed\", {\n          userId: state.data.userId,\n        });\n      } else {\n        // Alert team about failure\n        await slack.alert(`Onboarding failed for ${state.data.userId}`);\n      }\n    },\n  },\n})\n  .andThen({ id: \"create-profile\", execute: createUserProfile })\n  .andThen({ id: \"send-verification\", execute: sendVerificationEmail })\n  .andThen({ id: \"assign-defaults\", execute: assignDefaultSettings });\n\n```\n\n## Next Steps [â€‹](https://voltagent.dev/docs/workflows/hooks/\\#next-steps \"Direct link to Next Steps\")\n\n- Learn about [Suspend & Resume](https://voltagent.dev/docs/workflows/suspend-resume/) for human-in-the-loop workflows\n- Explore [Schemas](https://voltagent.dev/docs/workflows/schemas/) for type-safe workflows\n- See [Error Handling](https://voltagent.dev/docs/workflows/overview/) for robust workflows\n- Integrate with [REST API](https://voltagent.dev/docs/api/overview/#workflow-endpoints) to trigger workflows externally\n\n> **Remember**: Hooks are for observing, not changing. Use them to watch your workflow, not control it.\n\n### Table of Contents\n\n- [Quick Start](https://voltagent.dev/docs/workflows/hooks/#quick-start)\n- [The Four Hooks](https://voltagent.dev/docs/workflows/hooks/#the-four-hooks)\n  - [1\\. onStart](https://voltagent.dev/docs/workflows/hooks/#1-onstart)\n  - [2\\. onEnd](https://voltagent.dev/docs/workflows/hooks/#2-onend)\n  - [3\\. onStepStart](https://voltagent.dev/docs/workflows/hooks/#3-onstepstart)\n  - [4\\. onStepEnd](https://voltagent.dev/docs/workflows/hooks/#4-onstepend)\n- [Common Patterns](https://voltagent.dev/docs/workflows/hooks/#common-patterns)\n  - [Performance Monitoring](https://voltagent.dev/docs/workflows/hooks/#performance-monitoring)\n  - [Error Tracking](https://voltagent.dev/docs/workflows/hooks/#error-tracking)\n  - [Audit Logging](https://voltagent.dev/docs/workflows/hooks/#audit-logging)\n  - [Development Debugging](https://voltagent.dev/docs/workflows/hooks/#development-debugging)\n- [Hook Execution Order](https://voltagent.dev/docs/workflows/hooks/#hook-execution-order)\n- [Best Practices](https://voltagent.dev/docs/workflows/hooks/#best-practices)\n- [Real World Example](https://voltagent.dev/docs/workflows/hooks/#real-world-example)\n- [Next Steps](https://voltagent.dev/docs/workflows/hooks/#next-steps)",
      "metadata": {
        "language": "en",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "ogTitle": "Workflow Hooks | VoltAgent",
        "generator": "Docusaurus v3.1.1",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_tag": "docs-default-current",
        "description": "Run code at specific moments in your workflow. Perfect for logging, monitoring, and debugging.",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "docusaurus_version": "current",
        "og:url": "https://voltagent.dev/docs/workflows/hooks/",
        "og:image": "https://voltagent.dev/img/social3.png",
        "ogUrl": "https://voltagent.dev/docs/workflows/hooks/",
        "twitter:card": "summary_large_image",
        "og:locale": "en",
        "docusaurus_locale": "en",
        "docsearch:version": "current",
        "og:description": "Run code at specific moments in your workflow. Perfect for logging, monitoring, and debugging.",
        "title": "Workflow Hooks | VoltAgent",
        "ogDescription": "Run code at specific moments in your workflow. Perfect for logging, monitoring, and debugging.",
        "docsearch:language": "en",
        "ogLocale": "en",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:title": "Workflow Hooks | VoltAgent",
        "scrapeId": "f4314fba-dc1d-4bcd-9287-7dd9e498bb01",
        "sourceURL": "https://voltagent.dev/docs/workflows/hooks/",
        "url": "https://voltagent.dev/docs/workflows/hooks/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:50.479Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/workflows/streaming/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Streaming\n\nWorkflow streaming provides real-time visibility into workflow execution through event emission and token usage tracking.\n\n## Stream Events [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#stream-events \"Direct link to Stream Events\")\n\nEvery workflow execution emits a stream of events. Each event follows this structure:\n\n```codeBlockLines_e6Vv\ninterface WorkflowStreamEvent {\n  type: string; // Event type identifier\n  executionId: string; // Workflow execution ID\n  from: string; // Source step ID or name\n  input?: Record<string, any>; // Input data for the step\n  output?: Record<string, any>; // Output data from the step\n  status: \"pending\" | \"running\" | \"success\" | \"error\" | \"suspended\";\n  userContext?: UserContext; // User context from workflow\n  timestamp: string; // ISO 8601 timestamp\n  stepIndex?: number; // Current step index\n  stepType?: string; // Type of step (agent, func, etc.)\n  metadata?: Record<string, any>; // Additional event metadata\n  error?: any; // Error details if status is \"error\"\n}\n\n```\n\n### Event Types [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#event-types \"Direct link to Event Types\")\n\nWorkflows emit these event types during execution:\n\n| Event Type | Source | When Emitted |\n| --- | --- | --- |\n| `workflow-start` | Workflow | Before first step executes |\n| `workflow-complete` | Workflow | After final step completes |\n| `workflow-error` | Workflow | When workflow fails |\n| `workflow-suspended` | Workflow | When workflow suspends |\n| `step-start` | Step | Before step executes |\n| `step-complete` | Step | After step succeeds |\n| `step-error` | Step | When step fails |\n| `step-suspend` | Step | When step suspends |\n| Custom events | Writer API | When you call `writer.write()` |\n\n### Consuming the Stream [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#consuming-the-stream \"Direct link to Consuming the Stream\")\n\nVoltAgent provides two methods for workflow execution:\n\n- `.run()` \\- Standard execution without streaming\n- `.stream()` \\- Real-time execution with event streaming\n\n```codeBlockLines_e6Vv\n// Method 1: Stream execution for real-time events\nconst stream = workflow.stream(input);\n\n// Iterate through events as they happen\nfor await (const event of stream) {\n  switch (event.type) {\n    case \"step-start\":\n      console.log(`Starting ${event.from} at ${event.timestamp}`);\n      break;\n    case \"step-complete\":\n      console.log(`Completed ${event.from}:`, event.output);\n      break;\n    case \"workflow-suspended\":\n      console.log(`Workflow suspended: ${event.metadata?.reason}`);\n      break;\n    default:\n      console.log(`Event: ${event.type} from ${event.from}`);\n  }\n}\n\n// Get the final result (promise-based)\nconst result = await stream.result;\nconsole.log(\"Final result:\", result);\n\n// Method 2: Standard execution without streaming\nconst execution = await workflow.run(input);\nconsole.log(\"Result:\", execution.result);\n\n```\n\n## Writer API [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#writer-api \"Direct link to Writer API\")\n\nThe `writer` object is available in the execution context of all step types. Use it to emit custom events during step execution.\n\n### Basic Usage [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#basic-usage \"Direct link to Basic Usage\")\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"process-data\",\n  execute: async ({ data, writer }) => {\n    // Emit a custom event\n    writer.write({\n      type: \"processing-started\",\n      metadata: {\n        itemCount: data.items.length,\n        timestamp: Date.now()\n      }\n    });\n\n    const processed = await processItems(data.items);\n\n    writer.write({\n      type: \"processing-complete\",\n      output: { processedCount: processed.length }\n    });\n\n    return processed;\n  }\n})\n\n```\n\n### Writer Methods [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#writer-methods \"Direct link to Writer Methods\")\n\nThe writer provides two methods:\n\n#### `write(event: Partial<WorkflowStreamEvent> & { type: string })` [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#writeevent-partialworkflowstreamevent---type-string- \"Direct link to writeevent-partialworkflowstreamevent---type-string-\")\n\nSynchronously emits a custom event. Required fields:\n\n- `type`: Event type identifier\n\nOptional fields inherit from WorkflowStreamEvent. The writer automatically populates:\n\n- `executionId`: From workflow context\n- `from`: Current step name or ID\n- `timestamp`: Current ISO timestamp\n- `stepIndex`: Current step index\n- `status`: Defaults to \"running\"\n\n#### `pipeFrom(stream: AsyncIterable<any>, options?)` [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#pipefromstream-asynciterableany-options \"Direct link to pipefromstream-asynciterableany-options\")\n\nAsynchronously forwards events from an agent's fullStream to the workflow stream.\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"generate-content\",\n  execute: async ({ data, writer }) => {\n    const agent = new Agent({ /* ... */ });\n    const response = await agent.streamText(prompt);\n\n    if (response.fullStream) {\n      await writer.pipeFrom(response.fullStream, {\n        prefix: \"agent-\",      // Prefix for event types\n        agentId: agent.id,     // Override 'from' field\n        filter: (part) => {    // Filter events\n          return part.type !== \"finish\";\n        }\n      });\n    }\n\n    const text = await response.text;\n    return { ...data, generated: text };\n  }\n})\n\n```\n\nOptions for `pipeFrom`:\n\n- `prefix?: string` \\- Prepended to event types (e.g., \"agent-\" + \"text-delta\" = \"agent-text-delta\")\n- `agentId?: string` \\- Sets the `from` field in events\n- `filter?: (part: any) => boolean` \\- Predicate to filter events\n\n### Event Mapping [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#event-mapping \"Direct link to Event Mapping\")\n\nWhen using `pipeFrom`, agent stream parts are mapped to WorkflowStreamEvent:\n\n| Stream Part Field | WorkflowStreamEvent Field | Condition |\n| --- | --- | --- |\n| `part.type` | `type` | Always (with optional prefix) |\n| `part.args` | `input` | When type is \"tool-call\" |\n| `part.textDelta` | `output` | When type is \"text-delta\" |\n| `part.result` | `output` | When type is \"tool-result\" |\n| `part.usage` | `metadata.usage` | When type is \"finish\" |\n| `part.error` | `metadata.error` | When type is \"error\" |\n\n## Suspend/Resume with Streaming [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#suspendresume-with-streaming \"Direct link to Suspend/Resume with Streaming\")\n\n### Programmatic API [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#programmatic-api \"Direct link to Programmatic API\")\n\nWhen using the programmatic API, **the stream remains continuous across suspend and resume operations**. When a workflow suspends and then resumes, all events continue flowing through the same stream iterator.\n\n#### Continuous Stream Example [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#continuous-stream-example \"Direct link to Continuous Stream Example\")\n\n```codeBlockLines_e6Vv\nconst stream = workflow.stream(input);\n\n// Single iterator handles all events, including after resume\nfor await (const event of stream) {\n  console.log(`Event: ${event.type} from ${event.from}`);\n\n  if (event.type === \"workflow-suspended\") {\n    console.log(\"Workflow suspended, resuming in 3 seconds...\");\n\n    // Resume after delay\n    setTimeout(async () => {\n      await stream.resume({ approved: true });\n    }, 3000);\n\n    // The stream continues - no need for a new iterator!\n    // Events from the resumed execution will flow through this same loop\n  }\n}\n\n// After the loop completes, get the final result\nconst finalResult = await stream.result;\nconsole.log(\"Workflow completed:\", finalResult);\n\n```\n\n#### Key Benefits [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#key-benefits \"Direct link to Key Benefits\")\n\n1. **Single Stream Iterator**: You don't need to create a new stream or iterator after resume\n2. **Continuous Event Flow**: All events (before suspend, during suspend, and after resume) flow through the same stream\n3. **Simplified Code**: No need to manage multiple streams or reconnect after suspension\n4. **Complete History**: The stream captures the entire execution lifecycle\n\n### REST API Streaming [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#rest-api-streaming \"Direct link to REST API Streaming\")\n\nVoltAgent also provides REST API endpoints for streaming workflow execution using Server-Sent Events (SSE). However, the behavior differs from the programmatic API due to VoltAgent's **stateless architecture**.\n\n#### Starting a Stream [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#starting-a-stream \"Direct link to Starting a Stream\")\n\n```codeBlockLines_e6Vv\n// Start workflow stream via REST API\nconst response = await fetch(\"http://localhost:3141/workflows/expense-approval/stream\", {\n  method: \"POST\",\n  headers: { \"Content-Type\": \"application/json\" },\n  body: JSON.stringify({\n    input: {\n      employeeId: \"EMP001\",\n      amount: 750,\n      category: \"travel\",\n      description: \"Conference attendance\",\n    },\n    options: {\n      userId: \"user-123\",\n      executionId: \"exec-456\",\n    },\n  }),\n});\n\n// Process SSE stream\nconst reader = response.body.getReader();\nconst decoder = new TextDecoder();\n\nwhile (true) {\n  const { done, value } = await reader.read();\n  if (done) break;\n\n  const text = decoder.decode(value);\n  // Parse SSE events (lines starting with \"data: \")\n  const lines = text.split(\"\\n\");\n  for (const line of lines) {\n    if (line.startsWith(\"data: \")) {\n      const event = JSON.parse(line.slice(6));\n      console.log(`[${event.type}] ${event.from}`, event);\n\n      if (event.type === \"workflow-suspended\") {\n        console.log(\"Workflow suspended - stream will close\");\n        // Stream closes here - stateless architecture\n      }\n    }\n  }\n}\n\n```\n\n#### Stateless Architecture: Important Differences [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#stateless-architecture-important-differences \"Direct link to Stateless Architecture: Important Differences\")\n\nDue to VoltAgent's stateless design, REST API streaming behaves differently from the programmatic API:\n\n1. **Initial Execution**: Stream events via SSE until completion or suspension\n2. **On Suspension**: SSE stream closes (server doesn't maintain stream state)\n3. **Resume Execution**: Returns complete result via standard HTTP response (not streamed)\n\n```codeBlockLines_e6Vv\n// After suspension, resume via separate endpoint\nconst resumeResponse = await fetch(\n  \"http://localhost:3141/workflows/expense-approval/executions/exec-456/resume\",\n  {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify({\n      resumeData: {\n        approved: true,\n        managerId: \"MGR001\",\n        comments: \"Approved for conference\",\n      },\n    }),\n  }\n);\n\n// Resume returns complete result (not streamed)\nconst result = await resumeResponse.json();\nconsole.log(\"Final result:\", result);\n// {\n//   status: \"completed\",\n//   result: { status: \"approved\", approvedBy: \"MGR001\", ... },\n//   usage: { totalTokens: 450, ... }\n// }\n\n```\n\n#### Comparison: Programmatic vs REST API [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#comparison-programmatic-vs-rest-api \"Direct link to Comparison: Programmatic vs REST API\")\n\n| Feature | Programmatic API | REST API |\n| --- | --- | --- |\n| Initial execution | Streamed | Streamed via SSE |\n| Suspension handling | Stream continues | Stream closes |\n| Resume behavior | Same stream continues | Returns complete result |\n| State management | In-memory (stateful) | Stateless |\n| Use case | Long-running processes | Request-response patterns |\n\n#### Complete REST API Example [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#complete-rest-api-example \"Direct link to Complete REST API Example\")\n\nHere's a complete example handling the full lifecycle:\n\n```codeBlockLines_e6Vv\nasync function executeWorkflowWithREST() {\n  const apiUrl = \"http://localhost:3141\";\n  const workflowId = \"expense-approval\";\n  let executionId: string | null = null;\n\n  // 1. Start streaming execution\n  console.log(\"Starting workflow stream...\");\n  const streamResponse = await fetch(`${apiUrl}/workflows/${workflowId}/stream`, {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify({\n      input: {\n        employeeId: \"EMP001\",\n        amount: 750,\n        category: \"travel\",\n        description: \"Conference attendance\",\n      },\n      options: {\n        userId: \"user-123\",\n      },\n    }),\n  });\n\n  // 2. Process stream until suspension\n  const reader = streamResponse.body!.getReader();\n  const decoder = new TextDecoder();\n  let suspended = false;\n\n  while (true) {\n    const { done, value } = await reader.read();\n    if (done) break;\n\n    const chunk = decoder.decode(value);\n    const lines = chunk.split(\"\\n\");\n\n    for (const line of lines) {\n      if (line.startsWith(\"data: \")) {\n        const event = JSON.parse(line.slice(6));\n        console.log(`Event: ${event.type}`);\n\n        if (!executionId && event.executionId) {\n          executionId = event.executionId;\n        }\n\n        if (event.type === \"workflow-suspended\") {\n          suspended = true;\n          console.log(\"Workflow suspended, stream closed\");\n        }\n      }\n    }\n  }\n\n  // 3. If suspended, resume after approval\n  if (suspended && executionId) {\n    console.log(\"Getting manager approval...\");\n    await new Promise((resolve) => setTimeout(resolve, 2000)); // Simulate delay\n\n    console.log(\"Resuming workflow...\");\n    const resumeResponse = await fetch(\n      `${apiUrl}/workflows/${workflowId}/executions/${executionId}/resume`,\n      {\n        method: \"POST\",\n        headers: { \"Content-Type\": \"application/json\" },\n        body: JSON.stringify({\n          resumeData: {\n            approved: true,\n            managerId: \"MGR001\",\n            comments: \"Approved for conference\",\n            adjustedAmount: 700,\n          },\n        }),\n      }\n    );\n\n    const result = await resumeResponse.json();\n    console.log(\"Workflow completed:\", result);\n    return result;\n  }\n}\n\n```\n\n#### Current Limitations and Future Development [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#current-limitations-and-future-development \"Direct link to Current Limitations and Future Development\")\n\nCurrently, the REST API does not support continuous streaming across suspend/resume cycles. This is a known limitation that may be addressed in future releases.\n\n**Current Behavior:**\n\n- SSE stream closes when workflow suspends\n- Resume returns complete result without streaming\n- No WebSocket-based continuous streaming yet\n\n**Planned Enhancement:**\nContinuous streaming across suspend/resume cycles via WebSocket is being considered for implementation. This would provide:\n\n- Persistent connection across workflow lifecycle\n- Real-time events during resume execution\n- Unified stream for complete workflow history\n\n**Contributing:**\nIf you need continuous streaming across suspend/resume in the REST API, please:\n\n1. Open a GitHub issue at [github.com/VoltAgent/voltagent/issues](https://github.com/VoltAgent/voltagent/issues)\n2. Describe your use case and requirements\n3. Consider contributing to the implementation\n\nFor now, use the programmatic API directly if you need continuous streaming across suspend/resume cycles.\n\n### Suspend/Resume Event Flow [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#suspendresume-event-flow \"Direct link to Suspend/Resume Event Flow\")\n\n```codeBlockLines_e6Vv\n// Example workflow with suspension\nconst workflow = createWorkflowChain(config)\n  .andThen({\n    id: \"check-approval\",\n    execute: async ({ data, suspend, resumeData }) => {\n      if (!resumeData) {\n        // First execution - suspend for approval\n        await suspend(\"Approval required\", { requestId: data.id });\n      }\n      // After resume - continue with resumeData\n      return { ...data, approved: resumeData.approved };\n    },\n  })\n  .andThen({\n    id: \"process\",\n    execute: async ({ data }) => {\n      // This step executes after resume\n      return processApprovedData(data);\n    },\n  });\n\n// Stream captures entire lifecycle\nconst stream = workflow.stream({ id: \"123\", amount: 1000 });\n\nfor await (const event of stream) {\n  console.log(event.type);\n  // Output sequence:\n  // 1. \"workflow-start\"\n  // 2. \"step-start\" (check-approval)\n  // 3. \"workflow-suspended\"\n  // --- resume called ---\n  // 4. \"step-complete\" (check-approval)\n  // 5. \"step-start\" (process)\n  // 6. \"step-complete\" (process)\n  // 7. \"workflow-complete\"\n\n  if (event.type === \"workflow-suspended\") {\n    await stream.resume({ approved: true });\n  }\n}\n\n```\n\n## Usage Tracking [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#usage-tracking \"Direct link to Usage Tracking\")\n\nWorkflows automatically track token usage from `andAgent` steps. The accumulated usage is available on the execution result:\n\n```codeBlockLines_e6Vv\nconst execution = await workflow.run(input);\n\nconsole.log(execution.usage);\n// {\n//   promptTokens: 250,\n//   completionTokens: 150,\n//   totalTokens: 400\n// }\n\n```\n\n### Accumulation Rules [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#accumulation-rules \"Direct link to Accumulation Rules\")\n\n- Only `andAgent` steps contribute to usage\n- Custom agent calls in `andThen` steps are not tracked\n- Usage accumulates across all andAgent executions\n- Default values are 0 if no agents are used\n\n### Accessing Usage in Steps [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#accessing-usage-in-steps \"Direct link to Accessing Usage in Steps\")\n\nThe accumulated usage is available in the state:\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"check-usage\",\n  execute: async ({ data, state }) => {\n    if (state.usage.totalTokens > 1000) {\n      console.log(\"High token usage:\", state.usage.totalTokens);\n    }\n    return data;\n  }\n})\n\n```\n\n## Implementation Patterns [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#implementation-patterns \"Direct link to Implementation Patterns\")\n\n### Progress Monitoring [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#progress-monitoring \"Direct link to Progress Monitoring\")\n\nTrack progress through multi-step operations:\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"batch-processor\",\n  execute: async ({ data, writer }) => {\n    const items = data.items;\n    const results = [];\n\n    for (let i = 0; i < items.length; i++) {\n      writer.write({\n        type: \"batch-progress\",\n        metadata: {\n          current: i + 1,\n          total: items.length,\n          percentage: ((i + 1) / items.length) * 100\n        }\n      });\n\n      results.push(await processItem(items[i]));\n    }\n\n    return { ...data, results };\n  }\n})\n\n```\n\n### Debugging Data Flow [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#debugging-data-flow \"Direct link to Debugging Data Flow\")\n\nEmit checkpoint events to trace data transformations:\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"transform\",\n  execute: async ({ data, writer }) => {\n    writer.write({\n      type: \"debug-checkpoint\",\n      metadata: {\n        stepName: \"transform\",\n        inputKeys: Object.keys(data),\n        inputSize: JSON.stringify(data).length\n      }\n    });\n\n    const transformed = transformData(data);\n\n    writer.write({\n      type: \"debug-checkpoint\",\n      metadata: {\n        stepName: \"transform\",\n        outputKeys: Object.keys(transformed),\n        outputSize: JSON.stringify(transformed).length\n      }\n    });\n\n    return transformed;\n  }\n})\n\n```\n\n### Cost Tracking [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#cost-tracking \"Direct link to Cost Tracking\")\n\nMonitor token usage and calculate costs:\n\n```codeBlockLines_e6Vv\nconst workflow = createWorkflowChain(config)\n  .andAgent(prompt1, agent1, { schema: schema1 })\n  .andAgent(prompt2, agent2, { schema: schema2 })\n  .andThen({\n    id: \"calculate-cost\",\n    execute: async ({ data, state }) => {\n      const costPerToken = 0.0001; // Example rate\n      const totalCost = state.usage.totalTokens * costPerToken;\n\n      return {\n        ...data,\n        tokenUsage: state.usage,\n        estimatedCost: totalCost,\n      };\n    },\n  });\n\nconst execution = await workflow.run(input);\n\n// Final usage and cost\nconsole.log(\"Total tokens:\", execution.usage.totalTokens);\nconsole.log(\"Estimated cost:\", execution.result.estimatedCost);\n\n```\n\n### Real-time UI Updates [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#real-time-ui-updates \"Direct link to Real-time UI Updates\")\n\nStream events to a WebSocket for live UI updates:\n\n```codeBlockLines_e6Vv\nasync function executeWithLiveUpdates(workflow, input, ws) {\n  const stream = workflow.stream(input);\n\n  // Send events to WebSocket client\n  for await (const event of stream) {\n    ws.send(\n      JSON.stringify({\n        type: \"workflow-event\",\n        event: event,\n      })\n    );\n\n    // Handle specific events\n    if (event.type === \"step-complete\") {\n      ws.send(\n        JSON.stringify({\n          type: \"step-progress\",\n          completed: event.stepIndex + 1,\n          total: workflow.steps.length,\n        })\n      );\n    }\n\n    // Handle suspension for user approval\n    if (event.type === \"workflow-suspended\") {\n      ws.send(\n        JSON.stringify({\n          type: \"approval-required\",\n          suspendData: event.metadata?.suspendData,\n        })\n      );\n\n      // Wait for approval from client\n      // In real app, this would be triggered by client message\n      ws.on(\"message\", async (message) => {\n        const data = JSON.parse(message);\n        if (data.type === \"approve\") {\n          await stream.resume(data.resumeData);\n        }\n      });\n    }\n  }\n\n  return await stream.result;\n}\n\n```\n\n## Technical Constraints [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#technical-constraints \"Direct link to Technical Constraints\")\n\n### Stream Ordering [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#stream-ordering \"Direct link to Stream Ordering\")\n\nEvents are emitted in execution order through a central `WorkflowStreamController`. This ensures:\n\n- Events maintain chronological order\n- Parent events precede child events\n- Custom events appear between step-start and step-complete\n\n### Memory Considerations [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#memory-considerations \"Direct link to Memory Considerations\")\n\nThe stream buffers all events until consumed. For long-running workflows:\n\n- Consume events as they're generated\n- Avoid storing large objects in event metadata\n- Use event filtering when piping agent streams\n\n### Error Handling [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#error-handling \"Direct link to Error Handling\")\n\nStream consumption continues even if individual events fail to process:\n\n```codeBlockLines_e6Vv\nfor await (const event of execution.stream) {\n  try {\n    await processEvent(event);\n  } catch (error) {\n    console.error(`Failed to process event ${event.type}:`, error);\n    // Stream continues\n  }\n}\n\n```\n\n### Async Iterator Behavior [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#async-iterator-behavior \"Direct link to Async Iterator Behavior\")\n\nThe stream is an async iterator that:\n\n- Yields events as they're emitted\n- Completes when the workflow finishes (success or error)\n- **Remains open during suspension** \\- continues after resume\n- Cannot be restarted once consumed\n- Maintains event order across suspend/resume cycles\n\n## API Reference [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#api-reference \"Direct link to API Reference\")\n\n### WorkflowExecutionResult [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#workflowexecutionresult \"Direct link to WorkflowExecutionResult\")\n\nReturned by `.run()` method - standard execution without streaming:\n\n```codeBlockLines_e6Vv\ninterface WorkflowExecutionResult<RESULT_SCHEMA, RESUME_SCHEMA> {\n  executionId: string;\n  workflowId: string;\n  startAt: Date;\n  endAt: Date;\n  status: \"completed\" | \"suspended\" | \"error\";\n  result: z.infer<RESULT_SCHEMA> | null;\n  usage: UsageInfo;\n  suspension?: WorkflowSuspensionMetadata;\n  error?: unknown;\n  resume: (\n    input: z.infer<RESUME_SCHEMA>,\n    options?: { stepId?: string }\n  ) => Promise<WorkflowExecutionResult<RESULT_SCHEMA, RESUME_SCHEMA>>;\n}\n\n```\n\n### WorkflowStreamResult [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#workflowstreamresult \"Direct link to WorkflowStreamResult\")\n\nReturned by `.stream()` method - real-time streaming execution:\n\n```codeBlockLines_e6Vv\ninterface WorkflowStreamResult<RESULT_SCHEMA, RESUME_SCHEMA>\n  extends AsyncIterable<WorkflowStreamEvent> {\n  executionId: string;\n  workflowId: string;\n  startAt: Date;\n  // Promise-based fields that resolve when execution completes\n  endAt: Promise<Date>;\n  status: Promise<\"completed\" | \"suspended\" | \"error\">;\n  result: Promise<z.infer<RESULT_SCHEMA> | null>;\n  suspension: Promise<WorkflowSuspensionMetadata | undefined>;\n  error: Promise<unknown | undefined>;\n  usage: Promise<UsageInfo>;\n  // Resume continues with the same stream\n  resume: (\n    input: z.infer<RESUME_SCHEMA>\n  ) => Promise<WorkflowStreamResult<RESULT_SCHEMA, RESUME_SCHEMA>>;\n  abort: () => void;\n}\n\n```\n\n### Key Differences [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#key-differences \"Direct link to Key Differences\")\n\n| Feature | `.run()` | `.stream()` |\n| --- | --- | --- |\n| Returns | `WorkflowExecutionResult` | `WorkflowStreamResult` |\n| Event streaming | No | Yes (AsyncIterable) |\n| Field resolution | Immediate | Promise-based |\n| Use case | Simple execution | Real-time monitoring |\n| Resume behavior | New execution | Same stream continues |\n\n### UsageInfo [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#usageinfo \"Direct link to UsageInfo\")\n\n```codeBlockLines_e6Vv\ninterface UsageInfo {\n  promptTokens: number;\n  completionTokens: number;\n  totalTokens: number;\n}\n\n```\n\n### WorkflowStreamWriter [â€‹](https://voltagent.dev/docs/workflows/streaming/\\#workflowstreamwriter \"Direct link to WorkflowStreamWriter\")\n\n```codeBlockLines_e6Vv\ninterface WorkflowStreamWriter {\n  write(event: Partial<WorkflowStreamEvent> & { type: string }): void;\n\n  pipeFrom(\n    fullStream: AsyncIterable<any>,\n    options?: {\n      prefix?: string;\n      agentId?: string;\n      filter?: (part: any) => boolean;\n    }\n  ): Promise<void>;\n}\n\n```\n\n### Table of Contents\n\n- [Stream Events](https://voltagent.dev/docs/workflows/streaming/#stream-events)\n  - [Event Types](https://voltagent.dev/docs/workflows/streaming/#event-types)\n  - [Consuming the Stream](https://voltagent.dev/docs/workflows/streaming/#consuming-the-stream)\n- [Writer API](https://voltagent.dev/docs/workflows/streaming/#writer-api)\n  - [Basic Usage](https://voltagent.dev/docs/workflows/streaming/#basic-usage)\n  - [Writer Methods](https://voltagent.dev/docs/workflows/streaming/#writer-methods)\n  - [Event Mapping](https://voltagent.dev/docs/workflows/streaming/#event-mapping)\n- [Suspend/Resume with Streaming](https://voltagent.dev/docs/workflows/streaming/#suspendresume-with-streaming)\n  - [Programmatic API](https://voltagent.dev/docs/workflows/streaming/#programmatic-api)\n  - [REST API Streaming](https://voltagent.dev/docs/workflows/streaming/#rest-api-streaming)\n  - [Suspend/Resume Event Flow](https://voltagent.dev/docs/workflows/streaming/#suspendresume-event-flow)\n- [Usage Tracking](https://voltagent.dev/docs/workflows/streaming/#usage-tracking)\n  - [Accumulation Rules](https://voltagent.dev/docs/workflows/streaming/#accumulation-rules)\n  - [Accessing Usage in Steps](https://voltagent.dev/docs/workflows/streaming/#accessing-usage-in-steps)\n- [Implementation Patterns](https://voltagent.dev/docs/workflows/streaming/#implementation-patterns)\n  - [Progress Monitoring](https://voltagent.dev/docs/workflows/streaming/#progress-monitoring)\n  - [Debugging Data Flow](https://voltagent.dev/docs/workflows/streaming/#debugging-data-flow)\n  - [Cost Tracking](https://voltagent.dev/docs/workflows/streaming/#cost-tracking)\n  - [Real-time UI Updates](https://voltagent.dev/docs/workflows/streaming/#real-time-ui-updates)\n- [Technical Constraints](https://voltagent.dev/docs/workflows/streaming/#technical-constraints)\n  - [Stream Ordering](https://voltagent.dev/docs/workflows/streaming/#stream-ordering)\n  - [Memory Considerations](https://voltagent.dev/docs/workflows/streaming/#memory-considerations)\n  - [Error Handling](https://voltagent.dev/docs/workflows/streaming/#error-handling)\n  - [Async Iterator Behavior](https://voltagent.dev/docs/workflows/streaming/#async-iterator-behavior)\n- [API Reference](https://voltagent.dev/docs/workflows/streaming/#api-reference)\n  - [WorkflowExecutionResult](https://voltagent.dev/docs/workflows/streaming/#workflowexecutionresult)\n  - [WorkflowStreamResult](https://voltagent.dev/docs/workflows/streaming/#workflowstreamresult)\n  - [Key Differences](https://voltagent.dev/docs/workflows/streaming/#key-differences)\n  - [UsageInfo](https://voltagent.dev/docs/workflows/streaming/#usageinfo)\n  - [WorkflowStreamWriter](https://voltagent.dev/docs/workflows/streaming/#workflowstreamwriter)",
      "metadata": {
        "description": "Workflow streaming provides real-time visibility into workflow execution through event emission and token usage tracking.",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "og:description": "Workflow streaming provides real-time visibility into workflow execution through event emission and token usage tracking.",
        "ogDescription": "Workflow streaming provides real-time visibility into workflow execution through event emission and token usage tracking.",
        "docsearch:language": "en",
        "og:title": "Streaming | VoltAgent",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "ogLocale": "en",
        "generator": "Docusaurus v3.1.1",
        "docusaurus_tag": "docs-default-current",
        "docsearch:version": "current",
        "docsearch:docusaurus_tag": "docs-default-current",
        "language": "en",
        "og:locale": "en",
        "docusaurus_locale": "en",
        "docusaurus_version": "current",
        "og:url": "https://voltagent.dev/docs/workflows/streaming/",
        "viewport": "width=device-width, initial-scale=1.0",
        "ogTitle": "Streaming | VoltAgent",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "ogUrl": "https://voltagent.dev/docs/workflows/streaming/",
        "twitter:card": "summary_large_image",
        "title": "Streaming | VoltAgent",
        "og:image": "https://voltagent.dev/img/social3.png",
        "scrapeId": "3d8ad526-f932-460c-8146-5003e0beab45",
        "sourceURL": "https://voltagent.dev/docs/workflows/streaming/",
        "url": "https://voltagent.dev/docs/workflows/streaming/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:56.568Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/providers/xsai/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# xsAI Provider ( `@voltagent/xsai`)\n\nThe xsAI Provider acts as a versatile connector between VoltAgent and any OpenAI-compatible API endpoint. It leverages the [`xsai`](https://www.npmjs.com/package/xsai) library, providing a unified interface for interacting with various services like OpenAI, Groq, Together AI, Anyscale Endpoints, Mistral AI (via compatible endpoints), and more.\n\n**Key Characteristics:**\n\n- **OpenAI Compatibility:** Designed to work seamlessly with APIs adhering to the OpenAI specification.\n- **Endpoint Flexibility:** Allows specifying a custom `baseURL`, enabling connection to various self-hosted or alternative LLM providers.\n- **Full Functionality:** Supports text generation, object generation, streaming for both, and robust tool usage.\n- **Dynamic Imports:** Uses dynamic imports for the `xsai` library, potentially reducing initial load times.\n\n## Installation [â€‹](https://voltagent.dev/docs/providers/xsai/\\#installation \"Direct link to Installation\")\n\n- npm\n- yarn\n- pnpm\n\n```codeBlockLines_e6Vv\nnpm install @voltagent/core @voltagent/xsai xsai zod\n\n```\n\n_Note: `xsai` is a required peer dependency. `zod` is needed for `generateObject` and `streamObject`._\n\n## Configuration [â€‹](https://voltagent.dev/docs/providers/xsai/\\#configuration \"Direct link to Configuration\")\n\nThe `XSAIProvider` requires an API key compatible with the target endpoint.\n\n```codeBlockLines_e6Vv\nimport { XSAIProvider } from \"@voltagent/xsai\";\n\n// Example using OpenAI API key from environment variables\nconst openaiProvider = new XSAIProvider({\n  apiKey: process.env.OPENAI_API_KEY!, // Assumes OPENAI_API_KEY is set\n});\n\n// Example connecting to a different OpenAI-compatible endpoint (like Groq)\nconst groqProvider = new XSAIProvider({\n  apiKey: process.env.GROQ_API_KEY!, // Assumes GROQ_API_KEY is set\n  baseURL: \"https://api.groq.com/openai/v1/\", // Groq's OpenAI-compatible endpoint\n});\n\n// Example connecting to a local endpoint (like Ollama with an OpenAI adapter)\nconst localProvider = new XSAIProvider({\n  apiKey: \"ollama\", // Often not required or a placeholder for local models\n  baseURL: \"http://localhost:11434/v1/\", // Default Ollama endpoint\n});\n\n```\n\n- `apiKey`: Your API key for the service.\n- `baseURL` (Optional): The base URL of the OpenAI-compatible API endpoint. Defaults to `https://api.openai.com/v1/`.\n\n## Full Runnable Example [â€‹](https://voltagent.dev/docs/providers/xsai/\\#full-runnable-example \"Direct link to Full Runnable Example\")\n\nFor a complete, runnable example demonstrating basic use with OpenAI, please see:\n\n- **xsAI (with OpenAI):** [`examples/with-xsai`](https://github.com/VoltAgent/voltagent/tree/main/examples/with-xsai)\n\n## Usage [â€‹](https://voltagent.dev/docs/providers/xsai/\\#usage \"Direct link to Usage\")\n\nInstantiate your `Agent` with the configured `XSAIProvider`.\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { XSAIProvider } from \"@voltagent/xsai\";\n\n// Using OpenAI configuration from above\nconst XSAIProvider = new XSAIProvider({ apiKey: process.env.OPENAI_API_KEY! });\n\nconst agent = new Agent({\n  name: \"Compatible Agent\",\n  instructions: \"An agent using an OpenAI-compatible API via xsAI\",\n  llm: XSAIProvider,\n  // Model identifier specific to the target API (e.g., OpenAI, Groq, local)\n  model: \"gpt-4o-mini\",\n});\n\n// Example call\nasync function run() {\n  const response = await agent.generateText(\"What is the capital of Canada?\");\n  console.log(response.text);\n}\n\nrun();\n\n```\n\n## Supported Methods [â€‹](https://voltagent.dev/docs/providers/xsai/\\#supported-methods \"Direct link to Supported Methods\")\n\n- **`generateText`**: Supported. Can include tool usage.\n- **`streamText`**: Supported. Can include tool usage streaming.\n- **`generateObject`**: Supported. Uses the underlying API's JSON mode if available.\n- **`streamObject`**: Supported. Streams partial JSON object updates.\n- **Tool Usage:** Supported via the `tools` parameter in `generateText` and `streamText`.\n\n## Multi-modal Support [â€‹](https://voltagent.dev/docs/providers/xsai/\\#multi-modal-support \"Direct link to Multi-modal Support\")\n\nâš ï¸ **Conditional Support.**\n\nThe `@voltagent/xsai` provider will pass multi-modal `BaseMessage` structures (containing text and image parts in the `content` array) to the underlying xsAI functions.\n\nxsAI cannot verify that the model you use is multimodal, so you must confirm this before using it.\n\nRefer to the [Multi-modal Agents](https://voltagent.dev/docs/agents/multi-modal/) guide for details on configuring and using multi-modal models.\n\n```codeBlockLines_e6Vv\n// Example: Sending multi-modal input\nconst messages = [\\\n  {\\\n    role: \"user\",\\\n    content: [\\\n      { type: \"text\", text: \"Describe this image:\" },\\\n      { type: \"image\", image: \"data:image/png;base64,...\" },\\\n    ],\\\n  },\\\n];\n\nconst response = await agent.generateText(messages);\n\n```\n\n## Model Selection & Options [â€‹](https://voltagent.dev/docs/providers/xsai/\\#model-selection--options \"Direct link to Model Selection & Options\")\n\nThe `model` property during `Agent` instantiation should be the specific model identifier recognized by the target API endpoint (e.g., `'gpt-4o-mini'` for OpenAI, `'llama3-70b-8192'` for Groq, etc.).\n\nYou can pass provider-specific options (like `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, etc.) compatible with the OpenAI API specification using the `provider` key in the method options.\n\n```codeBlockLines_e6Vv\nconst response = await agent.generateText(\"Tell me a joke.\", {\n  provider: {\n    temperature: 0.9,\n    max_tokens: 100,\n    // Other OpenAI-compatible parameters\n  },\n});\n\n```\n\nRefer to the API documentation of your specific endpoint provider (e.g., [OpenAI API Reference](https://platform.openai.com/docs/api-reference/chat/create)) for available parameters.\n\n## Code Examples [â€‹](https://voltagent.dev/docs/providers/xsai/\\#code-examples \"Direct link to Code Examples\")\n\n### Text Generation ( `generateText`) [â€‹](https://voltagent.dev/docs/providers/xsai/\\#text-generation-generatetext \"Direct link to text-generation-generatetext\")\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { XSAIProvider } from \"@voltagent/xsai\";\n\nasync function main() {\n  // Assumes OPENAI_API_KEY is set\n  const provider = new XSAIProvider({ apiKey: process.env.OPENAI_API_KEY! });\n\n  const agent = new Agent({\n    name: \"xsAI Text Agent\",\n    instructions: \"Generates text using an OpenAI-compatible API\",\n    llm: provider,\n    model: \"gpt-4o-mini\",\n  });\n\n  const prompt = \"Explain the concept of Large Language Models simply.\";\n\n  try {\n    const response = await agent.generateText(prompt);\n    console.log(`Agent response to \"${prompt}\":`);\n    console.log(response.text);\n    console.log(\"Usage:\", response.usage);\n    console.log(\"Finish Reason:\", response.finishReason);\n  } catch (error) {\n    console.error(\"Error generating text:\", error);\n  }\n}\n\nmain();\n\n```\n\n### Streaming Text ( `streamText`) [â€‹](https://voltagent.dev/docs/providers/xsai/\\#streaming-text-streamtext \"Direct link to streaming-text-streamtext\")\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { XSAIProvider } from \"@voltagent/xsai\";\n\nasync function main() {\n  const provider = new XSAIProvider({ apiKey: process.env.OPENAI_API_KEY! });\n\n  const agent = new Agent({\n    name: \"xsAI Streaming Agent\",\n    instructions: \"Streams text using an OpenAI-compatible API\",\n    llm: provider,\n    model: \"gpt-4o-mini\",\n  });\n\n  const prompt = \"Write a short paragraph about the future of AI.\";\n\n  try {\n    const streamResponse = await agent.streamText(prompt);\n\n    console.log(`Streaming agent response to \"${prompt}\":`);\n    for await (const chunk of streamResponse.textStream) {\n      process.stdout.write(chunk);\n    }\n    console.log(\"\\n--- Stream Finished ---\");\n    // Usage and finish reason might be available via callbacks\n  } catch (error) {\n    console.error(\"Error streaming text:\", error);\n  }\n}\n\nmain();\n\n```\n\n### Generating Structured Objects ( `generateObject`) [â€‹](https://voltagent.dev/docs/providers/xsai/\\#generating-structured-objects-generateobject \"Direct link to generating-structured-objects-generateobject\")\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { XSAIProvider } from \"@voltagent/xsai\";\nimport { z } from \"zod\";\n\nconst recipeSchema = z.object({\n  dishName: z.string(),\n  ingredients: z.array(z.object({ name: z.string(), quantity: z.string() })),\n  steps: z.array(z.string()),\n});\n\nasync function main() {\n  const provider = new XSAIProvider({ apiKey: process.env.OPENAI_API_KEY! });\n\n  const agent = new Agent({\n    name: \"xsAI Object Agent\",\n    instructions: \"Generates structured objects\",\n    llm: provider,\n    model: \"gpt-4o\", // Use a model known for good JSON output\n  });\n\n  const prompt = \"Generate a simple recipe for pancakes as a JSON object.\";\n\n  try {\n    const response = await agent.generateObject(prompt, recipeSchema);\n    console.log(\"Generated Object:\");\n    console.log(JSON.stringify(response.object, null, 2));\n    console.log(\"Usage:\", response.usage);\n    console.log(\"Finish Reason:\", response.finishReason);\n  } catch (error) {\n    console.error(\"Error generating object:\", error);\n  }\n}\n\nmain();\n\n```\n\n### Streaming Structured Objects ( `streamObject`) [â€‹](https://voltagent.dev/docs/providers/xsai/\\#streaming-structured-objects-streamobject \"Direct link to streaming-structured-objects-streamobject\")\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { XSAIProvider } from \"@voltagent/xsai\";\nimport { z } from \"zod\";\n\nconst travelPlanSchema = z.object({\n  destination: z.string(),\n  durationDays: z.number().int(),\n  activities: z.array(z.string()),\n  budget: z.string().optional(),\n});\n\nasync function main() {\n  const provider = new XSAIProvider({ apiKey: process.env.OPENAI_API_KEY! });\n\n  const agent = new Agent({\n    name: \"xsAI Object Streaming Agent\",\n    instructions: \"Streams structured objects\",\n    llm: provider,\n    model: \"gpt-4o\",\n  });\n\n  const prompt = \"Generate a 3-day travel plan for Tokyo.\";\n\n  try {\n    const response = await agent.streamObject(prompt, travelPlanSchema);\n    console.log(\"Streaming Object Updates:\");\n    for await (const partialObject of response.objectStream) {\n      console.log(\"Partial:\", partialObject);\n    }\n    // Final object/usage might be available via callbacks or provider result\n    console.log(\"\\n--- Object Stream Finished ---\");\n  } catch (error) {\n    console.error(\"Error streaming object:\", error);\n  }\n}\n\nmain();\n\n```\n\n### Table of Contents\n\n- [Installation](https://voltagent.dev/docs/providers/xsai/#installation)\n- [Configuration](https://voltagent.dev/docs/providers/xsai/#configuration)\n- [Full Runnable Example](https://voltagent.dev/docs/providers/xsai/#full-runnable-example)\n- [Usage](https://voltagent.dev/docs/providers/xsai/#usage)\n- [Supported Methods](https://voltagent.dev/docs/providers/xsai/#supported-methods)\n- [Multi-modal Support](https://voltagent.dev/docs/providers/xsai/#multi-modal-support)\n- [Model Selection & Options](https://voltagent.dev/docs/providers/xsai/#model-selection--options)\n- [Code Examples](https://voltagent.dev/docs/providers/xsai/#code-examples)\n  - [Text Generation ( `generateText`)](https://voltagent.dev/docs/providers/xsai/#text-generation-generatetext)\n  - [Streaming Text ( `streamText`)](https://voltagent.dev/docs/providers/xsai/#streaming-text-streamtext)\n  - [Generating Structured Objects ( `generateObject`)](https://voltagent.dev/docs/providers/xsai/#generating-structured-objects-generateobject)\n  - [Streaming Structured Objects ( `streamObject`)](https://voltagent.dev/docs/providers/xsai/#streaming-structured-objects-streamobject)",
      "metadata": {
        "og:title": "xsAI (OpenAI Compatible) | VoltAgent",
        "docsearch:docusaurus_tag": "docs-default-current",
        "language": "en",
        "docusaurus_locale": "en",
        "title": "xsAI (OpenAI Compatible) | VoltAgent",
        "docsearch:language": "en",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "description": "The xsAI Provider acts as a versatile connector between VoltAgent and any OpenAI-compatible API endpoint. It leverages the xsai library, providing a unified interface for interacting with various services like OpenAI, Groq, Together AI, Anyscale Endpoints, Mistral AI (via compatible endpoints), and more.",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "og:locale": "en",
        "docusaurus_version": "current",
        "ogTitle": "xsAI (OpenAI Compatible) | VoltAgent",
        "ogDescription": "The xsAI Provider acts as a versatile connector between VoltAgent and any OpenAI-compatible API endpoint. It leverages the xsai library, providing a unified interface for interacting with various services like OpenAI, Groq, Together AI, Anyscale Endpoints, Mistral AI (via compatible endpoints), and more.",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "docusaurus_tag": "docs-default-current",
        "og:url": "https://voltagent.dev/docs/providers/xsai/",
        "og:image": "https://voltagent.dev/img/social3.png",
        "twitter:card": "summary_large_image",
        "docsearch:version": "current",
        "og:description": "The xsAI Provider acts as a versatile connector between VoltAgent and any OpenAI-compatible API endpoint. It leverages the xsai library, providing a unified interface for interacting with various services like OpenAI, Groq, Together AI, Anyscale Endpoints, Mistral AI (via compatible endpoints), and more.",
        "ogUrl": "https://voltagent.dev/docs/providers/xsai/",
        "generator": "Docusaurus v3.1.1",
        "viewport": "width=device-width, initial-scale=1.0",
        "ogLocale": "en",
        "scrapeId": "a6d6f124-9feb-491a-89c3-46468d6f81cf",
        "sourceURL": "https://voltagent.dev/docs/providers/xsai/",
        "url": "https://voltagent.dev/docs/providers/xsai/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:41:08.082Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/agents/multi-modal/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Multi-modal Capabilities\n\nVoltAgent supports multi-modal interactions, allowing agents to process and understand inputs that combine different types of content, primarily text and images. This enables more complex and richer interactions, such as asking questions about an uploaded image or providing visual context alongside text prompts.\n\n## `BaseMessage` Content Structure [â€‹](https://voltagent.dev/docs/agents/multi-modal/\\#basemessage-content-structure \"Direct link to basemessage-content-structure\")\n\nThe core of multi-modal input lies in the structure of the `content` field within a `BaseMessage` object. While simple text interactions might use a plain string for `content`, multi-modal inputs require `content` to be an **array** of specific content part objects.\n\n```codeBlockLines_e6Vv\nimport type { BaseMessage } from \"@voltagent/core\";\n\n// Basic Text Message\nconst textMessage: BaseMessage = {\n  role: \"user\",\n  content: \"Describe this image for me.\",\n};\n\n// Multi-modal Message (Text + Image)\nconst multiModalMessage: BaseMessage = {\n  role: \"user\",\n  content: [\\\n    {\\\n      type: \"text\",\\\n      text: \"What is shown in this image?\",\\\n    },\\\n    {\\\n      type: \"image\",\\\n      image: \"data:image/jpeg;base64,/9j/4AAQSk...\", // Base64 string or Data URI\\\n      mimeType: \"image/jpeg\", // Optional but recommended\\\n    },\\\n  ],\n};\n\n```\n\n### Content Part Types [â€‹](https://voltagent.dev/docs/agents/multi-modal/\\#content-part-types \"Direct link to Content Part Types\")\n\nWhen `content` is an array, each element must be an object with a `type` field indicating the kind of content. Common types include:\n\n1. **Text Part:**\n\n\n   - `type: 'text'`\n   - `text: string` \\- The actual text content.\n\n```codeBlockLines_e6Vv\n{ type: 'text', text: 'This is the text part.' }\n\n```\n\n2. **Image Part:**\n\n\n   - `type: 'image'`\n   - `image: string` \\- The image data, typically provided as a **Base64 encoded string** or a **Data URI** (e.g., `data:image/png;base64,...`).\n   - `mimeType?: string` \\- (Optional but Recommended) The MIME type of the image (e.g., `image/jpeg`, `image/png`, `image/webp`). Helps the provider interpret the data correctly.\n   - `alt?: string` \\- (Optional) Alternative text describing the image.\n\n```codeBlockLines_e6Vv\n{\n  type: 'image',\n  image: 'data:image/png;base64,iVBORw0KGgoAAAANSUhEUg...',\n  mimeType: 'image/png',\n  alt: 'A cute cat sleeping'\n}\n\n```\n\n3. **File Part (Used less commonly for direct LLM input, but supported):**\n\n\n   - `type: 'file'`\n   - `data: string` \\- Base64 encoded file data.\n   - `filename: string` \\- Original filename.\n   - `mimeType: string` \\- The MIME type of the file (e.g., `application/pdf`).\n   - `size?: number` \\- File size in bytes.\n\n```codeBlockLines_e6Vv\n{\n  type: 'file',\n  data: 'JVBERi0xLjQKJ...',\n  filename: 'report.pdf',\n  mimeType: 'application/pdf',\n  size: 102400\n}\n\n```\n\nYou can mix different part types within the `content` array.\n\n## Sending Multi-modal Input to Agents [â€‹](https://voltagent.dev/docs/agents/multi-modal/\\#sending-multi-modal-input-to-agents \"Direct link to Sending Multi-modal Input to Agents\")\n\nTo send multi-modal input, construct your `messages` array ensuring that the `content` field for relevant messages is an array of content parts, and pass it to the agent's generation methods ( `generateText`, `streamText`, `generateObject`, etc.).\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelProvider } from \"@voltagent/vercel-ai\";\n\n// Assume 'agent' is an initialized Agent instance using the Vercel provider\ndeclare const agent: Agent<VercelProvider>;\n\nasync function askAboutImage(imageUrlOrBase64: string, question: string) {\n  const messages: BaseMessage[] = [\\\n    {\\\n      role: \"user\",\\\n      content: [\\\n        { type: \"text\", text: question },\\\n        {\\\n          type: \"image\",\\\n          image: imageUrlOrBase64, // Can be Data URI or Base64 string\\\n          // Ensure you provide mimeType if not using a Data URI\\\n          // mimeType: 'image/jpeg'\\\n        },\\\n      ],\\\n    },\\\n  ];\n\n  try {\n    // Use generateText for a single response\n    const response = await agent.generateText(messages);\n    console.log(\"Agent Response:\", response);\n\n    // Or use streamText for streaming responses\n    // const streamResponse = await agent.streamText(messages);\n    // for await (const chunk of streamResponse.textStream) {\n    //   process.stdout.write(chunk);\n    // }\n    // console.log(); // Newline after stream\n  } catch (error) {\n    console.error(\"Error generating response:\", error);\n  }\n}\n\n// Example usage:\nconst catImageBase64 = \"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQE...\";\naskAboutImage(catImageBase64, \"What breed is this cat?\");\n\n```\n\n## Provider Support & Considerations [â€‹](https://voltagent.dev/docs/agents/multi-modal/\\#provider-support--considerations \"Direct link to Provider Support & Considerations\")\n\n**Crucially, multi-modal support depends heavily on the specific LLM provider and model you are using.**\n\n- Not all models can process images or other non-text modalities.\n- Consult the documentation for the underlying model to understand its specific multi-modal capabilities and limitations (e.g., supported image formats, resolutions, token costs for images).\n\nHere's a summary of the official VoltAgent providers:\n\n- **`@voltagent/anthropic-ai`**: âœ… **Supports Image Input.** The provider fully supports multi-modal content with Claude 3 models, handling both image URLs and base64-encoded images (including data URIs). Supported image formats include JPEG, PNG, GIF, and WebP. File content is converted to text descriptions.\n\n- **`@voltagent/google-ai`**: âœ… **Supports Image Input.** The provider correctly maps `ImagePart` data to the format expected by the Google Generative AI SDK (Gemini models).\n\n- **`@voltagent/groq-ai`**: âœ… **Supports Image Input.** The provider maps `ImagePart` data to the `image_url` format compatible with Groq API (for models that support vision).\n\n- **`@voltagent/vercel-ai`**: âš ï¸ **Conditional Support.** This provider passes the `BaseMessage` structure (including image parts) to the Vercel AI SDK functions ( `streamText`, `generateText`). Actual multi-modal support depends entirely on whether the underlying model configured _within your Vercel AI SDK setup_ (e.g., GPT-4 Vision, Claude 3 Haiku/Sonnet/Opus) accepts image input. Check the Vercel AI SDK documentation and your model provider's capabilities.\n\n- **`@voltagent/xsai`**: âš ï¸ **Conditional Support.** This provider passes the `BaseMessage` structure (including image parts) to the xsAI functions ( `streamText`, `generateText`). Actual multi-modal support depends entirely on whether the underlying model configured _within your xsAI setup_ (e.g., GPT-4 Vision, Claude 3 Haiku/Sonnet/Opus) accepts image input. Check your model provider's capabilities.\n\n\nSee the [Providers](https://voltagent.dev/docs/providers/overview/) documentation for more general details on individual providers.\n\n## VoltOps Platform Integration [â€‹](https://voltagent.dev/docs/agents/multi-modal/\\#voltops-platform-integration \"Direct link to VoltOps Platform Integration\")\n\n![VoltAgent VoltOps Platform Multi-modal Demo](https://cdn.voltagent.dev/docs/multi-modal-demo.gif)\n\nThe [VoltAgent VoltOps Platform](https://console.voltagent.dev/) provides a user-friendly way to interact with multi-modal agents:\n\n- **Assistant Chat:** The chat interface includes an attachment button (ðŸ“Ž).\n- **Uploading:** Clicking the button allows you to select one or more image files (and potentially other supported file types) from your computer.\n- **Preview:** Uploaded files are shown as previews below the text input area.\n- **Sending:** When you send the message, the Console automatically converts the uploaded files into the appropriate `ImagePart` or `FilePart` format (using Base64 data URIs) and constructs the `BaseMessage` with the `content` field as an array containing both your typed text and the file/image parts. This structured message is then sent to the agent API.\n\nThis provides a seamless way for you and your users to test and utilize the multi-modal capabilities of your agents directly within the Console.\n\n### Table of Contents\n\n- [`BaseMessage` Content Structure](https://voltagent.dev/docs/agents/multi-modal/#basemessage-content-structure)\n  - [Content Part Types](https://voltagent.dev/docs/agents/multi-modal/#content-part-types)\n- [Sending Multi-modal Input to Agents](https://voltagent.dev/docs/agents/multi-modal/#sending-multi-modal-input-to-agents)\n- [Provider Support & Considerations](https://voltagent.dev/docs/agents/multi-modal/#provider-support--considerations)\n- [VoltOps Platform Integration](https://voltagent.dev/docs/agents/multi-modal/#voltops-platform-integration)",
      "metadata": {
        "docusaurus_tag": "docs-default-current",
        "docsearch:version": "current",
        "ogTitle": "Multi-modal Capabilities | VoltAgent",
        "language": "en",
        "ogDescription": "VoltAgent supports multi-modal interactions, allowing agents to process and understand inputs that combine different types of content, primarily text and images. This enables more complex and richer interactions, such as asking questions about an uploaded image or providing visual context alongside text prompts.",
        "og:locale": "en",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "generator": "Docusaurus v3.1.1",
        "docsearch:language": "en",
        "twitter:card": "summary_large_image",
        "viewport": "width=device-width, initial-scale=1.0",
        "ogUrl": "https://voltagent.dev/docs/agents/multi-modal/",
        "title": "Multi-modal Capabilities | VoltAgent",
        "docusaurus_locale": "en",
        "docusaurus_version": "current",
        "ogLocale": "en",
        "og:image": "https://voltagent.dev/img/social3.png",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:title": "Multi-modal Capabilities | VoltAgent",
        "og:url": "https://voltagent.dev/docs/agents/multi-modal/",
        "description": "VoltAgent supports multi-modal interactions, allowing agents to process and understand inputs that combine different types of content, primarily text and images. This enables more complex and richer interactions, such as asking questions about an uploaded image or providing visual context alongside text prompts.",
        "og:description": "VoltAgent supports multi-modal interactions, allowing agents to process and understand inputs that combine different types of content, primarily text and images. This enables more complex and richer interactions, such as asking questions about an uploaded image or providing visual context alongside text prompts.",
        "scrapeId": "cbf5d852-e32a-42e9-8bcc-34c5f56496de",
        "sourceURL": "https://voltagent.dev/docs/agents/multi-modal/",
        "url": "https://voltagent.dev/docs/agents/multi-modal/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:19.940Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/agents/overview/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Agent Overview\n\nThe `Agent` class is the fundamental building block of VoltAgent. It acts as the central orchestrator, allowing you to create AI agents that interact with Large Language Models (LLMs), use tools to interact with the outside world, maintain conversational memory, and embody specific personalities or instructions.\n\n## Creating an Agent [â€‹](https://voltagent.dev/docs/agents/overview/\\#creating-an-agent \"Direct link to Creating an Agent\")\n\nAt its core, an agent needs a name, instructions (which guides its behavior), an LLM Provider to handle communication with an AI model, and the specific model to use.\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\"; // Handles communication\nimport { openai } from \"@ai-sdk/openai\"; // Defines the specific model source\n\nconst agent = new Agent({\n  name: \"My Assistant\",\n  instructions: \"A helpful and friendly assistant that can answer questions clearly and concisely.\",\n  // The LLM Provider acts as the bridge to the AI service\n  llm: new VercelAIProvider(),\n  // The model specifies which AI model to use (e.g., from OpenAI via Vercel AI SDK)\n  model: openai(\"gpt-4o\"),\n});\n\n```\n\n## Constructor Options [â€‹](https://voltagent.dev/docs/agents/overview/\\#constructor-options \"Direct link to Constructor Options\")\n\nThe `Agent` constructor accepts an options object with these properties:\n\n```codeBlockLines_e6Vv\nconst agent = new Agent({\n  // Required\n  name: \"MyAgent\", // Agent identifier\n  instructions: \"You are a helpful assistant\", // Behavior guidelines\n  llm: new VercelAIProvider(), // LLM provider instance\n  model: openai(\"gpt-4o\"), // AI model to use\n\n  // Optional\n  id: \"custom-id\", // Unique ID (auto-generated if not provided)\n  purpose: \"Customer support agent\", // Agent purpose for supervisor context\n  tools: [weatherTool, searchTool], // Available tools\n  memory: new LibSQLStorage(), // Memory storage (or false to disable)\n  memoryOptions: { maxMessages: 100 }, // Memory configuration\n  userContext: new Map([\\\n    // Default context for all operations\\\n    [\"environment\", \"production\"],\\\n  ]),\n  maxSteps: 10, // Maximum tool-use iterations\n  subAgents: [researchAgent], // Sub-agents for delegation\n  supervisorConfig: {\n    // Supervisor behavior config\n    systemMessage: \"Custom supervisor instructions\",\n    includeAgentsMemory: true,\n  },\n\n  // Additional constructor parameters\n  hooks: createHooks({ onStart, onEnd }), // Lifecycle event handlers\n  retriever: new PineconeRetriever(), // RAG retriever\n  voice: new ElevenLabsVoice(), // Voice configuration\n  markdown: true, // Enable markdown formatting\n  voltOpsClient: new VoltOpsClient({\n    // Observability & prompt management\n    publicKey: \"...\",\n    secretKey: \"...\",\n  }),\n  maxHistoryEntries: 1000, // Max history entries to store\n});\n\n```\n\n## Core Interaction Methods [â€‹](https://voltagent.dev/docs/agents/overview/\\#core-interaction-methods \"Direct link to Core Interaction Methods\")\n\nThe primary ways to interact with an agent are through the `generate*` and `stream*` methods. These methods handle sending your input to the configured LLM, processing the response, and potentially orchestrating tool usage or memory retrieval based on the agent's configuration and the LLM's decisions.\n\n### Text Generation ( `generateText`/ `streamText`) [â€‹](https://voltagent.dev/docs/agents/overview/\\#text-generation-generatetextstreamtext \"Direct link to text-generation-generatetextstreamtext\")\n\nUse these methods when you expect a primarily text-based response. The agent might still decide to use tools based on the prompt and its capabilities.\n\n- `generateText`: Returns the complete text response after the LLM and any necessary tool calls are finished.\n- `streamText`: Returns a stream that yields chunks of the response (text, tool calls, tool results) as they become available, providing a more interactive experience.\n\n```codeBlockLines_e6Vv\nimport { Agent, createTool } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { z } from \"zod\";\n\n// Example Tool (see Tools section for details)\nconst weatherTool = createTool({\n  name: \"get_weather\",\n  description: \"Get the current weather for a specific location\",\n  parameters: z.object({ location: z.string().describe(\"City and state\") }),\n  execute: async ({ location }) => {\n    console.log(`Tool: Getting weather for ${location}`);\n    // Call API... return mock data\n    return { temperature: 72, conditions: \"sunny\" };\n  },\n});\n\nconst agent = new Agent({\n  name: \"Chat Assistant\",\n  instructions: \"A helpful assistant that can check the weather.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  tools: [weatherTool],\n});\n\n// Example using streamText for a chat-like interaction\nasync function chat(input: string) {\n  console.log(`User: ${input}`);\n  // Use streamText for interactive responses\n  const stream = await agent.streamText(input);\n\n  for await (const chunk of stream.textStream) {\n    console.log(chunk);\n  }\n}\n\n// Example usage that might trigger the weather tool\nawait chat(\"What's the weather like in London?\");\n\n// Example using generateText for a complete response\nconst completeResponse = await agent.generateText(\"Explain machine learning briefly.\");\nconsole.log(\"Complete Response:\", completeResponse.text);\n// Additional metadata available (provider-dependent):\n// completeResponse.reasoning - Model's reasoning process (if available)\n// completeResponse.warnings - Any provider warnings\n\n```\n\n#### Enhanced Streaming with `fullStream` [â€‹](https://voltagent.dev/docs/agents/overview/\\#enhanced-streaming-with-fullstream \"Direct link to enhanced-streaming-with-fullstream\")\n\nFor more detailed streaming information including tool calls, reasoning steps, and completion status, you can use the `fullStream` property available in the response:\n\n```codeBlockLines_e6Vv\n// Example using fullStream for detailed streaming events\nasync function enhancedChat(input: string) {\n  console.log(`User: ${input}`);\n  const response = await agent.streamText(input);\n\n  // Check if fullStream is available (provider-dependent)\n  if (response.fullStream) {\n    for await (const chunk of response.fullStream) {\n      switch (chunk.type) {\n        case \"text-delta\":\n          // Output text as it's generated\n          process.stdout.write(chunk.textDelta);\n          break;\n        case \"tool-call\":\n          console.log(`\\nðŸ”§ Using tool: ${chunk.toolName}`);\n          break;\n        case \"tool-result\":\n          console.log(`âœ… Tool completed: ${chunk.toolName}`);\n          break;\n        case \"reasoning\":\n          console.log(`ðŸ¤” AI thinking: ${chunk.reasoning}`);\n          break;\n        case \"source\":\n          console.log(`ðŸ“š Retrieved context: ${chunk.source}`);\n          break;\n        case \"finish\":\n          console.log(`\\nâœ¨ Done! Tokens used: ${chunk.usage?.totalTokens}`);\n          break;\n      }\n    }\n  } else {\n    // Fallback to standard textStream\n    for await (const chunk of response.textStream) {\n      process.stdout.write(chunk);\n    }\n  }\n}\n\nawait enhancedChat(\"Write a short story about a cat and format it nicely\");\n\n```\n\nfullStream Support\n\nCurrently, `fullStream` is only supported by the `@voltagent/vercel-ai` provider. For other providers (Google AI, Groq, Anthropic, XsAI), the response will fall back to the standard `textStream`.\n\nWe're actively looking for community contributions to add `fullStream` support to other providers! If you're interested in helping, please check out our [GitHub repository](https://github.com/VoltAgent/voltagent) or join our [Discord community](https://s.voltagent.dev/discord).\n\n#### Promise-based Properties in Streaming Responses [â€‹](https://voltagent.dev/docs/agents/overview/\\#promise-based-properties-in-streaming-responses \"Direct link to Promise-based Properties in Streaming Responses\")\n\nFor more convenient access to final values when streaming, VoltAgent provides Promise-based properties that resolve when the stream completes:\n\n```codeBlockLines_e6Vv\n// Example using Promise properties with streamText\nasync function streamWithPromises(input: string) {\n  const response = await agent.streamText(input);\n\n  // Start processing the stream\n  const streamProcessing = (async () => {\n    for await (const chunk of response.textStream) {\n      process.stdout.write(chunk);\n    }\n  })();\n\n  // Access final values via Promises (these resolve when streaming completes)\n  const [fullText, usage, finishReason] = await Promise.all([\\\n    response.text, // Promise<string> - Full generated text\\\n    response.usage, // Promise<UsageInfo> - Token usage statistics\\\n    response.finishReason, // Promise<string> - Why generation stopped\\\n  ]);\n\n  console.log(\"\\n\\nGeneration complete!\");\n  console.log(`Total text: ${fullText.length} characters`);\n  console.log(`Tokens used: ${usage?.totalTokens}`);\n  console.log(`Finish reason: ${finishReason}`);\n}\n\n// Example using Promise properties with streamObject\nasync function streamObjectWithPromises() {\n  const schema = z.object({\n    name: z.string(),\n    age: z.number(),\n    skills: z.array(z.string()),\n  });\n\n  const response = await agent.streamObject(\"Generate a developer profile\", schema);\n\n  // Process partial updates\n  console.log(\"Building object...\");\n  for await (const partial of response.objectStream) {\n    console.log(\"Partial:\", partial);\n  }\n\n  // Get the final complete object and metadata\n  const finalObject = await response.object; // Promise<T> - Final validated object\n  const usage = await response.usage; // Promise<UsageInfo> - Token usage\n\n  console.log(\"\\nFinal object:\", finalObject);\n  console.log(\"Generation used\", usage?.totalTokens, \"tokens\");\n}\n\n```\n\nPromise Properties Availability\n\nPromise-based properties for streaming responses are currently only implemented in the `@voltagent/vercel-ai` provider. These properties are optional in the provider interface to maintain backward compatibility.\n\n**Available Promise properties:**\n\n- **streamText**: `text`, `finishReason`, `usage`, `reasoning`\n- **streamObject**: `object`, `usage`, `warnings`\n\nFor providers that don't support these properties, you'll need to collect the values manually from the stream or use callbacks.\n\n### SubAgent Event Filtering [â€‹](https://voltagent.dev/docs/agents/overview/\\#subagent-event-filtering \"Direct link to SubAgent Event Filtering\")\n\nWhen using `fullStream` with sub-agents, by default only `tool-call` and `tool-result` events are forwarded from sub-agents to the parent stream. This keeps the stream focused on meaningful actions while reducing noise.\n\n#### Default Behavior [â€‹](https://voltagent.dev/docs/agents/overview/\\#default-behavior \"Direct link to Default Behavior\")\n\n```codeBlockLines_e6Vv\n// By default, only tool-call and tool-result events are forwarded\nconst supervisorAgent = new Agent({\n  name: \"Supervisor\",\n  instructions: \"You coordinate between agents\",\n  llm: provider,\n  subAgents: [writerAgent, editorAgent],\n  // No configuration needed - defaults to ['tool-call', 'tool-result']\n});\n\nconst response = await supervisorAgent.streamText(\"Write and edit a story\");\n\nif (response.fullStream) {\n  for await (const chunk of response.fullStream) {\n    // You'll only see tool events from sub-agents by default\n    if (chunk.subAgentId && chunk.subAgentName) {\n      console.log(`[${chunk.subAgentName}] Tool: ${chunk.toolName}`);\n    }\n  }\n}\n\n```\n\n#### Enabling All Event Types [â€‹](https://voltagent.dev/docs/agents/overview/\\#enabling-all-event-types \"Direct link to Enabling All Event Types\")\n\nTo receive all sub-agent events (text deltas, reasoning, sources, etc.), configure the supervisor:\n\n```codeBlockLines_e6Vv\nconst supervisorAgent = new Agent({\n  name: \"Supervisor\",\n  instructions: \"You coordinate between agents\",\n  llm: provider,\n  subAgents: [writerAgent, editorAgent],\n  supervisorConfig: {\n    fullStreamEventForwarding: {\n      types: [\"tool-call\", \"tool-result\", \"text-delta\", \"reasoning\", \"source\", \"error\", \"finish\"],\n      addSubAgentPrefix: true, // Adds agent name to tool names (default: true)\n    },\n  },\n});\n\n// Now you'll receive all event types\nif (response.fullStream) {\n  for await (const chunk of response.fullStream) {\n    const isSubAgentEvent = chunk.subAgentId && chunk.subAgentName;\n\n    if (isSubAgentEvent) {\n      switch (chunk.type) {\n        case \"text-delta\":\n          process.stdout.write(chunk.textDelta); // Stream sub-agent text\n          break;\n        case \"reasoning\":\n          console.log(`[${chunk.subAgentName}] Thinking: ${chunk.reasoning}`);\n          break;\n        case \"tool-call\":\n          // Tool names include agent prefix: \"WriterAgent: search_tool\"\n          console.log(`[${chunk.subAgentName}] Using: ${chunk.toolName}`);\n          break;\n      }\n    }\n  }\n}\n\n```\n\n#### Custom Event Filtering [â€‹](https://voltagent.dev/docs/agents/overview/\\#custom-event-filtering \"Direct link to Custom Event Filtering\")\n\nYou can selectively enable specific event types:\n\n```codeBlockLines_e6Vv\nsupervisorConfig: {\n  fullStreamEventForwarding: {\n    // Only forward text and tool events, no reasoning or sources\n    types: ['tool-call', 'tool-result', 'text-delta'],\n    addSubAgentPrefix: false // Don't add agent name prefix to tools\n  }\n}\n\n```\n\n**Available SubAgent Event Types:**\n\n- `text-delta`: SubAgent text output (character by character)\n- `reasoning`: SubAgent internal reasoning steps\n- `source`: SubAgent context retrieval results\n- `tool-call`: SubAgent tool execution starts\n- `tool-result`: SubAgent tool execution completes\n- `error`: SubAgent errors\n- `finish`: SubAgent completion events\n\nThis configuration approach provides fine-grained control over which sub-agent events reach your application, allowing you to balance between information richness and stream performance.\n\n#### Markdown Formatting [â€‹](https://voltagent.dev/docs/agents/overview/\\#markdown-formatting \"Direct link to Markdown Formatting\")\n\n**Why?** To have the agent automatically format its text responses using Markdown for better readability and presentation.\n\nBy setting the `markdown` property to `true` in the agent's configuration, you instruct the LLM to use Markdown syntax (like headings, lists, bold text, etc.) when generating text responses. VoltAgent adds a corresponding instruction to the system prompt automatically.\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  name: \"Markdown Assistant\",\n  instructions: \"A helpful assistant that formats answers clearly.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  markdown: true, // Enable automatic Markdown formatting\n});\n\n// Now, when you call generateText or streamText,\n// the agent will attempt to format its response using Markdown.\nconst response = await agent.generateText(\"Explain the steps to make a cup of tea.\");\nconsole.log(response.text);\n\n```\n\nThis is particularly useful when displaying agent responses in UIs that support Markdown rendering.\n\n### Structured Data Generation ( `generateObject`/ `streamObject`) [â€‹](https://voltagent.dev/docs/agents/overview/\\#structured-data-generation-generateobjectstreamobject \"Direct link to structured-data-generation-generateobjectstreamobject\")\n\nUse these methods when you need the LLM to generate output conforming to a specific structure (defined by a Zod schema). This is ideal for data extraction, function calling based on schema, or generating predictable JSON.\n\n- `generateObject`: Returns the complete structured object once generation is finished.\n- `streamObject`: Returns a stream that yields partial updates to the object as it's being constructed by the LLM.\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { z } from \"zod\";\n\nconst agent = new Agent({\n  name: \"Data Extractor\",\n  instructions: \"Extracts structured data.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"), // Ensure model supports structured output/function calling\n});\n\n// Define a simple schema with Zod\nconst personSchema = z.object({\n  name: z.string().describe(\"Full name\"), // Descriptions help the LLM\n  age: z.number(),\n  occupation: z.string(),\n  skills: z.array(z.string()),\n});\n\n// Example using generateObject\nconst objectResponse = await agent.generateObject(\n  \"Create a profile for a talented software developer named Alex.\",\n  personSchema\n);\nconsole.log(\"Complete object:\", objectResponse.object);\n\n// Example using streamObject\nconst streamObjectResponse = await agent.streamObject(\n  \"Generate details for a data scientist named Jamie.\",\n  personSchema\n);\n\nfor await (const partial of streamObjectResponse.objectStream) {\n  console.log(\"Received update:\", partial); // Shows the object being built incrementally\n}\n\n// Get the final object (if supported by provider)\nif (streamObjectResponse.object) {\n  const finalObject = await streamObjectResponse.object;\n  console.log(\"Final object:\", finalObject);\n}\n\n```\n\n## Advanced Features [â€‹](https://voltagent.dev/docs/agents/overview/\\#advanced-features \"Direct link to Advanced Features\")\n\nEnhance your agents with these powerful capabilities, which are integrated into the core `generate*`/ `stream*` methods:\n\n### Memory [â€‹](https://voltagent.dev/docs/agents/overview/\\#memory \"Direct link to Memory\")\n\n**Why?** To give your agent context of past interactions, enabling more natural, coherent, and personalized conversations.\n\nVoltAgent's memory management system allows agents to store and retrieve conversation history or state using configurable Memory Providers.\n\n```codeBlockLines_e6Vv\n// Example: Configuring memory (Provider details omitted for brevity)\nimport { Agent, LibSQLStorage } from \"@voltagent/core\";\n// ... other imports\n\nconst memoryStorage = new LibSQLStorage({\n  /* ... provider config ... */\n});\n\nconst agent = new Agent({\n  name: \"Assistant with Memory\",\n  // ... other config ...\n  memory: memoryStorage,\n});\n\n```\n\nWhen memory is configured, the agent automatically retrieves relevant context before calling the LLM and saves new interactions afterwards.\n\n**[Learn more about Memory Management & Providers](https://voltagent.dev/docs/agents/memory/overview/)**\n\n### Tools [â€‹](https://voltagent.dev/docs/agents/overview/\\#tools \"Direct link to Tools\")\n\n**Why?** To allow your agent to interact with the outside world, access real-time information, or perform actions via APIs, databases, or other systems.\n\nWhen you call `generateText` or `streamText`, the LLM can decide to use one of the provided tools. VoltAgent handles the execution and feeds the result back to the LLM to continue generation.\n\n```codeBlockLines_e6Vv\nimport { Agent, createTool } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { z } from \"zod\";\n\n// Create a weather tool using the helper function\nconst weatherTool = createTool({\n  name: \"get_weather\",\n  description: \"Get the current weather for a specific location\",\n  parameters: z.object({\n    location: z.string().describe(\"The city and state, e.g., San Francisco, CA\"),\n  }),\n  // The function the agent executes when using the tool\n  execute: async ({ location }) => {\n    console.log(`Tool: Getting weather for ${location}`);\n    // In a real scenario, call a weather API here\n    // Returning mock data for demonstration\n    if (location.toLowerCase().includes(\"london\")) {\n      return { temperature: 55, conditions: \"cloudy\" };\n    }\n    return { temperature: 72, conditions: \"sunny\" };\n  },\n});\n\nconst agent = new Agent({\n  name: \"Weather Assistant\",\n  instructions: \"An assistant that can check the weather using available tools.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"), // Models supporting tool use are required\n  tools: [weatherTool], // Provide the list of tools to the agent\n});\n\n// Example: Call streamText and the agent might use the tool\nconst response = await agent.generateText(\"What's the weather in London?\");\nconsole.log(response.text);\n// The agent should call the 'get_weather' tool during the generation.\n\n```\n\n[Learn more about Tools](https://voltagent.dev/docs/agents/tools/)\n\n### Sub-Agents [â€‹](https://voltagent.dev/docs/agents/overview/\\#sub-agents \"Direct link to Sub-Agents\")\n\n**Why?** To break down complex tasks into smaller, manageable parts handled by specialized agents, promoting modularity and focused expertise (similar to a team of specialists).\n\nA coordinator agent uses a special `delegate_task` tool (added automatically when sub-agents are present) to pass control to a sub-agent during a `generate*`/ `stream*` call.\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Assume researchAgent and writingAgent are configured Agents\nconst researchAgent = new Agent({ name: \"Researcher\" /* ... */ });\nconst writingAgent = new Agent({ name: \"Writer\" /* ... */ });\n\n// Create a coordinator agent that uses the others\nconst mainAgent = new Agent({\n  name: \"Coordinator\",\n  instructions: \"Coordinates research and writing tasks by delegating to specialized sub-agents.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  // List the agents this one can delegate tasks to\n  subAgents: [researchAgent, writingAgent],\n});\n\n// Example: Call streamText on the main agent\nconst response = await mainAgent.generateText(\"Write a blog post about quantum computing.\");\nconsole.log(response.text);\n// The Coordinator might decide to use the delegate_task tool to involve researchAgent and writingAgent.\n\n```\n\n[Learn more about Sub-Agents](https://voltagent.dev/docs/agents/sub-agents/)\n\n### Hooks [â€‹](https://voltagent.dev/docs/agents/overview/\\#hooks \"Direct link to Hooks\")\n\n**Why?** To observe and potentially intercept or modify the agent's behavior at various lifecycle stages (start, end, tool calls, etc.) for logging, debugging, or custom logic.\n\nHooks are triggered at specific points during the execution of `generate*`/ `stream*` methods. Each hook receives a single argument object containing relevant information like the agent instance and operation context.\n\n```codeBlockLines_e6Vv\nimport {\n  Agent,\n  createHooks,\n  type OnStartHookArgs,\n  type OnEndHookArgs,\n  type OnToolStartHookArgs,\n  type OnToolEndHookArgs,\n} from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst hooks = createHooks({\n  // Called when any agent interaction starts (generateText, streamText, etc.)\n  onStart: async ({ agent, context }: OnStartHookArgs) => {\n    console.log(`Agent ${agent.name} starting interaction... Context:`, context);\n  },\n  // Called when the interaction finishes (successfully or with an error)\n  onEnd: async ({ agent, output, error, context }: OnEndHookArgs) => {\n    if (error) {\n      console.error(`Agent ${agent.name} finished with error:`, error);\n    } else if (output) {\n      // Output format depends on the method called (e.g., { text: ..., usage: ... } for generateText)\n      console.log(\n        `Agent ${agent.name} finished successfully. Final output:`,\n        output.text ?? output.object // Access 'text' or 'object' based on the operation type\n      );\n    }\n    console.log(\"Finished context:\", context);\n  },\n  // Called before a tool is executed\n  onToolStart: async ({ agent, tool, context }: OnToolStartHookArgs) => {\n    console.log(`Agent ${agent.name} starting tool: ${tool.name}. Context:`, context);\n  },\n  // Called after a tool finishes execution (successfully or with an error)\n  onToolEnd: async ({ agent, tool, output, error, context }: OnToolEndHookArgs) => {\n    if (error) {\n      console.error(`Agent ${agent.name} failed tool: ${tool.name}. Error:`, error);\n    } else {\n      console.log(\n        `Agent ${agent.name} finished tool: ${tool.name}. Result:`,\n        output // Tool output is directly available\n      );\n    }\n    console.log(\"Tool context:\", context);\n  },\n  // Note: There is no top-level 'onError' hook. Errors are handled within onEnd and onToolEnd.\n  // The 'onHandoff' hook (not shown here) is called when control is passed between agents (e.g., sub-agents).\n});\n\nconst agent = new Agent({\n  name: \"Observable Agent\",\n  instructions: \"An agent with logging hooks.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  hooks, // Attach the defined hooks\n});\n\n```\n\n[Learn more about Hooks](https://voltagent.dev/docs/agents/hooks/)\n\n### Prompt Management [â€‹](https://voltagent.dev/docs/agents/overview/\\#prompt-management \"Direct link to Prompt Management\")\n\n**Why?** To manage your agent's instructions and behavior efficiently across different environments, enable team collaboration on prompts, maintain version control, and implement A/B testing without code deployments.\n\nVoltAgent provides a three-tier prompt management system: Static Instructions (hardcoded strings), Dynamic Instructions (runtime functions), and VoltOps Management (enterprise-grade remote prompt management with analytics).\n\n```codeBlockLines_e6Vv\nimport { Agent, VoltAgent, VoltOpsClient } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Option 1: Static Instructions (simple, hardcoded)\nconst staticAgent = new Agent({\n  name: \"Static Assistant\",\n  instructions: \"You are a helpful customer support agent. Be polite and efficient.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n});\n\n// Option 2: Dynamic Instructions (runtime-based)\nconst dynamicAgent = new Agent({\n  name: \"Dynamic Assistant\",\n  instructions: async ({ userContext }) => {\n    const userTier = userContext.get(\"userTier\") || \"basic\";\n\n    if (userTier === \"premium\") {\n      return \"You are a premium support agent. Provide detailed, thorough assistance.\";\n    } else {\n      return \"You are a support agent. Provide helpful but concise answers.\";\n    }\n  },\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n});\n\n// Option 3: VoltOps Management (enterprise-grade)\nconst voltOpsClient = new VoltOpsClient({\n  publicKey: process.env.VOLTOPS_PUBLIC_KEY,\n  secretKey: process.env.VOLTOPS_SECRET_KEY,\n});\n\nconst managedAgent = new Agent({\n  name: \"Managed Assistant\",\n  instructions: async ({ prompts }) => {\n    return await prompts.getPrompt({\n      promptName: \"customer-support-prompt\",\n      label: process.env.NODE_ENV === \"production\" ? \"production\" : \"development\",\n      variables: {\n        companyName: \"VoltAgent Corp\",\n        tone: \"friendly and professional\",\n      },\n    });\n  },\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n});\n\nconst voltAgent = new VoltAgent({\n  agents: { managedAgent },\n  voltOpsClient: voltOpsClient,\n});\n\n```\n\n[Learn more about Prompt Management](https://voltagent.dev/docs/agents/prompts/)\n\n### Dynamic Agents [â€‹](https://voltagent.dev/docs/agents/overview/\\#dynamic-agents \"Direct link to Dynamic Agents\")\n\n**Why?** To create adaptive AI agents that change their behavior, capabilities, and configuration based on runtime context. Instead of having fixed instructions, models, or tools, you can define functions that dynamically determine these properties based on user context, request parameters, or any other runtime information.\n\nDynamic agents are perfect for multi-tenant applications, role-based access control, subscription tiers, internationalization, and A/B testing scenarios.\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst dynamicAgent = new Agent({\n  name: \"Adaptive Assistant\",\n\n  // Dynamic instructions based on user context\n  instructions: ({ userContext }) => {\n    const role = (userContext.get(\"role\") as string) || \"user\";\n    const language = (userContext.get(\"language\") as string) || \"English\";\n\n    if (role === \"admin\") {\n      return `You are an admin assistant with special privileges. Respond in ${language}.`;\n    } else {\n      return `You are a helpful assistant. Respond in ${language}.`;\n    }\n  },\n\n  // Dynamic model based on subscription tier\n  model: ({ userContext }) => {\n    const tier = (userContext.get(\"tier\") as string) || \"free\";\n\n    switch (tier) {\n      case \"premium\":\n        return openai(\"gpt-4o\");\n      case \"pro\":\n        return openai(\"gpt-4o-mini\");\n      default:\n        return openai(\"gpt-3.5-turbo\");\n    }\n  },\n\n  llm: new VercelAIProvider(),\n});\n\n// Use with context\nconst userContext = new Map<string, unknown>();\nuserContext.set(\"role\", \"admin\");\nuserContext.set(\"language\", \"Spanish\");\nuserContext.set(\"tier\", \"premium\");\n\nconst response = await dynamicAgent.generateText(\"Help me manage the system settings\", {\n  userContext: userContext,\n});\n// The agent will respond in Spanish, with admin capabilities, using the premium model\n\n```\n\n[Learn more about Dynamic Agents](https://voltagent.dev/docs/agents/dynamic-agents/)\n\n### Operation Context ( `userContext`) [â€‹](https://voltagent.dev/docs/agents/overview/\\#operation-context-usercontext \"Direct link to operation-context-usercontext\")\n\n**Why?** To pass custom, request-specific data between different parts of an agent's execution flow (like hooks and tools) for a single operation, without affecting other concurrent or subsequent operations. Useful for tracing, logging, metrics, or passing temporary configuration.\n\n`userContext` is a `Map` accessible via the `OperationContext` object, which is passed to hooks and available in tool execution contexts. This context is isolated to each individual operation ( `generateText`, `streamObject`, etc.).\n\n```codeBlockLines_e6Vv\nimport {\n  Agent,\n  createHooks,\n  createTool,\n  type OperationContext,\n  type ToolExecutionContext,\n} from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { z } from \"zod\";\n\nconst hooks = createHooks({\n  onStart: async (agent: Agent<any>, context: OperationContext) => {\n    const requestId = `req-${Date.now()}`;\n    context.userContext.set(\"requestId\", requestId); // Set data in context\n    console.log(`[${agent.name}] Operation started. RequestID: ${requestId}`);\n  },\n  onEnd: async (agent: Agent<any>, result: any, context: OperationContext) => {\n    const requestId = context.userContext.get(\"requestId\"); // Get data from context\n    console.log(`[${agent.name}] Operation finished. RequestID: ${requestId}`);\n  },\n});\n\nconst loggerTool = createTool({\n  name: \"context_aware_logger\",\n  description: \"Logs a message using the request ID from context.\",\n  parameters: z.object({ message: z.string() }),\n  execute: async (params: { message: string }, options?: ToolExecutionContext) => {\n    const requestId = options?.operationContext?.userContext?.get(\"requestId\") || \"unknown\";\n    const logMessage = `[ReqID: ${requestId}] Tool Log: ${params.message}`;\n    console.log(logMessage);\n    return `Logged: ${params.message}`;\n  },\n});\n\nconst agent = new Agent({\n  name: \"Context Agent\",\n  instructions: \"Uses userContext.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  hooks: hooks,\n  tools: [loggerTool],\n});\n\nawait agent.generateText(\"Log this message: 'Processing user data.'\");\n// The requestId set in onStart will be available in loggerTool and onEnd.\n\n```\n\n[Learn more about Operation Context (userContext)](https://voltagent.dev/docs/agents/context/)\n\n### Retriever [â€‹](https://voltagent.dev/docs/agents/overview/\\#retriever \"Direct link to Retriever\")\n\n**Why?** To provide the agent with access to external knowledge bases or documents, allowing it to answer questions or generate content based on information not present in its original training data (Retrieval-Augmented Generation - RAG).\n\nThe retriever is automatically invoked before calling the LLM within `generate*`/ `stream*` methods to fetch relevant context, which is then added to the system prompt.\n\n```codeBlockLines_e6Vv\nimport { BaseRetriever } from \"@voltagent/core\";\nimport type { BaseMessage } from \"@voltagent/core\";\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Create a simple retriever (replace with actual vector search in production)\nclass SimpleRetriever extends BaseRetriever {\n  // Sample knowledge base\n  private documents = [\\\n    { id: \"doc1\", content: \"VoltAgent is a TypeScript framework for building AI agents.\" },\\\n    { id: \"doc2\", content: \"Agents can use tools, memory, and sub-agents.\" },\\\n    { id: \"doc3\", content: \"Retrievers enhance AI agents with external knowledge using RAG.\" },\\\n  ];\n\n  // Method to fetch relevant documents\n  async retrieve(input: string | BaseMessage[]): Promise<string> {\n    // Extract the query text\n    const query = typeof input === \"string\" ? input : (input[input.length - 1].content as string);\n    console.log(`Retriever: Searching for \"${query}\"`);\n\n    // Simple keyword matching (use vector embeddings for real applications)\n    const results = this.documents.filter((doc) =>\n      doc.content.toLowerCase().includes(query.toLowerCase())\n    );\n\n    if (results.length === 0) return \"No relevant information found in documents.\";\n\n    // Format results for the LLM\n    return results.map((doc) => `Document ${doc.id}: ${doc.content}`).join(\"\\n\\n\");\n  }\n}\n\n// Create agent with the retriever\nconst agent = new Agent({\n  name: \"Knowledge Assistant\",\n  instructions: \"An assistant that uses retrieved documents to answer questions.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  retriever: new SimpleRetriever(), // Add the retriever instance\n});\n\n// Example: Ask a question using streamText\nconst response = await agent.generateText(\"What are Retrievers in VoltAgent?\");\nconsole.log(response.text);\n// The agent will use SimpleRetriever *before* calling the LLM,\n// then generate an answer based on the retrieved context.\n\n```\n\n[Learn more about Retrievers](https://voltagent.dev/docs/rag/overview/)\n\n### Providers [â€‹](https://voltagent.dev/docs/agents/overview/\\#providers \"Direct link to Providers\")\n\n**Why?** To abstract the communication layer with different LLM backends (like OpenAI, Anthropic, Google Gemini, Cohere, local models via Ollama, etc.), allowing you to switch providers without rewriting your core agent logic.\n\nVoltAgent achieves this through `LLMProvider` implementations. You configure your `Agent` with a specific provider instance and the desired model compatible with that provider.\n\nCurrently, VoltAgent offers built-in providers for various services and APIs:\n\n- **`@voltagent/vercel-ai`**: Uses the Vercel AI SDK to connect to a wide range of models (OpenAI, Anthropic, Google, Groq, etc.).\n- **`@voltagent/xsai`**: Connects to any OpenAI-compatible API (OpenAI, Groq, Together AI, local models, etc.).\n- **`@voltagent/google-ai`**: Uses the official Google AI SDK for Gemini and Vertex AI.\n- **`@voltagent/groq-ai`**: Connects specifically to the Groq API for fast inference.\n- **`@voltagent/anthropic-ai`**: Connects directly to Anthropic's AI models (Claude) using the official `anthropic-ai/sdk` SDK.\n\nWe plan to add more official provider integrations in the future. Furthermore, developers can create their own custom providers by implementing the `LLMProvider` interface to connect VoltAgent to virtually any AI model or service.\n\n```codeBlockLines_e6Vv\n// 1. Vercel AI Provider (integrates with various models via Vercel AI SDK)\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\"; // Model definition for OpenAI via Vercel\nimport { anthropic } from \"@ai-sdk/anthropic\"; // Model definition for Anthropic via Vercel\n\n// Agent using OpenAI via Vercel\nconst vercelOpenAIAgent = new Agent({\n  name: \"Vercel OpenAI Assistant\",\n  instructions: \"Assistant using Vercel AI SDK with OpenAI.\",\n  llm: new VercelAIProvider(), // The provider\n  model: openai(\"gpt-4o\"), // The specific model\n});\n\n// Agent using Anthropic via Vercel\nconst vercelAnthropicAgent = new Agent({\n  name: \"Vercel Anthropic Assistant\",\n  instructions: \"Assistant using Vercel AI SDK with Anthropic.\",\n  llm: new VercelAIProvider(), // Same provider\n  model: anthropic(\"claude-3-5-sonnet-20240620\"), // Different model\n});\n\n// 2. XsAI Provider (Example of a custom/alternative provider)\nimport { XsAIProvider } from \"@voltagent/xsai\";\n\n// Agent using XsAI Provider (might use different model naming)\nconst xsaiAgent = new Agent({\n  name: \"XsAI Assistant\",\n  instructions: \"Assistant using XsAI Provider.\",\n  llm: new XsAIProvider({ apiKey: process.env.OPENAI_API_KEY }), // Provider instance\n  model: \"xsai-model-name\", // Model identifier specific to this provider\n});\n\n// Use the agents (example)\nconst response = await vercelOpenAIAgent.generateText(\"Hello OpenAI via Vercel!\");\nconsole.log(response.text);\n\nconst response2 = await xsaiAgent.generateText(\"Hello XsAI!\");\nconsole.log(response2.text);\n\n```\n\n[**Learn more about available Providers and their specific configurations.**](https://voltagent.dev/docs/providers/overview/)\n\n### Provider Options [â€‹](https://voltagent.dev/docs/agents/overview/\\#provider-options \"Direct link to Provider Options\")\n\n**Why?** To provide a standardized way to configure model behavior across different LLM providers, making it easier to adjust generation parameters without worrying about provider-specific implementation details.\n\nVoltAgent uses a standardized `ProviderOptions` type that abstracts common LLM configuration options like temperature, max tokens, and frequency penalties. These options are automatically mapped to each provider's specific format internally, giving you a consistent developer experience regardless of which provider you're using.\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  name: \"Configurable Assistant\",\n  instructions: \"An assistant with configurable generation parameters\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n});\n\n// Example: Configure common LLM parameters regardless of provider\nconst response = await agent.generateText(\"Write a creative story about a robot.\", {\n  provider: {\n    // Fine-tune generation behavior with standardized options\n    temperature: 0.8, // Higher creativity (0-1)\n    maxTokens: 500, // Limit response length\n    topP: 0.9, // Nucleus sampling parameter\n    frequencyPenalty: 0.5, // Reduce repetition\n    presencePenalty: 0.3, // Encourage topic diversity\n    seed: 12345, // Reproducible results\n    stopSequences: [\"THE END\"], // Stop generation at specific string\n\n    // Add provider callbacks for streaming\n    onStepFinish: async (step) => {\n      console.log(\"Step complete:\", step.type);\n    },\n    onFinish: async (result) => {\n      console.log(\"Generation complete!\");\n    },\n    onError: async (error) => {\n      console.error(\"Generation error:\", error);\n    },\n\n    // Provider-specific options not covered by standard fields\n    extraOptions: {\n      someProviderSpecificOption: \"value\",\n    },\n  },\n});\n\n// Alternative: Provide parameters for streamed responses\nconst streamedResponse = await agent.streamText(\"Generate a business plan\", {\n  provider: {\n    temperature: 0.3, // More focused, less creative\n    maxTokens: 2000, // Longer response limit\n    // ... other options as needed\n  },\n});\n\n```\n\nUse these standardized options to:\n\n- Fine-tune response characteristics (creativity, length, diversity)\n- Register callbacks for streaming events\n- Achieve consistent behavior across different LLM providers\n- Create reproducible outputs with the same seed value\n\nThe options are applied consistently whether you're using `generateText`, `streamText`, `generateObject`, or `streamObject` methods.\n\n### Step Control with maxSteps [â€‹](https://voltagent.dev/docs/agents/overview/\\#step-control-with-maxsteps \"Direct link to Step Control with maxSteps\")\n\n**Why?** To control the number of iteration steps (turns) an agent can take during a single operation. This is particularly important for agents using tools, as they may need multiple LLM calls to complete a task: one to decide which tools to use, execute the tools, and then continue with the results.\n\nVoltAgent supports `maxSteps` configuration at both the agent level (applies to all operations) and per-operation level (overrides agent setting for specific calls).\n\n```codeBlockLines_e6Vv\nimport { Agent, createTool } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { z } from \"zod\";\n\nconst weatherTool = createTool({\n  name: \"get_weather\",\n  description: \"Get current weather\",\n  parameters: z.object({ location: z.string() }),\n  execute: async ({ location }) => {\n    return { temperature: 22, condition: \"sunny\" };\n  },\n});\n\n// Agent-level maxSteps (applies to all operations)\nconst agent = new Agent({\n  name: \"Weather Assistant\",\n  instructions: \"Help users with weather information using available tools\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  tools: [weatherTool],\n  maxSteps: 5, // All operations will use max 5 steps\n});\n\n// Basic usage - uses agent-level maxSteps (5)\nconst response1 = await agent.generateText(\"What's the weather in London?\");\nconsole.log(response1.text);\n\n// Override maxSteps for specific operation\nconst response2 = await agent.generateText(\"What's the weather in Tokyo?\", {\n  maxSteps: 3, // Override: use max 3 steps for this operation\n});\nconsole.log(response2.text);\n\n// Streaming with maxSteps override\nconst streamResponse = await agent.streamText(\"Check weather in Paris\", {\n  maxSteps: 2, // Override: use max 2 steps for this stream\n});\n\nfor await (const chunk of streamResponse.textStream) {\n  process.stdout.write(chunk);\n}\n\n```\n\n#### Understanding Steps [â€‹](https://voltagent.dev/docs/agents/overview/\\#understanding-steps \"Direct link to Understanding Steps\")\n\nEach \"step\" represents one interaction with the LLM. For example:\n\n- **Step 1**: LLM receives the prompt, decides to use the weather tool, and makes the tool call\n- **Step 2**: LLM receives the tool result and generates the final response\n\nWithout `maxSteps`, an agent might continue indefinitely if it keeps making tool calls. Setting `maxSteps` prevents runaway execution and ensures predictable behavior.\n\n#### maxSteps Priority [â€‹](https://voltagent.dev/docs/agents/overview/\\#maxsteps-priority \"Direct link to maxSteps Priority\")\n\nThe system follows this priority order:\n\n1. **Operation-level maxSteps** (highest priority) - specified in `generateText()`, `streamText()`, etc.\n2. **Agent-level maxSteps** \\- specified in agent constructor\n3. **Default calculation** \\- based on number of sub-agents (10 Ã— sub-agents count, minimum 10)\n\n#### Default maxSteps Values [â€‹](https://voltagent.dev/docs/agents/overview/\\#default-maxsteps-values \"Direct link to Default maxSteps Values\")\n\nVoltAgent provides sensible defaults that work well for most use cases:\n\n```codeBlockLines_e6Vv\n// Simple agent without sub-agents\nconst simpleAgent = new Agent({\n  name: \"Simple Assistant\",\n  instructions: \"A basic assistant\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  // Default: 10 steps (sufficient for most tool usage scenarios)\n});\n\n// Agent with sub-agents - automatic scaling\nconst supervisorAgent = new Agent({\n  name: \"Supervisor\",\n  instructions: \"Coordinates specialized tasks\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  subAgents: [agent1, agent2, agent3], // 3 sub-agents\n  // Default: 10 Ã— 3 = 30 steps (scales with complexity)\n});\n\n```\n\n**Default Values:**\n\n- **Basic agents**: 10 steps (covers initial request + tool usage + response)\n- **Multi-agent workflows**: 10 Ã— number of sub-agents (accommodates delegation overhead)\n\n**When Defaults Are Sufficient:**\n\n- Simple question-answering agents\n- Basic tool usage (1-3 tool calls)\n- Standard customer service interactions\n- Content generation with minimal tool usage\n\n**When to Increase maxSteps:**\n\n- Complex research tasks requiring multiple API calls\n- Advanced workflows with deep sub-agent interactions\n- Iterative problem-solving requiring multiple refinement steps\n- Custom enterprise workflows with specific requirements\n\n```codeBlockLines_e6Vv\n// Custom solution requiring higher step limits\nconst complexResearchAgent = new Agent({\n  name: \"Advanced Research Agent\",\n  instructions: \"Conducts comprehensive research with iterative refinement\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  tools: [webSearchTool, databaseTool, analysisTool],\n  maxSteps: 50, // Custom limit for complex workflows\n});\n\n// Enterprise workflow with multiple coordination layers\nconst enterpriseWorkflow = new Agent({\n  name: \"Enterprise Coordinator\",\n  instructions: \"Manages complex business processes\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  subAgents: [dataAgent, analysisAgent, reportAgent, reviewAgent],\n  maxSteps: 100, // High limit for enterprise complexity\n});\n\n```\n\n### Cancellation with AbortController [â€‹](https://voltagent.dev/docs/agents/overview/\\#cancellation-with-abortcontroller \"Direct link to Cancellation with AbortController\")\n\n**Why?** To provide graceful cancellation of long-running operations like LLM generation, tool execution, or streaming responses. This is essential for user-initiated cancellations, implementing timeouts, and preventing unnecessary work when results are no longer needed.\n\nVoltAgent supports the standard `AbortController` API across all generation methods. When an operation is aborted, it immediately stops processing, cancels any ongoing tool executions, and cleans up resources.\n\n```codeBlockLines_e6Vv\nimport { Agent, isAbortError } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  name: \"Cancellable Assistant\",\n  instructions: \"An assistant that supports operation cancellation\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n});\n\n// Example: Timeout-based cancellation\nconst abortController = new AbortController();\n\n// Cancel after 5 seconds\nsetTimeout(() => {\n  abortController.abort(\"Operation timeout after 5 seconds\");\n}, 5000);\n\ntry {\n  // Pass the abortController to any generation method\n  const response = await agent.generateText(\"Write a very long story...\", {\n    abortController, // The operation will be cancelled if timeout occurs\n  });\n  console.log(response.text);\n} catch (error) {\n  if (isAbortError(error)) {\n    console.log(\"Operation was cancelled:\", error.message);\n  } else {\n    console.error(\"Generation failed:\", error);\n  }\n}\n\n```\n\n#### Tool Cancellation [â€‹](https://voltagent.dev/docs/agents/overview/\\#tool-cancellation \"Direct link to Tool Cancellation\")\n\nWhen an `AbortController` is provided to agent methods, it's automatically propagated to tools through the operation context. Tools can access both the signal and the abort capability:\n\n```codeBlockLines_e6Vv\nconst searchTool = createTool({\n  name: \"search_web\",\n  description: \"Search the web for information\",\n  parameters: z.object({\n    query: z.string().describe(\"The search query\"),\n  }),\n  execute: async (args, options) => {\n    // Access the AbortController from operation context\n    const abortController = options?.operationContext?.abortController;\n\n    // Example: Tool can trigger abort if needed\n    if (args.query.includes(\"forbidden\")) {\n      abortController?.abort(\"Search query contains forbidden terms\");\n      return { error: \"Search cancelled due to policy violation\" };\n    }\n\n    const signal = abortController?.signal;\n    // Pass signal to cancellable operations like fetch\n    const response = await fetch(`https://api.search.com?q=${args.query}`, {\n      signal: signal,\n    });\n\n    return await response.json();\n  },\n});\n\n```\n\nTools access cancellation through `options.operationContext.abortController`:\n\n- `.signal` \\- Check if operation was aborted\n- `.abort()` \\- Trigger cancellation from within the tool\n\nThis means if you cancel an agent operation, any active tool executions will also be cancelled gracefully. Additionally, tools can trigger cancellation themselves when needed.\n\n**Common Cancellation Scenarios:**\n\n- **User Interface**: Let users cancel long-running operations\n- **Timeouts**: Prevent operations from running too long\n- **Resource Management**: Stop unnecessary work when switching contexts\n- **Error Recovery**: Cancel related operations when one fails\n- **Batch Processing**: Cancel remaining operations when stopping a batch\n\nFor detailed examples of implementing cancellable tools, including error handling and best practices, see the [Tools documentation on AbortSignal](https://voltagent.dev/docs/agents/tools/#cancellable-tools-with-abortsignal).\n\n### MCP (Model Context Protocol) [â€‹](https://voltagent.dev/docs/agents/overview/\\#mcp-model-context-protocol \"Direct link to MCP (Model Context Protocol)\")\n\n**Why?** To enable standardized communication between your agent and external, potentially independent, model/tool servers, promoting interoperability and modular deployment.\n\nConnect to external servers that adhere to the MCP specification to leverage their capabilities (e.g., specialized models or tools) without directly integrating their code. MCP tools are treated like any other tool and can be invoked during `generate*`/ `stream*` calls.\n\n```codeBlockLines_e6Vv\nimport { Agent, MCPConfiguration } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Set up MCP configuration pointing to your external server(s)\nconst mcpConfig = new MCPConfiguration({\n  servers: {\n    // Define one or more MCP-compliant servers\n    myModelServer: {\n      type: \"http\", // Communication type\n      url: \"https://my-mcp-server.example.com\", // URL of the MCP server\n    },\n  },\n});\n\n// Asynchronously fetch tools offered by the configured MCP server(s)\nconst mcpTools = await mcpConfig.getTools();\n\n// Create an agent that can utilize these external MCP tools\nconst agent = new Agent({\n  name: \"MCP Agent\",\n  instructions: \"Uses external model capabilities via MCP\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  // Add the tools fetched from the MCP server\n  tools: mcpTools,\n});\n\n// Example: Call streamText\nconst response = await agent.generateText(\"Use the external analysis tool on this data...\");\nconsole.log(response.text);\n// The agent can now potentially call tools hosted on 'myModelServer'.\n\n```\n\n[Learn more about MCP](https://voltagent.dev/docs/agents/mcp/)\n\n### Voice [â€‹](https://voltagent.dev/docs/agents/overview/\\#voice \"Direct link to Voice\")\n\n**Why?** To build voice-based applications by adding speech-to-text (STT) and text-to-speech (TTS) capabilities to your agent.\n\nIntegrate with voice providers like OpenAI or ElevenLabs. Use the provider directly for STT/TTS, or configure it on the agent ( `agent.voice`) and use its methods (e.g., `agent.voice.speak()`) to synthesize the agent's text response.\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n// Import voice providers\nimport { OpenAIVoiceProvider, ElevenLabsVoiceProvider } from \"@voltagent/voice\";\nimport { createReadStream, createWriteStream } from \"fs\";\nimport { pipeline } from \"stream/promises\";\n\n// --- Using a Voice Provider directly ---\n\n// Option 1: OpenAI Voice\nconst openaiVoice = new OpenAIVoiceProvider({\n  apiKey: process.env.OPENAI_API_KEY,\n  ttsModel: \"tts-1\", // Text-to-Speech model\n  voice: \"alloy\", // Choose a voice (alloy, echo, fable, onyx, nova, shimmer)\n});\n\n// Text to Speech (TTS) -> Returns a Readable stream of audio data\nconst audioStream = await openaiVoice.speak(\"Hello from OpenAI voice!\");\n// Example: Pipe the audio stream to a file\nawait pipeline(audioStream, createWriteStream(\"openai_output.mp3\"));\n\n// Speech to Text (STT) -> Takes an audio source (e.g., Readable stream)\nconst audioFileStream = createReadStream(\"input.mp3\");\nconst transcript = await openaiVoice.listen(audioFileStream);\nconsole.log(\"OpenAI Transcript:\", transcript);\n\n// Option 2: ElevenLabs Voice\nconst elevenLabsVoice = new ElevenLabsVoiceProvider({\n  apiKey: process.env.ELEVENLABS_API_KEY,\n  voice: \"Rachel\", // Choose an ElevenLabs voice ID or name\n});\n\n// TTS with ElevenLabs\nconst elAudioStream = await elevenLabsVoice.speak(\"Hello from ElevenLabs!\");\nawait pipeline(elAudioStream, createWriteStream(\"elevenlabs_output.mp3\"));\n\n// --- Integrating Voice with an Agent ---\n\nconst agent = new Agent({\n  name: \"Voice Assistant\",\n  instructions: \"A helpful voice assistant\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  // Assign a voice provider instance to the agent's voice property\n  voice: elevenLabsVoice, // Or use openaiVoice\n});\n\n// To generate voice from an agent response:\n// 1. Generate the text response using a core agent method.\nconst textResponse = await agent.generateText(\"Tell me a short story.\");\n\n// 2. Check if the agent has a voice provider configured.\nif (agent.voice && textResponse.text) {\n  // 3. Call the 'speak' method on the agent's voice provider instance.\n  console.log(\"Generating voice output...\");\n  const agentAudioStream = await agent.voice.speak(textResponse.text);\n\n  // Example: Save the agent's spoken response to a file\n  await pipeline(agentAudioStream, createWriteStream(\"agent_story.mp3\"));\n  console.log(\"Generated voice output stream.\");\n} else {\n  console.log(\"Agent response:\", textResponse.text);\n  if (!agent.voice) {\n    console.log(\"(Agent has no voice provider configured)\");\n  }\n}\n\n```\n\n[Learn more about Voice Agents](https://voltagent.dev/docs/agents/voice/)\n\n## Error Handling [â€‹](https://voltagent.dev/docs/agents/overview/\\#error-handling \"Direct link to Error Handling\")\n\nWhen interacting with agents ( `generateText`, `streamText`, etc.), operations can fail due to network issues, API errors, tool execution problems, or other runtime exceptions.\n\n**Synchronous Errors (e.g., during setup):**\n\nUse standard JavaScript `try...catch` blocks around the agent method calls ( `generateText`, `streamText`, `generateObject`, `streamObject`). This will catch errors that occur _before_ the main operation or stream begins, such as configuration issues or initial API connection failures.\n\n```codeBlockLines_e6Vv\nconst agent = new Agent({\n  /* ... configuration ... */\n});\n\ntry {\n  // This try/catch handles errors during the initial call setup\n  const response = await agent.streamText(\"Some complex request that might fail initially\");\n\n  // Processing the stream itself might encounter errors handled differently (see below)\n  console.log(\"Stream processing started...\");\n  for await (const delta of response.stream) {\n    // ... handle deltas ...\n    process.stdout.write(delta.type === \"text-delta\" ? delta.textDelta : \"\");\n  }\n  // Note: If an error occurs *during* the stream, the loop might finish,\n  // but the final history entry status will indicate an error.\n  console.log(\"Interaction finished processing stream.\");\n} catch (error) {\n  // Catches errors from the initial await agent.streamText() call\n  console.error(\"Agent interaction failed during setup:\", error);\n  // Implement fallback logic, inform the user, or log the error\n}\n\n```\n\n**Asynchronous Errors (e.g., during streaming):**\n\nErrors that occur _during_ the streaming process (after the initial `await agent.streamText()` call succeeds) are handled internally by VoltAgent:\n\n1. The corresponding history entry is automatically updated with an `error` status.\n2. An error event is added to the agent's timeline.\n3. These errors **do not** typically cause the `await agent.streamText(...)` call or the `for await...of response.stream` loop itself to throw.\n\nTo observe or react to these asynchronous errors, you can:\n\n- **Check History:** After the stream finishes (the `for await` loop completes), check the status of the corresponding `AgentHistoryEntry`.\n\n- **Use Agent Hooks:** The existing hooks ( `onStart`, `onEnd`, `onToolStart`, `onToolEnd`) can still provide valuable context for logging and debugging around the points where errors might occur, even though there isn't a specific `onError` hook.\n\n- **Use `onError` Callback (Per-Call):** Pass an `onError` callback directly in the `provider` options when calling `streamText` (or other methods). This is the most direct way to be notified of errors _during_ the stream for a specific call.\n\n\n\n\n\n```codeBlockLines_e6Vv\n// Example with streamText\nconst response = await agent.streamText(\"Another request\", {\n    provider: {\n      onError: async (error) => {\n        console.error(\"onError callback: Stream encountered an error:\", error);\n        // Implement specific error handling for this call\n      },\n    },\n});\n\n```\n\n\nBy combining `try...catch` for initial errors and using the per-call `onError` callback or checking history for stream errors, you can effectively manage issues during agent interactions.\n\n## Next Steps [â€‹](https://voltagent.dev/docs/agents/overview/\\#next-steps \"Direct link to Next Steps\")\n\nNow that you have an overview of the `Agent` class and its core interaction methods, dive deeper into specific areas:\n\n- Explore the dedicated documentation pages linked in each section above (Memory, Tools, Providers, etc.).\n- Check out our [examples repository](https://github.com/voltagent/voltagent/tree/main/examples) for complete working applications built with VoltAgent.\n\n### Table of Contents\n\n- [Creating an Agent](https://voltagent.dev/docs/agents/overview/#creating-an-agent)\n- [Constructor Options](https://voltagent.dev/docs/agents/overview/#constructor-options)\n- [Core Interaction Methods](https://voltagent.dev/docs/agents/overview/#core-interaction-methods)\n  - [Text Generation ( `generateText`/ `streamText`)](https://voltagent.dev/docs/agents/overview/#text-generation-generatetextstreamtext)\n  - [SubAgent Event Filtering](https://voltagent.dev/docs/agents/overview/#subagent-event-filtering)\n  - [Structured Data Generation ( `generateObject`/ `streamObject`)](https://voltagent.dev/docs/agents/overview/#structured-data-generation-generateobjectstreamobject)\n- [Advanced Features](https://voltagent.dev/docs/agents/overview/#advanced-features)\n  - [Memory](https://voltagent.dev/docs/agents/overview/#memory)\n  - [Tools](https://voltagent.dev/docs/agents/overview/#tools)\n  - [Sub-Agents](https://voltagent.dev/docs/agents/overview/#sub-agents)\n  - [Hooks](https://voltagent.dev/docs/agents/overview/#hooks)\n  - [Prompt Management](https://voltagent.dev/docs/agents/overview/#prompt-management)\n  - [Dynamic Agents](https://voltagent.dev/docs/agents/overview/#dynamic-agents)\n  - [Operation Context ( `userContext`)](https://voltagent.dev/docs/agents/overview/#operation-context-usercontext)\n  - [Retriever](https://voltagent.dev/docs/agents/overview/#retriever)\n  - [Providers](https://voltagent.dev/docs/agents/overview/#providers)\n  - [Provider Options](https://voltagent.dev/docs/agents/overview/#provider-options)\n  - [Step Control with maxSteps](https://voltagent.dev/docs/agents/overview/#step-control-with-maxsteps)\n  - [Cancellation with AbortController](https://voltagent.dev/docs/agents/overview/#cancellation-with-abortcontroller)\n  - [MCP (Model Context Protocol)](https://voltagent.dev/docs/agents/overview/#mcp-model-context-protocol)\n  - [Voice](https://voltagent.dev/docs/agents/overview/#voice)\n- [Error Handling](https://voltagent.dev/docs/agents/overview/#error-handling)\n- [Next Steps](https://voltagent.dev/docs/agents/overview/#next-steps)",
      "metadata": {
        "ogDescription": "The Agent class is the fundamental building block of VoltAgent. It acts as the central orchestrator, allowing you to create AI agents that interact with Large Language Models (LLMs), use tools to interact with the outside world, maintain conversational memory, and embody specific personalities or instructions.",
        "ogUrl": "https://voltagent.dev/docs/agents/overview/",
        "twitter:card": "summary_large_image",
        "viewport": "width=device-width, initial-scale=1.0",
        "docsearch:docusaurus_tag": "docs-default-current",
        "docsearch:version": "current",
        "ogTitle": "Overview | VoltAgent",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "title": "Overview | VoltAgent",
        "ogLocale": "en",
        "docusaurus_locale": "en",
        "og:title": "Overview | VoltAgent",
        "description": "The Agent class is the fundamental building block of VoltAgent. It acts as the central orchestrator, allowing you to create AI agents that interact with Large Language Models (LLMs), use tools to interact with the outside world, maintain conversational memory, and embody specific personalities or instructions.",
        "language": "en",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "docsearch:language": "en",
        "docusaurus_version": "current",
        "og:description": "The Agent class is the fundamental building block of VoltAgent. It acts as the central orchestrator, allowing you to create AI agents that interact with Large Language Models (LLMs), use tools to interact with the outside world, maintain conversational memory, and embody specific personalities or instructions.",
        "og:url": "https://voltagent.dev/docs/agents/overview/",
        "generator": "Docusaurus v3.1.1",
        "docusaurus_tag": "docs-default-current",
        "og:locale": "en",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "og:image": "https://voltagent.dev/img/social3.png",
        "scrapeId": "4c714feb-7e5a-42e0-aab9-94ad8340669e",
        "sourceURL": "https://voltagent.dev/docs/agents/overview/",
        "url": "https://voltagent.dev/docs/agents/overview/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:05.181Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/providers/google-ai/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\nDeprecated Package\n\n**This provider is deprecated.** We recommend using the [Vercel AI SDK's Google providers](https://ai-sdk.dev/providers/ai-sdk-providers/google-generative-ai) instead with `@voltagent/vercel-ai`.\n\n**Migration Guide:**\n\n```codeBlockLines_e6Vv\n// Old (deprecated)\nimport { GoogleAIProvider } from \"@voltagent/google-ai\";\nconst provider = new GoogleAIProvider({ apiKey: \"...\" });\n\n// New (recommended) - for Gemini API\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { google } from \"@ai-sdk/google\";\nconst provider = new VercelAIProvider();\n// Use with: model: google(\"gemini-1.5-pro\")\n\n// New (recommended) - for Vertex AI\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { vertex } from \"@ai-sdk/google-vertex\";\nconst provider = new VercelAIProvider();\n// Use with: model: vertex(\"gemini-1.5-pro\")\n\n```\n\nFor the latest models and features, please see our [Providers & Models guide](https://voltagent.dev/docs/getting-started/providers-models/).\n\n# Google AI Provider ( `@voltagent/google-ai`)\n\nThe Google AI Provider integrates VoltAgent with Google's Generative AI capabilities, supporting both the Gemini API (via API Key) and Vertex AI (via project/location configuration). It wraps the [`@google/genai`](https://github.com/googleapis/js-genai) SDK.\n\n**Key Characteristics:**\n\n- **Dual API Support:** Works seamlessly with both Google AI Studio's Gemini API (using an API key) and Google Cloud's Vertex AI platform.\n- **Model Agnostic (within Google):** Accepts standard Google model identifier strings (e.g., `'gemini-1.5-pro'`, `'gemini-1.5-flash'`).\n- **Core Functionality:** Focuses on text generation, streaming, and structured object generation using the underlying Google SDK.\n\n## Installation [â€‹](https://voltagent.dev/docs/providers/google-ai/\\#installation \"Direct link to Installation\")\n\n- npm\n- yarn\n- pnpm\n\n```codeBlockLines_e6Vv\nnpm install @voltagent/core @voltagent/google-ai zod\n\n```\n\n_Note: `@google/genai` is a peer dependency. `zod` is required if using `generateObject`._\n\nSubagents Known Issue\n\nThere's currently a known issue with using `@voltagent/google-ai` provider in [Subagents](https://voltagent.dev/docs/agents/sub-agents/) configurations. This is an open contribution opportunity!\n\n**Workaround:** Until this is fixed, you can use [`@voltagent/vercel-ai`](https://voltagent.dev/docs/providers/vercel-ai/) with `@ai-sdk/google` which works seamlessly with Google models.\n\n```codeBlockLines_e6Vv\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { google } from \"@ai-sdk/google\";\n\nconst agent = new Agent({\n  name: \"Google Assistant\",\n  llm: new VercelAIProvider(),\n  model: google(\"gemini-2.0-flash\"),\n});\n\n```\n\n## Configuration [â€‹](https://voltagent.dev/docs/providers/google-ai/\\#configuration \"Direct link to Configuration\")\n\nThe `GoogleGenAIProvider` requires configuration either for the Gemini API or Vertex AI.\n\n**1\\. Using Gemini API Key:**\n\nProvide your API key directly or set the `GEMINI_API_KEY` environment variable.\n\n```codeBlockLines_e6Vv\nimport { GoogleGenAIProvider } from \"@voltagent/google-ai\";\n\n// Option 1: Direct API Key\nconst googleProviderApiKey = new GoogleGenAIProvider({\n  apiKey: \"YOUR_GEMINI_API_KEY\",\n});\n\n// Option 2: Environment Variable (GEMINI_API_KEY)\n// Ensure process.env.GEMINI_API_KEY is set\nconst googleProviderEnv = new GoogleGenAIProvider({});\n\n```\n\n**2\\. Using Vertex AI:**\n\nProvide your Google Cloud project ID and location. Ensure your environment is authenticated (e.g., via `gcloud auth application-default login`). **Note:** The `vertexai: true` flag is required alongside `project` and `location`.\n\n```codeBlockLines_e6Vv\nimport { GoogleGenAIProvider } from \"@voltagent/google-ai\";\n\nconst googleProviderVertex = new GoogleGenAIProvider({\n  vertexai: true, // Required for Vertex AI\n  project: \"YOUR_GCP_PROJECT_ID\",\n  location: \"YOUR_GCP_LOCATION\", // e.g., 'us-central1'\n});\n\n```\n\n**Important:** You cannot provide both an `apiKey` and Vertex AI configuration ( `project`/ `location`) simultaneously.\n\n## Full Runnable Examples [â€‹](https://voltagent.dev/docs/providers/google-ai/\\#full-runnable-examples \"Direct link to Full Runnable Examples\")\n\nFor complete, runnable examples demonstrating the use of this provider, please see:\n\n- **Google AI (Gemini API Key):** [`examples/with-google-ai`](https://github.com/VoltAgent/voltagent/tree/main/examples/with-google-ai)\n- **Google Vertex AI:** [`examples/with-google-vertex-ai`](https://github.com/VoltAgent/voltagent/tree/main/examples/with-google-vertex-ai)\n\n## Usage [â€‹](https://voltagent.dev/docs/providers/google-ai/\\#usage \"Direct link to Usage\")\n\nInstantiate your `Agent` with the configured `GoogleGenAIProvider`:\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { GoogleGenAIProvider } from \"@voltagent/google-ai\";\n\n// Using API Key configuration from above\nconst googleProvider = new GoogleGenAIProvider({ apiKey: \"YOUR_GEMINI_API_KEY\" });\n// Or using Vertex AI configuration\n// const googleProvider = new GoogleGenAIProvider({ project: '...', location: '...' });\n\nconst agent = new Agent({\n  name: \"Google Gemini Agent\",\n  instructions: \"An agent powered by Google Gemini\",\n  llm: googleProvider,\n  model: \"gemini-1.5-flash\", // Specify the desired Google model ID\n});\n\n// Example call\nasync function run() {\n  const response = await agent.generateText(\n    \"Explain the difference between Google Gemini and Vertex AI.\"\n  );\n  console.log(response.text);\n}\n\nrun();\n\n```\n\n## Supported Methods [â€‹](https://voltagent.dev/docs/providers/google-ai/\\#supported-methods \"Direct link to Supported Methods\")\n\n- **`generateText`**: Supported. Calls Google GenAI SDK's `generateContent`.\n- **`streamText`**: Supported. Calls Google GenAI SDK's `generateContentStream`.\n- **`generateObject`**: Supported. Calls Google GenAI SDK's `generateContent` with `responseMimeType: 'application/json'` and a derived `responseSchema`. Requires a `z.ZodObject` schema.\n- **`streamObject`**: âŒ **Not Supported.** The underlying Google SDK streams partial text chunks, which cannot be reliably converted into partial JSON objects during the stream.\n\n## Multi-modal Support [â€‹](https://voltagent.dev/docs/providers/google-ai/\\#multi-modal-support \"Direct link to Multi-modal Support\")\n\nâŒ **Not Supported.**\n\nCurrently, the provider only processes the `text` parts of `BaseMessage` content arrays. Other modalities (like images) are ignored. Future versions may add support if the underlying Google SDK allows straightforward integration.\n\n## Tool Calling Support [â€‹](https://voltagent.dev/docs/providers/google-ai/\\#tool-calling-support \"Direct link to Tool Calling Support\")\n\nâœ… **Supported!**\n\nThe `@voltagent/google-ai` provider now supports native tool calling and function calling features directly through VoltAgent's `generateText` or `streamText` methods with tool definitions. This allows you to define tools (functions) that the Google AI models can invoke as part of their response generation.\n\nThis functionality was added in [PR #99](https://github.com/VoltAgent/voltagent/pull/99) by [@luixaviles](https://github.com/luixaviles). Thanks for the contribution!\n\nFor examples and further details on how to define and use tools with VoltAgent, please refer to the general VoltAgent documentation on [Tool Calling](https://voltagent.dev/docs/tools/overview/).\n\n## Model Selection & Options [â€‹](https://voltagent.dev/docs/providers/google-ai/\\#model-selection--options \"Direct link to Model Selection & Options\")\n\nThe specific Google model (e.g., `'gemini-1.5-pro'`, `'gemini-1.5-flash'`) is set via the `model` property during `Agent` instantiation.\n\nYou can override or provide additional Google-specific generation parameters (like `temperature`, `topP`, `seed`, `stopSequences`, etc.) per-request using the `provider` key within the options object of `generateText`, `streamText`, or `generateObject`.\n\n```codeBlockLines_e6Vv\n// Example: Overriding temperature for a specific call\nconst response = await agent.generateText(\"Write a creative story.\", {\n  provider: {\n    temperature: 0.9,\n    topK: 40, // Google-specific parameter\n    // Any other valid GenerateContentConfig options\n  },\n});\n\n// Example: Using thinkingConfig to control thinking budget\nconst response = await agent.generateText(\"Write a creative story.\", {\n  provider: {\n    thinkingConfig: {\n      thinkingBudget: 0,\n    },\n  },\n});\n\n```\n\nRefer to the [`@google/genai` documentation](https://github.com/googleapis/js-genai) for the full list of available configuration parameters within `GenerateContentConfig`.\n\n## Code Examples [â€‹](https://voltagent.dev/docs/providers/google-ai/\\#code-examples \"Direct link to Code Examples\")\n\n### Text Generation ( `generateText`) [â€‹](https://voltagent.dev/docs/providers/google-ai/\\#text-generation-generatetext \"Direct link to text-generation-generatetext\")\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { GoogleGenAIProvider } from \"@voltagent/google-ai\";\n\nasync function main() {\n  const googleProvider = new GoogleGenAIProvider({\n    apiKey: process.env.GEMINI_API_KEY, // Ensure GEMINI_API_KEY is set\n  });\n\n  const agent = new Agent({\n    name: \"Google Text Agent\",\n    instructions: \"Generates text using Google AI\",\n    llm: googleProvider,\n    model: \"gemini-1.5-flash\",\n  });\n\n  const prompt = \"What are the main features of the Gemini 1.5 Pro model?\";\n\n  try {\n    const response = await agent.generateText(prompt);\n    console.log(`Agent response to \"${prompt}\":`);\n    console.log(response.text);\n    console.log(\"Usage:\", response.usage);\n  } catch (error) {\n    console.error(\"Error generating text:\", error);\n  }\n}\n\nmain();\n\n```\n\n### Streaming Text ( `streamText`) [â€‹](https://voltagent.dev/docs/providers/google-ai/\\#streaming-text-streamtext \"Direct link to streaming-text-streamtext\")\n\n```codeBlockLines_e6Vv\nimport { Agent } from '@voltagent/core';\nimport { GoogleGenAIProvider } from '@voltagent/google-ai';\n\nasync function main() {\n  const googleProvider = new GoogleGenAIProvider({\n    apiKey: process.env.GEMINI_API_KEY,\n  });\n\n  const agent = new Agent({\n    name: 'Google Streaming Agent',\n    instructions: 'Streams text using Google AI',\n    llm: googleProvider,\n    model: 'gemini-1.5-flash',\n  });\n\n  const prompt = \"Write a short poem about the evolution of AI.\";\n\n  try {\n    const streamResponse = await agent.streamText(prompt);\n\n    console.log(`Streaming agent response to \"${prompt}\":`);\n    for await (const chunk of streamResponse.textStream) {\n      process.stdout.write(chunk);\n    }\n    console.log('\n--- Stream Finished ---');\n    // Note: Usage info might not be available until the stream completes\n    // and is accessed via callbacks (onFinish, onStepFinish) or potentially\n    // attached to the stream result object in future updates.\n  } catch (error) {\n    console.error(\"Error streaming text:\", error);\n  }\n}\n\nmain();\n\n```\n\n### Generating Structured Objects ( `generateObject`) [â€‹](https://voltagent.dev/docs/providers/google-ai/\\#generating-structured-objects-generateobject \"Direct link to generating-structured-objects-generateobject\")\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { GoogleGenAIProvider } from \"@voltagent/google-ai\";\nimport { z } from \"zod\"; // Import Zod\n\n// Define a Zod schema for the desired object structure\nconst characterSchema = z.object({\n  name: z.string().describe(\"The character's name\"),\n  species: z.string().describe(\"The character's species\"),\n  abilities: z.array(z.string()).describe(\"List of key abilities\"),\n  homePlanet: z.string().optional().describe(\"The character's home planet (if known)\"),\n});\n\nasync function main() {\n  const googleProvider = new GoogleGenAIProvider({\n    apiKey: process.env.GEMINI_API_KEY,\n  });\n\n  // Ensure the model supports function calling/JSON mode\n  const agent = new Agent({\n    name: \"Google Object Agent\",\n    instructions: \"Generates structured data using Google AI\",\n    llm: googleProvider,\n    model: \"gemini-1.5-pro\", // Models like Pro are generally better for structured output\n  });\n\n  const prompt =\n    \"Generate details for a sci-fi character: a veteran space pilot named Commander Valerius, who is human and known for exceptional navigation skills and piloting expertise.\";\n\n  try {\n    // Call generateObject with the prompt and Zod schema\n    const response = await agent.generateObject(prompt, characterSchema, {\n      provider: {\n        temperature: 0.2, // Lower temperature often helps with structured formats\n      },\n    });\n\n    console.log(\"Generated Object:\");\n    console.log(response.object);\n    console.log(\"Usage:\", response.usage);\n    console.log(\"Finish Reason:\", response.finishReason);\n  } catch (error) {\n    console.error(\"Error generating object:\", error);\n  }\n}\n\nmain();\n\n```\n\n### Table of Contents\n\n- [Installation](https://voltagent.dev/docs/providers/google-ai/#installation)\n- [Configuration](https://voltagent.dev/docs/providers/google-ai/#configuration)\n- [Full Runnable Examples](https://voltagent.dev/docs/providers/google-ai/#full-runnable-examples)\n- [Usage](https://voltagent.dev/docs/providers/google-ai/#usage)\n- [Supported Methods](https://voltagent.dev/docs/providers/google-ai/#supported-methods)\n- [Multi-modal Support](https://voltagent.dev/docs/providers/google-ai/#multi-modal-support)\n- [Tool Calling Support](https://voltagent.dev/docs/providers/google-ai/#tool-calling-support)\n- [Model Selection & Options](https://voltagent.dev/docs/providers/google-ai/#model-selection--options)\n- [Code Examples](https://voltagent.dev/docs/providers/google-ai/#code-examples)\n  - [Text Generation ( `generateText`)](https://voltagent.dev/docs/providers/google-ai/#text-generation-generatetext)\n  - [Streaming Text ( `streamText`)](https://voltagent.dev/docs/providers/google-ai/#streaming-text-streamtext)\n  - [Generating Structured Objects ( `generateObject`)](https://voltagent.dev/docs/providers/google-ai/#generating-structured-objects-generateobject)",
      "metadata": {
        "og:image": "https://voltagent.dev/img/social3.png",
        "og:locale": "en",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_tag": "docs-default-current",
        "title": "Google AI (Gemini & Vertex AI) | VoltAgent",
        "ogDescription": "This provider is deprecated. We recommend using the Vercel AI SDK's Google providers instead with @voltagent/vercel-ai.",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "docusaurus_locale": "en",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "description": "This provider is deprecated. We recommend using the Vercel AI SDK's Google providers instead with @voltagent/vercel-ai.",
        "language": "en",
        "docsearch:version": "current",
        "og:url": "https://voltagent.dev/docs/providers/google-ai/",
        "ogUrl": "https://voltagent.dev/docs/providers/google-ai/",
        "ogTitle": "Google AI (Gemini & Vertex AI) | VoltAgent",
        "ogLocale": "en",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:title": "Google AI (Gemini & Vertex AI) | VoltAgent",
        "generator": "Docusaurus v3.1.1",
        "docsearch:language": "en",
        "docusaurus_version": "current",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "twitter:card": "summary_large_image",
        "og:description": "This provider is deprecated. We recommend using the Vercel AI SDK's Google providers instead with @voltagent/vercel-ai.",
        "scrapeId": "4d976f8b-9932-417b-8b0d-ffc9d6fa7219",
        "sourceURL": "https://voltagent.dev/docs/providers/google-ai/",
        "url": "https://voltagent.dev/docs/providers/google-ai/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:43.669Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/rag/pinecone/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# VoltAgent with Pinecone\n\n[Pinecone](https://www.pinecone.io/) is a fully managed vector database built for machine learning applications that require fast, accurate vector search at scale. It offers serverless deployment, automatic scaling, and enterprise-grade security.\n\n## Prerequisites [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#prerequisites \"Direct link to Prerequisites\")\n\nBefore starting, ensure you have:\n\n- Node.js 18+ installed\n- Pinecone account (free tier available)\n- Pinecone API key\n- OpenAI API key (for embeddings)\n\n## Installation [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#installation \"Direct link to Installation\")\n\nCreate a new VoltAgent project with Pinecone integration:\n\n```codeBlockLines_e6Vv\nnpm create voltagent-app@latest -- --example with-pinecone\ncd with-pinecone\n\n```\n\nThis creates a complete VoltAgent + Pinecone setup with sample data and two different agent configurations.\n\nInstall the dependencies:\n\n- npm\n- pnpm\n- yarn\n\n```codeBlockLines_e6Vv\nnpm install\n\n```\n\n## Environment Setup [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#environment-setup \"Direct link to Environment Setup\")\n\nCreate a `.env` file with your configuration:\n\n```codeBlockLines_e6Vv\n# Pinecone API key from https://app.pinecone.io/\nPINECONE_API_KEY=your-pinecone-api-key-here\n\n# OpenAI API key for embeddings and LLM\nOPENAI_API_KEY=your-openai-api-key-here\n\n```\n\n### Getting Your Pinecone API Key [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#getting-your-pinecone-api-key \"Direct link to Getting Your Pinecone API Key\")\n\n1. Sign up for a free account at [pinecone.io](https://pinecone.io/)\n2. Navigate to the [Pinecone console](https://app.pinecone.io/)\n3. Go to \"API Keys\" in the sidebar\n4. Create a new API key or copy your existing one\n\n## Run Your Application [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#run-your-application \"Direct link to Run Your Application\")\n\nStart your VoltAgent application:\n\n- npm\n- pnpm\n- yarn\n\n```codeBlockLines_e6Vv\nnpm run dev\n\n```\n\nYou'll see:\n\n```codeBlockLines_e6Vv\nðŸš€ VoltAgent with Pinecone is running!\nðŸ“‹ Creating new index \"voltagent-knowledge-base\"...\nâœ… Index \"voltagent-knowledge-base\" created successfully\nðŸ“š Populating index with sample documents...\nâœ… Successfully upserted 5 documents to index\nðŸ“š Two different agents are ready:\n  1ï¸âƒ£ Assistant with Retriever - Automatic semantic search on every interaction\n  2ï¸âƒ£ Assistant with Tools - LLM decides when to search autonomously\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  VOLTAGENT SERVER STARTED SUCCESSFULLY\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  âœ“ HTTP Server: http://localhost:3141\n\n  VoltOps Platform:    https://console.voltagent.dev\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n```\n\n## Interact with Your Agents [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#interact-with-your-agents \"Direct link to Interact with Your Agents\")\n\nYour agents are now running! To interact with them:\n\n1. **Open the Console:** Click the [`https://console.voltagent.dev`](https://console.voltagent.dev/) link in your terminal output (or copy-paste it into your browser).\n2. **Find Your Agents:** On the VoltOps LLM Observability Platform page, you should see both agents listed:\n\n   - \"Assistant with Retriever\"\n   - \"Assistant with Tools\"\n3. **Open Agent Details:** Click on either agent's name.\n4. **Start Chatting:** On the agent detail page, click the chat icon in the bottom right corner to open the chat window.\n5. **Test RAG Capabilities:** Try questions like:\n\n   - \"What is VoltAgent?\"\n   - \"Tell me about Pinecone\"\n   - \"How does vector search work?\"\n   - \"What is RAG?\"\n\n![VoltAgent with Pinecone Demo](https://cdn.voltagent.dev/docs/chroma-rag-example.gif)\n\nYou should receive responses from your AI agents that include relevant information from your Pinecone knowledge base, along with source references showing which documents were used to generate the response.\n\n## How It Works [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#how-it-works \"Direct link to How It Works\")\n\nThe following sections explain how this example is built and how you can customize it.\n\n### Create the Pinecone Retriever [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#create-the-pinecone-retriever \"Direct link to Create the Pinecone Retriever\")\n\nCreate `src/retriever/index.ts`:\n\n```codeBlockLines_e6Vv\nimport { BaseRetriever, type BaseMessage, type RetrieveOptions } from \"@voltagent/core\";\nimport { Pinecone } from \"@pinecone-database/pinecone\";\n\n// Initialize Pinecone client\nconst pc = new Pinecone({\n  apiKey: process.env.PINECONE_API_KEY!,\n  sourceTag: \"voltagent\",\n});\n\nconst indexName = \"voltagent-knowledge-base\";\n\n```\n\n**Key Components Explained**:\n\n- **Pinecone Client**: Connects to Pinecone's managed service\n- **Index**: A named container for your vectors in Pinecone\n- **Serverless Architecture**: Automatically scales based on usage\n\n### Initialize Index and Sample Data [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#initialize-index-and-sample-data \"Direct link to Initialize Index and Sample Data\")\n\nThe example automatically creates and populates your Pinecone index:\n\n```codeBlockLines_e6Vv\nasync function initializeIndex() {\n  try {\n    // Check if index exists\n    let indexExists = false;\n    try {\n      await pc.describeIndex(indexName);\n      indexExists = true;\n    } catch (error) {\n      console.log(`ðŸ“‹ Creating new index \"${indexName}\"...`);\n    }\n\n    // Create index if it doesn't exist\n    if (!indexExists) {\n      await pc.createIndex({\n        name: indexName,\n        dimension: 1536, // OpenAI text-embedding-3-small dimension\n        metric: \"cosine\",\n        spec: {\n          serverless: {\n            cloud: \"aws\",\n            region: \"us-east-1\",\n          },\n        },\n        waitUntilReady: true,\n      });\n    }\n\n    // Get the index and populate with sample data\n    const index = pc.index(indexName);\n    const stats = await index.describeIndexStats();\n\n    if (stats.totalRecordCount === 0) {\n      // Generate embeddings and upsert documents\n      await populateWithSampleData(index);\n    }\n  } catch (error) {\n    console.error(\"Error initializing Pinecone index:\", error);\n  }\n}\n\n```\n\n**What This Does**:\n\n- Creates a serverless Pinecone index in AWS us-east-1\n- Uses cosine similarity for vector comparisons\n- Automatically populates with sample documents\n- Generates embeddings using OpenAI's API\n\n### Implement the Retriever Class [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#implement-the-retriever-class \"Direct link to Implement the Retriever Class\")\n\nCreate the main retriever class:\n\n```codeBlockLines_e6Vv\nasync function retrieveDocuments(query: string, topK = 3) {\n  try {\n    // Generate embedding for the query\n    const OpenAI = await import(\"openai\");\n    const openai = new OpenAI.default({\n      apiKey: process.env.OPENAI_API_KEY!,\n    });\n\n    const embeddingResponse = await openai.embeddings.create({\n      model: \"text-embedding-3-small\",\n      input: query,\n    });\n\n    const queryVector = embeddingResponse.data[0].embedding;\n\n    // Search the index\n    const index = pc.index(indexName);\n    const searchResults = await index.query({\n      vector: queryVector,\n      topK,\n      includeMetadata: true,\n      includeValues: false,\n    });\n\n    // Format results\n    return (\n      searchResults.matches?.map((match) => ({\n        content: match.metadata?.text || \"\",\n        metadata: match.metadata || {},\n        score: match.score || 0,\n        id: match.id,\n      })) || []\n    );\n  } catch (error) {\n    console.error(\"Error retrieving documents:\", error);\n    return [];\n  }\n}\n\nexport class PineconeRetriever extends BaseRetriever {\n  async retrieve(input: string | BaseMessage[], options: RetrieveOptions): Promise<string> {\n    // Convert input to searchable string\n    let searchText = \"\";\n\n    if (typeof input === \"string\") {\n      searchText = input;\n    } else if (Array.isArray(input) && input.length > 0) {\n      const lastMessage = input[input.length - 1];\n\n      if (Array.isArray(lastMessage.content)) {\n        const textParts = lastMessage.content\n          .filter((part: any) => part.type === \"text\")\n          .map((part: any) => part.text);\n        searchText = textParts.join(\" \");\n      } else {\n        searchText = lastMessage.content as string;\n      }\n    }\n\n    // Perform semantic search\n    const results = await retrieveDocuments(searchText, 3);\n\n    // Add references to userContext for tracking\n    if (options.userContext && results.length > 0) {\n      const references = results.map((doc: any, index: number) => ({\n        id: doc.id,\n        title: doc.metadata.topic || `Document ${index + 1}`,\n        source: \"Pinecone Knowledge Base\",\n        score: doc.score,\n        category: doc.metadata.category,\n      }));\n\n      options.userContext.set(\"references\", references);\n    }\n\n    // Format results for the LLM\n    if (results.length === 0) {\n      return \"No relevant documents found in the knowledge base.\";\n    }\n\n    return results\n      .map(\n        (doc: any, index: number) =>\n          `Document ${index + 1} (ID: ${doc.id}, Score: ${doc.score.toFixed(4)}, Category: ${doc.metadata.category}):\\n${doc.content}`\n      )\n      .join(\"\\n\\n---\\n\\n\");\n  }\n}\n\nexport const retriever = new PineconeRetriever();\n\n```\n\n**Key Features**:\n\n- **Input Handling**: Supports both string and message array inputs\n- **Embedding Generation**: Uses OpenAI's embedding API\n- **Vector Search**: Leverages Pinecone's optimized search\n- **User Context**: Tracks references and similarity scores\n- **Error Handling**: Graceful fallbacks for search failures\n\n### Create Your Agents [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#create-your-agents \"Direct link to Create Your Agents\")\n\nNow create agents using different retrieval patterns in `src/index.ts`:\n\n```codeBlockLines_e6Vv\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent, VoltAgent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { retriever } from \"./retriever/index.js\";\n\n// Agent 1: Automatic retrieval on every interaction\nconst agentWithRetriever = new Agent({\n  name: \"Assistant with Retriever\",\n  description:\n    \"A helpful assistant that automatically searches the Pinecone knowledge base for relevant information\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  retriever: retriever,\n});\n\n// Agent 2: LLM decides when to search\nconst agentWithTools = new Agent({\n  name: \"Assistant with Tools\",\n  description: \"A helpful assistant that can search the knowledge base when needed\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  tools: [retriever.tool],\n});\n\nnew VoltAgent({\n  agents: {\n    agentWithRetriever,\n    agentWithTools,\n  },\n});\n\n```\n\n## Usage Patterns [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#usage-patterns \"Direct link to Usage Patterns\")\n\n### Automatic Retrieval [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#automatic-retrieval \"Direct link to Automatic Retrieval\")\n\nThe first agent automatically searches before every response:\n\n```codeBlockLines_e6Vv\nUser: \"What is Pinecone?\"\nAgent: Based on the knowledge base, Pinecone is a vector database built for machine learning applications that require fast, accurate vector search...\n\nSources:\n- Document 2 (ID: doc2, Score: 0.9876, Category: databases): Pinecone Knowledge Base\n- Document 3 (ID: doc3, Score: 0.8543, Category: databases): Pinecone Knowledge Base\n\n```\n\n### Tool-Based Retrieval [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#tool-based-retrieval \"Direct link to Tool-Based Retrieval\")\n\nThe second agent only searches when it determines it's necessary:\n\n```codeBlockLines_e6Vv\nUser: \"Tell me about RAG\"\nAgent: Let me search for relevant information about RAG.\n[Searches knowledge base]\nAccording to the search results, Retrieval-Augmented Generation (RAG) combines information retrieval with language generation for better AI responses...\n\nSources:\n- Document 4 (ID: doc4, Score: 0.9234, Category: techniques): Pinecone Knowledge Base\n\n```\n\n### Accessing Sources in Your Code [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#accessing-sources-in-your-code \"Direct link to Accessing Sources in Your Code\")\n\nYou can access the sources that were used in the retrieval from the response:\n\n```codeBlockLines_e6Vv\n// After generating a response\nconst response = await agent.generateText(\"What is Pinecone?\");\nconsole.log(\"Answer:\", response.text);\n\n// Check what sources were used\nconst references = response.userContext?.get(\"references\");\nif (references) {\n  console.log(\"Used sources:\", references);\n  references.forEach((ref) => {\n    console.log(`- ${ref.title} (ID: ${ref.id}, Score: ${ref.score}, Category: ${ref.category})`);\n  });\n}\n\n```\n\n## Customization Options [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#customization-options \"Direct link to Customization Options\")\n\n### Different Embedding Models [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#different-embedding-models \"Direct link to Different Embedding Models\")\n\nYou can use different OpenAI embedding models:\n\n```codeBlockLines_e6Vv\n// More powerful but more expensive\nconst embeddingResponse = await openai.embeddings.create({\n  model: \"text-embedding-3-large\", // 3072 dimensions\n  input: query,\n});\n\n// Balanced option (recommended)\nconst embeddingResponse = await openai.embeddings.create({\n  model: \"text-embedding-3-small\", // 1536 dimensions\n  input: query,\n});\n\n// Legacy model\nconst embeddingResponse = await openai.embeddings.create({\n  model: \"text-embedding-ada-002\", // 1536 dimensions\n  input: query,\n});\n\n```\n\n### Adding Your Own Documents [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#adding-your-own-documents \"Direct link to Adding Your Own Documents\")\n\nTo add documents programmatically:\n\n```codeBlockLines_e6Vv\nasync function addDocument(content: string, metadata: Record<string, any> = {}) {\n  const index = pc.index(indexName);\n\n  // Generate embedding\n  const embeddingResponse = await openai.embeddings.create({\n    model: \"text-embedding-3-small\",\n    input: content,\n  });\n\n  const id = `doc_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n\n  await index.upsert([\\\n    {\\\n      id,\\\n      values: embeddingResponse.data[0].embedding,\\\n      metadata: {\\\n        text: content,\\\n        ...metadata,\\\n        timestamp: new Date().toISOString(),\\\n      },\\\n    },\\\n  ]);\n\n  return id;\n}\n\n```\n\n### Metadata Filtering [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#metadata-filtering \"Direct link to Metadata Filtering\")\n\nPinecone supports advanced metadata filtering:\n\n```codeBlockLines_e6Vv\nconst searchResults = await index.query({\n  vector: queryVector,\n  topK: 10,\n  filter: {\n    category: { $eq: \"documentation\" },\n    timestamp: { $gte: \"2024-01-01\" },\n  },\n  includeMetadata: true,\n});\n\n```\n\n### Namespace Organization [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#namespace-organization \"Direct link to Namespace Organization\")\n\nOrganize your data using namespaces:\n\n```codeBlockLines_e6Vv\n// Use different namespaces for different data types\nconst index = pc.index(indexName).namespace(\"documentation\");\nconst userIndex = pc.index(indexName).namespace(\"user-data\");\n\nawait index.upsert([\\\n  {\\\n    id: \"doc1\",\\\n    values: embedding,\\\n    metadata: { type: \"guide\" },\\\n  },\\\n]);\n\n```\n\n## Best Practices [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#best-practices \"Direct link to Best Practices\")\n\n**Index Design**:\n\n- Choose the right region for your users (lower latency)\n- Use serverless for variable workloads\n- Use pods for consistent high performance\n- Consider costs vs. performance trade-offs\n\n**Embedding Strategy**:\n\n- Use `text-embedding-3-small` for cost efficiency\n- Use `text-embedding-3-large` for maximum quality\n- Keep embedding model consistent across all documents\n- Batch embedding generation to reduce API calls\n\n**Document Management**:\n\n- Include relevant metadata for filtering\n- Use meaningful document IDs\n- Consider document chunking for large texts\n- Use namespaces to organize different data types\n\n**Performance**:\n\n- Limit search results (3-5 documents typically sufficient)\n- Use metadata filtering to narrow searches\n- Consider caching for frequently accessed documents\n- Monitor query latency and costs\n\n**Security**:\n\n- Rotate API keys regularly\n- Use environment variables for credentials\n- Implement proper access controls\n- Monitor usage for anomalies\n\n## Troubleshooting [â€‹](https://voltagent.dev/docs/rag/pinecone/\\#troubleshooting \"Direct link to Troubleshooting\")\n\n**Authentication Issues**:\n\n```codeBlockLines_e6Vv\n# Check if your API key is valid\ncurl -H \"Api-Key: YOUR_API_KEY\" https://api.pinecone.io/indexes\n\n```\n\n**Index Creation Problems**:\n\n- Verify your Pinecone plan supports the index type\n- Check if the index name already exists\n- Ensure proper region availability\n- Verify dimension matches your embedding model\n\n**Embedding Errors**:\n\n- Verify your OpenAI API key is valid\n- Check API quota and billing\n- Ensure network connectivity to OpenAI\n- Monitor rate limits\n\n**No Search Results**:\n\n- Verify documents were upserted successfully\n- Check embedding model consistency\n- Try broader search queries\n- Verify metadata filters aren't too restrictive\n\n**Performance Issues**:\n\n- Check index statistics for proper scaling\n- Monitor query latency in Pinecone console\n- Consider upgrading to pod-based indexes\n- Optimize metadata filtering\n\nThis integration provides a production-ready foundation for adding semantic search capabilities to your VoltAgent applications. The combination of VoltAgent's flexible architecture and Pinecone's scalable vector search creates a robust RAG system that can handle enterprise-scale knowledge retrieval needs.\n\n### Table of Contents\n\n- [Prerequisites](https://voltagent.dev/docs/rag/pinecone/#prerequisites)\n- [Installation](https://voltagent.dev/docs/rag/pinecone/#installation)\n- [Environment Setup](https://voltagent.dev/docs/rag/pinecone/#environment-setup)\n  - [Getting Your Pinecone API Key](https://voltagent.dev/docs/rag/pinecone/#getting-your-pinecone-api-key)\n- [Run Your Application](https://voltagent.dev/docs/rag/pinecone/#run-your-application)\n- [Interact with Your Agents](https://voltagent.dev/docs/rag/pinecone/#interact-with-your-agents)\n- [How It Works](https://voltagent.dev/docs/rag/pinecone/#how-it-works)\n  - [Create the Pinecone Retriever](https://voltagent.dev/docs/rag/pinecone/#create-the-pinecone-retriever)\n  - [Initialize Index and Sample Data](https://voltagent.dev/docs/rag/pinecone/#initialize-index-and-sample-data)\n  - [Implement the Retriever Class](https://voltagent.dev/docs/rag/pinecone/#implement-the-retriever-class)\n  - [Create Your Agents](https://voltagent.dev/docs/rag/pinecone/#create-your-agents)\n- [Usage Patterns](https://voltagent.dev/docs/rag/pinecone/#usage-patterns)\n  - [Automatic Retrieval](https://voltagent.dev/docs/rag/pinecone/#automatic-retrieval)\n  - [Tool-Based Retrieval](https://voltagent.dev/docs/rag/pinecone/#tool-based-retrieval)\n  - [Accessing Sources in Your Code](https://voltagent.dev/docs/rag/pinecone/#accessing-sources-in-your-code)\n- [Customization Options](https://voltagent.dev/docs/rag/pinecone/#customization-options)\n  - [Different Embedding Models](https://voltagent.dev/docs/rag/pinecone/#different-embedding-models)\n  - [Adding Your Own Documents](https://voltagent.dev/docs/rag/pinecone/#adding-your-own-documents)\n  - [Metadata Filtering](https://voltagent.dev/docs/rag/pinecone/#metadata-filtering)\n  - [Namespace Organization](https://voltagent.dev/docs/rag/pinecone/#namespace-organization)\n- [Best Practices](https://voltagent.dev/docs/rag/pinecone/#best-practices)\n- [Troubleshooting](https://voltagent.dev/docs/rag/pinecone/#troubleshooting)",
      "metadata": {
        "docsearch:language": "en",
        "og:url": "https://voltagent.dev/docs/rag/pinecone/",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:title": "Pinecone Integration | VoltAgent",
        "og:locale": "en",
        "docusaurus_version": "current",
        "docusaurus_tag": "docs-default-current",
        "description": "Pinecone is a fully managed vector database built for machine learning applications that require fast, accurate vector search at scale. It offers serverless deployment, automatic scaling, and enterprise-grade security.",
        "og:description": "Pinecone is a fully managed vector database built for machine learning applications that require fast, accurate vector search at scale. It offers serverless deployment, automatic scaling, and enterprise-grade security.",
        "docusaurus_locale": "en",
        "viewport": "width=device-width, initial-scale=1.0",
        "ogUrl": "https://voltagent.dev/docs/rag/pinecone/",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "title": "Pinecone Integration | VoltAgent",
        "ogTitle": "Pinecone Integration | VoltAgent",
        "ogLocale": "en",
        "generator": "Docusaurus v3.1.1",
        "og:image": "https://voltagent.dev/img/social3.png",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "language": "en",
        "docsearch:version": "current",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "ogDescription": "Pinecone is a fully managed vector database built for machine learning applications that require fast, accurate vector search at scale. It offers serverless deployment, automatic scaling, and enterprise-grade security.",
        "twitter:card": "summary_large_image",
        "scrapeId": "3e9d8a3c-52b3-4620-9c5f-3428ad30dd2f",
        "sourceURL": "https://voltagent.dev/docs/rag/pinecone/",
        "url": "https://voltagent.dev/docs/rag/pinecone/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:28.602Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/agents/cancellation/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Cancellation\n\nVoltAgent implements cancellation through the standard `AbortController` API, enabling you to stop operations at any point. This includes LLM generation, tool execution, and multi-agent workflows.\n\n## Basic Cancellation [â€‹](https://voltagent.dev/docs/agents/cancellation/\\#basic-cancellation \"Direct link to Basic Cancellation\")\n\nThe simplest cancellation pattern involves creating an `AbortController` and passing it to agent methods:\n\n```codeBlockLines_e6Vv\nimport { Agent, isAbortError } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  name: \"Assistant\",\n  instructions: \"A helpful assistant\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n});\n\nconst abortController = new AbortController();\n\n// Cancel after 5 seconds\nsetTimeout(() => {\n  abortController.abort(\"Timeout: Operation took too long\");\n}, 5000);\n\ntry {\n  const response = await agent.generateText(\"Write a detailed analysis...\", {\n    abortController,\n  });\n  console.log(response.text);\n} catch (error) {\n  if (isAbortError(error)) {\n    console.log(\"Operation cancelled:\", error.message);\n  } else {\n    throw error;\n  }\n}\n\n```\n\n## How Cancellation Works [â€‹](https://voltagent.dev/docs/agents/cancellation/\\#how-cancellation-works \"Direct link to How Cancellation Works\")\n\nWhen you provide an `AbortController` to an agent method:\n\n1. The controller's signal is stored in `operationContext.signal`\n2. This signal is passed to the LLM provider\n3. Tools receive access to both the signal and controller\n4. Subagents inherit the parent's abort controller\n5. All operations check the signal state before proceeding\n\nThe cancellation propagates through the entire operation chain, ensuring clean shutdown at every level.\n\n## Streaming Cancellation [â€‹](https://voltagent.dev/docs/agents/cancellation/\\#streaming-cancellation \"Direct link to Streaming Cancellation\")\n\nCancellation works seamlessly with streaming responses:\n\n```codeBlockLines_e6Vv\nconst abortController = new AbortController();\n\n// User can cancel anytime\ndocument.getElementById(\"stop-btn\")?.addEventListener(\"click\", () => {\n  abortController.abort(\"User requested stop\");\n});\n\nconst response = await agent.streamText(\"Generate a long report...\", {\n  abortController,\n});\n\ntry {\n  for await (const chunk of response.textStream) {\n    process.stdout.write(chunk);\n  }\n} catch (error) {\n  if (isAbortError(error)) {\n    console.log(\"\\nStream cancelled\");\n  }\n}\n\n```\n\nWith `fullStream`, you get more detailed cancellation feedback:\n\n```codeBlockLines_e6Vv\nconst response = await agent.streamText(\"Complex task...\", {\n  abortController,\n});\n\nif (response.fullStream) {\n  for await (const event of response.fullStream) {\n    if (event.type === \"error\" && isAbortError(event.error)) {\n      console.log(\"Cancelled during:\", event.context);\n      break;\n    }\n    // Process other events\n  }\n}\n\n```\n\n## Tool Cancellation [â€‹](https://voltagent.dev/docs/agents/cancellation/\\#tool-cancellation \"Direct link to Tool Cancellation\")\n\nTools receive the `AbortController` through their execution context and can both respond to and trigger cancellation:\n\n```codeBlockLines_e6Vv\nimport { createTool } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\nconst dataProcessingTool = createTool({\n  name: \"process_data\",\n  description: \"Process large datasets\",\n  parameters: z.object({\n    dataset: z.string(),\n    operation: z.string(),\n  }),\n  execute: async (args, options) => {\n    const abortController = options?.operationContext?.abortController;\n    const signal = abortController?.signal;\n\n    // Check if already aborted\n    if (signal?.aborted) {\n      return { error: \"Operation was already cancelled\" };\n    }\n\n    // Tool can trigger abort based on conditions\n    if (args.dataset === \"restricted\") {\n      abortController?.abort(\"Access to restricted dataset denied\");\n      return { error: \"Dataset access denied\" };\n    }\n\n    // Pass signal to async operations\n    try {\n      const response = await fetch(`/api/process/${args.dataset}`, {\n        method: \"POST\",\n        body: JSON.stringify({ operation: args.operation }),\n        signal: signal,\n      });\n\n      return await response.json();\n    } catch (error) {\n      if (error.name === \"AbortError\") {\n        return { error: \"Processing cancelled\" };\n      }\n      throw error;\n    }\n  },\n});\n\n```\n\n## Multi-Agent Cancellation [â€‹](https://voltagent.dev/docs/agents/cancellation/\\#multi-agent-cancellation \"Direct link to Multi-Agent Cancellation\")\n\nIn supervisor-subagent architectures, the abort signal automatically propagates to all subagents:\n\n```codeBlockLines_e6Vv\nconst researcher = new Agent({\n  name: \"Researcher\",\n  instructions: \"Research topics thoroughly\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n});\n\nconst writer = new Agent({\n  name: \"Writer\",\n  instructions: \"Write detailed content\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n});\n\nconst supervisor = new Agent({\n  name: \"Supervisor\",\n  instructions: \"Coordinate research and writing\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  subAgents: [researcher, writer],\n});\n\nconst abortController = new AbortController();\n\n// This will cancel supervisor and any active subagent operations\nsetTimeout(() => {\n  abortController.abort(\"Deadline reached\");\n}, 10000);\n\nconst response = await supervisor.streamText(\"Research and write about quantum computing\", {\n  abortController,\n});\n\n```\n\nWhen the supervisor is cancelled:\n\n- Any active `delegate_task` operations stop\n- Subagents receive the abort signal\n- All tool executions within subagents are cancelled\n- The entire workflow shuts down gracefully\n\n## Timeout Implementation [â€‹](https://voltagent.dev/docs/agents/cancellation/\\#timeout-implementation \"Direct link to Timeout Implementation\")\n\nA common pattern is implementing timeouts for operations:\n\n```codeBlockLines_e6Vv\nconst abortController = new AbortController();\n\n// Set a timeout to abort after 30 seconds\nconst timeoutId = setTimeout(() => {\n  abortController.abort(\"Operation timeout - exceeded 30 seconds\");\n}, 30000);\n\ntry {\n  const response = await agent.generateText(\"Complex analysis...\", {\n    abortController,\n  });\n\n  // Clear timeout if operation completes successfully\n  clearTimeout(timeoutId);\n  console.log(response.text);\n} catch (error) {\n  clearTimeout(timeoutId); // Always clear the timeout\n\n  if (isAbortError(error)) {\n    console.log(\"Operation timed out:\", error.message);\n  } else {\n    throw error;\n  }\n}\n\n```\n\n## Error Detection with Hooks [â€‹](https://voltagent.dev/docs/agents/cancellation/\\#error-detection-with-hooks \"Direct link to Error Detection with Hooks\")\n\nAgent hooks can detect and handle abort errors:\n\n```codeBlockLines_e6Vv\nimport { createHooks, isAbortError } from \"@voltagent/core\";\n\nconst agent = new Agent({\n  name: \"Assistant\",\n  instructions: \"A helpful assistant\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  hooks: createHooks({\n    onEnd: async ({ error, context }) => {\n      if (isAbortError(error)) {\n        // Handle abort - error.name === \"AbortError\"\n        console.log(\"Operation aborted:\", error.message);\n\n        // Cleanup resources\n        await cleanup(context);\n\n        // Log metrics\n        await logAbortMetrics({\n          operationId: context.operationId,\n          reason: error.message,\n          duration: Date.now() - context.startTime,\n        });\n      } else if (error) {\n        // Handle other errors\n        console.error(\"Operation failed:\", error);\n      }\n    },\n  }),\n});\n\n```\n\n## REST API Cancellation [â€‹](https://voltagent.dev/docs/agents/cancellation/\\#rest-api-cancellation \"Direct link to REST API Cancellation\")\n\nWhen using VoltAgent's REST API, clients can cancel requests by closing the connection:\n\n```codeBlockLines_e6Vv\n// Client-side cancellation\nconst controller = new AbortController();\n\nconst response = await fetch(\"http://localhost:3141/agents/my-agent/stream\", {\n  method: \"POST\",\n  headers: { \"Content-Type\": \"application/json\" },\n  body: JSON.stringify({\n    input: \"Generate a comprehensive report\",\n  }),\n  signal: controller.signal,\n});\n\n// Cancel button\ndocument.getElementById(\"cancel\")?.addEventListener(\"click\", () => {\n  controller.abort();\n});\n\n// Process stream\nconst reader = response.body?.getReader();\nif (reader) {\n  try {\n    while (true) {\n      const { done, value } = await reader.read();\n      if (done) break;\n      // Process chunk\n    }\n  } catch (error) {\n    if (error.name === \"AbortError\") {\n      console.log(\"Stream cancelled\");\n    }\n  }\n}\n\n```\n\nThe server automatically detects client disconnection and aborts the agent operation.\n\n## Cancellation States [â€‹](https://voltagent.dev/docs/agents/cancellation/\\#cancellation-states \"Direct link to Cancellation States\")\n\nOperations can be in different states regarding cancellation:\n\n```codeBlockLines_e6Vv\nconst abortController = new AbortController();\n\n// Check if aborted\nif (abortController.signal.aborted) {\n  console.log(\"Already aborted\");\n}\n\n// Listen for abort\nabortController.signal.addEventListener(\"abort\", () => {\n  console.log(\"Just aborted:\", abortController.signal.reason);\n});\n\n// Trigger abort with reason\nabortController.abort(\"User cancelled\");\n\n```\n\n## Implementation Patterns [â€‹](https://voltagent.dev/docs/agents/cancellation/\\#implementation-patterns \"Direct link to Implementation Patterns\")\n\n### Graceful Shutdown [â€‹](https://voltagent.dev/docs/agents/cancellation/\\#graceful-shutdown \"Direct link to Graceful Shutdown\")\n\n```codeBlockLines_e6Vv\nasync function processWithGracefulShutdown(agent: Agent, input: string) {\n  const abortController = new AbortController();\n\n  // Handle shutdown signals\n  const shutdownHandler = () => {\n    console.log(\"Shutting down gracefully...\");\n    abortController.abort(\"System shutdown\");\n  };\n\n  process.on(\"SIGINT\", shutdownHandler);\n  process.on(\"SIGTERM\", shutdownHandler);\n\n  try {\n    const response = await agent.generateText(input, {\n      abortController,\n    });\n    return response.text;\n  } finally {\n    process.off(\"SIGINT\", shutdownHandler);\n    process.off(\"SIGTERM\", shutdownHandler);\n  }\n}\n\n```\n\n### Concurrent Operations with Cancellation [â€‹](https://voltagent.dev/docs/agents/cancellation/\\#concurrent-operations-with-cancellation \"Direct link to Concurrent Operations with Cancellation\")\n\n```codeBlockLines_e6Vv\nasync function processMultiple(agent: Agent, inputs: string[]) {\n  const abortController = new AbortController();\n\n  // Cancel all if any fails\n  const promises = inputs.map(async (input) => {\n    try {\n      return await agent.generateText(input, { abortController });\n    } catch (error) {\n      abortController.abort(\"One operation failed\");\n      throw error;\n    }\n  });\n\n  return Promise.all(promises);\n}\n\n```\n\n### Resource Cleanup [â€‹](https://voltagent.dev/docs/agents/cancellation/\\#resource-cleanup \"Direct link to Resource Cleanup\")\n\n```codeBlockLines_e6Vv\nclass ResourceManager {\n  private resources: Set<() => Promise<void>> = new Set();\n\n  register(cleanup: () => Promise<void>) {\n    this.resources.add(cleanup);\n  }\n\n  async cleanupAll() {\n    await Promise.all([...this.resources].map((fn) => fn()));\n    this.resources.clear();\n  }\n}\n\nconst resources = new ResourceManager();\nconst abortController = new AbortController();\n\n// Register cleanup\nabortController.signal.addEventListener(\"abort\", async () => {\n  await resources.cleanupAll();\n});\n\n// Use with agent\nconst response = await agent.generateText(\"Process data\", {\n  abortController,\n});\n\n```\n\n## Next Steps [â€‹](https://voltagent.dev/docs/agents/cancellation/\\#next-steps \"Direct link to Next Steps\")\n\n- Learn about [Tools](https://voltagent.dev/docs/agents/tools/) and how they handle cancellation\n- Explore [Sub-Agents](https://voltagent.dev/docs/agents/sub-agents/) for multi-agent cancellation patterns\n- See [Hooks](https://voltagent.dev/docs/agents/hooks/) for cancellation detection and handling\n\n### Table of Contents\n\n- [Basic Cancellation](https://voltagent.dev/docs/agents/cancellation/#basic-cancellation)\n- [How Cancellation Works](https://voltagent.dev/docs/agents/cancellation/#how-cancellation-works)\n- [Streaming Cancellation](https://voltagent.dev/docs/agents/cancellation/#streaming-cancellation)\n- [Tool Cancellation](https://voltagent.dev/docs/agents/cancellation/#tool-cancellation)\n- [Multi-Agent Cancellation](https://voltagent.dev/docs/agents/cancellation/#multi-agent-cancellation)\n- [Timeout Implementation](https://voltagent.dev/docs/agents/cancellation/#timeout-implementation)\n- [Error Detection with Hooks](https://voltagent.dev/docs/agents/cancellation/#error-detection-with-hooks)\n- [REST API Cancellation](https://voltagent.dev/docs/agents/cancellation/#rest-api-cancellation)\n- [Cancellation States](https://voltagent.dev/docs/agents/cancellation/#cancellation-states)\n- [Implementation Patterns](https://voltagent.dev/docs/agents/cancellation/#implementation-patterns)\n  - [Graceful Shutdown](https://voltagent.dev/docs/agents/cancellation/#graceful-shutdown)\n  - [Concurrent Operations with Cancellation](https://voltagent.dev/docs/agents/cancellation/#concurrent-operations-with-cancellation)\n  - [Resource Cleanup](https://voltagent.dev/docs/agents/cancellation/#resource-cleanup)\n- [Next Steps](https://voltagent.dev/docs/agents/cancellation/#next-steps)",
      "metadata": {
        "title": "Cancellation | VoltAgent",
        "ogTitle": "Cancellation | VoltAgent",
        "docusaurus_tag": "docs-default-current",
        "ogLocale": "en",
        "ogDescription": "VoltAgent implements cancellation through the standard AbortController API, enabling you to stop operations at any point. This includes LLM generation, tool execution, and multi-agent workflows.",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:title": "Cancellation | VoltAgent",
        "description": "VoltAgent implements cancellation through the standard AbortController API, enabling you to stop operations at any point. This includes LLM generation, tool execution, and multi-agent workflows.",
        "og:description": "VoltAgent implements cancellation through the standard AbortController API, enabling you to stop operations at any point. This includes LLM generation, tool execution, and multi-agent workflows.",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "viewport": "width=device-width, initial-scale=1.0",
        "generator": "Docusaurus v3.1.1",
        "og:image": "https://voltagent.dev/img/social3.png",
        "docusaurus_locale": "en",
        "og:locale": "en",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "language": "en",
        "ogUrl": "https://voltagent.dev/docs/agents/cancellation/",
        "twitter:card": "summary_large_image",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "docsearch:version": "current",
        "og:url": "https://voltagent.dev/docs/agents/cancellation/",
        "docusaurus_version": "current",
        "docsearch:language": "en",
        "scrapeId": "8a3b4c9b-1ba9-4ae5-bac9-4e13076bfc02",
        "sourceURL": "https://voltagent.dev/docs/agents/cancellation/",
        "url": "https://voltagent.dev/docs/agents/cancellation/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:41:03.969Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/workflows/steps/and-then/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# andThen\n\n> Execute any TypeScript function in your workflow. The most basic and flexible step type.\n\n## Quick Start [â€‹](https://voltagent.dev/docs/workflows/steps/and-then/\\#quick-start \"Direct link to Quick Start\")\n\n```codeBlockLines_e6Vv\nimport { createWorkflowChain } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\nconst workflow = createWorkflowChain({\n  id: \"process-data\",\n  input: z.object({ text: z.string() }),\n}).andThen({\n  id: \"uppercase\",\n  execute: async ({ data }) => {\n    return {\n      text: data.text.toUpperCase(),\n      length: data.text.length,\n    };\n  },\n});\n\nconst result = await workflow.run({ text: \"hello\" });\n// Result: { text: \"HELLO\", length: 5 }\n\n```\n\n## How It Works [â€‹](https://voltagent.dev/docs/workflows/steps/and-then/\\#how-it-works \"Direct link to How It Works\")\n\n`andThen` runs your async function and passes the result to the next step:\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"step-name\",\n  execute: async ({ data }) => {\n    // Your code here\n    return newData;\n  }\n})\n\n```\n\n### Available Parameters [â€‹](https://voltagent.dev/docs/workflows/steps/and-then/\\#available-parameters \"Direct link to Available Parameters\")\n\n```codeBlockLines_e6Vv\nexecute: async ({ data, suspend, resumeData }) => {\n  // data: All accumulated data from previous steps\n  // suspend: Function to pause workflow\n  // resumeData: Data provided when resuming\n};\n\n```\n\n## Data Flow Example [â€‹](https://voltagent.dev/docs/workflows/steps/and-then/\\#data-flow-example \"Direct link to Data Flow Example\")\n\nEach step builds on the previous:\n\n```codeBlockLines_e6Vv\ncreateWorkflowChain({\n  id: \"user-flow\",\n  input: z.object({ userId: z.string() }),\n})\n  .andThen({\n    id: \"get-user\",\n    execute: async ({ data }) => {\n      const user = await getUser(data.userId);\n      return { user }; // Next step gets: { userId, user }\n    },\n  })\n  .andThen({\n    id: \"get-posts\",\n    execute: async ({ data }) => {\n      const posts = await getPosts(data.user.id);\n      return { posts }; // Next step gets: { userId, user, posts }\n    },\n  })\n  .andThen({\n    id: \"format-result\",\n    execute: async ({ data }) => {\n      return {\n        userName: data.user.name,\n        postCount: data.posts.length,\n      };\n    },\n  });\n\n```\n\n## Common Patterns [â€‹](https://voltagent.dev/docs/workflows/steps/and-then/\\#common-patterns \"Direct link to Common Patterns\")\n\n### API Calls [â€‹](https://voltagent.dev/docs/workflows/steps/and-then/\\#api-calls \"Direct link to API Calls\")\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"fetch-user\",\n  execute: async ({ data }) => {\n    const response = await fetch(`/api/users/${data.id}`);\n    const user = await response.json();\n    return { user };\n  }\n})\n\n```\n\n### Data Validation [â€‹](https://voltagent.dev/docs/workflows/steps/and-then/\\#data-validation \"Direct link to Data Validation\")\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"validate-email\",\n  execute: async ({ data }) => {\n    const isValid = data.email.includes(\"@\");\n    if (!isValid) {\n      throw new Error(\"Invalid email\");\n    }\n    return data;\n  }\n})\n\n```\n\n### Error Handling [â€‹](https://voltagent.dev/docs/workflows/steps/and-then/\\#error-handling \"Direct link to Error Handling\")\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"safe-operation\",\n  execute: async ({ data }) => {\n    try {\n      const result = await riskyOperation(data);\n      return { result };\n    } catch (error) {\n      return { result: null, error: error.message };\n    }\n  }\n})\n\n```\n\n## Suspend & Resume Support [â€‹](https://voltagent.dev/docs/workflows/steps/and-then/\\#suspend--resume-support \"Direct link to Suspend & Resume Support\")\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"approval-step\",\n  execute: async ({ data, suspend, resumeData }) => {\n    // Check if resuming\n    if (resumeData) {\n      return {\n        ...data,\n        approved: resumeData.approved\n      };\n    }\n\n    // Suspend for approval\n    if (data.amount > 1000) {\n      await suspend(\"Needs manager approval\");\n    }\n\n    // Auto-approve small amounts\n    return { ...data, approved: true };\n  }\n})\n\n```\n\n## Schema Support [â€‹](https://voltagent.dev/docs/workflows/steps/and-then/\\#schema-support \"Direct link to Schema Support\")\n\nDefine schemas for type safety:\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"process-order\",\n  inputSchema: z.object({\n    orderId: z.string(),\n    items: z.array(z.any())\n  }),\n  outputSchema: z.object({\n    total: z.number(),\n    tax: z.number()\n  }),\n  execute: async ({ data }) => {\n    const total = calculateTotal(data.items);\n    const tax = total * 0.1;\n    return { total, tax };\n  }\n})\n\n```\n\n## Best Practices [â€‹](https://voltagent.dev/docs/workflows/steps/and-then/\\#best-practices \"Direct link to Best Practices\")\n\n1. **Keep functions focused** \\- Do one thing well\n2. **Return new data** \\- Don't mutate input\n3. **Handle errors gracefully** \\- Use try/catch\n4. **Use descriptive IDs** \\- Makes debugging easier\n\n## Next Steps [â€‹](https://voltagent.dev/docs/workflows/steps/and-then/\\#next-steps \"Direct link to Next Steps\")\n\n- Learn about [andAgent](https://voltagent.dev/docs/workflows/steps/and-agent/) for AI integration\n- Explore [andWhen](https://voltagent.dev/docs/workflows/steps/and-when/) for conditional logic\n- See [andAll](https://voltagent.dev/docs/workflows/steps/and-all/) for parallel execution\n- Execute workflows via [REST API](https://voltagent.dev/docs/api/overview/#workflow-endpoints)\n\n### Table of Contents\n\n- [Quick Start](https://voltagent.dev/docs/workflows/steps/and-then/#quick-start)\n- [How It Works](https://voltagent.dev/docs/workflows/steps/and-then/#how-it-works)\n  - [Available Parameters](https://voltagent.dev/docs/workflows/steps/and-then/#available-parameters)\n- [Data Flow Example](https://voltagent.dev/docs/workflows/steps/and-then/#data-flow-example)\n- [Common Patterns](https://voltagent.dev/docs/workflows/steps/and-then/#common-patterns)\n  - [API Calls](https://voltagent.dev/docs/workflows/steps/and-then/#api-calls)\n  - [Data Validation](https://voltagent.dev/docs/workflows/steps/and-then/#data-validation)\n  - [Error Handling](https://voltagent.dev/docs/workflows/steps/and-then/#error-handling)\n- [Suspend & Resume Support](https://voltagent.dev/docs/workflows/steps/and-then/#suspend--resume-support)\n- [Schema Support](https://voltagent.dev/docs/workflows/steps/and-then/#schema-support)\n- [Best Practices](https://voltagent.dev/docs/workflows/steps/and-then/#best-practices)\n- [Next Steps](https://voltagent.dev/docs/workflows/steps/and-then/#next-steps)",
      "metadata": {
        "docusaurus_locale": "en",
        "docsearch:docusaurus_tag": "docs-default-current",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "docsearch:version": "current",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_version": "current",
        "ogTitle": "andThen | VoltAgent",
        "ogDescription": "Execute any TypeScript function in your workflow. The most basic and flexible step type.",
        "description": "Execute any TypeScript function in your workflow. The most basic and flexible step type.",
        "docsearch:language": "en",
        "title": "andThen | VoltAgent",
        "docusaurus_tag": "docs-default-current",
        "og:locale": "en",
        "generator": "Docusaurus v3.1.1",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "og:title": "andThen | VoltAgent",
        "ogLocale": "en",
        "og:url": "https://voltagent.dev/docs/workflows/steps/and-then/",
        "language": "en",
        "og:image": "https://voltagent.dev/img/social3.png",
        "ogUrl": "https://voltagent.dev/docs/workflows/steps/and-then/",
        "twitter:card": "summary_large_image",
        "og:description": "Execute any TypeScript function in your workflow. The most basic and flexible step type.",
        "scrapeId": "a1c6fa27-25ae-45ce-acce-b63182a8aaf3",
        "sourceURL": "https://voltagent.dev/docs/workflows/steps/and-then/",
        "url": "https://voltagent.dev/docs/workflows/steps/and-then/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:41:07.952Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/workflows/steps/and-race/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# andRace\n\n> Run multiple steps in parallel and use the first one that finishes. Perfect for timeouts, fallbacks, or getting the fastest response.\n\n## Quick Start [â€‹](https://voltagent.dev/docs/workflows/steps/and-race/\\#quick-start \"Direct link to Quick Start\")\n\nGet data from whichever source responds first:\n\n```codeBlockLines_e6Vv\nimport { createWorkflowChain, andThen, andRace } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\nconst workflow = createWorkflowChain({\n  id: \"get-user-data\",\n  input: z.object({ userId: z.string() }),\n}).andRace([\\\n  // Fast: Check cache (100ms)\\\n  andThen({\\\n    id: \"check-cache\",\\\n    execute: async ({ data }) => {\\\n      const cached = await checkCache(data.userId);\\\n      if (cached) return { data: cached, source: \"cache\" };\\\n      throw new Error(\"Not in cache\");\\\n    },\\\n  }),\\\n\\\n  // Medium: Database (300ms)\\\n  andThen({\\\n    id: \"check-database\",\\\n    execute: async ({ data }) => {\\\n      const user = await database.getUser(data.userId);\\\n      return { data: user, source: \"database\" };\\\n    },\\\n  }),\\\n\\\n  // Slow: External API (1000ms)\\\n  andThen({\\\n    id: \"fetch-from-api\",\\\n    execute: async ({ data }) => {\\\n      const response = await fetch(`/api/users/${data.userId}`);\\\n      return { data: await response.json(), source: \"api\" };\\\n    },\\\n  }),\\\n]);\n\nconst result = await workflow.run({ userId: \"123\" });\n// If cache has data: returns in ~100ms from cache\n// If cache misses: returns in ~300ms from database\n// If both fail: returns in ~1000ms from API\n\n```\n\n## How It Works [â€‹](https://voltagent.dev/docs/workflows/steps/and-race/\\#how-it-works \"Direct link to How It Works\")\n\n1. All steps start at the same time\n2. First one to finish \"wins\"\n3. Its result becomes the workflow result\n4. Other steps stop running\n5. If winner fails, next fastest wins\n\nThink of it like a race - whoever crosses the finish line first wins, regardless of who started strongest.\n\n## Function Signature [â€‹](https://voltagent.dev/docs/workflows/steps/and-race/\\#function-signature \"Direct link to Function Signature\")\n\n```codeBlockLines_e6Vv\n.andRace([step1, step2, step3])  // Array of steps to race\n\n```\n\n## Common Patterns [â€‹](https://voltagent.dev/docs/workflows/steps/and-race/\\#common-patterns \"Direct link to Common Patterns\")\n\n### Timeout Pattern [â€‹](https://voltagent.dev/docs/workflows/steps/and-race/\\#timeout-pattern \"Direct link to Timeout Pattern\")\n\nAdd a timeout to any operation:\n\n```codeBlockLines_e6Vv\n.andRace([\\\n  // Main operation\\\n  andThen({\\\n    id: \"slow-api\",\\\n    execute: async ({ data }) => {\\\n      const result = await slowAPICall(data);\\\n      return { result, timedOut: false };\\\n    }\\\n  }),\\\n  // Timeout after 5 seconds\\\n  andThen({\\\n    id: \"timeout\",\\\n    execute: async () => {\\\n      await new Promise(resolve => setTimeout(resolve, 5000));\\\n      return { result: \"Timeout\", timedOut: true };\\\n    }\\\n  })\\\n])\n\n```\n\n### Multiple AI Providers [â€‹](https://voltagent.dev/docs/workflows/steps/and-race/\\#multiple-ai-providers \"Direct link to Multiple AI Providers\")\n\nGet response from fastest AI:\n\n```codeBlockLines_e6Vv\n.andRace([\\\n  andAgent(\\\n    ({ data }) => data.prompt,\\\n    openaiAgent,\\\n    { schema: z.object({ response: z.string(), ai: z.literal(\"openai\") }) }\\\n  ),\\\n  andAgent(\\\n    ({ data }) => data.prompt,\\\n    claudeAgent,\\\n    { schema: z.object({ response: z.string(), ai: z.literal(\"claude\") }) }\\\n  ),\\\n  andAgent(\\\n    ({ data }) => data.prompt,\\\n    geminiAgent,\\\n    { schema: z.object({ response: z.string(), ai: z.literal(\"gemini\") }) }\\\n  )\\\n])\n\n```\n\n### Cache vs Database [â€‹](https://voltagent.dev/docs/workflows/steps/and-race/\\#cache-vs-database \"Direct link to Cache vs Database\")\n\nTry cache first, fall back to database:\n\n```codeBlockLines_e6Vv\n.andRace([\\\n  // Try cache (fast)\\\n  andThen({\\\n    id: \"cache-lookup\",\\\n    execute: async ({ data }) => {\\\n      const cached = await cache.get(data.key);\\\n      if (!cached) throw new Error(\"Cache miss\");\\\n      return { value: cached, from: \"cache\" };\\\n    }\\\n  }),\\\n  // Fall back to database (slower)\\\n  andThen({\\\n    id: \"db-lookup\",\\\n    execute: async ({ data }) => {\\\n      const value = await db.find(data.key);\\\n      await cache.set(data.key, value); // Update cache\\\n      return { value, from: \"database\" };\\\n    }\\\n  })\\\n])\n\n```\n\n## Error Handling [â€‹](https://voltagent.dev/docs/workflows/steps/and-race/\\#error-handling \"Direct link to Error Handling\")\n\nIf the fastest step fails, the race continues:\n\n```codeBlockLines_e6Vv\n.andRace([\\\n  andThen({\\\n    id: \"unreliable-fast\",\\\n    execute: async () => {\\\n      if (Math.random() > 0.5) {\\\n        throw new Error(\"Failed!\");\\\n      }\\\n      return { result: \"fast\" };\\\n    }\\\n  }),\\\n  andThen({\\\n    id: \"reliable-slow\",\\\n    execute: async () => {\\\n      await sleep(1000);\\\n      return { result: \"slow but reliable\" };\\\n    }\\\n  })\\\n])\n// If fast fails, you get slow result\n// If fast succeeds, you get fast result\n\n```\n\n## Performance Comparison [â€‹](https://voltagent.dev/docs/workflows/steps/and-race/\\#performance-comparison \"Direct link to Performance Comparison\")\n\n```codeBlockLines_e6Vv\n// Without race: Always slow (2 seconds)\n.andThen({ execute: async () => await slowAPI() })\n\n// With race: Usually fast (50ms)\n.andRace([\\\n  andThen({ execute: async () => await cache() }),    // 50ms\\\n  andThen({ execute: async () => await database() }), // 500ms\\\n  andThen({ execute: async () => await slowAPI() })   // 2000ms\\\n])\n\n```\n\n## Best Practices [â€‹](https://voltagent.dev/docs/workflows/steps/and-race/\\#best-practices \"Direct link to Best Practices\")\n\n### 1\\. Order by Speed [â€‹](https://voltagent.dev/docs/workflows/steps/and-race/\\#1-order-by-speed \"Direct link to 1. Order by Speed\")\n\n```codeBlockLines_e6Vv\n// Good: Fastest first\n.andRace([\\\n  cacheStep,    // 10ms\\\n  databaseStep, // 100ms\\\n  apiStep       // 1000ms\\\n])\n\n```\n\n### 2\\. Handle Different Results [â€‹](https://voltagent.dev/docs/workflows/steps/and-race/\\#2-handle-different-results \"Direct link to 2. Handle Different Results\")\n\n```codeBlockLines_e6Vv\n.andRace([...steps])\n.andThen({\n  execute: async ({ data }) => {\n    // Check which source won\n    if (data.source === \"cache\") {\n      console.log(\"Got cached data\");\n    }\n    return data;\n  }\n})\n\n```\n\n### 3\\. Use for Redundancy [â€‹](https://voltagent.dev/docs/workflows/steps/and-race/\\#3-use-for-redundancy \"Direct link to 3. Use for Redundancy\")\n\n```codeBlockLines_e6Vv\n// Multiple APIs for reliability\n.andRace([\\\n  primaryAPI,\\\n  backupAPI,\\\n  fallbackAPI\\\n])\n\n```\n\n## Comparison with andAll [â€‹](https://voltagent.dev/docs/workflows/steps/and-race/\\#comparison-with-andall \"Direct link to Comparison with andAll\")\n\n| Feature | andRace | andAll |\n| --- | --- | --- |\n| Returns | First to finish | All results |\n| Speed | Fast as possible | Slow as slowest |\n| Use case | Need any result | Need all results |\n| Failure | Continues if one fails | Fails if any fail |\n\n## Next Steps [â€‹](https://voltagent.dev/docs/workflows/steps/and-race/\\#next-steps \"Direct link to Next Steps\")\n\n- Learn about [andAll](https://voltagent.dev/docs/workflows/steps/and-all/) for when you need all results\n- Explore [andThen](https://voltagent.dev/docs/workflows/steps/and-then/) for sequential processing\n- See [andWhen](https://voltagent.dev/docs/workflows/steps/and-when/) for conditional execution\n- Execute workflows via [REST API](https://voltagent.dev/docs/api/overview/#workflow-endpoints)\n\n### Table of Contents\n\n- [Quick Start](https://voltagent.dev/docs/workflows/steps/and-race/#quick-start)\n- [How It Works](https://voltagent.dev/docs/workflows/steps/and-race/#how-it-works)\n- [Function Signature](https://voltagent.dev/docs/workflows/steps/and-race/#function-signature)\n- [Common Patterns](https://voltagent.dev/docs/workflows/steps/and-race/#common-patterns)\n  - [Timeout Pattern](https://voltagent.dev/docs/workflows/steps/and-race/#timeout-pattern)\n  - [Multiple AI Providers](https://voltagent.dev/docs/workflows/steps/and-race/#multiple-ai-providers)\n  - [Cache vs Database](https://voltagent.dev/docs/workflows/steps/and-race/#cache-vs-database)\n- [Error Handling](https://voltagent.dev/docs/workflows/steps/and-race/#error-handling)\n- [Performance Comparison](https://voltagent.dev/docs/workflows/steps/and-race/#performance-comparison)\n- [Best Practices](https://voltagent.dev/docs/workflows/steps/and-race/#best-practices)\n  - [1\\. Order by Speed](https://voltagent.dev/docs/workflows/steps/and-race/#1-order-by-speed)\n  - [2\\. Handle Different Results](https://voltagent.dev/docs/workflows/steps/and-race/#2-handle-different-results)\n  - [3\\. Use for Redundancy](https://voltagent.dev/docs/workflows/steps/and-race/#3-use-for-redundancy)\n- [Comparison with andAll](https://voltagent.dev/docs/workflows/steps/and-race/#comparison-with-andall)\n- [Next Steps](https://voltagent.dev/docs/workflows/steps/and-race/#next-steps)",
      "metadata": {
        "docusaurus_tag": "docs-default-current",
        "language": "en",
        "og:locale": "en",
        "generator": "Docusaurus v3.1.1",
        "og:description": "Run multiple steps in parallel and use the first one that finishes. Perfect for timeouts, fallbacks, or getting the fastest response.",
        "twitter:card": "summary_large_image",
        "og:url": "https://voltagent.dev/docs/workflows/steps/and-race/",
        "docusaurus_locale": "en",
        "docsearch:docusaurus_tag": "docs-default-current",
        "docsearch:language": "en",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "docsearch:version": "current",
        "title": "andRace | VoltAgent",
        "og:title": "andRace | VoltAgent",
        "ogDescription": "Run multiple steps in parallel and use the first one that finishes. Perfect for timeouts, fallbacks, or getting the fastest response.",
        "ogUrl": "https://voltagent.dev/docs/workflows/steps/and-race/",
        "description": "Run multiple steps in parallel and use the first one that finishes. Perfect for timeouts, fallbacks, or getting the fastest response.",
        "docusaurus_version": "current",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "og:image": "https://voltagent.dev/img/social3.png",
        "viewport": "width=device-width, initial-scale=1.0",
        "ogLocale": "en",
        "ogTitle": "andRace | VoltAgent",
        "scrapeId": "e154766f-6b13-40a3-b613-873f566643a3",
        "sourceURL": "https://voltagent.dev/docs/workflows/steps/and-race/",
        "url": "https://voltagent.dev/docs/workflows/steps/and-race/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:51.100Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/getting-started/mcp-docs-server/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# VoltAgent MCP Docs Server\n\nThe VoltAgent MCP (Model Context Protocol) Docs Server enables your AI assistants to directly access VoltAgent documentation, examples, and changelogs. This allows your AI assistant to answer VoltAgent-related questions in real-time using the most up-to-date documentation.\n\n## What Does It Do? [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#what-does-it-do \"Direct link to What Does It Do?\")\n\nWith the MCP Docs Server, your AI assistant can:\n\n- ðŸ“š **Search VoltAgent documentation** \\- Find detailed explanations on any topic\n- ðŸ” **Browse code examples** \\- Show working code examples from real projects\n- ðŸ“‹ **Browse changelogs** \\- Provide information about bug fixes and new features\n\n## Automatic Installation [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#automatic-installation \"Direct link to Automatic Installation\")\n\nAutomatic Installation\n\nWhen you create a new project with `create-voltagent-app@latest`, you'll be asked which IDE you're using (Cursor, Windsurf, or VS Code). The MCP Docs Server will be automatically installed and configured for your chosen IDE. No additional setup is required.\n\n```codeBlockLines_e6Vv\nnpm create voltagent-app@latest\n# âœ” What is your project named? â€º my-app\n# âœ” Which package manager do you want to use? â€º npm\n# âœ” Which IDE are you using? (For MCP Docs Server configuration) â€º Cursor\n# âœ” MCP Docs Server configured for Cursor!\n#   Configuration file created in .cursor/mcp.json\n\n```\n\n## Manual Setup (Advanced) [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#manual-setup-advanced \"Direct link to Manual Setup (Advanced)\")\n\nWhen is Manual Setup Needed?\n\nManual setup is only needed if you're adding MCP Docs Server to an existing project that wasn't created with `create-voltagent-app@latest`.\n\n### Quick Setup with CLI [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#quick-setup-with-cli \"Direct link to Quick Setup with CLI\")\n\nFor existing VoltAgent projects, you can use the dedicated CLI command:\n\n```codeBlockLines_e6Vv\nvolt mcp setup\n\n```\n\nThis interactive command will:\n\n- Create the appropriate configuration files\n- Guide you through the setup process\n\n### Manual Configuration [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#manual-configuration \"Direct link to Manual Configuration\")\n\nIf you prefer manual configuration, directly configure your IDE:\n\n- Cursor\n- Windsurf\n- VS Code\n\n1. **Open Cursor settings**: `Cmd/Ctrl + ,`\n2. **Navigate to \"Features\" > \"Model Context Protocol\"**\n3. **Add a new MCP server**:\n\n```codeBlockLines_e6Vv\n{\n  \"name\": \"voltagent\",\n  \"command\": \"npx\",\n  \"args\": [\"-y\", \"@voltagent/docs-mcp\"]\n}\n\n```\n\n**To use a local build**:\n\n```codeBlockLines_e6Vv\n{\n  \"name\": \"voltagent\",\n  \"command\": \"node\",\n  \"args\": [\"path/to/voltagent/packages/docs-mcp/dist/server.js\"]\n}\n\n```\n\n4. **Save settings** and restart Cursor\n\n## Testing Your Setup [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#testing-your-setup \"Direct link to Testing Your Setup\")\n\nAfter creating your project with `create-voltagent-app@latest` (or completing manual setup), restart your IDE and test the MCP connection by asking your AI assistant questions like:\n\n```codeBlockLines_e6Vv\nHow do I create an agent in VoltAgent?\n\n```\n\n```codeBlockLines_e6Vv\nDo you have a Next.js example with VoltAgent?\n\n```\n\n```codeBlockLines_e6Vv\nHow do I use the voice features?\n\n```\n\n## CLI Commands [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#cli-commands \"Direct link to CLI Commands\")\n\nThe VoltAgent CLI provides several commands to manage your MCP setup:\n\n### `volt mcp setup` [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#volt-mcp-setup \"Direct link to volt-mcp-setup\")\n\nInteractive setup command that configures MCP for your IDE:\n\n```codeBlockLines_e6Vv\nvolt mcp setup        # Interactive setup\nvolt mcp setup --force # Force overwrite existing configuration\n\n```\n\n### `volt mcp status` [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#volt-mcp-status \"Direct link to volt-mcp-status\")\n\nCheck the current MCP configuration status:\n\n```codeBlockLines_e6Vv\nvolt mcp status\n\n```\n\n### `volt mcp test` [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#volt-mcp-test \"Direct link to volt-mcp-test\")\n\nGet test suggestions and troubleshooting tips:\n\n```codeBlockLines_e6Vv\nvolt mcp test\n\n```\n\n### `volt mcp remove` [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#volt-mcp-remove \"Direct link to volt-mcp-remove\")\n\nRemove MCP configuration:\n\n```codeBlockLines_e6Vv\nvolt mcp remove\n\n```\n\n## Available Tools [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#available-tools \"Direct link to Available Tools\")\n\nThe MCP Docs Server provides these tools:\n\n### ðŸ“š Documentation Tools [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#-documentation-tools \"Direct link to ðŸ“š Documentation Tools\")\n\n- **search\\_voltagent\\_docs**: Search through documentation\n- **get\\_voltagent\\_doc**: Get specific documentation file\n- **list\\_voltagent\\_docs**: List documentation structure\n\n### ðŸ” Example Tools [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#-example-tools \"Direct link to ðŸ” Example Tools\")\n\n- **search\\_voltagent\\_examples**: Search through examples\n- **get\\_voltagent\\_example**: Get specific example content\n- **list\\_voltagent\\_examples**: List available examples\n\n### ðŸ“‹ Changelog Tools [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#-changelog-tools \"Direct link to ðŸ“‹ Changelog Tools\")\n\n- **list\\_voltagent\\_changelogs**: List package changelogs\n- **get\\_voltagent\\_changelog**: Get specific package changelog\n- **search\\_voltagent\\_changelogs**: Search across changelogs\n\n## Example Usage Scenarios [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#example-usage-scenarios \"Direct link to Example Usage Scenarios\")\n\n### Quick Start Questions [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#quick-start-questions \"Direct link to Quick Start Questions\")\n\n```codeBlockLines_e6Vv\n\"How do I get started with VoltAgent?\"\n\"How do I create the simplest agent example?\"\n\n```\n\n### Technology-Specific Questions [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#technology-specific-questions \"Direct link to Technology-Specific Questions\")\n\n```codeBlockLines_e6Vv\n\"How do I integrate VoltAgent with Supabase?\"\n\"Can you explain the voice features?\"\n\"Do you have an example using VoltAgent with Next.js?\"\n\n```\n\n### Problem Solving [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#problem-solving \"Direct link to Problem Solving\")\n\n```codeBlockLines_e6Vv\n\"I'm getting an authentication error, is there a solution?\"\n\"What bug fixes were made in recent updates?\"\n\n```\n\n### Code Examples [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#code-examples \"Direct link to Code Examples\")\n\n```codeBlockLines_e6Vv\n\"How do I create an MCP server, show me an example\"\n\"How do I write a tool, I want working code\"\n\n```\n\n## Manual Server Execution [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#manual-server-execution \"Direct link to Manual Server Execution\")\n\nIf you want to run the server manually:\n\n```codeBlockLines_e6Vv\n# Run with NPX\nnpx @voltagent/docs-mcp\n\n# Run with local build\nnode path/to/voltagent/packages/docs-mcp/dist/server.js\n\n```\n\nThe server will start and begin listening for MCP connections.\n\n## Troubleshooting [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#troubleshooting \"Direct link to Troubleshooting\")\n\n### Server Won't Start [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#server-wont-start \"Direct link to Server Won't Start\")\n\n- Ensure your Node.js version is up to date (Node.js 18+)\n- Check package installation: `npm ls @voltagent/docs-mcp`\n\n### AI Assistant Can't See Tools [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#ai-assistant-cant-see-tools \"Direct link to AI Assistant Can't See Tools\")\n\n- Restart your editor\n- Check your MCP configuration\n- Verify the server is running\n\n### Slow Responses [â€‹](https://voltagent.dev/docs/getting-started/mcp-docs-server/\\#slow-responses \"Direct link to Slow Responses\")\n\n- Check your internet connection\n- Test if the server is running locally\n\nNeed More Help?\n\nIf problems persist, you can join our [VoltAgent Discord](https://s.voltagent.dev/discord) or get support through [GitHub Issues](https://github.com/voltagent/voltagent/issues).\n\n### Table of Contents\n\n- [What Does It Do?](https://voltagent.dev/docs/getting-started/mcp-docs-server/#what-does-it-do)\n- [Automatic Installation](https://voltagent.dev/docs/getting-started/mcp-docs-server/#automatic-installation)\n- [Manual Setup (Advanced)](https://voltagent.dev/docs/getting-started/mcp-docs-server/#manual-setup-advanced)\n  - [Quick Setup with CLI](https://voltagent.dev/docs/getting-started/mcp-docs-server/#quick-setup-with-cli)\n  - [Manual Configuration](https://voltagent.dev/docs/getting-started/mcp-docs-server/#manual-configuration)\n- [Testing Your Setup](https://voltagent.dev/docs/getting-started/mcp-docs-server/#testing-your-setup)\n- [CLI Commands](https://voltagent.dev/docs/getting-started/mcp-docs-server/#cli-commands)\n  - [`volt mcp setup`](https://voltagent.dev/docs/getting-started/mcp-docs-server/#volt-mcp-setup)\n  - [`volt mcp status`](https://voltagent.dev/docs/getting-started/mcp-docs-server/#volt-mcp-status)\n  - [`volt mcp test`](https://voltagent.dev/docs/getting-started/mcp-docs-server/#volt-mcp-test)\n  - [`volt mcp remove`](https://voltagent.dev/docs/getting-started/mcp-docs-server/#volt-mcp-remove)\n- [Available Tools](https://voltagent.dev/docs/getting-started/mcp-docs-server/#available-tools)\n  - [ðŸ“š Documentation Tools](https://voltagent.dev/docs/getting-started/mcp-docs-server/#-documentation-tools)\n  - [ðŸ” Example Tools](https://voltagent.dev/docs/getting-started/mcp-docs-server/#-example-tools)\n  - [ðŸ“‹ Changelog Tools](https://voltagent.dev/docs/getting-started/mcp-docs-server/#-changelog-tools)\n- [Example Usage Scenarios](https://voltagent.dev/docs/getting-started/mcp-docs-server/#example-usage-scenarios)\n  - [Quick Start Questions](https://voltagent.dev/docs/getting-started/mcp-docs-server/#quick-start-questions)\n  - [Technology-Specific Questions](https://voltagent.dev/docs/getting-started/mcp-docs-server/#technology-specific-questions)\n  - [Problem Solving](https://voltagent.dev/docs/getting-started/mcp-docs-server/#problem-solving)\n  - [Code Examples](https://voltagent.dev/docs/getting-started/mcp-docs-server/#code-examples)\n- [Manual Server Execution](https://voltagent.dev/docs/getting-started/mcp-docs-server/#manual-server-execution)\n- [Troubleshooting](https://voltagent.dev/docs/getting-started/mcp-docs-server/#troubleshooting)\n  - [Server Won't Start](https://voltagent.dev/docs/getting-started/mcp-docs-server/#server-wont-start)\n  - [AI Assistant Can't See Tools](https://voltagent.dev/docs/getting-started/mcp-docs-server/#ai-assistant-cant-see-tools)\n  - [Slow Responses](https://voltagent.dev/docs/getting-started/mcp-docs-server/#slow-responses)",
      "metadata": {
        "ogUrl": "https://voltagent.dev/docs/getting-started/mcp-docs-server/",
        "ogLocale": "en",
        "generator": "Docusaurus v3.1.1",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "language": "en",
        "og:locale": "en",
        "title": "MCP Docs Server | VoltAgent",
        "og:image": "https://voltagent.dev/img/social3.png",
        "og:url": "https://voltagent.dev/docs/getting-started/mcp-docs-server/",
        "docusaurus_tag": "docs-default-current",
        "og:title": "MCP Docs Server | VoltAgent",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "docsearch:language": "en",
        "ogTitle": "MCP Docs Server | VoltAgent",
        "docsearch:version": "current",
        "description": "The VoltAgent MCP (Model Context Protocol) Docs Server enables your AI assistants to directly access VoltAgent documentation, examples, and changelogs. This allows your AI assistant to answer VoltAgent-related questions in real-time using the most up-to-date documentation.",
        "og:description": "The VoltAgent MCP (Model Context Protocol) Docs Server enables your AI assistants to directly access VoltAgent documentation, examples, and changelogs. This allows your AI assistant to answer VoltAgent-related questions in real-time using the most up-to-date documentation.",
        "viewport": "width=device-width, initial-scale=1.0",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "docusaurus_version": "current",
        "ogDescription": "The VoltAgent MCP (Model Context Protocol) Docs Server enables your AI assistants to directly access VoltAgent documentation, examples, and changelogs. This allows your AI assistant to answer VoltAgent-related questions in real-time using the most up-to-date documentation.",
        "docusaurus_locale": "en",
        "twitter:card": "summary_large_image",
        "docsearch:docusaurus_tag": "docs-default-current",
        "scrapeId": "1d385ef0-e3a9-4e25-ac80-5cdfdc268d0f",
        "sourceURL": "https://voltagent.dev/docs/getting-started/mcp-docs-server/",
        "url": "https://voltagent.dev/docs/getting-started/mcp-docs-server/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:31.321Z",
        "creditsUsed": 1
      },
      "warning": "This scrape job was throttled at your current concurrency limit. If you'd like to scrape faster, you can upgrade your plan."
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/agents/memory/supabase/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Supabase Memory\n\nThe `@voltagent/supabase` package provides a `SupabaseMemory` provider that uses a [Supabase](https://supabase.com/) project (PostgreSQL database) for persistent storage of agent memory.\n\nThis is a good choice if your application is already built on Supabase or if you require a robust, scalable PostgreSQL backend with managed features like authentication, real-time subscriptions, and storage.\n\n## Setup [â€‹](https://voltagent.dev/docs/agents/memory/supabase/\\#setup \"Direct link to Setup\")\n\n### Install Package [â€‹](https://voltagent.dev/docs/agents/memory/supabase/\\#install-package \"Direct link to Install Package\")\n\nFirst, install the necessary packages:\n\n- npm\n- yarn\n- pnpm\n\n```codeBlockLines_e6Vv\nnpm install @voltagent/supabase @supabase/supabase-js\n\n```\n\n### Database Setup [â€‹](https://voltagent.dev/docs/agents/memory/supabase/\\#database-setup \"Direct link to Database Setup\")\n\nUnlike `LibSQLStorage`, `SupabaseMemory` **does not automatically create database tables**. You must run the following SQL commands in your Supabase project's SQL Editor (Dashboard -> SQL Editor -> New query) before using the provider.\n\n**Note:** These commands use the default table prefix `voltagent_memory`. If you provide a custom `tableName` option when initializing `SupabaseMemory` (e.g., `new SupabaseMemory({ ..., tableName: 'my_custom_prefix' })`), you **must** replace `voltagent_memory` with `my_custom_prefix` in the SQL commands below.\n\nClick to view Database Setup SQL\n\n```codeBlockLines_e6Vv\n-- Conversations Table\nCREATE TABLE IF NOT EXISTS voltagent_memory_conversations (\n    id TEXT PRIMARY KEY,\n    resource_id TEXT NOT NULL,\n    user_id TEXT,  -- Associates conversation with user (nullable)\n    title TEXT,\n    metadata JSONB, -- Use JSONB for efficient querying\n    created_at TIMESTAMPTZ NOT NULL DEFAULT timezone('utc'::text, now()),\n    updated_at TIMESTAMPTZ NOT NULL DEFAULT timezone('utc'::text, now())\n);\n\n-- Index for faster lookup by resource_id\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_conversations_resource\nON voltagent_memory_conversations(resource_id);\n\n-- Index for faster lookup by user_id\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_conversations_user\nON voltagent_memory_conversations(user_id);\n\n-- Composite index for user_id + resource_id queries\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_conversations_user_resource\nON voltagent_memory_conversations(user_id, resource_id);\n\n-- Index for ordering by updated_at (most common query pattern)\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_conversations_updated_at\nON voltagent_memory_conversations(updated_at DESC);\n\n-- Messages Table\nCREATE TABLE IF NOT EXISTS voltagent_memory_messages (\n    conversation_id TEXT NOT NULL REFERENCES voltagent_memory_conversations(id) ON DELETE CASCADE,\n    message_id TEXT NOT NULL,\n    role TEXT NOT NULL,\n    content TEXT NOT NULL, -- Consider JSONB if content is often structured\n    type TEXT NOT NULL,\n    created_at TIMESTAMPTZ NOT NULL DEFAULT timezone('utc'::text, now()),\n    -- Primary key: conversation_id + message_id ensures uniqueness within conversation\n    PRIMARY KEY (conversation_id, message_id)\n);\n\n-- Index for faster message retrieval (most common query pattern)\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_messages_lookup\nON voltagent_memory_messages(conversation_id, created_at);\n\n-- Index for message role filtering\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_messages_role\nON voltagent_memory_messages(conversation_id, role, created_at);\n\n-- Agent History Table (New Structured Format)\nCREATE TABLE IF NOT EXISTS voltagent_memory_agent_history (\n    id TEXT PRIMARY KEY,\n    agent_id TEXT NOT NULL,\n    timestamp TEXT NOT NULL,\n    status TEXT,\n    input JSONB,\n    output JSONB,\n    usage JSONB,\n    metadata JSONB,\n    user_id TEXT,\n    conversation_id TEXT,\n    -- Legacy columns for migration compatibility\n    key TEXT,\n    value JSONB\n);\n\n-- Indexes for agent history\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_agent_history_id\nON voltagent_memory_agent_history(id);\n\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_agent_history_agent_id\nON voltagent_memory_agent_history(agent_id);\n\n-- Agent History Steps Table\nCREATE TABLE IF NOT EXISTS voltagent_memory_agent_history_steps (\n    key TEXT PRIMARY KEY,\n    value JSONB NOT NULL, -- Store the step object as JSONB\n    -- Foreign key to history entry\n    history_id TEXT NOT NULL,\n    agent_id TEXT NOT NULL\n);\n\n-- Indexes for faster lookup\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_agent_history_steps_history_id\nON voltagent_memory_agent_history_steps(history_id);\n\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_agent_history_steps_agent_id\nON voltagent_memory_agent_history_steps(agent_id);\n\n-- Timeline Events Table (New)\nCREATE TABLE IF NOT EXISTS voltagent_memory_agent_history_timeline_events (\n    id TEXT PRIMARY KEY,\n    history_id TEXT NOT NULL,\n    agent_id TEXT,\n    event_type TEXT NOT NULL,\n    event_name TEXT NOT NULL,\n    start_time TEXT NOT NULL,\n    end_time TEXT,\n    status TEXT,\n    status_message TEXT,\n    level TEXT DEFAULT 'INFO',\n    version TEXT,\n    parent_event_id TEXT,\n    tags JSONB,\n    input JSONB,\n    output JSONB,\n    error JSONB,\n    metadata JSONB,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\n-- Indexes for timeline events\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_timeline_events_history_id\nON voltagent_memory_agent_history_timeline_events(history_id);\n\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_timeline_events_agent_id\nON voltagent_memory_agent_history_timeline_events(agent_id);\n\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_timeline_events_event_type\nON voltagent_memory_agent_history_timeline_events(event_type);\n\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_timeline_events_event_name\nON voltagent_memory_agent_history_timeline_events(event_name);\n\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_timeline_events_parent_event_id\nON voltagent_memory_agent_history_timeline_events(parent_event_id);\n\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_timeline_events_status\nON voltagent_memory_agent_history_timeline_events(status);\n\n-- Workflow History Table\nCREATE TABLE IF NOT EXISTS voltagent_memory_workflow_history (\n    id TEXT PRIMARY KEY,\n    name TEXT NOT NULL,\n    workflow_id TEXT NOT NULL,\n    status TEXT NOT NULL CHECK (status IN ('running', 'completed', 'error', 'cancelled')),\n    start_time TIMESTAMPTZ NOT NULL,\n    end_time TIMESTAMPTZ,\n    input JSONB,\n    output JSONB,\n    metadata JSONB,\n    user_id TEXT,\n    conversation_id TEXT,\n    created_at TIMESTAMPTZ NOT NULL DEFAULT timezone('utc'::text, now()),\n    updated_at TIMESTAMPTZ NOT NULL DEFAULT timezone('utc'::text, now())\n);\n\n-- Workflow Steps Table\nCREATE TABLE IF NOT EXISTS voltagent_memory_workflow_steps (\n    id TEXT PRIMARY KEY,\n    workflow_history_id TEXT NOT NULL REFERENCES voltagent_memory_workflow_history(id) ON DELETE CASCADE,\n    step_index INTEGER NOT NULL,\n    step_type TEXT NOT NULL CHECK (step_type IN ('agent', 'func', 'conditional-when', 'parallel-all', 'parallel-race')),\n    step_name TEXT NOT NULL,\n    status TEXT NOT NULL CHECK (status IN ('running', 'completed', 'error', 'skipped')),\n    start_time TIMESTAMPTZ NOT NULL,\n    end_time TIMESTAMPTZ,\n    input JSONB,\n    output JSONB,\n    error_message TEXT,\n    agent_execution_id TEXT,\n    created_at TIMESTAMPTZ NOT NULL DEFAULT timezone('utc'::text, now()),\n    updated_at TIMESTAMPTZ NOT NULL DEFAULT timezone('utc'::text, now())\n);\n\n-- Workflow Timeline Events Table\nCREATE TABLE IF NOT EXISTS voltagent_memory_workflow_timeline_events (\n    id TEXT PRIMARY KEY,\n    workflow_history_id TEXT NOT NULL REFERENCES voltagent_memory_workflow_history(id) ON DELETE CASCADE,\n    event_id TEXT NOT NULL,\n    type TEXT NOT NULL,\n    name TEXT NOT NULL,\n    start_time TIMESTAMPTZ NOT NULL,\n    end_time TIMESTAMPTZ,\n    status TEXT,\n    level TEXT DEFAULT 'INFO',\n    input JSONB,\n    output JSONB,\n    metadata JSONB,\n    event_sequence INTEGER,\n    trace_id TEXT,\n    parent_event_id TEXT,\n    status_message TEXT,\n    created_at TIMESTAMPTZ NOT NULL DEFAULT timezone('utc'::text, now())\n);\n\n-- Indexes for workflow tables\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_workflow_history_workflow_id\nON voltagent_memory_workflow_history(workflow_id);\n\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_workflow_history_status\nON voltagent_memory_workflow_history(status);\n\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_workflow_history_start_time\nON voltagent_memory_workflow_history(start_time);\n\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_workflow_history_user_id\nON voltagent_memory_workflow_history(user_id);\n\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_workflow_history_conversation_id\nON voltagent_memory_workflow_history(conversation_id);\n\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_workflow_steps_workflow_history_id\nON voltagent_memory_workflow_steps(workflow_history_id);\n\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_workflow_steps_step_index\nON voltagent_memory_workflow_steps(workflow_history_id, step_index);\n\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_workflow_timeline_events_workflow_history_id\nON voltagent_memory_workflow_timeline_events(workflow_history_id);\n\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_workflow_timeline_events_type\nON voltagent_memory_workflow_timeline_events(type);\n\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_workflow_timeline_events_start_time\nON voltagent_memory_workflow_timeline_events(start_time);\n\nCREATE INDEX IF NOT EXISTS idx_voltagent_memory_workflow_timeline_events_sequence\nON voltagent_memory_workflow_timeline_events(event_sequence);\n\n-- Migration Flags Table (Prevents duplicate migrations)\nCREATE TABLE IF NOT EXISTS voltagent_memory_conversations_migration_flags (\n    id SERIAL PRIMARY KEY,\n    migration_type TEXT NOT NULL UNIQUE,\n    completed_at TIMESTAMPTZ NOT NULL DEFAULT timezone('utc'::text, now()),\n    migrated_count INTEGER DEFAULT 0,\n    metadata JSONB DEFAULT '{}'::jsonb\n);\n\n-- Insert fresh installation flags to prevent future migrations\nINSERT INTO voltagent_memory_conversations_migration_flags (migration_type, migrated_count, metadata)\nVALUES\n    ('conversation_schema_migration', 0, '{\"fresh_install\": true}'::jsonb),\n    ('agent_history_migration', 0, '{\"fresh_install\": true}'::jsonb)\nON CONFLICT (migration_type) DO NOTHING;\n\n```\n\nAlternatively, integrate these SQL statements into your Supabase migration workflow using the [Supabase CLI](https://supabase.com/docs/guides/cli).\n\n### Credentials [â€‹](https://voltagent.dev/docs/agents/memory/supabase/\\#credentials \"Direct link to Credentials\")\n\nYou will need your Supabase project's URL and `anon` key.\n\n1. Navigate to your project in the [Supabase Dashboard](https://app.supabase.com/).\n2. Go to **Project Settings** (the gear icon).\n3. Select the **API** section.\n4. Find your **Project URL** and the **Project API key** labelled `anon` (public).\n\nStore these credentials securely, typically as environment variables (e.g., `SUPABASE_URL` and `SUPABASE_KEY`).\n\n## Configuration [â€‹](https://voltagent.dev/docs/agents/memory/supabase/\\#configuration \"Direct link to Configuration\")\n\nImport `SupabaseMemory` and initialize it with your credentials:\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { SupabaseMemory } from \"@voltagent/supabase\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { createPinoLogger } from \"@voltagent/logger\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Get credentials from environment variables\nconst supabaseUrl = process.env.SUPABASE_URL;\nconst supabaseKey = process.env.SUPABASE_KEY;\n\nif (!supabaseUrl || !supabaseKey) {\n  throw new Error(\"Supabase URL and Key must be provided via environment variables.\");\n}\n\n// Initialize SupabaseMemory\nconst memory = new SupabaseMemory({\n  supabaseUrl,\n  supabaseKey,\n  // Optional: Specify a custom base table name prefix\n  // This MUST match the prefix used in your SQL setup if customized.\n  tableName: \"voltagent_memory\", // Defaults to 'voltagent_memory'\n  // Optional: Limit the number of messages stored per conversation\n  storageLimit: 100, // Defaults to 100\n  // Optional: Enable verbose debug logging from the memory provider\n  debug: true, // Defaults to false\n  // Optional: Custom logger for structured logging\n  logger: createPinoLogger({ name: \"memory-supabase\" }),\n});\n\n// Alternative: Use existing Supabase client\nimport { createClient } from \"@supabase/supabase-js\";\n\nconst supabaseClient = createClient(supabaseUrl, supabaseKey);\nconst memory = new SupabaseMemory({\n  client: supabaseClient,\n  tableName: \"voltagent_memory\", // Optional\n  storageLimit: 150, // Optional: Custom storage limit\n  debug: false, // Optional: Debug logging\n  logger: createPinoLogger({ name: \"memory-supabase\" }), // Optional: Custom logger\n});\n\nconst agent = new Agent({\n  name: \"Supabase Memory Agent\",\n  instructions: \"An agent using Supabase for memory.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  memory: memory, // Assign the memory provider instance\n});\n\n```\n\n**Configuration Options:**\n\nWhen using Supabase URL and key:\n\n- `supabaseUrl` (string, required): Your Supabase project URL.\n- `supabaseKey` (string, required): Your Supabase project `anon` key (or a service role key if used in a secure backend environment, though `anon` key with appropriate RLS policies is often sufficient).\n- `tableName` (string, optional): A prefix for the database table names. Defaults to `voltagent_memory`. If you change this, ensure your SQL table creation script uses the same prefix.\n- `storageLimit` (number, optional): The maximum number of messages to retain per conversation. When the limit is reached, the oldest messages are automatically deleted to make room for new ones. Defaults to `100`.\n- `debug` (boolean, optional): Enables detailed logging from the `SupabaseMemory` provider to the console, useful for understanding memory operations during development. Defaults to `false`.\n- `logger` (Logger, optional): Custom logger instance for structured logging. Supports any logger that implements the standard logger interface (e.g., Pino, Winston). When provided, this overrides the `debug` option.\n\nWhen using an existing Supabase client:\n\n- `client` (SupabaseClient, required when not using supabaseUrl/supabaseKey): An existing Supabase client instance. The constructor validates that this is a proper SupabaseClient instance.\n- `tableName` (string, optional): Table name prefix when using existing client.\n- `storageLimit` (number, optional): Storage limit when using existing client. Defaults to `100`.\n- `debug` (boolean, optional): Debug logging when using existing client. Defaults to `false`.\n- `logger` (Logger, optional): Custom logger instance for structured logging.\n\n## Conversation Management [â€‹](https://voltagent.dev/docs/agents/memory/supabase/\\#conversation-management \"Direct link to Conversation Management\")\n\nThe Supabase provider supports conversation management similar to other storage providers:\n\n```codeBlockLines_e6Vv\n// Get conversations for a specific user\nconst conversations = await memory.getConversationsByUserId(\"user-123\", {\n  limit: 50,\n  orderBy: \"updated_at\",\n  orderDirection: \"DESC\",\n});\n\n// Create and update conversations\nconst newConversation = await memory.createConversation({\n  id: \"conversation-id\",\n  resourceId: \"app-resource-1\",\n  userId: \"user-123\",\n  title: \"New Chat Session\",\n  metadata: { source: \"web-app\" },\n});\n\nawait memory.updateConversation(\"conversation-id\", {\n  title: \"Updated Title\",\n});\n\n```\n\n## Querying Conversations [â€‹](https://voltagent.dev/docs/agents/memory/supabase/\\#querying-conversations \"Direct link to Querying Conversations\")\n\nThe Supabase storage provides conversation querying capabilities with filtering, pagination, and sorting options:\n\n```codeBlockLines_e6Vv\n// Query with multiple filters\nconst workConversations = await memory.queryConversations({\n  userId: \"user-123\",\n  resourceId: \"work-agent\",\n  limit: 25,\n  offset: 0,\n  orderBy: \"created_at\",\n  orderDirection: \"DESC\",\n});\n\n// Get all conversations for a user\nconst userConversations = await memory.queryConversations({\n  userId: \"user-123\",\n  limit: 50,\n});\n\n// Get conversations for a specific resource\nconst resourceConversations = await memory.queryConversations({\n  resourceId: \"chatbot-v1\",\n  limit: 100,\n  orderBy: \"updated_at\",\n});\n\n// Admin view - get all conversations\nconst allConversations = await memory.queryConversations({\n  limit: 200,\n  orderBy: \"created_at\",\n  orderDirection: \"ASC\",\n});\n\n```\n\n**Query Options:**\n\n- `userId` (optional): Filter conversations by specific user\n- `resourceId` (optional): Filter conversations by specific resource\n- `limit` (optional): Maximum number of conversations to return (default: 50)\n- `offset` (optional): Number of conversations to skip for pagination (default: 0)\n- `orderBy` (optional): Field to sort by: 'created\\_at', 'updated\\_at', or 'title' (default: 'updated\\_at')\n- `orderDirection` (optional): Sort direction: 'ASC' or 'DESC' (default: 'DESC')\n\n## Getting Conversation Messages [â€‹](https://voltagent.dev/docs/agents/memory/supabase/\\#getting-conversation-messages \"Direct link to Getting Conversation Messages\")\n\nRetrieve messages for a specific conversation with pagination support:\n\n```codeBlockLines_e6Vv\n// Get all messages for a conversation\nconst messages = await memory.getConversationMessages(\"conversation-456\");\n\n// Get messages with pagination\nconst firstBatch = await memory.getConversationMessages(\"conversation-456\", {\n  limit: 50,\n  offset: 0,\n});\n\n// Get next batch\nconst nextBatch = await memory.getConversationMessages(\"conversation-456\", {\n  limit: 50,\n  offset: 50,\n});\n\n// Process messages in batches for large conversations\nconst batchSize = 100;\nlet offset = 0;\nlet hasMore = true;\n\nwhile (hasMore) {\n  const batch = await memory.getConversationMessages(\"conversation-456\", {\n    limit: batchSize,\n    offset: offset,\n  });\n\n  // Process batch\n  processBatch(batch);\n\n  hasMore = batch.length === batchSize;\n  offset += batchSize;\n}\n\n```\n\n**Message Query Options:**\n\n- `limit` (optional): Maximum number of messages to return (default: 100)\n- `offset` (optional): Number of messages to skip for pagination (default: 0)\n\nMessages are returned in chronological order (oldest first) for natural conversation flow.\n\n## Use Cases [â€‹](https://voltagent.dev/docs/agents/memory/supabase/\\#use-cases \"Direct link to Use Cases\")\n\n- Applications already using Supabase for backend services.\n- Projects requiring a scalable, managed PostgreSQL database.\n- Scenarios where leveraging Supabase features like Auth, Realtime, or Storage alongside agent memory is beneficial.\n- Production environments where robust data management and security policies (RLS) are essential.\n\n### Table of Contents\n\n- [Setup](https://voltagent.dev/docs/agents/memory/supabase/#setup)\n  - [Install Package](https://voltagent.dev/docs/agents/memory/supabase/#install-package)\n  - [Database Setup](https://voltagent.dev/docs/agents/memory/supabase/#database-setup)\n  - [Credentials](https://voltagent.dev/docs/agents/memory/supabase/#credentials)\n- [Configuration](https://voltagent.dev/docs/agents/memory/supabase/#configuration)\n- [Conversation Management](https://voltagent.dev/docs/agents/memory/supabase/#conversation-management)\n- [Querying Conversations](https://voltagent.dev/docs/agents/memory/supabase/#querying-conversations)\n- [Getting Conversation Messages](https://voltagent.dev/docs/agents/memory/supabase/#getting-conversation-messages)\n- [Use Cases](https://voltagent.dev/docs/agents/memory/supabase/#use-cases)",
      "metadata": {
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "docsearch:docusaurus_tag": "docs-default-current",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "ogUrl": "https://voltagent.dev/docs/agents/memory/supabase/",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "ogDescription": "The @voltagent/supabase package provides a SupabaseMemory provider that uses a Supabase project (PostgreSQL database) for persistent storage of agent memory.",
        "ogTitle": "Supabase Memory | VoltAgent",
        "language": "en",
        "generator": "Docusaurus v3.1.1",
        "og:image": "https://voltagent.dev/img/social3.png",
        "og:locale": "en",
        "docsearch:language": "en",
        "og:description": "The @voltagent/supabase package provides a SupabaseMemory provider that uses a Supabase project (PostgreSQL database) for persistent storage of agent memory.",
        "docusaurus_tag": "docs-default-current",
        "description": "The @voltagent/supabase package provides a SupabaseMemory provider that uses a Supabase project (PostgreSQL database) for persistent storage of agent memory.",
        "docsearch:version": "current",
        "og:title": "Supabase Memory | VoltAgent",
        "og:url": "https://voltagent.dev/docs/agents/memory/supabase/",
        "title": "Supabase Memory | VoltAgent",
        "docusaurus_locale": "en",
        "docusaurus_version": "current",
        "ogLocale": "en",
        "viewport": "width=device-width, initial-scale=1.0",
        "twitter:card": "summary_large_image",
        "scrapeId": "7e8c60ae-47ab-4cd7-bf49-056b00d7abda",
        "sourceURL": "https://voltagent.dev/docs/agents/memory/supabase/",
        "url": "https://voltagent.dev/docs/agents/memory/supabase/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:53.181Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/community/licence/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Overview\n\n**VoltAgent** is licensed under the MIT License. It only requires the preservation of copyright and license notices. Licensed works, modifications, and larger works may be distributed under different terms and without source code.\n\n## Permissions [â€‹](https://voltagent.dev/docs/community/licence/\\#permissions \"Direct link to Permissions\")\n\n- âœ… Commercial use\n- âœ… Modification\n- âœ… Distribution\n- âœ… Private use\n\n## Limitations [â€‹](https://voltagent.dev/docs/community/licence/\\#limitations \"Direct link to Limitations\")\n\n- âŒ Liability\n- âŒ Warranty\n\n# License\n\nMIT License\n\nCopyright (c) 2025 VoltAgent\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n### Table of Contents\n\n- [Permissions](https://voltagent.dev/docs/community/licence/#permissions)\n- [Limitations](https://voltagent.dev/docs/community/licence/#limitations)",
      "metadata": {
        "language": "en",
        "docsearch:version": "current",
        "docusaurus_locale": "en",
        "og:url": "https://voltagent.dev/docs/community/licence/",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "ogDescription": "VoltAgent is licensed under the MIT License. It only requires the preservation of copyright and license notices. Licensed works, modifications, and larger works may be distributed under different terms and without source code.",
        "title": "License | VoltAgent",
        "ogLocale": "en",
        "docsearch:language": "en",
        "docusaurus_version": "current",
        "docusaurus_tag": "docs-default-current",
        "og:title": "License | VoltAgent",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "description": "VoltAgent is licensed under the MIT License. It only requires the preservation of copyright and license notices. Licensed works, modifications, and larger works may be distributed under different terms and without source code.",
        "og:description": "VoltAgent is licensed under the MIT License. It only requires the preservation of copyright and license notices. Licensed works, modifications, and larger works may be distributed under different terms and without source code.",
        "twitter:card": "summary_large_image",
        "ogTitle": "License | VoltAgent",
        "ogUrl": "https://voltagent.dev/docs/community/licence/",
        "og:locale": "en",
        "generator": "Docusaurus v3.1.1",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "og:image": "https://voltagent.dev/img/social3.png",
        "docsearch:docusaurus_tag": "docs-default-current",
        "viewport": "width=device-width, initial-scale=1.0",
        "scrapeId": "9740502a-ad58-48a2-8c61-f200b75af294",
        "sourceURL": "https://voltagent.dev/docs/community/licence/",
        "url": "https://voltagent.dev/docs/community/licence/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:36.859Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/providers/contributing/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Contributing a new Provider\n\nThank you for your interest in contributing a new VoltAgent provider. This guide will walk you through the process of creating a new provider in under 15 minutes!\n\nBefore You Start\n\n**VoltAgent leverages the Vercel AI SDK** which already supports 30+ providers. Before creating a custom provider, please check:\n\n1. Is your provider already available in [Vercel AI SDK](https://voltagent.dev/docs/getting-started/providers-models/)?\n2. Can the [OpenAI-compatible provider](https://ai-sdk.dev/providers/openai-compatible-providers) work with your service?\n3. Is this a proprietary/internal service that truly requires custom implementation?\n\n**Most providers should be added to Vercel AI SDK** rather than as custom VoltAgent providers. This benefits the entire ecosystem!\n\n## When to Create a Custom Provider [â€‹](https://voltagent.dev/docs/providers/contributing/\\#when-to-create-a-custom-provider \"Direct link to When to Create a Custom Provider\")\n\nCustom providers are appropriate for:\n\n- **Internal/Proprietary Services**: Company-specific LLMs or APIs\n- **Special Authentication**: Non-standard auth mechanisms\n- **Custom Protocol**: Services that don't follow OpenAI or standard APIs\n- **Advanced Control**: When you need fine-grained control over request/response handling\n\n## Contributing to Vercel AI SDK Instead [â€‹](https://voltagent.dev/docs/providers/contributing/\\#contributing-to-vercel-ai-sdk-instead \"Direct link to Contributing to Vercel AI SDK Instead\")\n\nIf your provider would benefit the broader community, consider contributing it to Vercel AI SDK:\n\n- [Vercel AI SDK Repository](https://github.com/vercel/ai)\n- [Contributing Guide](https://github.com/vercel/ai/blob/main/CONTRIBUTING.md)\n- Your contribution helps thousands of developers!\n\n## Prerequisites [â€‹](https://voltagent.dev/docs/providers/contributing/\\#prerequisites \"Direct link to Prerequisites\")\n\n- Node.js 24+\n- pnpm\n- [VoltAgent repo](https://github.com/Voltagent/voltagent) cloned locally\n\n## TL;DR: [â€‹](https://voltagent.dev/docs/providers/contributing/\\#tldr \"Direct link to TL;DR:\")\n\n1. Generate a new provider using the generator `pnpm nx generate @voltagent/core:provider acme-ai`\n2. Install dependencies `cd packages/acme-ai && pnpm install acme-ai-sdk`\n3. Implement all required methods in `src/provider.ts`\n4. Verify tests pass in `src/provider.spec.ts` and add any new tests to `src/provider-custom.spec.ts`\n5. Verify `pnpm build` passes (this will also run typescript checks)\n6. Update `README.md` with usage examples and any other relevant information\n7. Submit PR to contribute back\n\n## Detailed Guide [â€‹](https://voltagent.dev/docs/providers/contributing/\\#detailed-guide \"Direct link to Detailed Guide\")\n\n### 1\\. Generate Provider [â€‹](https://voltagent.dev/docs/providers/contributing/\\#1-generate-provider \"Direct link to 1. Generate Provider\")\n\nYou can use the generator to create a new provider. This will create a new directory in `packages/` with the provider name and all the necessary files.\n\n```codeBlockLines_e6Vv\npnpm nx generate @voltagent/core:provider acme-ai\n\n```\n\n### 2\\. Install Dependencies [â€‹](https://voltagent.dev/docs/providers/contributing/\\#2-install-dependencies \"Direct link to 2. Install Dependencies\")\n\nYou will need to `cd` into the provider directory and install the dependencies for the provider.\n\n```codeBlockLines_e6Vv\ncd packages/acme-ai\npnpm install acme-ai-sdk\n\n```\n\n### 3\\. Implement Provider [â€‹](https://voltagent.dev/docs/providers/contributing/\\#3-implement-provider \"Direct link to 3. Implement Provider\")\n\nEdit `src/provider.ts` and make sure to implement all required methods and update all the `any` types to the correct types from the provider.\n\nPro Tip\n\nAll methods **MUST** have the `public`, `private` or `protected` modifier. See the [vercel-ai provider](https://github.com/VoltAgent/voltagent/blob/main/packages/vercel-ai/src/provider.ts) for a well built example.\n\n#### Example [â€‹](https://voltagent.dev/docs/providers/contributing/\\#example \"Direct link to Example\")\n\n```codeBlockLines_e6Vv\n// Custom provider for a proprietary/internal LLM service\n// Only create custom providers when Vercel AI SDK doesn't cover your use case\nimport { LLMProvider, GenerateTextOptions, ProviderTextResponse } from \"@voltagent/core\";\nimport { AcmeAI, ModelV1 } from \"acme-ai-sdk\";\n\nexport class AcmeAIProvider implements LLMProvider<{ model: ModelV1 }> {\n  private client: AcmeAI;\n\n  constructor(config?: { apiKey?: string }) {\n    this.client = new AcmeAI({\n      apiKey: config?.apiKey ?? process.env.ACME_AI_API_KEY,\n    });\n  }\n\n  public async generateText(\n    options: GenerateTextOptions<string>\n  ): Promise<ProviderTextResponse<string>> {\n    const response = await this.client.chat.completions.create({\n      model: options.model,\n      messages: options.messages.map((msg) => ({\n        role: msg.role,\n        content: msg.content,\n      })),\n      temperature: options.temperature,\n      max_tokens: options.maxTokens,\n    });\n\n    return {\n      text: response.choices[0].message.content,\n      provider: response,\n      usage: {\n        promptTokens: response.usage.prompt_tokens,\n        completionTokens: response.usage.completion_tokens,\n        totalTokens: response.usage.total_tokens,\n      },\n      finishReason: response.choices[0].finish_reason,\n    };\n  }\n\n  // Implement other required methods (streamText, generateObject, streamObject)\n  // See generated template for full implementation\n}\n\n```\n\n### 4\\. Verify Tests Pass [â€‹](https://voltagent.dev/docs/providers/contributing/\\#4-verify-tests-pass \"Direct link to 4. Verify Tests Pass\")\n\nYou will need to run the tests to make sure your provider is working correctly.\n\n```codeBlockLines_e6Vv\npnpm test\n\n```\n\nThe tests in `provider.spec.ts` are standard for all providers and will help you get started. If you need to add new tests, its recommended to create a new file (e.g. `provider-custom.spec.ts`) in the same directory as the provider, as the `provider.spec.ts` file could be overwritten by the generator in the future.\n\n### 5\\. Verify Build [â€‹](https://voltagent.dev/docs/providers/contributing/\\#5-verify-build \"Direct link to 5. Verify Build\")\n\nYou should also test running a build to make sure your provider is output correctly.\n\n```codeBlockLines_e6Vv\npnpm build\n\n```\n\n### 6\\. Update README [â€‹](https://voltagent.dev/docs/providers/contributing/\\#6-update-readme \"Direct link to 6. Update README\")\n\nUpdate the `README.md` file to include usage examples and any other relevant information, for example:\n\n```codeBlockLines_e6Vv\n# Acme AI Provider\n\nThis is a provider for the Acme AI API.\n\n## Usage\n\n\\`\\`\\`typescript\nimport { Agent } from \"@voltagent/core\";\nimport { AcmeAIProvider } from \"@voltagent/acme-ai\";\n\nconst agent = new Agent({\nid: \"my-agent\",\npurpose: \"Help users\",\ninstructions: \"You are helpful\",\nllm: new AcmeAIProvider(),\n});\n\nconst response = await agent.generateText({\nmodel: \"acme-ai-4o\",\nmessages: [{ role: \"user\", content: \"Hello!\" }],\n});\n\\`\\`\\`\n\n```\n\n### 7\\. Ship it! [â€‹](https://voltagent.dev/docs/providers/contributing/\\#7-ship-it \"Direct link to 7. Ship it!\")\n\nIf you've followed all the steps above, you can submit a PR to the VoltAgent repo!\n\n## Final Checklist [â€‹](https://voltagent.dev/docs/providers/contributing/\\#final-checklist \"Direct link to Final Checklist\")\n\nBefore submitting your PR, please confirm:\n\n- [ ]  This provider cannot be implemented using Vercel AI SDK\n- [ ]  The OpenAI-compatible provider doesn't work for this service\n- [ ]  All tests pass\n- [ ]  README includes clear usage examples\n- [ ]  The provider implements all required `LLMProvider` methods\n- [ ]  TypeScript types are properly defined (no `any` types)\n\n## Need Help? [â€‹](https://voltagent.dev/docs/providers/contributing/\\#need-help \"Direct link to Need Help?\")\n\n- [Discord Community](https://discord.gg/voltagent)\n- [Provider Examples](https://github.com/VoltAgent/voltagent/tree/main/packages)\n- Consider if your provider should be in [Vercel AI SDK](https://github.com/vercel/ai) instead\n\n### Table of Contents\n\n- [When to Create a Custom Provider](https://voltagent.dev/docs/providers/contributing/#when-to-create-a-custom-provider)\n- [Contributing to Vercel AI SDK Instead](https://voltagent.dev/docs/providers/contributing/#contributing-to-vercel-ai-sdk-instead)\n- [Prerequisites](https://voltagent.dev/docs/providers/contributing/#prerequisites)\n- [TL;DR:](https://voltagent.dev/docs/providers/contributing/#tldr)\n- [Detailed Guide](https://voltagent.dev/docs/providers/contributing/#detailed-guide)\n  - [1\\. Generate Provider](https://voltagent.dev/docs/providers/contributing/#1-generate-provider)\n  - [2\\. Install Dependencies](https://voltagent.dev/docs/providers/contributing/#2-install-dependencies)\n  - [3\\. Implement Provider](https://voltagent.dev/docs/providers/contributing/#3-implement-provider)\n  - [4\\. Verify Tests Pass](https://voltagent.dev/docs/providers/contributing/#4-verify-tests-pass)\n  - [5\\. Verify Build](https://voltagent.dev/docs/providers/contributing/#5-verify-build)\n  - [6\\. Update README](https://voltagent.dev/docs/providers/contributing/#6-update-readme)\n  - [7\\. Ship it!](https://voltagent.dev/docs/providers/contributing/#7-ship-it)\n- [Final Checklist](https://voltagent.dev/docs/providers/contributing/#final-checklist)\n- [Need Help?](https://voltagent.dev/docs/providers/contributing/#need-help)",
      "metadata": {
        "ogUrl": "https://voltagent.dev/docs/providers/contributing/",
        "title": "Contributing a new Provider | VoltAgent",
        "docusaurus_version": "current",
        "og:title": "Contributing a new Provider | VoltAgent",
        "docsearch:language": "en",
        "docsearch:version": "current",
        "docusaurus_locale": "en",
        "og:locale": "en",
        "description": "Thank you for your interest in contributing a new VoltAgent provider. This guide will walk you through the process of creating a new provider in under 15 minutes!",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "language": "en",
        "ogLocale": "en",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "twitter:card": "summary_large_image",
        "og:image": "https://voltagent.dev/img/social3.png",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "docusaurus_tag": "docs-default-current",
        "og:description": "Thank you for your interest in contributing a new VoltAgent provider. This guide will walk you through the process of creating a new provider in under 15 minutes!",
        "ogDescription": "Thank you for your interest in contributing a new VoltAgent provider. This guide will walk you through the process of creating a new provider in under 15 minutes!",
        "ogTitle": "Contributing a new Provider | VoltAgent",
        "generator": "Docusaurus v3.1.1",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:url": "https://voltagent.dev/docs/providers/contributing/",
        "viewport": "width=device-width, initial-scale=1.0",
        "scrapeId": "c0cd77db-6e34-4211-808e-bc6e12ede037",
        "sourceURL": "https://voltagent.dev/docs/providers/contributing/",
        "url": "https://voltagent.dev/docs/providers/contributing/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:35.339Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/evals/quick-start/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Evals Quick Start Guide\n\nThis guide will walk you through setting up your first evaluation pipeline with VoltAgent and Viteval. In just a few minutes, you'll have a working eval system that can measure your agent's performance.\n\n## Prerequisites [â€‹](https://voltagent.dev/docs/evals/quick-start/\\#prerequisites \"Direct link to Prerequisites\")\n\nBefore starting, make sure you have:\n\n- A VoltAgent project set up with `@voltagent/core`\n- Node.js 22+ installed\n- An AI provider configured (OpenAI, Anthropic, etc.)\n\n## Installation [â€‹](https://voltagent.dev/docs/evals/quick-start/\\#installation \"Direct link to Installation\")\n\nInstall Viteval as a development dependency:\n\n- npm\n- yarn\n- pnpm\n\n```codeBlockLines_e6Vv\nnpm install viteval --save-dev\n\n```\n\n## Quick Setup [â€‹](https://voltagent.dev/docs/evals/quick-start/\\#quick-setup \"Direct link to Quick Setup\")\n\n### 1\\. Set up VoltAgent [â€‹](https://voltagent.dev/docs/evals/quick-start/\\#1-set-up-voltagent \"Direct link to 1. Set up VoltAgent\")\n\n```codeBlockLines_e6Vv\nviteval init\n\n```\n\nThis will create a `viteval.config.ts` and `viteval.setup.ts` file in your project root.\n\n### 2\\. Viteval Setup File [â€‹](https://voltagent.dev/docs/evals/quick-start/\\#2-viteval-setup-file \"Direct link to 2. Viteval Setup File\")\n\nUncomment the setup file content to use env variables or remove it if you don't need it:\n\n```codeBlockLines_e6Vv\n// viteval.setup.ts\nimport dotenv from \"dotenv\";\n\ndotenv.config({ path: \"./.env\", quiet: true });\n\n```\n\n### 3\\. Configure Viteval (Optional) [â€‹](https://voltagent.dev/docs/evals/quick-start/\\#3-configure-viteval-optional \"Direct link to 3. Configure Viteval (Optional)\")\n\nUpdate the Viteval configuration file:\n\n```codeBlockLines_e6Vv\n// viteval.config.ts\nimport { defineConfig } from \"viteval/config\";\n\nexport default defineConfig({\n  reporter: \"console\",\n  eval: {\n    include: [\"src/**/*.eval.ts\"],\n    setupFiles: [\"./viteval.setup.ts\"],\n  },\n});\n\n```\n\n### 4\\. Create Your Agent [â€‹](https://voltagent.dev/docs/evals/quick-start/\\#4-create-your-agent \"Direct link to 4. Create Your Agent\")\n\nFirst, create your VoltAgent agent:\n\n```codeBlockLines_e6Vv\n// src/agents/support.ts\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nexport const supportAgent = new Agent({\n  name: \"Customer Support\",\n  instructions:\n    \"You are a helpful customer support agent. Provide accurate and friendly assistance.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n});\n\n```\n\n### 5\\. Create Test Dataset [â€‹](https://voltagent.dev/docs/evals/quick-start/\\#5-create-test-dataset \"Direct link to 5. Create Test Dataset\")\n\nDefine your test cases in a dataset file:\n\n```codeBlockLines_e6Vv\n// src/agents/support.dataset.ts\nimport { defineDataset } from \"viteval/dataset\";\n\nexport default defineDataset({\n  name: \"support\",\n  data: async () => [\\\n    {\\\n      input: \"What is your refund policy?\",\\\n      expected: \"Our refund policy allows returns within 30 days of purchase with a valid receipt.\",\\\n    },\\\n    {\\\n      input: \"How long does shipping take?\",\\\n      expected: \"Standard shipping takes 3-5 business days, express shipping takes 1-2 days.\",\\\n    },\\\n    {\\\n      input: \"Hello, I need help with my order\",\\\n      expected:\\\n        \"Hello! I'd be happy to help you with your order. What specific assistance do you need?\",\\\n    },\\\n  ],\n});\n\n```\n\ntip\n\nYou can also use an LLM to generate the dataset dynamically. See an example in [Viteval Example](https://github.com/voltagent/examples/tree/main/with-viteval)\n\n### 6\\. Create Evaluation File [â€‹](https://voltagent.dev/docs/evals/quick-start/\\#6-create-evaluation-file \"Direct link to 6. Create Evaluation File\")\n\nCreate the evaluation logic:\n\n```codeBlockLines_e6Vv\n// src/agents/support.eval.ts\nimport { evaluate, scorers } from \"viteval\";\nimport { supportAgent } from \"./support\";\nimport supportDataset from \"./support.dataset\";\n\nevaluate(\"Customer Support Agent\", {\n  description: \"Evaluates customer support agent capabilities\",\n  data: supportDataset,\n  task: async ({ input }) => {\n    const result = await supportAgent.generateText(input);\n    return result.text;\n  },\n  scorers: [scorers.answerCorrectness, scorers.answerRelevancy, scorers.moderation],\n  threshold: 0.7,\n});\n\n```\n\ntip\n\nYou can learn more about Viteval scorers by visiting the [Viteval Scorers](https://viteval.dev/guide/concepts#scorers?ref=voltagent) documentation.\n\n### 7\\. Add NPM Script [â€‹](https://voltagent.dev/docs/evals/quick-start/\\#7-add-npm-script \"Direct link to 7. Add NPM Script\")\n\nAdd a script to your `package.json`:\n\n```codeBlockLines_e6Vv\n{\n  \"scripts\": {\n    \"eval\": \"viteval\"\n  }\n}\n\n```\n\n### 8\\. Run Your First Evaluation [â€‹](https://voltagent.dev/docs/evals/quick-start/\\#8-run-your-first-evaluation \"Direct link to 8. Run Your First Evaluation\")\n\n```codeBlockLines_e6Vv\nnpm run eval\n\n```\n\nYou'll see output like:\n\n```codeBlockLines_e6Vv\nâœ“ Customer Support Agent (3/3 passed)\n  âœ“ answerCorrectness: 0.85\n  âœ“ answerRelevancy: 0.82\n  âœ“ moderation: 0.98\n  Overall: 0.883 (threshold: 0.7) âœ“\n\n```\n\n## Next Steps [â€‹](https://voltagent.dev/docs/evals/quick-start/\\#next-steps \"Direct link to Next Steps\")\n\n- [**View Available Scorers**](https://viteval.dev/api/scorers?ref=voltagent): Understanding evaluation metrics\n- [**CI Integration**](https://viteval.dev/guide/advanced/ci?ref=voltagent): Integrate Viteval into your CI pipeline\n\n### Table of Contents\n\n- [Prerequisites](https://voltagent.dev/docs/evals/quick-start/#prerequisites)\n- [Installation](https://voltagent.dev/docs/evals/quick-start/#installation)\n- [Quick Setup](https://voltagent.dev/docs/evals/quick-start/#quick-setup)\n  - [1\\. Set up VoltAgent](https://voltagent.dev/docs/evals/quick-start/#1-set-up-voltagent)\n  - [2\\. Viteval Setup File](https://voltagent.dev/docs/evals/quick-start/#2-viteval-setup-file)\n  - [3\\. Configure Viteval (Optional)](https://voltagent.dev/docs/evals/quick-start/#3-configure-viteval-optional)\n  - [4\\. Create Your Agent](https://voltagent.dev/docs/evals/quick-start/#4-create-your-agent)\n  - [5\\. Create Test Dataset](https://voltagent.dev/docs/evals/quick-start/#5-create-test-dataset)\n  - [6\\. Create Evaluation File](https://voltagent.dev/docs/evals/quick-start/#6-create-evaluation-file)\n  - [7\\. Add NPM Script](https://voltagent.dev/docs/evals/quick-start/#7-add-npm-script)\n  - [8\\. Run Your First Evaluation](https://voltagent.dev/docs/evals/quick-start/#8-run-your-first-evaluation)\n- [Next Steps](https://voltagent.dev/docs/evals/quick-start/#next-steps)",
      "metadata": {
        "language": "en",
        "og:description": "This guide will walk you through setting up your first evaluation pipeline with VoltAgent and Viteval. In just a few minutes, you'll have a working eval system that can measure your agent's performance.",
        "viewport": "width=device-width, initial-scale=1.0",
        "description": "This guide will walk you through setting up your first evaluation pipeline with VoltAgent and Viteval. In just a few minutes, you'll have a working eval system that can measure your agent's performance.",
        "generator": "Docusaurus v3.1.1",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "og:image": "https://voltagent.dev/img/social3.png",
        "og:url": "https://voltagent.dev/docs/evals/quick-start/",
        "docsearch:language": "en",
        "docusaurus_version": "current",
        "og:title": "Quick Start | VoltAgent",
        "og:locale": "en",
        "docusaurus_tag": "docs-default-current",
        "ogLocale": "en",
        "twitter:card": "summary_large_image",
        "ogUrl": "https://voltagent.dev/docs/evals/quick-start/",
        "title": "Quick Start | VoltAgent",
        "docusaurus_locale": "en",
        "ogTitle": "Quick Start | VoltAgent",
        "ogDescription": "This guide will walk you through setting up your first evaluation pipeline with VoltAgent and Viteval. In just a few minutes, you'll have a working eval system that can measure your agent's performance.",
        "docsearch:version": "current",
        "docsearch:docusaurus_tag": "docs-default-current",
        "scrapeId": "bddc3427-0bbc-45ab-b421-5925fc3857e1",
        "sourceURL": "https://voltagent.dev/docs/evals/quick-start/",
        "url": "https://voltagent.dev/docs/evals/quick-start/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:55.116Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/workflows/suspend-resume/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Suspend & Resume\n\n> Pause workflows and continue them later. Perfect for human approvals, external events, or any async operation that takes time.\n\n## Quick Start [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#quick-start \"Direct link to Quick Start\")\n\nThe simplest suspend & resume example:\n\n```codeBlockLines_e6Vv\nimport { createWorkflowChain } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\nconst simpleApproval = createWorkflowChain({\n  id: \"simple-approval\",\n  name: \"Simple Approval\",\n  input: z.object({ item: z.string() }),\n  result: z.object({ approved: z.boolean() }),\n}).andThen({\n  id: \"wait-for-approval\",\n  execute: async ({ data, suspend, resumeData }) => {\n    // If we're resuming, return the decision\n    if (resumeData) {\n      return { approved: resumeData.approved };\n    }\n\n    // Otherwise, suspend and wait\n    await suspend(\"Waiting for approval\");\n  },\n});\n\n// Run the workflow - it will suspend\nconst execution = await simpleApproval.run({ item: \"New laptop\" });\nconsole.log(execution.status); // \"suspended\"\n\n// Later, resume with a decision\nconst result = await execution.resume({ approved: true });\nconsole.log(result.result); // { approved: true }\n\n```\n\n## How It Works [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#how-it-works \"Direct link to How It Works\")\n\nWhen a workflow suspends:\n\n1. Current state is saved\n2. Workflow status becomes \"suspended\"\n3. You get back an execution object with a `resume()` method\n4. Later, call `resume()` with new data to continue\n\n## Using Schemas for Type Safety [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#using-schemas-for-type-safety \"Direct link to Using Schemas for Type Safety\")\n\nDefine what data you expect when resuming:\n\n```codeBlockLines_e6Vv\nconst approvalWorkflow = createWorkflowChain({\n  id: \"document-approval\",\n  name: \"Document Approval\",\n  input: z.object({\n    documentId: z.string(),\n    authorId: z.string(),\n  }),\n  // Define what resume() accepts\n  resumeSchema: z.object({\n    approved: z.boolean(),\n    reviewerId: z.string(),\n    comments: z.string().optional(),\n  }),\n  result: z.object({\n    status: z.enum([\"approved\", \"rejected\"]),\n    reviewedBy: z.string(),\n  }),\n}).andThen({\n  id: \"review-document\",\n  execute: async ({ data, suspend, resumeData }) => {\n    // resumeData is fully typed!\n    if (resumeData) {\n      return {\n        status: resumeData.approved ? \"approved\" : \"rejected\",\n        reviewedBy: resumeData.reviewerId,\n      };\n    }\n\n    // Suspend for review\n    await suspend(\"Document needs review\");\n  },\n});\n\n// TypeScript knows exactly what resume() expects\nconst result = await execution.resume({\n  approved: true,\n  reviewerId: \"mgr-123\",\n  comments: \"Looks good\",\n});\n\n```\n\n## Step-Level Resume Schemas [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#step-level-resume-schemas \"Direct link to Step-Level Resume Schemas\")\n\nDifferent steps can expect different resume data:\n\n```codeBlockLines_e6Vv\nconst multiStepApproval = createWorkflowChain({\n  id: \"multi-approval\",\n  input: z.object({ amount: z.number() }),\n  // Default resume schema\n  resumeSchema: z.object({ continue: z.boolean() }),\n})\n  .andThen({\n    id: \"manager-approval\",\n    // This step needs manager-specific data\n    resumeSchema: z.object({\n      approved: z.boolean(),\n      managerId: z.string(),\n    }),\n    execute: async ({ data, suspend, resumeData }) => {\n      if (resumeData) {\n        return { ...data, managerApproved: resumeData.approved };\n      }\n      await suspend(\"Needs manager approval\");\n    },\n  })\n  .andThen({\n    id: \"finance-approval\",\n    // This step needs finance-specific data\n    resumeSchema: z.object({\n      approved: z.boolean(),\n      financeId: z.string(),\n      budgetCode: z.string(),\n    }),\n    execute: async ({ data, suspend, resumeData }) => {\n      if (resumeData) {\n        return {\n          ...data,\n          financeApproved: resumeData.approved,\n          budgetCode: resumeData.budgetCode,\n        };\n      }\n      if (data.amount > 1000) {\n        await suspend(\"Needs finance approval\");\n      }\n      return data;\n    },\n  });\n\n```\n\n## Practical Example: User Verification [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#practical-example-user-verification \"Direct link to Practical Example: User Verification\")\n\n```codeBlockLines_e6Vv\nconst userVerification = createWorkflowChain({\n  id: \"verify-user\",\n  input: z.object({\n    userId: z.string(),\n    email: z.string().email(),\n  }),\n  suspendSchema: z.object({\n    verificationCode: z.string(),\n    expiresAt: z.string(),\n  }),\n  resumeSchema: z.object({\n    code: z.string(),\n  }),\n  result: z.object({\n    verified: z.boolean(),\n    verifiedAt: z.string().optional(),\n  }),\n})\n  .andThen({\n    id: \"send-verification\",\n    execute: async ({ data, suspend }) => {\n      const code = Math.random().toString(36).substring(2, 8);\n      const expiresAt = new Date(Date.now() + 3600000).toISOString();\n\n      // Send email (your implementation)\n      await sendEmail(data.email, `Your code: ${code}`);\n\n      // Suspend with the code for later verification\n      await suspend(\"Waiting for verification\", {\n        verificationCode: code,\n        expiresAt,\n      });\n    },\n  })\n  .andThen({\n    id: \"verify-code\",\n    execute: async ({ data, resumeData, suspendData }) => {\n      // suspendData contains what was saved during suspend\n      if (new Date(suspendData.expiresAt) < new Date()) {\n        return { verified: false };\n      }\n\n      if (resumeData.code === suspendData.verificationCode) {\n        return {\n          verified: true,\n          verifiedAt: new Date().toISOString(),\n        };\n      }\n\n      return { verified: false };\n    },\n  });\n\n// Usage\nconst execution = await userVerification.run({\n  userId: \"user-123\",\n  email: \"user@example.com\",\n});\n\n// Email sent, workflow suspended\nconsole.log(execution.status); // \"suspended\"\n\n// User enters code from email\nconst result = await execution.resume({ code: \"abc123\" });\nconsole.log(result.result); // { verified: true, verifiedAt: \"...\" }\n\n```\n\n## Resume From Specific Steps [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#resume-from-specific-steps \"Direct link to Resume From Specific Steps\")\n\nSkip ahead or go back to any step when resuming:\n\n```codeBlockLines_e6Vv\nconst reviewWorkflow = createWorkflowChain({\n  id: \"multi-review\",\n  input: z.object({ docId: z.string() }),\n})\n  .andThen({\n    id: \"step-1-legal\",\n    resumeSchema: z.object({ approved: z.boolean() }),\n    execute: async ({ data, suspend, resumeData }) => {\n      if (resumeData) return { ...data, legal: resumeData.approved };\n      await suspend(\"Legal review needed\");\n    },\n  })\n  .andThen({\n    id: \"step-2-finance\",\n    resumeSchema: z.object({ approved: z.boolean() }),\n    execute: async ({ data, suspend, resumeData }) => {\n      if (resumeData) return { ...data, finance: resumeData.approved };\n      await suspend(\"Finance review needed\");\n    },\n  })\n  .andThen({\n    id: \"step-3-final\",\n    execute: async ({ data }) => {\n      return { approved: data.legal && data.finance };\n    },\n  });\n\n// Normal resume - continues from suspended step\nconst exec = await reviewWorkflow.run({ docId: \"doc-123\" });\nawait exec.resume({ approved: true }); // Resumes at step-1-legal\n\n// Skip to different step\nconst exec2 = await reviewWorkflow.run({ docId: \"doc-456\" });\nawait exec2.resume(\n  { approved: true },\n  { stepId: \"step-2-finance\" } // Jump directly to finance review\n);\n\n```\n\n## Key Concepts [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#key-concepts \"Direct link to Key Concepts\")\n\n### What Happens During Suspend? [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#what-happens-during-suspend \"Direct link to What Happens During Suspend?\")\n\n1. Workflow pauses at current step\n2. State is saved automatically\n3. You get an execution object back\n4. Call `resume()` when ready to continue\n\n### What Happens During Resume? [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#what-happens-during-resume \"Direct link to What Happens During Resume?\")\n\n1. The suspended step runs again from the start\n2. `resumeData` contains your new data\n3. Workflow continues with next steps\n\n### Important Variables [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#important-variables \"Direct link to Important Variables\")\n\n- `data` \\- The accumulated data from all previous steps\n- `suspend` \\- Function to pause the workflow\n- `resumeData` \\- Data provided when resuming (undefined on first run)\n- `suspendData` \\- Data that was saved during suspension\n\n## Common Patterns [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#common-patterns \"Direct link to Common Patterns\")\n\n### Auto-Approve Pattern [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#auto-approve-pattern \"Direct link to Auto-Approve Pattern\")\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"approval\",\n  execute: async ({ data, suspend, resumeData }) => {\n    if (resumeData) {\n      return { approved: resumeData.approved };\n    }\n\n    // Auto-approve small amounts\n    if (data.amount < 100) {\n      return { approved: true };\n    }\n\n    // Otherwise suspend for manual approval\n    await suspend(\"Manual approval required\");\n  }\n})\n\n```\n\n### Timeout Pattern [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#timeout-pattern \"Direct link to Timeout Pattern\")\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"wait-for-payment\",\n  suspendSchema: z.object({\n    orderId: z.string(),\n    expiresAt: z.string()\n  }),\n  resumeSchema: z.object({\n    paid: z.boolean()\n  }),\n  execute: async ({ data, suspend, resumeData, suspendData }) => {\n    if (resumeData) {\n      // Check if expired\n      if (new Date() > new Date(suspendData.expiresAt)) {\n        return { status: \"expired\" };\n      }\n      return { status: resumeData.paid ? \"completed\" : \"cancelled\" };\n    }\n\n    await suspend(\"Waiting for payment\", {\n      orderId: data.orderId,\n      expiresAt: new Date(Date.now() + 3600000).toISOString() // 1 hour\n    });\n  }\n})\n\n```\n\n## Best Practices [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#best-practices \"Direct link to Best Practices\")\n\n### 1\\. Always Check resumeData First [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#1-always-check-resumedata-first \"Direct link to 1. Always Check resumeData First\")\n\n```codeBlockLines_e6Vv\nexecute: async ({ data, suspend, resumeData }) => {\n  if (resumeData) {\n    // Handle resume case\n    return { ...data, approved: resumeData.approved };\n  }\n\n  // Normal execution\n  await suspend(\"Needs approval\");\n};\n\n```\n\n### 2\\. Use Clear Schema Names [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#2-use-clear-schema-names \"Direct link to 2. Use Clear Schema Names\")\n\n```codeBlockLines_e6Vv\nresumeSchema: z.object({\n  approved: z.boolean(), // Not just \"value\"\n  approvedBy: z.string(), // Not just \"user\"\n  rejectionReason: z.string(), // Not just \"reason\"\n});\n\n```\n\n### 3\\. Handle Timeouts [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#3-handle-timeouts \"Direct link to 3. Handle Timeouts\")\n\n```codeBlockLines_e6Vv\nif (resumeData) {\n  const expired = new Date() > new Date(suspendData.expiresAt);\n  if (expired) {\n    return { status: \"timeout\" };\n  }\n}\n\n```\n\n## Quick Reference [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#quick-reference \"Direct link to Quick Reference\")\n\n### Functions [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#functions \"Direct link to Functions\")\n\n- `suspend(reason?, data?)` \\- Pause workflow\n- `execution.resume(data?, options?)` \\- Continue workflow\n\n### Key Parameters [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#key-parameters \"Direct link to Key Parameters\")\n\n- `data` \\- Accumulated data from all steps\n- `resumeData` \\- Data provided when resuming\n- `suspendData` \\- Data saved during suspension\n\n### Resume Options [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#resume-options \"Direct link to Resume Options\")\n\n```codeBlockLines_e6Vv\n// Resume from suspended step\nawait execution.resume({ approved: true });\n\n// Resume from specific step\nawait execution.resume({ approved: true }, { stepId: \"step-2\" });\n\n```\n\n## External Suspension [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#external-suspension \"Direct link to External Suspension\")\n\nYou can also pause workflows from outside using `createSuspendController`:\n\n```codeBlockLines_e6Vv\nimport { createWorkflowChain, createSuspendController } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\nconst workflow = createWorkflowChain({\n  id: \"long-process\",\n  name: \"Long Process\",\n  input: z.object({ items: z.number() }),\n  result: z.object({ processed: z.number() }),\n}).andThen({\n  id: \"process-items\",\n  execute: async ({ data }) => {\n    // Simulate long processing\n    for (let i = 0; i < data.items; i++) {\n      await new Promise((resolve) => setTimeout(resolve, 1000));\n      console.log(`Processed ${i + 1}/${data.items}`);\n    }\n    return { processed: data.items };\n  },\n});\n\n// Create controller to control the workflow externally\nconst controller = createSuspendController();\n\n// Run workflow with the controller\nconst execution = await workflow.run({ items: 10 }, { suspendController: controller });\n\n// Pause from outside (e.g., when user clicks pause button)\nsetTimeout(() => {\n  controller.suspend(\"User clicked pause\");\n}, 3000);\n\n// Check the result\nif (execution.status === \"suspended\") {\n  console.log(\"Paused:\", execution.suspension?.reason);\n  // Resume later\n  const result = await execution.resume();\n}\n\n```\n\n### UI Integration Example [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#ui-integration-example \"Direct link to UI Integration Example\")\n\n```codeBlockLines_e6Vv\nclass WorkflowManager {\n  private controller = createSuspendController();\n\n  async start(workflow: any, input: any) {\n    return workflow.run(input, {\n      suspendController: this.controller,\n    });\n  }\n\n  pause(reason?: string) {\n    this.controller.suspend(reason || \"User paused\");\n  }\n\n  isPaused() {\n    return this.controller.isSuspended();\n  }\n}\n\n// In your UI\nconst manager = new WorkflowManager();\nconst execution = await manager.start(myWorkflow, input);\n\n// Pause button handler\nonPauseClick(() => {\n  manager.pause(\"User clicked pause button\");\n});\n\n```\n\n## REST API Usage [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#rest-api-usage \"Direct link to REST API Usage\")\n\nYou can also control workflow suspension and resumption through the REST API. This is useful for web applications, mobile apps, or any external system that needs to manage workflows.\n\n### Suspend a Running Workflow [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#suspend-a-running-workflow \"Direct link to Suspend a Running Workflow\")\n\n**Endpoint:** `POST /workflows/{id}/executions/{executionId}/suspend`\n\nSuspend a running workflow execution from outside the workflow.\n\n**Request:**\n\n```codeBlockLines_e6Vv\n{\n  \"reason\": \"User clicked pause button\" // Optional\n}\n\n```\n\n**Response:**\n\n```codeBlockLines_e6Vv\n{\n  \"success\": true,\n  \"data\": {\n    \"executionId\": \"exec_1234567890_abc123\",\n    \"status\": \"suspended\",\n    \"suspension\": {\n      \"suspendedAt\": \"2024-01-15T10:30:45.123Z\",\n      \"reason\": \"User clicked pause button\"\n    }\n  }\n}\n\n```\n\n**cURL Example:**\n\n```codeBlockLines_e6Vv\ncurl -X POST http://localhost:3141/workflows/order-approval/executions/exec_1234567890_abc123/suspend \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"reason\": \"Manager is on vacation\"}'\n\n```\n\n**JavaScript Example:**\n\n```codeBlockLines_e6Vv\nasync function suspendWorkflow(workflowId, executionId, reason) {\n  const response = await fetch(\n    `http://localhost:3141/workflows/${workflowId}/executions/${executionId}/suspend`,\n    {\n      method: \"POST\",\n      headers: { \"Content-Type\": \"application/json\" },\n      body: JSON.stringify({ reason }),\n    }\n  );\n\n  const result = await response.json();\n  if (result.success) {\n    console.log(\"Workflow suspended:\", result.data);\n  }\n}\n\n// Usage\nawait suspendWorkflow(\n  \"order-approval\",\n  \"exec_1234567890_abc123\",\n  \"Waiting for payment confirmation\"\n);\n\n```\n\n### Resume a Suspended Workflow [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#resume-a-suspended-workflow \"Direct link to Resume a Suspended Workflow\")\n\n**Endpoint:** `POST /workflows/{id}/executions/{executionId}/resume`\n\nResume a suspended workflow with optional data and step selection.\n\n**Request:**\n\n```codeBlockLines_e6Vv\n{\n  \"resumeData\": {\n    \"approved\": true,\n    \"approvedBy\": \"manager@company.com\"\n  },\n  \"options\": {\n    \"stepId\": \"step-2\" // Optional: resume from specific step\n  }\n}\n\n```\n\n**Response:**\n\n```codeBlockLines_e6Vv\n{\n  \"success\": true,\n  \"data\": {\n    \"executionId\": \"exec_1234567890_abc123\",\n    \"startAt\": \"2024-01-15T10:00:00.000Z\",\n    \"endAt\": \"2024-01-15T10:31:15.456Z\",\n    \"status\": \"completed\",\n    \"result\": {\n      \"approved\": true,\n      \"processedBy\": \"manager@company.com\"\n    }\n  }\n}\n\n```\n\n**cURL Example:**\n\n```codeBlockLines_e6Vv\ncurl -X POST http://localhost:3141/workflows/order-approval/executions/exec_1234567890_abc123/resume \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"resumeData\": {\n         \"approved\": true,\n         \"managerId\": \"mgr-789\",\n         \"comments\": \"Approved for urgent delivery\"\n       }\n     }'\n\n```\n\n**JavaScript Example:**\n\n```codeBlockLines_e6Vv\nasync function resumeWorkflow(workflowId, executionId, resumeData, stepId) {\n  const response = await fetch(\n    `http://localhost:3141/workflows/${workflowId}/executions/${executionId}/resume`,\n    {\n      method: \"POST\",\n      headers: { \"Content-Type\": \"application/json\" },\n      body: JSON.stringify({\n        resumeData,\n        ...(stepId && { options: { stepId } }),\n      }),\n    }\n  );\n\n  const result = await response.json();\n  if (result.success) {\n    console.log(\"Workflow resumed:\", result.data);\n    return result.data;\n  }\n}\n\n// Resume with approval data\nconst result = await resumeWorkflow(\"order-approval\", \"exec_1234567890_abc123\", {\n  approved: true,\n  approvedBy: \"manager@company.com\",\n});\n\n// Resume from specific step\nconst result2 = await resumeWorkflow(\n  \"multi-step-workflow\",\n  \"exec_9876543210_xyz789\",\n  { retryData: true },\n  \"step-3\" // Jump to step-3\n);\n\n```\n\n### Complete Workflow Example with REST API [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#complete-workflow-example-with-rest-api \"Direct link to Complete Workflow Example with REST API\")\n\nHere's a full example showing how to execute, suspend, and resume a workflow via REST API:\n\n```codeBlockLines_e6Vv\n// 1. Execute workflow\nasync function executeWorkflow(workflowId, input) {\n  const response = await fetch(`http://localhost:3141/workflows/${workflowId}/execute`, {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify({ input }),\n  });\n\n  const result = await response.json();\n  return result.data;\n}\n\n// 2. Monitor workflow and suspend if needed\nasync function monitorAndSuspend(workflowId, executionId) {\n  // In a real app, you might poll the status or use webhooks\n  setTimeout(async () => {\n    // User clicked pause\n    await fetch(`http://localhost:3141/workflows/${workflowId}/executions/${executionId}/suspend`, {\n      method: \"POST\",\n      headers: { \"Content-Type\": \"application/json\" },\n      body: JSON.stringify({ reason: \"User requested pause\" }),\n    });\n    console.log(\"Workflow suspended\");\n  }, 2000);\n}\n\n// 3. Resume after user input\nasync function handleUserApproval(workflowId, executionId, approved) {\n  const response = await fetch(\n    `http://localhost:3141/workflows/${workflowId}/executions/${executionId}/resume`,\n    {\n      method: \"POST\",\n      headers: { \"Content-Type\": \"application/json\" },\n      body: JSON.stringify({\n        resumeData: {\n          approved,\n          timestamp: new Date().toISOString(),\n          userId: \"current-user-id\",\n        },\n      }),\n    }\n  );\n\n  const result = await response.json();\n  return result.data;\n}\n\n// Usage flow\nasync function processOrder() {\n  // Start workflow\n  const execution = await executeWorkflow(\"order-approval\", {\n    orderId: \"order-123\",\n    amount: 5000,\n    items: [\"laptop\", \"mouse\"],\n  });\n\n  console.log(\"Workflow started:\", execution.executionId);\n\n  // Monitor and possibly suspend\n  await monitorAndSuspend(\"order-approval\", execution.executionId);\n\n  // Later, after user makes decision\n  const finalResult = await handleUserApproval(\n    \"order-approval\",\n    execution.executionId,\n    true // approved\n  );\n\n  console.log(\"Order processed:\", finalResult);\n}\n\n```\n\n### Error Handling [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#error-handling \"Direct link to Error Handling\")\n\nBoth endpoints return appropriate HTTP status codes:\n\n**Suspend Errors:**\n\n- `404`: Workflow execution not found\n- `400`: Cannot suspend workflow in current state (e.g., already completed)\n- `500`: Server error\n\n**Resume Errors:**\n\n- `404`: Workflow execution not found or not suspended\n- `400`: Invalid resume data (schema validation failed)\n- `500`: Server error\n\n**Error Response Format:**\n\n```codeBlockLines_e6Vv\n{\n  \"success\": false,\n  \"error\": \"Cannot suspend workflow in completed state\"\n}\n\n```\n\n**Example Error Handling:**\n\n```codeBlockLines_e6Vv\ntry {\n  const response = await fetch(\n    `http://localhost:3141/workflows/${workflowId}/executions/${executionId}/resume`,\n    {\n      method: \"POST\",\n      headers: { \"Content-Type\": \"application/json\" },\n      body: JSON.stringify({ resumeData }),\n    }\n  );\n\n  const result = await response.json();\n\n  if (!result.success) {\n    console.error(\"Resume failed:\", result.error);\n    // Handle specific error cases\n    if (response.status === 404) {\n      alert(\"Workflow not found or not suspended\");\n    } else if (response.status === 400) {\n      alert(\"Invalid resume data provided\");\n    }\n  }\n} catch (error) {\n  console.error(\"Network error:\", error);\n}\n\n```\n\n## Next Steps [â€‹](https://voltagent.dev/docs/workflows/suspend-resume/\\#next-steps \"Direct link to Next Steps\")\n\n- Learn about [Workflow Schemas](https://voltagent.dev/docs/workflows/schemas/) for type safety\n- Explore [Step Types](https://voltagent.dev/docs/workflows/steps/and-then/) that support suspension\n- Try the [VoltOps Console](https://console.voltagent.dev/) to manage suspended workflows\n- See [REST API Documentation](https://voltagent.dev/docs/api/overview/#workflow-endpoints) for complete API reference\n\n### Table of Contents\n\n- [Quick Start](https://voltagent.dev/docs/workflows/suspend-resume/#quick-start)\n- [How It Works](https://voltagent.dev/docs/workflows/suspend-resume/#how-it-works)\n- [Using Schemas for Type Safety](https://voltagent.dev/docs/workflows/suspend-resume/#using-schemas-for-type-safety)\n- [Step-Level Resume Schemas](https://voltagent.dev/docs/workflows/suspend-resume/#step-level-resume-schemas)\n- [Practical Example: User Verification](https://voltagent.dev/docs/workflows/suspend-resume/#practical-example-user-verification)\n- [Resume From Specific Steps](https://voltagent.dev/docs/workflows/suspend-resume/#resume-from-specific-steps)\n- [Key Concepts](https://voltagent.dev/docs/workflows/suspend-resume/#key-concepts)\n  - [What Happens During Suspend?](https://voltagent.dev/docs/workflows/suspend-resume/#what-happens-during-suspend)\n  - [What Happens During Resume?](https://voltagent.dev/docs/workflows/suspend-resume/#what-happens-during-resume)\n  - [Important Variables](https://voltagent.dev/docs/workflows/suspend-resume/#important-variables)\n- [Common Patterns](https://voltagent.dev/docs/workflows/suspend-resume/#common-patterns)\n  - [Auto-Approve Pattern](https://voltagent.dev/docs/workflows/suspend-resume/#auto-approve-pattern)\n  - [Timeout Pattern](https://voltagent.dev/docs/workflows/suspend-resume/#timeout-pattern)\n- [Best Practices](https://voltagent.dev/docs/workflows/suspend-resume/#best-practices)\n  - [1\\. Always Check resumeData First](https://voltagent.dev/docs/workflows/suspend-resume/#1-always-check-resumedata-first)\n  - [2\\. Use Clear Schema Names](https://voltagent.dev/docs/workflows/suspend-resume/#2-use-clear-schema-names)\n  - [3\\. Handle Timeouts](https://voltagent.dev/docs/workflows/suspend-resume/#3-handle-timeouts)\n- [Quick Reference](https://voltagent.dev/docs/workflows/suspend-resume/#quick-reference)\n  - [Functions](https://voltagent.dev/docs/workflows/suspend-resume/#functions)\n  - [Key Parameters](https://voltagent.dev/docs/workflows/suspend-resume/#key-parameters)\n  - [Resume Options](https://voltagent.dev/docs/workflows/suspend-resume/#resume-options)\n- [External Suspension](https://voltagent.dev/docs/workflows/suspend-resume/#external-suspension)\n  - [UI Integration Example](https://voltagent.dev/docs/workflows/suspend-resume/#ui-integration-example)\n- [REST API Usage](https://voltagent.dev/docs/workflows/suspend-resume/#rest-api-usage)\n  - [Suspend a Running Workflow](https://voltagent.dev/docs/workflows/suspend-resume/#suspend-a-running-workflow)\n  - [Resume a Suspended Workflow](https://voltagent.dev/docs/workflows/suspend-resume/#resume-a-suspended-workflow)\n  - [Complete Workflow Example with REST API](https://voltagent.dev/docs/workflows/suspend-resume/#complete-workflow-example-with-rest-api)\n  - [Error Handling](https://voltagent.dev/docs/workflows/suspend-resume/#error-handling)\n- [Next Steps](https://voltagent.dev/docs/workflows/suspend-resume/#next-steps)",
      "metadata": {
        "ogImage": "https://voltagent.dev/img/social3.png",
        "ogDescription": "Pause workflows and continue them later. Perfect for human approvals, external events, or any async operation that takes time.",
        "ogUrl": "https://voltagent.dev/docs/workflows/suspend-resume/",
        "description": "Pause workflows and continue them later. Perfect for human approvals, external events, or any async operation that takes time.",
        "docsearch:version": "current",
        "og:locale": "en",
        "ogTitle": "Suspend & Resume | VoltAgent",
        "language": "en",
        "og:image": "https://voltagent.dev/img/social3.png",
        "twitter:card": "summary_large_image",
        "ogLocale": "en",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "og:url": "https://voltagent.dev/docs/workflows/suspend-resume/",
        "title": "Suspend & Resume | VoltAgent",
        "docusaurus_tag": "docs-default-current",
        "docsearch:docusaurus_tag": "docs-default-current",
        "generator": "Docusaurus v3.1.1",
        "og:title": "Suspend & Resume | VoltAgent",
        "docsearch:language": "en",
        "docusaurus_locale": "en",
        "viewport": "width=device-width, initial-scale=1.0",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "docusaurus_version": "current",
        "og:description": "Pause workflows and continue them later. Perfect for human approvals, external events, or any async operation that takes time.",
        "scrapeId": "4b25d66d-8c44-421d-aba1-b6ef925bd7f0",
        "sourceURL": "https://voltagent.dev/docs/workflows/suspend-resume/",
        "url": "https://voltagent.dev/docs/workflows/suspend-resume/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:23.379Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/workflows/steps/and-agent/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# andAgent\n\n> Add AI to your workflow. Get structured, typed responses from language models.\n\n## Quick Start [â€‹](https://voltagent.dev/docs/workflows/steps/and-agent/\\#quick-start \"Direct link to Quick Start\")\n\n```codeBlockLines_e6Vv\nimport { createWorkflowChain, Agent } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\n// Create an agent\nconst agent = new Agent({\n  name: \"Assistant\",\n  llm: provider,\n  model: \"gpt-4\",\n});\n\n// Use it in a workflow\nconst workflow = createWorkflowChain({\n  id: \"analyze-text\",\n  input: z.object({ text: z.string() }),\n}).andAgent(({ data }) => `Analyze this text: ${data.text}`, agent, {\n  schema: z.object({\n    sentiment: z.enum([\"positive\", \"negative\", \"neutral\"]),\n    summary: z.string(),\n  }),\n});\n\nconst result = await workflow.run({ text: \"I love this!\" });\n// Result: { sentiment: \"positive\", summary: \"Expression of enthusiasm\" }\n\n```\n\n## How It Works [â€‹](https://voltagent.dev/docs/workflows/steps/and-agent/\\#how-it-works \"Direct link to How It Works\")\n\n`andAgent` = AI prompt + structured output schema:\n\n```codeBlockLines_e6Vv\n.andAgent(\n  prompt,    // What to ask the AI\n  agent,     // Which AI to use\n  { schema } // What shape the answer should be\n)\n\n```\n\n## Function Signature [â€‹](https://voltagent.dev/docs/workflows/steps/and-agent/\\#function-signature \"Direct link to Function Signature\")\n\n```codeBlockLines_e6Vv\n// Simple prompt\n.andAgent(\"Summarize this\", agent, { schema })\n\n// Dynamic prompt from data\n.andAgent(({ data }) => `Analyze: ${data.text}`, agent, { schema })\n\n```\n\n## Common Patterns [â€‹](https://voltagent.dev/docs/workflows/steps/and-agent/\\#common-patterns \"Direct link to Common Patterns\")\n\n### Text Analysis [â€‹](https://voltagent.dev/docs/workflows/steps/and-agent/\\#text-analysis \"Direct link to Text Analysis\")\n\n```codeBlockLines_e6Vv\n.andAgent(\n  ({ data }) => `Analyze sentiment of: ${data.review}`,\n  agent,\n  {\n    schema: z.object({\n      sentiment: z.enum([\"positive\", \"negative\", \"neutral\"]),\n      score: z.number().min(0).max(1),\n      keywords: z.array(z.string())\n    })\n  }\n)\n\n```\n\n### Content Generation [â€‹](https://voltagent.dev/docs/workflows/steps/and-agent/\\#content-generation \"Direct link to Content Generation\")\n\n```codeBlockLines_e6Vv\n.andAgent(\n  ({ data }) => `Write a ${data.tone} email about ${data.topic}`,\n  agent,\n  {\n    schema: z.object({\n      subject: z.string(),\n      body: z.string(),\n      suggestedSendTime: z.string()\n    })\n  }\n)\n\n```\n\n### Data Extraction [â€‹](https://voltagent.dev/docs/workflows/steps/and-agent/\\#data-extraction \"Direct link to Data Extraction\")\n\n```codeBlockLines_e6Vv\n.andAgent(\n  ({ data }) => `Extract key information from: ${data.document}`,\n  agent,\n  {\n    schema: z.object({\n      people: z.array(z.string()),\n      dates: z.array(z.string()),\n      locations: z.array(z.string()),\n      mainTopic: z.string()\n    })\n  }\n)\n\n```\n\n## Dynamic Prompts [â€‹](https://voltagent.dev/docs/workflows/steps/and-agent/\\#dynamic-prompts \"Direct link to Dynamic Prompts\")\n\nBuild prompts from workflow data:\n\n```codeBlockLines_e6Vv\n.andAgent(\n  ({ data }) => {\n    // Adjust prompt based on data\n    if (data.userLevel === \"beginner\") {\n      return `Explain in simple terms: ${data.question}`;\n    }\n    return `Provide technical details about: ${data.question}`;\n  },\n  agent,\n  { schema: z.object({ answer: z.string() }) }\n)\n\n```\n\n## Chaining with Other Steps [â€‹](https://voltagent.dev/docs/workflows/steps/and-agent/\\#chaining-with-other-steps \"Direct link to Chaining with Other Steps\")\n\nCombine AI with logic:\n\n```codeBlockLines_e6Vv\ncreateWorkflowChain({ id: \"smart-email\" })\n  // Step 1: Classify with AI\n  .andAgent(({ data }) => `What type of email is this: ${data.email}`, agent, {\n    schema: z.object({\n      type: z.enum([\"support\", \"sales\", \"spam\"]),\n      priority: z.enum([\"low\", \"medium\", \"high\"]),\n    }),\n  })\n  // Step 2: Route based on classification\n  .andThen({\n    id: \"route-email\",\n    execute: async ({ data }) => {\n      if (data.type === \"spam\") {\n        return { action: \"delete\" };\n      }\n      return {\n        action: \"forward\",\n        to: data.type === \"support\" ? \"support@\" : \"sales@\",\n      };\n    },\n  });\n\n```\n\n## Best Practices [â€‹](https://voltagent.dev/docs/workflows/steps/and-agent/\\#best-practices \"Direct link to Best Practices\")\n\n1. **Keep prompts clear** \\- AI performs better with specific instructions\n2. **Use enums for categories** \\- `z.enum()` ensures valid options\n3. **Add descriptions to schema fields** \\- Helps AI understand what you want\n4. **Handle edge cases** \\- Check for missing or low-confidence results\n\n## Next Steps [â€‹](https://voltagent.dev/docs/workflows/steps/and-agent/\\#next-steps \"Direct link to Next Steps\")\n\n- Learn about [andWhen](https://voltagent.dev/docs/workflows/steps/and-when/) for conditional logic\n- Explore [andAll](https://voltagent.dev/docs/workflows/steps/and-all/) to run multiple agents in parallel\n- See [andThen](https://voltagent.dev/docs/workflows/steps/and-then/) to process AI outputs\n- Execute workflows via [REST API](https://voltagent.dev/docs/api/overview/#workflow-endpoints)\n\n### Table of Contents\n\n- [Quick Start](https://voltagent.dev/docs/workflows/steps/and-agent/#quick-start)\n- [How It Works](https://voltagent.dev/docs/workflows/steps/and-agent/#how-it-works)\n- [Function Signature](https://voltagent.dev/docs/workflows/steps/and-agent/#function-signature)\n- [Common Patterns](https://voltagent.dev/docs/workflows/steps/and-agent/#common-patterns)\n  - [Text Analysis](https://voltagent.dev/docs/workflows/steps/and-agent/#text-analysis)\n  - [Content Generation](https://voltagent.dev/docs/workflows/steps/and-agent/#content-generation)\n  - [Data Extraction](https://voltagent.dev/docs/workflows/steps/and-agent/#data-extraction)\n- [Dynamic Prompts](https://voltagent.dev/docs/workflows/steps/and-agent/#dynamic-prompts)\n- [Chaining with Other Steps](https://voltagent.dev/docs/workflows/steps/and-agent/#chaining-with-other-steps)\n- [Best Practices](https://voltagent.dev/docs/workflows/steps/and-agent/#best-practices)\n- [Next Steps](https://voltagent.dev/docs/workflows/steps/and-agent/#next-steps)",
      "metadata": {
        "docusaurus_locale": "en",
        "language": "en",
        "ogUrl": "https://voltagent.dev/docs/workflows/steps/and-agent/",
        "ogLocale": "en",
        "ogDescription": "Add AI to your workflow. Get structured, typed responses from language models.",
        "ogTitle": "andAgent | VoltAgent",
        "generator": "Docusaurus v3.1.1",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "docsearch:language": "en",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_version": "current",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:image": "https://voltagent.dev/img/social3.png",
        "og:title": "andAgent | VoltAgent",
        "description": "Add AI to your workflow. Get structured, typed responses from language models.",
        "og:locale": "en",
        "og:description": "Add AI to your workflow. Get structured, typed responses from language models.",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "docusaurus_tag": "docs-default-current",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "docsearch:version": "current",
        "title": "andAgent | VoltAgent",
        "twitter:card": "summary_large_image",
        "og:url": "https://voltagent.dev/docs/workflows/steps/and-agent/",
        "scrapeId": "916d2c43-c768-43a2-bdeb-4045f91041ef",
        "sourceURL": "https://voltagent.dev/docs/workflows/steps/and-agent/",
        "url": "https://voltagent.dev/docs/workflows/steps/and-agent/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:27.647Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/providers/vercel-ai/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Vercel AI Provider ( `@voltagent/vercel-ai`)\n\nThe Vercel AI Provider acts as a bridge between VoltAgent and the [Vercel AI SDK](https://sdk.vercel.ai/docs), allowing your agents to leverage models deployed or accessible via Vercel's infrastructure. It essentially wraps the Vercel AI SDK's `generateText` and `streamText` functions (and potentially others in the future).\n\n**Key Characteristics:**\n\n- **Model Agnostic (at Provider Level):** The specific LLM used (e.g., OpenAI, Anthropic, Cohere, Hugging Face) is determined by the model identifier string you pass during generation calls, which the Vercel AI SDK then routes accordingly.\n- **Focus on Text Generation:** Primarily designed for text-based generation and streaming via Vercel AI SDK's core functions.\n\n## Installation [â€‹](https://voltagent.dev/docs/providers/vercel-ai/\\#installation \"Direct link to Installation\")\n\n- npm\n- yarn\n- pnpm\n\n```codeBlockLines_e6Vv\nnpm install @voltagent/core @voltagent/vercel-ai\n\n```\n\n## Configuration [â€‹](https://voltagent.dev/docs/providers/vercel-ai/\\#configuration \"Direct link to Configuration\")\n\nThe `VercelProvider` itself doesn't require any constructor arguments, as it relies on the environment configuration recognized by the Vercel AI SDK.\n\n```codeBlockLines_e6Vv\nimport { VercelProvider } from \"@voltagent/vercel-ai\";\n\nconst vercelProvider = new VercelProvider();\n\n```\n\nEnsure your environment variables (e.g., `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`, `GOOGLE_GENERATIVE_AI_API_KEY`, etc.) are set up correctly for the models you intend to use. The Vercel AI SDK automatically reads these keys from your environment (like a `.env` file or system variables).\n\nThe Vercel AI SDK supports a wide array of providers beyond OpenAI and Anthropic. For a comprehensive list and setup instructions for each, please refer to the [official Vercel AI SDK Provider documentation](https://sdk.vercel.ai/docs/foundations/providers-and-models).\n\n## Usage [â€‹](https://voltagent.dev/docs/providers/vercel-ai/\\#usage \"Direct link to Usage\")\n\nInstantiate your `Agent` with the `VercelProvider`:\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst vercelProvider = new VercelProvider();\n\nconst agent = new Agent({\n  name: \"Vercel Chat Agent\",\n  instructions: \"An agent powered by models via Vercel AI SDK\",\n  llm: vercelProvider,\n  model: openai(\"gpt-4o\"),\n});\n\n```\n\n## Supported Methods [â€‹](https://voltagent.dev/docs/providers/vercel-ai/\\#supported-methods \"Direct link to Supported Methods\")\n\n- **`generateText`**: Supported. Calls Vercel AI SDK's `generateText`.\n- **`streamText`**: Supported. Calls Vercel AI SDK's `streamText`.\n- **`generateObject`**: âš ï¸ **Partially Supported.** Uses Vercel AI SDK's `generateObject` function. Support depends on the underlying model's capability to generate structured JSON output reliably based on the provided Zod schema. Check Vercel AI SDK documentation for model compatibility.\n- **`streamObject`**: âš ï¸ **Partially Supported.** Uses Vercel AI SDK's `streamObject` function. Support depends on the underlying model and Vercel AI SDK's ability to stream partial object updates.\n\n## Multi-modal Support [â€‹](https://voltagent.dev/docs/providers/vercel-ai/\\#multi-modal-support \"Direct link to Multi-modal Support\")\n\nâš ï¸ **Conditional Support.**\n\nThe `@voltagent/vercel-ai` provider will pass multi-modal `BaseMessage` structures (containing text and image parts in the `content` array) to the underlying Vercel AI SDK functions.\n\nActual multi-modal support **depends entirely** on whether the specific model identifier you provide (e.g., `'gpt-4o-mini'`, `'gpt-4o'`) corresponds to a model that Vercel AI SDK can route to and that supports image input.\n\nRefer to the [Multi-modal Agents](https://voltagent.dev/docs/agents/multi-modal/) guide and the [Vercel AI SDK documentation](https://sdk.vercel.ai/docs) for details on configuring and using multi-modal models.\n\n```codeBlockLines_e6Vv\n// Make sure to import the model definition (e.g., openai)\nimport { openai } from \"@ai-sdk/openai\";\n// Example: Sending multi-modal input (requires Vercel AI SDK setup for a vision model)\nconst messages = [\\\n  {\\\n    role: \"user\",\\\n    content: [\\\n      { type: \"text\", text: \"Describe this image:\" },\\\n      { type: \"image\", image: \"data:image/png;base64,...\" },\\\n    ],\\\n  },\\\n];\n\n// Ensure the model identifier matches a vision-capable model configured in Vercel AI SDK\nconst response = await agent.generateText(messages, { model: openai(\"gpt-4-vision-preview\") });\n\n```\n\n## Model Selection [â€‹](https://voltagent.dev/docs/providers/vercel-ai/\\#model-selection \"Direct link to Model Selection\")\n\nThe model used by the agent is specified during its instantiation using the `model` property. Currently, the model **cannot** be overridden dynamically per-request in the `generateText` or `streamText` options. To use different models, you would typically create separate `Agent` instances.\n\nThe `model` identifier should be created using the functions provided by the Vercel AI SDK's model packages (e.g., `@ai-sdk/openai`, `@ai-sdk/anthropic`).\n\n```codeBlockLines_e6Vv\n// Make sure to import model definitions\nimport { openai } from \"@ai-sdk/openai\";\nimport { anthropic } from \"@ai-sdk/anthropic\";\n\n// Example: Agent configured with OpenAI model\nconst openAIAgent = new Agent({\n  id: \"openai-agent\",\n  llm: new VercelProvider(),\n  model: openai(\"gpt-4o\"),\n  instructions: \"Uses OpenAI\",\n});\n\n// Example: Agent configured with Anthropic model\nconst anthropicAgent = new Agent({\n  id: \"anthropic-agent\",\n  llm: new VercelProvider(),\n  model: anthropic(\"claude-opus-4-1\"),\n  instructions: \"Uses Anthropic\",\n});\n\n// Example: Using generateText with the configured agent\nconst response = await openAIAgent.generateText(\"Translate 'hello' to French.\");\n\nconsole.log(response);\n\n// Example: Streaming with a different configured agent\nconst streamResponse = await anthropicAgent.streamText(\"Write a poem about clouds.\");\n\nfor await (const chunk of streamResponse.textStream) {\n  process.stdout.write(chunk);\n}\n\n```\n\n## Code Examples [â€‹](https://voltagent.dev/docs/providers/vercel-ai/\\#code-examples \"Direct link to Code Examples\")\n\n### Text Generation [â€‹](https://voltagent.dev/docs/providers/vercel-ai/\\#text-generation \"Direct link to Text Generation\")\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nasync function main() {\n  const vercelProvider = new VercelProvider();\n\n  const agent = new Agent({\n    name: \"Simple Vercel Agent\",\n    instructions: \"A simple agent powered by Vercel AI SDK\",\n    llm: vercelProvider,\n    model: openai(\"gpt-4o-mini\"),\n  });\n\n  const prompt = \"What is the capital of France?\";\n\n  try {\n    const response = await agent.generateText(prompt);\n    console.log(`Agent response to \"${prompt}\":`);\n    console.log(response);\n  } catch (error) {\n    console.error(\"Error generating text:\", error);\n  }\n}\n\nmain();\n\n```\n\n### Streaming Text [â€‹](https://voltagent.dev/docs/providers/vercel-ai/\\#streaming-text \"Direct link to Streaming Text\")\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelProvider } from \"@voltagent/vercel-ai\";\nimport { anthropic } from \"@ai-sdk/anthropic\";\n\nasync function main() {\n  const vercelProvider = new VercelProvider();\n\n  const agent = new Agent({\n    name: \"Vercel Streaming Agent\",\n    instructions: \"A streaming agent powered by Vercel AI SDK\",\n    llm: vercelProvider,\n    model: anthropic(\"claude-3-haiku-20240307\"),\n  });\n\n  const prompt = \"Write a short story about a robot learning to paint.\";\n\n  try {\n    const streamResponse = await agent.streamText(prompt);\n\n    console.log(`Streaming agent response to \"${prompt}\":`);\n    for await (const chunk of streamResponse.textStream) {\n      process.stdout.write(chunk);\n    }\n    console.log();\n  } catch (error) {\n    console.error(\"Error streaming text:\", error);\n  }\n}\n\nmain();\n\n```\n\n### Generating Structured Objects ( `generateObject`) [â€‹](https://voltagent.dev/docs/providers/vercel-ai/\\#generating-structured-objects-generateobject \"Direct link to generating-structured-objects-generateobject\")\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { z } from \"zod\"; // Import Zod\n\n// Define a schema for the desired object structure\nconst personSchema = z.object({\n  name: z.string().describe(\"The person's full name\"),\n  age: z.number().describe(\"The person's age\"),\n  city: z.string().describe(\"The city they live in\"),\n});\n\nasync function main() {\n  const vercelProvider = new VercelProvider();\n\n  // Ensure the model supports object generation (e.g., gpt-4o)\n  const agent = new Agent({\n    name: \"Vercel Object Agent\",\n    instructions: \"An agent that generates structured data via Vercel AI SDK\",\n    llm: vercelProvider,\n    model: openai(\"gpt-4o\"),\n  });\n\n  const prompt =\n    \"Generate details for a software engineer named Alex who is 30 years old and lives in London.\";\n\n  try {\n    // Call generateObject with the prompt and schema\n    const response = await agent.generateObject(prompt, personSchema);\n\n    console.log(\"Generated Object:\");\n    console.log(response.object);\n    console.log(\"Usage:\", response.usage);\n  } catch (error) {\n    console.error(\"Error generating object:\", error);\n  }\n}\n\nmain();\n\n```\n\n### Streaming Structured Objects ( `streamObject`) [â€‹](https://voltagent.dev/docs/providers/vercel-ai/\\#streaming-structured-objects-streamobject \"Direct link to streaming-structured-objects-streamobject\")\n\n_Note: `streamObject` support is highly dependent on the specific model and provider implementation._\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { z } from \"zod\"; // Import Zod\n\n// Define a schema for the desired object structure\nconst recipeSchema = z.object({\n  dishName: z.string().describe(\"Name of the dish\"),\n  ingredients: z.array(z.string()).describe(\"List of ingredients\"),\n  steps: z.array(z.string()).describe(\"Cooking steps\"),\n});\n\nasync function main() {\n  const vercelProvider = new VercelProvider();\n\n  // Ensure the model supports object streaming (e.g., gpt-4o)\n  const agent = new Agent({\n    name: \"Vercel Object Streaming Agent\",\n    instructions: \"An agent that streams structured data via Vercel AI SDK\",\n    llm: vercelProvider,\n    model: openai(\"gpt-4o\"),\n  });\n\n  const prompt = \"Generate a simple recipe for pancakes.\";\n\n  try {\n    // Call streamObject with the prompt and schema\n    const response = await agent.streamObject(prompt, recipeSchema);\n\n    console.log(\"Streaming Object Updates:\");\n    // Stream partial object updates\n    for await (const partialObject of response.objectStream) {\n      console.log(\"Partial:\", partialObject);\n    }\n\n    // Get the final object once streaming is complete\n    const finalObject = await response.object;\n    console.log(\"\\nFinal Streamed Object:\");\n    console.log(finalObject);\n    console.log(\"Usage:\", response.usage);\n  } catch (error) {\n    console.error(\"Error streaming object:\", error);\n  }\n}\n\nmain();\n\n```\n\n### Provider-Specific Options [â€‹](https://voltagent.dev/docs/providers/vercel-ai/\\#provider-specific-options \"Direct link to Provider-Specific Options\")\n\nYou can pass provider-specific options directly to the underlying Vercel AI SDK functions ( `generateText`, `streamText`, `generateObject`, `streamObject`) using the `provider` property within the options object. This allows you to leverage features or configurations specific to the Vercel AI SDK or the underlying model provider that might not be part of the standard VoltAgent options.\n\nFor example, to use an experimental Vercel AI SDK feature:\n\n```codeBlockLines_e6Vv\nagent.streamText(\"Tell me a joke\", {\n  provider: {\n    // Pass any Vercel AI SDK compatible option here\n    experimental_activeTools: [\"tool1\", \"tool2\"], // Example Vercel AI SDK option\n    // otherProviderOptions...\n  },\n});\n\n```\n\nRefer to the [Vercel AI SDK documentation](https://sdk.vercel.ai/docs) for the available options for each function and model provider.\n\n## Migration Guide: Vercel AI SDK v5 [â€‹](https://voltagent.dev/docs/providers/vercel-ai/\\#migration-guide-vercel-ai-sdk-v5 \"Direct link to Migration Guide: Vercel AI SDK v5\")\n\nThe `@voltagent/vercel-ai` package now uses Vercel AI SDK v5 internally. Here's what you need to do to upgrade:\n\n### Required Updates [â€‹](https://voltagent.dev/docs/providers/vercel-ai/\\#required-updates \"Direct link to Required Updates\")\n\nUpdate the following packages:\n\n```codeBlockLines_e6Vv\nnpm install @voltagent/core@latest @voltagent/vercel-ai@latest zod@^3.25.0\n\n```\n\nIf you're using any `@ai-sdk/*` packages (like `@ai-sdk/openai`, `@ai-sdk/anthropic`), update them to latest version:\n\n```codeBlockLines_e6Vv\n// Update @ai-sdk/openai\nnpm install @ai-sdk/openai@latest\n\n// Update @ai-sdk/anthropic\nnpm install @ai-sdk/anthropic@latest\n\n```\n\n### Important Notes [â€‹](https://voltagent.dev/docs/providers/vercel-ai/\\#important-notes \"Direct link to Important Notes\")\n\n- **Zod Version**: Zod v3.25.0 or later is required. Note that Zod v4 doesn't exist yet - Zod went directly from v3.24 to v3.25.\n- **Core API Unchanged**: Your existing VoltAgent code will continue to work without changes. The API remains the same.\n\n### Table of Contents\n\n- [Installation](https://voltagent.dev/docs/providers/vercel-ai/#installation)\n- [Configuration](https://voltagent.dev/docs/providers/vercel-ai/#configuration)\n- [Usage](https://voltagent.dev/docs/providers/vercel-ai/#usage)\n- [Supported Methods](https://voltagent.dev/docs/providers/vercel-ai/#supported-methods)\n- [Multi-modal Support](https://voltagent.dev/docs/providers/vercel-ai/#multi-modal-support)\n- [Model Selection](https://voltagent.dev/docs/providers/vercel-ai/#model-selection)\n- [Code Examples](https://voltagent.dev/docs/providers/vercel-ai/#code-examples)\n  - [Text Generation](https://voltagent.dev/docs/providers/vercel-ai/#text-generation)\n  - [Streaming Text](https://voltagent.dev/docs/providers/vercel-ai/#streaming-text)\n  - [Generating Structured Objects ( `generateObject`)](https://voltagent.dev/docs/providers/vercel-ai/#generating-structured-objects-generateobject)\n  - [Streaming Structured Objects ( `streamObject`)](https://voltagent.dev/docs/providers/vercel-ai/#streaming-structured-objects-streamobject)\n  - [Provider-Specific Options](https://voltagent.dev/docs/providers/vercel-ai/#provider-specific-options)\n- [Migration Guide: Vercel AI SDK v5](https://voltagent.dev/docs/providers/vercel-ai/#migration-guide-vercel-ai-sdk-v5)\n  - [Required Updates](https://voltagent.dev/docs/providers/vercel-ai/#required-updates)\n  - [Important Notes](https://voltagent.dev/docs/providers/vercel-ai/#important-notes)",
      "metadata": {
        "docusaurus_version": "current",
        "title": "Vercel AI | VoltAgent",
        "docsearch:language": "en",
        "og:locale": "en",
        "description": "The Vercel AI Provider acts as a bridge between VoltAgent and the Vercel AI SDK, allowing your agents to leverage models deployed or accessible via Vercel's infrastructure. It essentially wraps the Vercel AI SDK's generateText and streamText functions (and potentially others in the future).",
        "language": "en",
        "twitter:card": "summary_large_image",
        "docusaurus_tag": "docs-default-current",
        "docsearch:version": "current",
        "og:description": "The Vercel AI Provider acts as a bridge between VoltAgent and the Vercel AI SDK, allowing your agents to leverage models deployed or accessible via Vercel's infrastructure. It essentially wraps the Vercel AI SDK's generateText and streamText functions (and potentially others in the future).",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "og:image": "https://voltagent.dev/img/social3.png",
        "ogDescription": "The Vercel AI Provider acts as a bridge between VoltAgent and the Vercel AI SDK, allowing your agents to leverage models deployed or accessible via Vercel's infrastructure. It essentially wraps the Vercel AI SDK's generateText and streamText functions (and potentially others in the future).",
        "ogUrl": "https://voltagent.dev/docs/providers/vercel-ai/",
        "generator": "Docusaurus v3.1.1",
        "docsearch:docusaurus_tag": "docs-default-current",
        "docusaurus_locale": "en",
        "og:url": "https://voltagent.dev/docs/providers/vercel-ai/",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "ogLocale": "en",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "ogTitle": "Vercel AI | VoltAgent",
        "og:title": "Vercel AI | VoltAgent",
        "viewport": "width=device-width, initial-scale=1.0",
        "scrapeId": "ade0f6e3-2bb5-491d-9ec5-be03f79ac471",
        "sourceURL": "https://voltagent.dev/docs/providers/vercel-ai/",
        "url": "https://voltagent.dev/docs/providers/vercel-ai/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:58.946Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/agents/tools/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Tools\n\nTools allow your agents to interact with external systems, APIs, databases, and perform specific actions. They are one of the most powerful features of VoltAgent, giving your agents the ability to affect the world beyond just generating text.\n\n## Creating Basic Tools [â€‹](https://voltagent.dev/docs/agents/tools/\\#creating-basic-tools \"Direct link to Creating Basic Tools\")\n\nVoltAgent provides a `createTool` helper function that makes it easy to create type-safe tools with full IntelliSense support. Let's start with a simple example - a calculator tool:\n\n```codeBlockLines_e6Vv\nimport { createTool } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\nconst calculatorTool = createTool({\n  name: \"calculate\",\n  description: \"Perform a mathematical calculation\",\n  parameters: z.object({\n    expression: z.string().describe(\"The mathematical expression to evaluate, e.g. (2 + 2) * 3\"),\n  }),\n  execute: async (args) => {\n    try {\n      // In production, use a secure math parser instead of eval\n      const result = eval(args.expression);\n      return { result };\n    } catch (error) {\n      throw new Error(`Invalid expression: ${args.expression}`);\n    }\n  },\n});\n\n```\n\nThis tool takes a mathematical expression as input and returns the calculated result. Notice how the `execute` function automatically infers its parameter types from the Zod schema defined in `parameters`. This provides full IntelliSense support in your IDE, helping catch errors during development.\n\n## Understanding Tools [â€‹](https://voltagent.dev/docs/agents/tools/\\#understanding-tools \"Direct link to Understanding Tools\")\n\nA tool in VoltAgent is a function that an agent can call to perform an action or retrieve information. Each tool has:\n\n- **Name**: A unique identifier for the tool\n- **Description**: Explains what the tool does (the agent uses this to decide when to use the tool)\n- **Parameters**: The inputs the tool requires, defined using Zod schemas\n- **Execute function**: The code that runs when the tool is called\n\n## Using Tools with an Agent [â€‹](https://voltagent.dev/docs/agents/tools/\\#using-tools-with-an-agent \"Direct link to Using Tools with an Agent\")\n\nTo use a tool with an agent, simply include it in the agent's configuration. When you interact with the agent (e.g., using `generateText` or `streamText`), the LLM will decide based on the prompt and the tool's description whether using the tool is appropriate to fulfill the request.\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  name: \"Calculator Assistant\",\n  description: \"An assistant that can perform calculations\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  tools: [calculatorTool],\n});\n\n// The agent can now use the calculator tool when needed\n// const response = await agent.generateText(\"What is 123 * 456?\");\n// console.log(response.text);\n\n```\n\n## Using Multiple Tools Together [â€‹](https://voltagent.dev/docs/agents/tools/\\#using-multiple-tools-together \"Direct link to Using Multiple Tools Together\")\n\nAgents become more powerful when they can use multiple tools together. Here's an example of an agent that can both check the weather and perform calculations:\n\n```codeBlockLines_e6Vv\nimport { Agent, createTool } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { z } from \"zod\";\n\n// Calculator tool\nconst calculatorTool = createTool({\n  name: \"calculate\",\n  description: \"Perform a mathematical calculation\",\n  parameters: z.object({\n    expression: z.string().describe(\"The mathematical expression to evaluate\"),\n  }),\n  execute: async (args) => {\n    try {\n      // args is automatically typed as { expression: string }\n      const result = eval(args.expression);\n      return { result };\n    } catch (error) {\n      throw new Error(`Invalid expression: ${args.expression}`);\n    }\n  },\n});\n\n// Weather tool\nconst weatherTool = createTool({\n  name: \"get_weather\",\n  description: \"Get the current weather for a location\",\n  parameters: z.object({\n    location: z.string().describe(\"The city name\"),\n  }),\n  execute: async (args) => {\n    // args is automatically typed as { location: string }\n    const { location } = args;\n\n    // In a real implementation, you would call a weather API\n    // This is a simplified example\n    return {\n      location,\n      temperature: 22,\n      conditions: \"sunny\",\n    };\n  },\n});\n\n// Create an agent with multiple tools\nconst multiToolAgent = new Agent({\n  name: \"Multi-Tool Assistant\",\n  description: \"An assistant that can check weather and perform calculations\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  tools: [calculatorTool, weatherTool],\n});\n\n// The agent can now use both tools in the same conversation\nconst response = await multiToolAgent.generateText(\n  \"What's the weather in Paris today? Also, what is 24 * 7?\"\n);\nconsole.log(response.text);\n\n// Example response:\n// \"The current weather in Paris is 22Â°C and sunny. As for your calculation, 24 * 7 = 168.\"\n\n```\n\nIn this example, the agent can decide which tool to use based on the user's question. When asked both about the weather and a calculation, it will use both tools and combine the results into a single coherent response.\n\n## Type Safety with Tools [â€‹](https://voltagent.dev/docs/agents/tools/\\#type-safety-with-tools \"Direct link to Type Safety with Tools\")\n\nWhen you use `createTool`, the type of the `args` parameter in the `execute` function is automatically inferred from the Zod schema you define in `parameters`. This provides several benefits:\n\n- **IntelliSense support**: Your IDE will show autocomplete suggestions for the properties of `args`\n- **Type checking**: TypeScript will catch errors if you try to access properties that don't exist\n- **Refactoring support**: When you change the schema, TypeScript will help you update all the places that use it\n- **Documentation**: The types serve as documentation for what data the tool expects\n\nFor example, with this tool definition:\n\n```codeBlockLines_e6Vv\nconst weatherTool = createTool({\n  name: \"get_weather\",\n  description: \"Get the current weather for a location\",\n  parameters: z.object({\n    location: z.string().describe(\"The city name\"),\n    unit: z.enum([\"celsius\", \"fahrenheit\"]).optional().describe(\"Temperature unit\"),\n  }),\n  execute: async (args) => {\n    // args is typed as { location: string; unit?: \"celsius\" | \"fahrenheit\" }\n    const { location, unit = \"celsius\" } = args;\n    // ...\n  },\n});\n\n```\n\nThe `args` parameter is automatically typed as `{ location: string; unit?: \"celsius\" | \"fahrenheit\" }`, giving you full IDE support without having to manually specify the type.\n\n## Tool Hooks [â€‹](https://voltagent.dev/docs/agents/tools/\\#tool-hooks \"Direct link to Tool Hooks\")\n\nVoltAgent provides lifecycle hooks that let you respond to tool execution events. This allows you to add logging, perform additional actions, or modify behavior when tools are used.\n\n### Using hooks [â€‹](https://voltagent.dev/docs/agents/tools/\\#using-hooks \"Direct link to Using hooks\")\n\nThe `onToolStart` hook is called just before a tool is executed, and `onToolEnd` is called after execution completes. These hooks are particularly useful for:\n\n- Logging tool usage\n- Updating UI when tools are running\n- Cleaning up resources after tool execution\n\n```codeBlockLines_e6Vv\nimport { Agent, createHooks, isAbortError } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Define the hooks using createHooks\nconst hooks = createHooks({\n  onToolStart({ agent, tool, context }) {\n    console.log(`Tool starting: ${tool.name}`);\n    console.log(`Agent: ${agent.name}`);\n    console.log(`Operation ID: ${context.operationId}`);\n  },\n  onToolEnd({ agent, tool, output, error, context }) {\n    console.log(`Tool completed: ${tool.name}`);\n\n    if (error) {\n      if (isAbortError(error)) {\n        console.log(`Tool was aborted: ${error.message}`);\n      } else {\n        console.error(`Tool failed: ${error.message}`);\n      }\n    } else {\n      console.log(`Result: ${JSON.stringify(output)}`);\n    }\n  },\n});\n\n// Create an agent with hooks\nconst agent = new Agent({\n  name: \"Assistant with Tool Hooks\",\n  instructions: \"An assistant that logs tool execution\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  tools: [calculatorTool],\n  hooks: hooks,\n});\n\n// When the agent uses a tool, the hooks will be triggered\n// const response = await agent.generateText(\"What is 123 * 456?\");\n\n```\n\n## Best Practices [â€‹](https://voltagent.dev/docs/agents/tools/\\#best-practices \"Direct link to Best Practices\")\n\n### Clear Descriptions [â€‹](https://voltagent.dev/docs/agents/tools/\\#clear-descriptions \"Direct link to Clear Descriptions\")\n\nProvide clear descriptions for your tools and parameters. The agent relies heavily on these descriptions to understand the tool's purpose, capabilities, and required inputs. Remember that the `.describe()` strings in your Zod parameter schemas are crucial information passed directly to the LLM.\n\n**Bad Example:**\n\n```codeBlockLines_e6Vv\nconst badTool = createTool({\n  name: \"search\",\n  description: \"Searches things\", // Vague, doesn't explain what it searches or when to use it\n  parameters: z.object({\n    q: z.string(), // Unclear parameter name with no description\n    n: z.number().optional(), // Unclear what this parameter does\n  }),\n  execute: async (args) => {\n    /* ... */\n  },\n});\n\n```\n\n**Good Example:**\n\n```codeBlockLines_e6Vv\nconst goodTool = createTool({\n  name: \"search_web\",\n  description:\n    \"Searches the web for current information on a topic. Use this when you need to find recent or factual information that may not be in your training data.\", // Clear purpose and usage guidance\n  parameters: z.object({\n    query: z\n      .string()\n      .describe(\"The search query. Should be specific and focused on what information is needed.\"),\n    results_count: z\n      .number()\n      .min(1)\n      .max(10)\n      .optional()\n      .describe(\"Number of results to return. Defaults to 3 if not specified.\"),\n  }),\n  execute: async (args) => {\n    /* ... */\n  },\n});\n\n```\n\n### Error Handling [â€‹](https://voltagent.dev/docs/agents/tools/\\#error-handling \"Direct link to Error Handling\")\n\nImplement proper error handling in your tool's execute function. Return useful error messages that the agent can understand.\n\n```codeBlockLines_e6Vv\nexecute: async (args) => {\n  try {\n    // Tool implementation\n    return result;\n  } catch (error) {\n    throw new Error(`Failed to process request: ${error.message}`);\n  }\n};\n\n```\n\n### Cancellable Tools with AbortController [â€‹](https://voltagent.dev/docs/agents/tools/\\#cancellable-tools-with-abortcontroller \"Direct link to Cancellable Tools with AbortController\")\n\nFor long-running tools, implement cancellation with AbortController. This allows tools to be gracefully cancelled when needed, such as when a user cancels a request or when an operation times out.\n\nTools receive an options object as their second parameter, which contains the operation context with an AbortController. The tool can:\n\n- **Check if already aborted** using `signal.aborted`\n- **Listen for abort events** using `signal.addEventListener('abort', ...)`\n- **Trigger abort** using `abortController.abort()` to cancel the entire agent operation\n\n> **Important**: When a tool calls `abortController.abort()`, it cancels the entire agent operation, not just the current tool execution. This will stop any subsequent tool calls and cause the agent to throw an `AbortError`.\n\n```codeBlockLines_e6Vv\nconst searchTool = createTool({\n  name: \"search_web\",\n  description: \"Search the web for current information\",\n  parameters: z.object({\n    query: z.string().describe(\"The search query\"),\n  }),\n  execute: async (args, options) => {\n    // Extract the AbortController from operation context\n    const abortController = options?.operationContext?.abortController;\n    const signal = abortController?.signal;\n\n    // Check if already aborted\n    if (signal?.aborted) {\n      throw new Error(\"Search was cancelled before it started\");\n    }\n\n    // Tool can trigger abort to cancel the entire operation\n    if (args.query.includes(\"forbidden\")) {\n      // This will abort the entire agent operation, not just this tool\n      abortController?.abort(\"Forbidden query detected - cancelling entire operation\");\n      throw new Error(\"Search query contains forbidden terms\");\n    }\n\n    // Example of a fetch operation that respects abort signal\n    try {\n      const response = await fetch(`https://api.search.com?q=${args.query}`, {\n        signal: signal, // Pass the signal to fetch\n      });\n\n      // Tool can also abort based on response\n      if (!response.ok && response.status === 429) {\n        abortController?.abort(\"Rate limit exceeded - stopping all operations\");\n        throw new Error(\"API rate limit exceeded\");\n      }\n\n      return await response.json();\n    } catch (error) {\n      // If fetch was aborted, it will throw an AbortError\n      if (error.name === \"AbortError\") {\n        throw new Error(\"Search was cancelled during execution\");\n      }\n      throw error;\n    }\n  },\n});\n\n```\n\nWhen calling a tool directly, you can pass an AbortController:\n\n```codeBlockLines_e6Vv\n// Create an AbortController\nconst abortController = new AbortController();\n\n// Set a timeout to abort after 5 seconds\nsetTimeout(() => abortController.abort(\"Operation timeout\"), 5000);\n\ntry {\n  // Pass the abortController directly\n  const result = await searchTool.execute({ query: \"Latest AI developments\" }, { abortController });\n  console.log(\"Results:\", result);\n} catch (error) {\n  if (error.name === \"AbortError\") {\n    console.log(\"Search was cancelled\");\n  } else {\n    console.error(\"Search failed:\", error);\n  }\n}\n\n```\n\nWhen using tools with an agent, you can pass the AbortController in the options of the agent's generateText or streamText methods:\n\n```codeBlockLines_e6Vv\nimport { isAbortError } from \"@voltagent/core\";\n\n// Create an AbortController\nconst abortController = new AbortController();\n\n// Set a timeout to abort after 30 seconds\nsetTimeout(() => abortController.abort(\"Operation timeout\"), 30000);\n\ntry {\n  // Pass the abortController to the agent\n  const response = await agent.generateText(\"Search for the latest AI developments\", {\n    abortController, // The agent will pass this to any tools it uses\n  });\n  console.log(response.text);\n} catch (error) {\n  if (isAbortError(error)) {\n    console.log(\"Operation was cancelled:\", error.message);\n  } else {\n    console.error(\"Error:\", error);\n  }\n}\n\n```\n\nThe AbortSignal mechanism is particularly useful for:\n\n- User-initiated cancellations\n- Implementing timeouts for slow operations\n- Gracefully stopping batch operations\n- Preventing unnecessary work when results are no longer needed\n\n### Timeout Handling [â€‹](https://voltagent.dev/docs/agents/tools/\\#timeout-handling \"Direct link to Timeout Handling\")\n\nFor tools that call external APIs, implement timeout handling. While `Promise.race` can be used, the `AbortController` pattern often integrates more cleanly, especially with `fetch` and the agent's own signal propagation.\n\n```codeBlockLines_e6Vv\nexecute: async (args) => {\n  const timeoutPromise = new Promise((_, reject) => {\n    setTimeout(() => reject(new Error(\"Request timed out\")), 5000);\n  });\n\n  const resultPromise = fetchDataFromApi(args);\n\n  return Promise.race([resultPromise, timeoutPromise]);\n};\n\n```\n\nAlternatively, using AbortController with a timeout:\n\n```codeBlockLines_e6Vv\nexecute: async (args, options) => {\n  // Get parent abort controller if provided\n  const parentController = options?.operationContext?.abortController;\n\n  // Create a new AbortController for timeout\n  const timeoutController = new AbortController();\n\n  // Create a timeout that will abort the controller\n  const timeoutId = setTimeout(() => {\n    timeoutController.abort(\"Operation timed out\");\n  }, 5000); // 5-second timeout\n\n  try {\n    // Listen to parent abort if provided\n    if (parentController?.signal) {\n      parentController.signal.addEventListener(\"abort\", () => {\n        timeoutController.abort(\"Parent operation aborted\");\n        clearTimeout(timeoutId);\n      });\n    }\n\n    // Use our controller's signal for the API call\n    const result = await fetchDataFromApi(args, { signal: timeoutController.signal });\n    clearTimeout(timeoutId); // Clear the timeout if the operation completed successfully\n    return result;\n  } catch (error) {\n    clearTimeout(timeoutId); // Ensure timeout is cleared on error too\n    throw error;\n  }\n};\n\n```\n\n## Dynamic Tool Registration [â€‹](https://voltagent.dev/docs/agents/tools/\\#dynamic-tool-registration \"Direct link to Dynamic Tool Registration\")\n\nYou can add tools to an agent after it's been created:\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Create an agent without tools initially\nconst agent = new Agent({\n  name: \"Dynamic Assistant\",\n  description: \"An assistant that can gain new abilities\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n});\n\n// Later, add tools to the agent\nagent.addTools([calculatorTool]);\n\n// You can also add toolkits\nagent.addTools([myToolkit]);\n\n// Or provide tools for a specific request only\nconst response = await agent.generateText(\"Calculate 123 * 456\", {\n  tools: [calculatorTool],\n});\n\n```\n\n## MCP (Model Context Protocol) Support [â€‹](https://voltagent.dev/docs/agents/tools/\\#mcp-model-context-protocol-support \"Direct link to MCP (Model Context Protocol) Support\")\n\nVoltAgent supports the [Model Context Protocol (MCP)](https://github.com/modelcontextprotocol/mcp), allowing your agents to seamlessly connect with external model servers, AI systems, and other tools that implement this protocol. This enables you to expand your agent's capabilities without having to write complex integration code.\n\n### Using MCP Tools [â€‹](https://voltagent.dev/docs/agents/tools/\\#using-mcp-tools \"Direct link to Using MCP Tools\")\n\nYou can connect to external MCP-compatible servers and use their tools with your agents:\n\n```codeBlockLines_e6Vv\nimport { Agent, MCPConfiguration } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Set up MCP configuration with multiple servers\nconst mcpConfig = new MCPConfiguration({\n  servers: {\n    // HTTP server configuration\n    browserTools: {\n      type: \"http\",\n      url: \"https://your-mcp-server.example.com/browser\",\n    },\n    // Local stdio server configuration\n    localAI: {\n      type: \"stdio\",\n      command: \"python\",\n      args: [\"local_ai_server.py\"],\n    },\n  },\n});\n\n// Option 1: Get tools grouped by server using getToolsets()\nconst toolsets = await mcpConfig.getToolsets();\n// Access tools for a specific server\nconst browserToolsOnly = toolsets.browserTools.getTools();\nconst localAiToolsOnly = toolsets.localAI.getTools();\n\n// Option 2: Get all tools from all servers combined into a single array\nconst allMcpTools = await mcpConfig.getTools();\n\n// Create an agent using only the browser tools\nconst agentWithBrowserTools = new Agent({\n  name: \"Browser Agent\",\n  description: \"Assistant using only browser tools via MCP\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  tools: browserToolsOnly, // Use the specific toolset\n});\n\n// Create another agent using *all* fetched MCP tools\nconst agentWithAllMcpTools = new Agent({\n  name: \"MCP-Enhanced Assistant\",\n  description: \"Assistant with access to all configured MCP tools\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  tools: allMcpTools, // Use the combined list\n});\n\n// Use the agents (example)\n// const response = await agentWithBrowserTools.generateText(\n//   \"Take a screenshot of the current page.\"\n// );\n// console.log(response.text);\n\n```\n\nMCP enables your agents to:\n\n- Connect to browser extensions for web automation\n- Access specialized local AI models (image recognition, voice processing, etc.)\n- Use API gateways that implement the MCP protocol\n- Tap into ecosystems of MCP-compatible tools\n\nFor in-depth details on setting up and using the Model Context Protocol with your agents, see the [MCP documentation](https://voltagent.dev/docs/agents/mcp/).\n\n### Table of Contents\n\n- [Creating Basic Tools](https://voltagent.dev/docs/agents/tools/#creating-basic-tools)\n- [Understanding Tools](https://voltagent.dev/docs/agents/tools/#understanding-tools)\n- [Using Tools with an Agent](https://voltagent.dev/docs/agents/tools/#using-tools-with-an-agent)\n- [Using Multiple Tools Together](https://voltagent.dev/docs/agents/tools/#using-multiple-tools-together)\n- [Type Safety with Tools](https://voltagent.dev/docs/agents/tools/#type-safety-with-tools)\n- [Tool Hooks](https://voltagent.dev/docs/agents/tools/#tool-hooks)\n  - [Using hooks](https://voltagent.dev/docs/agents/tools/#using-hooks)\n- [Best Practices](https://voltagent.dev/docs/agents/tools/#best-practices)\n  - [Clear Descriptions](https://voltagent.dev/docs/agents/tools/#clear-descriptions)\n  - [Error Handling](https://voltagent.dev/docs/agents/tools/#error-handling)\n  - [Cancellable Tools with AbortController](https://voltagent.dev/docs/agents/tools/#cancellable-tools-with-abortcontroller)\n  - [Timeout Handling](https://voltagent.dev/docs/agents/tools/#timeout-handling)\n- [Dynamic Tool Registration](https://voltagent.dev/docs/agents/tools/#dynamic-tool-registration)\n- [MCP (Model Context Protocol) Support](https://voltagent.dev/docs/agents/tools/#mcp-model-context-protocol-support)\n  - [Using MCP Tools](https://voltagent.dev/docs/agents/tools/#using-mcp-tools)",
      "metadata": {
        "docusaurus_locale": "en",
        "twitter:card": "summary_large_image",
        "docusaurus_tag": "docs-default-current",
        "ogLocale": "en",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "docsearch:version": "current",
        "description": "Tools allow your agents to interact with external systems, APIs, databases, and perform specific actions. They are one of the most powerful features of VoltAgent, giving your agents the ability to affect the world beyond just generating text.",
        "docsearch:language": "en",
        "ogUrl": "https://voltagent.dev/docs/agents/tools/",
        "docusaurus_version": "current",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:description": "Tools allow your agents to interact with external systems, APIs, databases, and perform specific actions. They are one of the most powerful features of VoltAgent, giving your agents the ability to affect the world beyond just generating text.",
        "og:title": "Tools | VoltAgent",
        "ogTitle": "Tools | VoltAgent",
        "language": "en",
        "title": "Tools | VoltAgent",
        "ogDescription": "Tools allow your agents to interact with external systems, APIs, databases, and perform specific actions. They are one of the most powerful features of VoltAgent, giving your agents the ability to affect the world beyond just generating text.",
        "generator": "Docusaurus v3.1.1",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "og:image": "https://voltagent.dev/img/social3.png",
        "og:locale": "en",
        "viewport": "width=device-width, initial-scale=1.0",
        "og:url": "https://voltagent.dev/docs/agents/tools/",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "scrapeId": "46fada82-4d7c-466a-9345-72dee3e9ac3f",
        "sourceURL": "https://voltagent.dev/docs/agents/tools/",
        "url": "https://voltagent.dev/docs/agents/tools/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:29.626Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/workflows/execute-api/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Execute Function API\n\n> **The heart of every workflow step.** Learn how to use the execute function to process data, access workflow state, and control flow.\n\n## Quick Start [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#quick-start \"Direct link to Quick Start\")\n\nEvery workflow step has an `execute` function that receives a context object:\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"my-step\",\n  execute: async ({ data, state, getStepData, suspend, resumeData }) => {\n    // Your logic here\n    return { result: \"processed\" };\n  }\n})\n\n```\n\n## What's in the Context? [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#whats-in-the-context \"Direct link to What's in the Context?\")\n\nThe execute function receives one parameter - a context object with these properties:\n\n### 1\\. `data` \\- The Step's Input [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#1-data---the-steps-input \"Direct link to 1-data---the-steps-input\")\n\nThis is the data flowing into your step:\n\n- **First step**: Gets the workflow's initial input\n- **Other steps**: Gets the output from the previous step\n\n```codeBlockLines_e6Vv\nconst workflow = createWorkflowChain({\n  input: z.object({ name: z.string() }),\n  // ...\n})\n  .andThen({\n    id: \"step-1\",\n    execute: async ({ data }) => {\n      console.log(data.name); // Original input\n      return { ...data, step1: \"done\" };\n    },\n  })\n  .andThen({\n    id: \"step-2\",\n    execute: async ({ data }) => {\n      console.log(data.name); // Still there!\n      console.log(data.step1); // \"done\" - from previous step\n      return { ...data, step2: \"also done\" };\n    },\n  });\n\n```\n\n### 2\\. `state` \\- Workflow Information [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#2-state---workflow-information \"Direct link to 2-state---workflow-information\")\n\nContains metadata about the current workflow execution:\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"log-info\",\n  execute: async ({ data, state }) => {\n    console.log(state.executionId);    // Unique ID for this run\n    console.log(state.userId);         // Who's running it\n    console.log(state.conversationId); // Conversation context\n    console.log(state.input);          // Original workflow input\n    console.log(state.startAt);        // When it started\n\n    // userContext is a Map for custom data\n    const userRole = state.userContext?.get(\"role\");\n\n    return data;\n  }\n})\n\n```\n\n### 3\\. `getStepData` \\- Access Any Previous Step [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#3-getstepdata---access-any-previous-step \"Direct link to 3-getstepdata---access-any-previous-step\")\n\nGet data from any step that has already executed:\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"combine-results\",\n  execute: async ({ data, getStepData }) => {\n    // Get data from a specific step\n    const step1Data = getStepData(\"step-1\");\n\n    if (step1Data) {\n      console.log(step1Data.input);  // What went INTO step-1\n      console.log(step1Data.output); // What came OUT of step-1\n    }\n\n    return data;\n  }\n})\n\n```\n\n### 4\\. `suspend` \\- Pause the Workflow [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#4-suspend---pause-the-workflow \"Direct link to 4-suspend---pause-the-workflow\")\n\nPause execution and wait for external input (like human approval):\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"wait-for-approval\",\n  execute: async ({ data, suspend }) => {\n    if (data.amount > 1000) {\n      // This stops execution immediately\n      await suspend(\"Manager approval required\");\n      // Code below never runs during suspension\n    }\n\n    return { ...data, approved: true };\n  }\n})\n\n```\n\n### 5\\. `resumeData` \\- Data from Resume [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#5-resumedata---data-from-resume \"Direct link to 5-resumedata---data-from-resume\")\n\nWhen a suspended workflow resumes, this contains the resume data:\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"approval-step\",\n  execute: async ({ data, suspend, resumeData }) => {\n    // Check if we're resuming\n    if (resumeData) {\n      // We're resuming! Use the approval decision\n      return {\n        ...data,\n        approved: resumeData.approved,\n        approvedBy: resumeData.managerId\n      };\n    }\n\n    // First time through - suspend for approval\n    if (data.amount > 1000) {\n      await suspend(\"Needs approval\");\n    }\n\n    // Auto-approve small amounts\n    return { ...data, approved: true, approvedBy: \"auto\" };\n  }\n})\n\n```\n\n## Complete Example [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#complete-example \"Direct link to Complete Example\")\n\nHere's a real-world example using all context properties:\n\n```codeBlockLines_e6Vv\nimport { createWorkflowChain } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\nconst orderWorkflow = createWorkflowChain({\n  id: \"order-processor\",\n  name: \"Order Processing\",\n  input: z.object({\n    orderId: z.string(),\n    amount: z.number(),\n    items: z.array(z.string()),\n  }),\n  result: z.object({\n    status: z.string(),\n    trackingNumber: z.string(),\n  }),\n})\n  .andThen({\n    id: \"validate-order\",\n    execute: async ({ data, state }) => {\n      console.log(`Processing order ${data.orderId} for user ${state.userId}`);\n\n      const isValid = data.items.length > 0 && data.amount > 0;\n      return { ...data, isValid };\n    },\n  })\n  .andThen({\n    id: \"check-inventory\",\n    execute: async ({ data, getStepData }) => {\n      // Only check if validation passed\n      const validation = getStepData(\"validate-order\");\n      if (!validation?.output?.isValid) {\n        return { ...data, inStock: false };\n      }\n\n      // Check inventory for each item\n      const inStock = await checkInventory(data.items);\n      return { ...data, inStock };\n    },\n  })\n  .andThen({\n    id: \"approve-payment\",\n    execute: async ({ data, suspend, resumeData }) => {\n      // Handle resume from suspension\n      if (resumeData) {\n        return {\n          ...data,\n          paymentApproved: resumeData.approved,\n          approvedBy: resumeData.approver,\n        };\n      }\n\n      // Auto-approve small amounts\n      if (data.amount <= 100) {\n        return { ...data, paymentApproved: true, approvedBy: \"auto\" };\n      }\n\n      // Suspend for manual approval\n      await suspend(`Payment approval needed for $${data.amount}`);\n    },\n  })\n  .andThen({\n    id: \"ship-order\",\n    execute: async ({ data, state }) => {\n      if (!data.paymentApproved) {\n        return {\n          status: \"cancelled\",\n          trackingNumber: \"N/A\",\n        };\n      }\n\n      // Ship the order\n      const tracking = await createShipment(data.orderId);\n\n      // Log completion\n      console.log(`Order ${data.orderId} shipped after ${Date.now() - state.startAt.getTime()}ms`);\n\n      return {\n        status: \"shipped\",\n        trackingNumber: tracking,\n      };\n    },\n  });\n\n```\n\n## Different Step Types [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#different-step-types \"Direct link to Different Step Types\")\n\n### Basic Steps ( `andThen`) [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#basic-steps-andthen \"Direct link to basic-steps-andthen\")\n\nTransform data or perform operations:\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"calculate-total\",\n  execute: async ({ data }) => {\n    const total = data.items.reduce((sum, item) => sum + item.price, 0);\n    return { ...data, total };\n  }\n})\n\n```\n\n### AI Agent Steps ( `andAgent`) [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#ai-agent-steps-andagent \"Direct link to ai-agent-steps-andagent\")\n\nThe task function also gets the context:\n\n```codeBlockLines_e6Vv\n.andAgent(\n  async ({ data }) => `Summarize this order: ${JSON.stringify(data.items)}`,\n  myAgent,\n  { schema: z.object({ summary: z.string() }) }\n)\n\n```\n\n### Conditional Steps ( `andWhen`) [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#conditional-steps-andwhen \"Direct link to conditional-steps-andwhen\")\n\nOnly run when a condition is met:\n\n```codeBlockLines_e6Vv\n.andWhen({\n  id: \"apply-discount\",\n  condition: async ({ data }) => data.total > 50,\n  step: andThen({\n    id: \"discount\",\n    execute: async ({ data }) => ({\n      ...data,\n      total: data.total * 0.9,\n      discountApplied: true\n    })\n  })\n})\n\n```\n\n### Side Effects ( `andTap`) [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#side-effects-andtap \"Direct link to side-effects-andtap\")\n\nRun code without changing the data:\n\n```codeBlockLines_e6Vv\n.andTap({\n  id: \"send-notification\",\n  execute: async ({ data, state }) => {\n    await sendEmail(state.userId, `Order ${data.orderId} processed`);\n    // Return value ignored - data passes through\n  }\n})\n\n```\n\n## Suspend & Resume Deep Dive [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#suspend--resume-deep-dive \"Direct link to Suspend & Resume Deep Dive\")\n\nFor human-in-the-loop workflows, suspension is key:\n\n```codeBlockLines_e6Vv\n.andThen({\n  id: \"review-step\",\n  execute: async ({ data, suspend, resumeData }) => {\n    // Step 1: Check if we're resuming\n    if (resumeData) {\n      console.log(\"Resuming with:\", resumeData);\n      return { ...data, reviewed: true, reviewer: resumeData.userId };\n    }\n\n    // Step 2: Check if we need to suspend\n    if (data.requiresReview) {\n      // This immediately stops execution\n      await suspend(\"Document needs review\", {\n        documentId: data.id,\n        reason: \"High risk score\"\n      });\n      // Never reaches here during suspension\n    }\n\n    // Step 3: Continue if no suspension needed\n    return { ...data, reviewed: true, reviewer: \"auto\" };\n  }\n})\n\n```\n\n**Important**: When resumed, the step runs again from the beginning with `resumeData` available.\n\nFor more details on suspension patterns, see [Suspend & Resume](https://voltagent.dev/docs/workflows/suspend-resume/).\n\n## Best Practices [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#best-practices \"Direct link to Best Practices\")\n\n### 1\\. Always Return New Objects [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#1-always-return-new-objects \"Direct link to 1. Always Return New Objects\")\n\n```codeBlockLines_e6Vv\n// âœ… Good - creates new object\nreturn { ...data, processed: true };\n\n// âŒ Bad - mutates existing object\ndata.processed = true;\nreturn data;\n\n```\n\n### 2\\. Check Step Data Exists [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#2-check-step-data-exists \"Direct link to 2. Check Step Data Exists\")\n\n```codeBlockLines_e6Vv\nconst previousStep = getStepData(\"step-id\");\nif (previousStep) {\n  // Safe to use previousStep.output\n}\n\n```\n\n### 3\\. Use Clear Step IDs [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#3-use-clear-step-ids \"Direct link to 3. Use Clear Step IDs\")\n\n```codeBlockLines_e6Vv\n// âœ… Good - descriptive\nid: \"validate-payment\";\n\n// âŒ Bad - unclear\nid: \"step2\";\n\n```\n\n### 4\\. Handle Errors Gracefully [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#4-handle-errors-gracefully \"Direct link to 4. Handle Errors Gracefully\")\n\n```codeBlockLines_e6Vv\nexecute: async ({ data }) => {\n  try {\n    const result = await riskyOperation(data);\n    return { ...data, result };\n  } catch (error) {\n    return { ...data, error: error.message, success: false };\n  }\n};\n\n```\n\n### 5\\. Log Important Events [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#5-log-important-events \"Direct link to 5. Log Important Events\")\n\n```codeBlockLines_e6Vv\nexecute: async ({ data, state }) => {\n  console.log(`[${state.executionId}] Processing ${data.id}`);\n  const result = await process(data);\n  console.log(`[${state.executionId}] Completed with status: ${result.status}`);\n  return result;\n};\n\n```\n\n## TypeScript Types [â€‹](https://voltagent.dev/docs/workflows/execute-api/\\#typescript-types \"Direct link to TypeScript Types\")\n\nThe execute function is fully type-safe:\n\n```codeBlockLines_e6Vv\ninterface ExecuteContext<TData, TSuspendData = any, TResumeData = any> {\n  data: TData;\n  state: WorkflowState;\n  getStepData: (stepId: string) => { input: any; output: any } | undefined;\n  suspend: (reason?: string, data?: TSuspendData) => Promise<never>;\n  resumeData?: TResumeData;\n}\n\n```\n\nTypes flow automatically through your workflow - TypeScript knows what data is available at each step!\n\n### Table of Contents\n\n- [Quick Start](https://voltagent.dev/docs/workflows/execute-api/#quick-start)\n- [What's in the Context?](https://voltagent.dev/docs/workflows/execute-api/#whats-in-the-context)\n  - [1\\. `data` \\- The Step's Input](https://voltagent.dev/docs/workflows/execute-api/#1-data---the-steps-input)\n  - [2\\. `state` \\- Workflow Information](https://voltagent.dev/docs/workflows/execute-api/#2-state---workflow-information)\n  - [3\\. `getStepData` \\- Access Any Previous Step](https://voltagent.dev/docs/workflows/execute-api/#3-getstepdata---access-any-previous-step)\n  - [4\\. `suspend` \\- Pause the Workflow](https://voltagent.dev/docs/workflows/execute-api/#4-suspend---pause-the-workflow)\n  - [5\\. `resumeData` \\- Data from Resume](https://voltagent.dev/docs/workflows/execute-api/#5-resumedata---data-from-resume)\n- [Complete Example](https://voltagent.dev/docs/workflows/execute-api/#complete-example)\n- [Different Step Types](https://voltagent.dev/docs/workflows/execute-api/#different-step-types)\n  - [Basic Steps ( `andThen`)](https://voltagent.dev/docs/workflows/execute-api/#basic-steps-andthen)\n  - [AI Agent Steps ( `andAgent`)](https://voltagent.dev/docs/workflows/execute-api/#ai-agent-steps-andagent)\n  - [Conditional Steps ( `andWhen`)](https://voltagent.dev/docs/workflows/execute-api/#conditional-steps-andwhen)\n  - [Side Effects ( `andTap`)](https://voltagent.dev/docs/workflows/execute-api/#side-effects-andtap)\n- [Suspend & Resume Deep Dive](https://voltagent.dev/docs/workflows/execute-api/#suspend--resume-deep-dive)\n- [Best Practices](https://voltagent.dev/docs/workflows/execute-api/#best-practices)\n  - [1\\. Always Return New Objects](https://voltagent.dev/docs/workflows/execute-api/#1-always-return-new-objects)\n  - [2\\. Check Step Data Exists](https://voltagent.dev/docs/workflows/execute-api/#2-check-step-data-exists)\n  - [3\\. Use Clear Step IDs](https://voltagent.dev/docs/workflows/execute-api/#3-use-clear-step-ids)\n  - [4\\. Handle Errors Gracefully](https://voltagent.dev/docs/workflows/execute-api/#4-handle-errors-gracefully)\n  - [5\\. Log Important Events](https://voltagent.dev/docs/workflows/execute-api/#5-log-important-events)\n- [TypeScript Types](https://voltagent.dev/docs/workflows/execute-api/#typescript-types)",
      "metadata": {
        "docusaurus_version": "current",
        "docusaurus_tag": "docs-default-current",
        "og:image": "https://voltagent.dev/img/social3.png",
        "docsearch:language": "en",
        "docsearch:docusaurus_tag": "docs-default-current",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "og:locale": "en",
        "viewport": "width=device-width, initial-scale=1.0",
        "ogLocale": "en",
        "ogTitle": "Execute Function API | VoltAgent",
        "ogUrl": "https://voltagent.dev/docs/workflows/execute-api/",
        "language": "en",
        "twitter:card": "summary_large_image",
        "generator": "Docusaurus v3.1.1",
        "ogDescription": "The heart of every workflow step. Learn how to use the execute function to process data, access workflow state, and control flow.",
        "og:url": "https://voltagent.dev/docs/workflows/execute-api/",
        "docusaurus_locale": "en",
        "og:title": "Execute Function API | VoltAgent",
        "description": "The heart of every workflow step. Learn how to use the execute function to process data, access workflow state, and control flow.",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "title": "Execute Function API | VoltAgent",
        "docsearch:version": "current",
        "og:description": "The heart of every workflow step. Learn how to use the execute function to process data, access workflow state, and control flow.",
        "scrapeId": "497f418f-48b4-40c6-beac-2f370e0cc2da",
        "sourceURL": "https://voltagent.dev/docs/workflows/execute-api/",
        "url": "https://voltagent.dev/docs/workflows/execute-api/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:41:03.841Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/workflows/steps/and-when/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# andWhen\n\n> Add if/then logic to your workflow. Run steps only when conditions are met.\n\n## Quick Start [â€‹](https://voltagent.dev/docs/workflows/steps/and-when/\\#quick-start \"Direct link to Quick Start\")\n\n```codeBlockLines_e6Vv\nimport { createWorkflowChain, andThen } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\nconst workflow = createWorkflowChain({\n  id: \"process-order\",\n  input: z.object({ amount: z.number() }),\n}).andWhen({\n  id: \"check-large-order\",\n  condition: ({ data }) => data.amount > 1000,\n  step: andThen({\n    id: \"apply-discount\",\n    execute: async ({ data }) => ({\n      ...data,\n      discount: 0.1,\n      total: data.amount * 0.9,\n    }),\n  }),\n});\n\n// Large order: { amount: 2000, discount: 0.1, total: 1800 }\n// Small order: { amount: 500 } (unchanged)\n\n```\n\n## How It Works [â€‹](https://voltagent.dev/docs/workflows/steps/and-when/\\#how-it-works \"Direct link to How It Works\")\n\n```codeBlockLines_e6Vv\n.andWhen({\n  condition: ({ data }) => boolean,  // If this returns true...\n  step: someStep                     // ...then run this step\n})\n\n```\n\n- **If condition is true**: Run the step and use its output\n- **If condition is false**: Skip the step, keep original data\n\n## Function Signature [â€‹](https://voltagent.dev/docs/workflows/steps/and-when/\\#function-signature \"Direct link to Function Signature\")\n\n```codeBlockLines_e6Vv\n.andWhen({\n  id: \"step-name\",\n  condition: ({ data }) => data.someField > 100,\n  step: andThen({ execute: async () => {...} })\n})\n\n```\n\n## Common Patterns [â€‹](https://voltagent.dev/docs/workflows/steps/and-when/\\#common-patterns \"Direct link to Common Patterns\")\n\n### Check User Permissions [â€‹](https://voltagent.dev/docs/workflows/steps/and-when/\\#check-user-permissions \"Direct link to Check User Permissions\")\n\n```codeBlockLines_e6Vv\n.andWhen({\n  id: \"check-admin\",\n  condition: ({ state }) => state.userContext?.get(\"role\") === \"admin\",\n  step: andThen({\n    id: \"admin-action\",\n    execute: async ({ data }) => ({\n      ...data,\n      adminData: await getAdminData()\n    })\n  })\n})\n\n```\n\n### Validate Data [â€‹](https://voltagent.dev/docs/workflows/steps/and-when/\\#validate-data \"Direct link to Validate Data\")\n\n```codeBlockLines_e6Vv\n.andWhen({\n  id: \"validate-email\",\n  condition: ({ data }) => data.email && data.email.includes(\"@\"),\n  step: andThen({\n    id: \"process-valid-email\",\n    execute: async ({ data }) => ({\n      ...data,\n      emailValid: true,\n      domain: data.email.split(\"@\")[1]\n    })\n  })\n})\n\n```\n\n### Apply Business Rules [â€‹](https://voltagent.dev/docs/workflows/steps/and-when/\\#apply-business-rules \"Direct link to Apply Business Rules\")\n\n```codeBlockLines_e6Vv\n.andWhen({\n  id: \"free-shipping\",\n  condition: ({ data }) => data.orderTotal > 100,\n  step: andThen({\n    id: \"apply-free-shipping\",\n    execute: async ({ data }) => ({\n      ...data,\n      shipping: 0,\n      message: \"Free shipping applied!\"\n    })\n  })\n})\n\n```\n\n## Chain Multiple Conditions [â€‹](https://voltagent.dev/docs/workflows/steps/and-when/\\#chain-multiple-conditions \"Direct link to Chain Multiple Conditions\")\n\n```codeBlockLines_e6Vv\nworkflow\n  .andWhen({\n    id: \"check-international\",\n    condition: ({ data }) => data.country !== \"US\",\n    step: andThen({\n      id: \"apply-fee\",\n      execute: async ({ data }) => ({\n        ...data,\n        fee: data.amount * 0.03,\n      }),\n    }),\n  })\n  .andWhen({\n    id: \"check-large-amount\",\n    condition: ({ data }) => data.amount > 10000,\n    step: andThen({\n      id: \"require-approval\",\n      execute: async ({ data }) => ({\n        ...data,\n        requiresApproval: true,\n      }),\n    }),\n  });\n\n```\n\n## Schema Support [â€‹](https://voltagent.dev/docs/workflows/steps/and-when/\\#schema-support \"Direct link to Schema Support\")\n\nDefine schemas for type-safe conditions:\n\n```codeBlockLines_e6Vv\n.andWhen({\n  id: \"check-approval\",\n  condition: ({ data }) => data.amount > 1000,\n  step: andThen({\n    id: \"get-approval\",\n    suspendSchema: z.object({\n      reason: z.string()\n    }),\n    resumeSchema: z.object({\n      approved: z.boolean(),\n      approver: z.string()\n    }),\n    execute: async ({ data, suspend, resumeData }) => {\n      if (resumeData) {\n        return { ...data, ...resumeData };\n      }\n      await suspend({ reason: \"Amount exceeds limit\" });\n    }\n  })\n})\n\n```\n\n## Best Practices [â€‹](https://voltagent.dev/docs/workflows/steps/and-when/\\#best-practices \"Direct link to Best Practices\")\n\n1. **Keep conditions simple** \\- One check per condition\n2. **Return false by default** \\- Safer than throwing errors\n3. **Use state for context** \\- Store user info, permissions, etc.\n4. **Chain for complex logic** \\- Multiple small conditions > one big condition\n\n## Next Steps [â€‹](https://voltagent.dev/docs/workflows/steps/and-when/\\#next-steps \"Direct link to Next Steps\")\n\n- **[andAll](https://voltagent.dev/docs/workflows/steps/and-all/)** \\- Run multiple steps in parallel\n- **[andRace](https://voltagent.dev/docs/workflows/steps/and-race/)** \\- First completed step wins\n- **[andThen](https://voltagent.dev/docs/workflows/steps/and-then/)** \\- Chain conditional results with functions\n- **[REST API](https://voltagent.dev/docs/api/overview/#workflow-endpoints)** \\- Execute workflows externally\n\n* * *\n\n> **Remember**: `andWhen` is if/then for workflows. True runs the step, false skips it.\n\n### Table of Contents\n\n- [Quick Start](https://voltagent.dev/docs/workflows/steps/and-when/#quick-start)\n- [How It Works](https://voltagent.dev/docs/workflows/steps/and-when/#how-it-works)\n- [Function Signature](https://voltagent.dev/docs/workflows/steps/and-when/#function-signature)\n- [Common Patterns](https://voltagent.dev/docs/workflows/steps/and-when/#common-patterns)\n  - [Check User Permissions](https://voltagent.dev/docs/workflows/steps/and-when/#check-user-permissions)\n  - [Validate Data](https://voltagent.dev/docs/workflows/steps/and-when/#validate-data)\n  - [Apply Business Rules](https://voltagent.dev/docs/workflows/steps/and-when/#apply-business-rules)\n- [Chain Multiple Conditions](https://voltagent.dev/docs/workflows/steps/and-when/#chain-multiple-conditions)\n- [Schema Support](https://voltagent.dev/docs/workflows/steps/and-when/#schema-support)\n- [Best Practices](https://voltagent.dev/docs/workflows/steps/and-when/#best-practices)\n- [Next Steps](https://voltagent.dev/docs/workflows/steps/and-when/#next-steps)",
      "metadata": {
        "twitter:card": "summary_large_image",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "ogLocale": "en",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "og:image": "https://voltagent.dev/img/social3.png",
        "ogUrl": "https://voltagent.dev/docs/workflows/steps/and-when/",
        "og:locale": "en",
        "docusaurus_version": "current",
        "docusaurus_tag": "docs-default-current",
        "title": "andWhen | VoltAgent",
        "viewport": "width=device-width, initial-scale=1.0",
        "docsearch:version": "current",
        "og:title": "andWhen | VoltAgent",
        "generator": "Docusaurus v3.1.1",
        "language": "en",
        "docsearch:language": "en",
        "description": "Add if/then logic to your workflow. Run steps only when conditions are met.",
        "ogDescription": "Add if/then logic to your workflow. Run steps only when conditions are met.",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:description": "Add if/then logic to your workflow. Run steps only when conditions are met.",
        "og:url": "https://voltagent.dev/docs/workflows/steps/and-when/",
        "ogTitle": "andWhen | VoltAgent",
        "docusaurus_locale": "en",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "scrapeId": "b38951f6-2b05-4249-b09c-bf8ad0e2c221",
        "sourceURL": "https://voltagent.dev/docs/workflows/steps/and-when/",
        "url": "https://voltagent.dev/docs/workflows/steps/and-when/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:58.509Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/api/overview/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\nThe VoltAgent Core API provides a programmatic interface to manage and interact with your VoltAgents. It allows you to list agents, generate text or structured object responses, manage agent history, check for updates, and more.\n\nThe API is built using [Hono](https://hono.dev/), a fast and lightweight web framework for Node.js and other JavaScript runtimes.\n\n## Getting Started [â€‹](https://voltagent.dev/docs/api/overview/\\#getting-started \"Direct link to Getting Started\")\n\nThe Core API server is typically started as part of your application when you initialize VoltAgent. By default, it tries to run on port `3141`, but may use other ports (like 4310, 1337) if the default is unavailable. Check your console output when starting your application to see the exact URL.\n\n```codeBlockLines_e6Vv\n# Example console output\n$ node your-app.js\n\n  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n    VOLTAGENT SERVER STARTED SUCCESSFULLY\n  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n    âœ“ HTTP Server:  http://localhost:3141\n    âœ“ Swagger UI:   http://localhost:3141/ui\n\n    VoltOps Platform:    https://console.voltagent.dev\n  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n```\n\n## Interactive API Documentation (Swagger UI) [â€‹](https://voltagent.dev/docs/api/overview/\\#interactive-api-documentation-swagger-ui \"Direct link to Interactive API Documentation (Swagger UI)\")\n\n![VoltAgent Swagger UI Demo](https://cdn.voltagent.dev/docs/swagger-ui-demo.gif)\n\nTo make exploring and interacting with the API easier, we provide interactive documentation using Swagger UI.\n\n- **Access:** Navigate to `/ui` on your running API server (e.g., `http://localhost:3141/ui`).\n- **Features:**\n  - Lists all available API endpoints grouped by tags (e.g., \"Agent Generation\", \"Agent Management\").\n  - Shows details for each endpoint: HTTP method, path, parameters, request body structure, and possible responses.\n  - Provides example values and schemas.\n  - Allows you to **execute API calls directly from your browser** (\"Try it out\" button) and see the results.\n\nThis is the recommended way to explore the API's capabilities.\n\nDiscoverability\n\nLinks to the Swagger UI ( `/ui`) is also conveniently available on the API server's root page ( `/`) and printed in the console logs when the server starts.\n\n### Swagger UI Configuration [â€‹](https://voltagent.dev/docs/api/overview/\\#swagger-ui-configuration \"Direct link to Swagger UI Configuration\")\n\nYou can control the availability of Swagger UI using the `enableSwaggerUI` option in your VoltAgent configuration:\n\n```codeBlockLines_e6Vv\nimport { Agent, VoltAgent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  name: \"My Assistant\",\n  instructions: \"A helpful assistant\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n});\n\nnew VoltAgent({\n  agents: { agent },\n  server: {\n    enableSwaggerUI: true, // default true in development, false in production\n  },\n});\n\n```\n\n**Default Behavior:**\n\n- **Development** ( `NODE_ENV !== 'production'`): Swagger UI is **enabled**\n- **Production** ( `NODE_ENV === 'production'`): Swagger UI is **disabled**\n\n**Override Examples:**\n\n```codeBlockLines_e6Vv\n// Force enable in production\nnew VoltAgent({\n  agents: { agent },\n  server: {\n    enableSwaggerUI: true, // Always enabled, even in production\n  },\n});\n\n// Force disable in development\nnew VoltAgent({\n  agents: { agent },\n  server: {\n    enableSwaggerUI: false, // Always disabled, even in development\n  },\n});\n\n```\n\n## Common Generation Options [â€‹](https://voltagent.dev/docs/api/overview/\\#common-generation-options \"Direct link to Common Generation Options\")\n\nWhen using the generation endpoints ( `/text`, `/stream`, `/object`, `/stream-object`), you can provide an `options` object in the request body to customize the generation process. All options are optional.\n\n| Option | Description | Type | Default |\n| --- | --- | --- | --- |\n| `userId` | Optional user ID for context tracking. | `string` | - |\n| `conversationId` | Optional conversation ID for context tracking. | `string` | - |\n| `contextLimit` | Optional limit for conversation history context. | `number` (integer) | `10` |\n| `maxSteps` | Maximum number of iteration steps for this request (overrides agent's maxSteps). | `number` (integer) | - |\n| `temperature` | Controls randomness (0-1). Lower is more deterministic. | `number` | `0.7` |\n| `maxTokens` | Maximum number of tokens to generate in the response. | `number` (integer) | `4000` |\n| `topP` | Controls diversity via nucleus sampling (0-1). | `number` | `1.0` |\n| `frequencyPenalty` | Penalizes repeated tokens (0-2). Higher values decrease repetition. | `number` | `0.0` |\n| `presencePenalty` | Penalizes tokens based on presence (0-2). Higher values encourage new topics. | `number` | `0.0` |\n| `seed` | Optional integer seed for reproducible results. | `number` (integer) | - |\n| `stopSequences` | An array of strings that will stop generation if encountered. | `array` of `string` | - |\n| `extraOptions` | A key-value object for provider-specific options. | `object` | - |\n| `userContext` | A key-value object for dynamic agent context (roles, tiers, etc.). | `object` | - |\n\n### Understanding maxSteps [â€‹](https://voltagent.dev/docs/api/overview/\\#understanding-maxsteps \"Direct link to Understanding maxSteps\")\n\nThe `maxSteps` parameter controls the number of iteration steps an agent can take during a single operation. This is particularly important for agents that use tools or coordinate with sub-agents, as they may require multiple LLM interactions to complete a task.\n\n**When to Use maxSteps:**\n\n- **Tool-using Agents**: Agents that make API calls, database queries, or other tool executions may need multiple steps to complete complex tasks\n- **Multi-agent Workflows**: Supervisor agents coordinating sub-agents need step limits to prevent runaway execution\n- **Resource Control**: Limit computational costs and execution time for expensive operations\n\n**Step Examples:**\n\n```codeBlockLines_e6Vv\n{\n  \"input\": \"Research the latest AI trends and write a summary\",\n  \"options\": {\n    \"maxSteps\": 8,\n    \"temperature\": 0.7\n  }\n}\n\n```\n\nThis might result in:\n\n1. Agent analyzes the request\n2. Agent uses research tool to gather data\n3. Agent processes research results\n4. Agent uses writing tool to draft content\n5. Agent reviews and refines the output\n6. Agent finalizes the response\n\n**Priority Order:**\n\n1. API request `maxSteps` option (highest priority)\n2. Agent-level `maxSteps` configuration\n3. Default calculation (10 Ã— number of sub-agents, minimum 10)\n\n**For Sub-agent Workflows**: The `maxSteps` limit applies to the entire workflow. All sub-agents inherit and share the same step budget, preventing infinite delegation loops.\n\n## Abort Signal Support [â€‹](https://voltagent.dev/docs/api/overview/\\#abort-signal-support \"Direct link to Abort Signal Support\")\n\nVoltAgent Core API now supports graceful operation cancellation using the standard Web API `AbortSignal`. This enables clients to cancel expensive operations when users navigate away or manually stop requests.\n\n### Client-Side Cancellation [â€‹](https://voltagent.dev/docs/api/overview/\\#client-side-cancellation \"Direct link to Client-Side Cancellation\")\n\nUse the standard `AbortController` to cancel requests:\n\n```codeBlockLines_e6Vv\n// Create AbortController\nconst abortController = new AbortController();\n\n// Cancel when user navigates away\nwindow.addEventListener(\"beforeunload\", () => abortController.abort());\n\n// Stream request with abort signal\nconst response = await fetch(\"http://localhost:3141/agents/my-agent/stream\", {\n  method: \"POST\",\n  headers: { \"Content-Type\": \"application/json\" },\n  body: JSON.stringify({\n    input: \"Write a very long story...\",\n    options: { maxTokens: 4000 },\n  }),\n  signal: abortController.signal, // âœ… Automatic cancellation\n});\n\n// Manual cancellation after timeout\nsetTimeout(() => abortController.abort(), 10000);\n\n```\n\n### Supported Endpoints [â€‹](https://voltagent.dev/docs/api/overview/\\#supported-endpoints \"Direct link to Supported Endpoints\")\n\nAll generation endpoints support abort signals:\n\n- **`/text`** \\- Non-streaming text generation\n- **`/stream`** \\- Streaming text generation\n- **`/object`** \\- Non-streaming object generation\n- **`/stream-object`** \\- Streaming object generation\n\n### Cancellation Behavior [â€‹](https://voltagent.dev/docs/api/overview/\\#cancellation-behavior \"Direct link to Cancellation Behavior\")\n\nWhen a request is cancelled:\n\n1. **Server-side**: Agent operations stop gracefully and resources are cleaned up\n2. **Non-streaming**: HTTP request terminates with standard abort behavior\n3. **Streaming**: SSE stream closes and no further events are sent\n4. **SubAgents**: Cancellation propagates through sub-agent hierarchies\n\n### Error Handling with Abort [â€‹](https://voltagent.dev/docs/api/overview/\\#error-handling-with-abort \"Direct link to Error Handling with Abort\")\n\nFor abort-related errors, see the Error Handling section below for details on how cancellation is reported.\n\n## OpenAPI Specification [â€‹](https://voltagent.dev/docs/api/overview/\\#openapi-specification \"Direct link to OpenAPI Specification\")\n\nFor developers needing the raw API specification for code generation or other tooling, the OpenAPI 3.1 specification is available in JSON format.\n\n- **Access:** Navigate to `/doc` on your running API server (e.g., `http://localhost:3141/doc`).\n\n## Key Endpoints (via Swagger UI) [â€‹](https://voltagent.dev/docs/api/overview/\\#key-endpoints-via-swagger-ui \"Direct link to Key Endpoints (via Swagger UI)\")\n\nWhile the Swagger UI ( `/ui`) provides the most comprehensive details, here's a brief overview of the main functionalities documented:\n\n- **`GET /agents`**: Lists all agents currently registered with the `AgentRegistry`.\n- **`POST /agents/{id}/text`**: Generates a plain text response from the specified agent based on the input prompt and options.\n- **`POST /agents/{id}/stream`**: Streams a text response chunk by chunk using Server-Sent Events (SSE).\n- **`POST /agents/{id}/object`**: Generates a structured JSON object response from the agent, guided by a provided schema.\n- **`POST /agents/{id}/stream-object`**: Streams parts of a structured JSON object response using SSE.\n- **`POST /workflows/{id}/execute`**: Executes a workflow with the provided input data and returns the result.\n- **(Other endpoints)**: Explore `/ui` for details on history, tool execution, update checks, etc.\n\nObject Generation Schema Mismatch\n\nPlease note that while the API documentation for `/object` and `/stream-object` specifies that the `schema` parameter should be a standard JSON Schema object, the current backend implementation ( `Agent.generateObject`, `Agent.streamObject`) still expects a Zod schema instance.\n\n## Custom REST Endpoints [â€‹](https://voltagent.dev/docs/api/overview/\\#custom-rest-endpoints \"Direct link to Custom REST Endpoints\")\n\nVoltAgent allows you to register custom REST API endpoints alongside the built-in agent endpoints. This feature enables you to extend your API server with custom business logic, data endpoints, or integration points.\n\n### Overview [â€‹](https://voltagent.dev/docs/api/overview/\\#overview \"Direct link to Overview\")\n\nCustom endpoints are regular REST API routes that you can define with:\n\n- **Path**: URL pattern (with optional parameters)\n- **HTTP Method**: GET, POST, PUT, PATCH, DELETE, OPTIONS\n- **Handler**: Function that processes requests and returns responses\n- **Description**: Optional documentation string\n\nAll custom endpoints are automatically displayed in the server startup banner and are included in your API server alongside the core VoltAgent endpoints.\n\n### Server Configuration [â€‹](https://voltagent.dev/docs/api/overview/\\#server-configuration \"Direct link to Server Configuration\")\n\nVoltAgent uses a unified `server` object to configure all server-related options including custom endpoints, Swagger UI, port, and auto-start behavior:\n\n```codeBlockLines_e6Vv\nnew VoltAgent({\n  agents: { myAgent },\n  server: {\n    autoStart: true, // default true\n    port: 3000, // default 3141\n    enableSwaggerUI: true, // default true in development, false in production\n    customEndpoints: [\\\n      // Custom API endpoints\\\n      {\\\n        path: \"/api/health\",\\\n        method: \"get\" as const,\\\n        handler: async (c) => c.json({ status: \"healthy\" }),\\\n        description: \"Health check endpoint\",\\\n      },\\\n    ],\n  },\n});\n\n```\n\n### Registration Methods [â€‹](https://voltagent.dev/docs/api/overview/\\#registration-methods \"Direct link to Registration Methods\")\n\nYou can register custom endpoints using two different methods:\n\n- Function Call Registration\n- Constructor Registration\n\nUse `registerCustomEndpoints()` for programmatic registration, conditional logic, or when you need to register endpoints before creating the VoltAgent instance.\n\n```codeBlockLines_e6Vv\nimport { registerCustomEndpoints } from \"@voltagent/core\";\n\nconst endpoints = [\\\n  {\\\n    path: \"/api/health\",\\\n    method: \"get\" as const,\\\n    handler: async (c) => {\\\n      return c.json({\\\n        success: true,\\\n        data: { status: \"healthy\", timestamp: new Date().toISOString() },\\\n      });\\\n    },\\\n    description: \"Health check endpoint\",\\\n  },\\\n];\n\n// Register before creating VoltAgent\nregisterCustomEndpoints(endpoints);\n\n// Then create your VoltAgent instance\nnew VoltAgent({ agents: { myAgent } });\n\n```\n\n**Best for:**\n\n- Conditional endpoint registration\n- Registering endpoints before VoltAgent creation\n- Multiple registration calls\n- Dynamic endpoint configuration\n\n#### Using Both Methods [â€‹](https://voltagent.dev/docs/api/overview/\\#using-both-methods \"Direct link to Using Both Methods\")\n\nBoth methods work together! You can use them simultaneously and all endpoints will be properly registered.\n\n```codeBlockLines_e6Vv\n// Function Call: Register some endpoints via function\nregisterCustomEndpoints(authEndpoints);\n\n// Constructor: Register others via constructor\nnew VoltAgent({\n  agents: { myAgent },\n  server: {\n    customEndpoints: dataEndpoints,\n  },\n});\n\n// Result: Both authEndpoints and dataEndpoints are registered\n\n```\n\n### Endpoint Definition Structure [â€‹](https://voltagent.dev/docs/api/overview/\\#endpoint-definition-structure \"Direct link to Endpoint Definition Structure\")\n\nEach custom endpoint follows this TypeScript interface:\n\n```codeBlockLines_e6Vv\ninterface CustomEndpointDefinition {\n  path: string; // Must start with \"/\"\n  method: HttpMethod; // \"get\" | \"post\" | \"put\" | \"patch\" | \"delete\" | \"options\"\n  handler: Function; // Request handler function\n  description?: string; // Optional description for documentation\n}\n\n```\n\n### Path Patterns [â€‹](https://voltagent.dev/docs/api/overview/\\#path-patterns \"Direct link to Path Patterns\")\n\nCustom endpoints support various path patterns:\n\n```codeBlockLines_e6Vv\nconst endpoints = [\\\n  // Static paths\\\n  { path: \"/api/health\", method: \"get\", handler: healthHandler },\\\n\\\n  // Path parameters\\\n  { path: \"/api/users/:id\", method: \"get\", handler: getUserHandler },\\\n  { path: \"/api/posts/:postId/comments/:commentId\", method: \"get\", handler: getCommentHandler },\\\n\\\n  // Nested paths\\\n  { path: \"/api/v1/admin/users\", method: \"post\", handler: createUserHandler },\\\n\\\n  // File-like paths\\\n  { path: \"/api/files/:filename\", method: \"get\", handler: getFileHandler },\\\n];\n\n```\n\n### Handler Functions [â€‹](https://voltagent.dev/docs/api/overview/\\#handler-functions \"Direct link to Handler Functions\")\n\nHandler functions receive a Hono context object with request/response utilities:\n\n```codeBlockLines_e6Vv\nconst endpoints = [\\\n  // GET endpoint\\\n  {\\\n    path: \"/api/users/:id\",\\\n    method: \"get\" as const,\\\n    handler: async (c) => {\\\n      const userId = c.req.param(\"id\");\\\n      const user = await getUserById(userId);\\\n\\\n      if (!user) {\\\n        return c.json({ success: false, error: \"User not found\" }, 404);\\\n      }\\\n\\\n      return c.json({ success: true, data: user });\\\n    },\\\n  },\\\n\\\n  // POST endpoint with JSON body\\\n  {\\\n    path: \"/api/users\",\\\n    method: \"post\" as const,\\\n    handler: async (c) => {\\\n      try {\\\n        const body = await c.req.json();\\\n        const { name, email } = body;\\\n\\\n        const newUser = await createUser({ name, email });\\\n        return c.json({ success: true, data: newUser }, 201);\\\n      } catch (error) {\\\n        return c.json(\\\n          {\\\n            success: false,\\\n            error: \"Invalid request body\",\\\n          },\\\n          400\\\n        );\\\n      }\\\n    },\\\n  },\\\n\\\n  // Query parameters\\\n  {\\\n    path: \"/api/search\",\\\n    method: \"get\" as const,\\\n    handler: async (c) => {\\\n      const query = c.req.query(\"q\");\\\n      const limit = parseInt(c.req.query(\"limit\") || \"10\");\\\n\\\n      const results = await searchData(query, limit);\\\n      return c.json({ success: true, data: results });\\\n    },\\\n  },\\\n];\n\n```\n\n### Request/Response Utilities [â€‹](https://voltagent.dev/docs/api/overview/\\#requestresponse-utilities \"Direct link to Request/Response Utilities\")\n\nThe handler context provides these utilities:\n\n```codeBlockLines_e6Vv\nhandler: async (c) => {\n  // Path parameters\n  const id = c.req.param(\"id\");\n\n  // Query parameters\n  const page = c.req.query(\"page\");\n  const filters = c.req.queries(\"filter\"); // Array for multiple values\n\n  // Request body\n  const jsonData = await c.req.json();\n  const formData = await c.req.formData();\n  const textData = await c.req.text();\n\n  // Headers\n  const authHeader = c.req.header(\"authorization\");\n\n  // JSON response\n  return c.json({ data: \"response\" });\n\n  // Text response\n  return c.text(\"Hello World\");\n\n  // HTML response\n  return c.html(\"<h1>Hello</h1>\");\n\n  // Custom response\n  return c.body(\"Custom content\", {\n    status: 201,\n    headers: { \"Content-Type\": \"text/plain\" },\n  });\n\n  // Redirect\n  return c.redirect(\"/new-url\");\n};\n\n```\n\n## Workflow Endpoints [â€‹](https://voltagent.dev/docs/api/overview/\\#workflow-endpoints \"Direct link to Workflow Endpoints\")\n\nVoltAgent provides a comprehensive set of REST API endpoints for managing and executing workflows. These endpoints allow you to list workflows, execute them, and control their execution state (suspend/resume).\n\n### List All Workflows [â€‹](https://voltagent.dev/docs/api/overview/\\#list-all-workflows \"Direct link to List All Workflows\")\n\n**`GET /workflows`**\n\nReturns a list of all registered workflows in the system.\n\n**Response:**\n\n```codeBlockLines_e6Vv\n{\n  \"success\": true,\n  \"data\": [\\\n    {\\\n      \"id\": \"order-approval\",\\\n      \"name\": \"Order Approval Workflow\",\\\n      \"purpose\": \"Process and approve customer orders\",\\\n      \"stepsCount\": 5,\\\n      \"status\": \"idle\"\\\n    },\\\n    {\\\n      \"id\": \"user-verification\",\\\n      \"name\": \"User Verification\",\\\n      \"purpose\": \"Verify new user accounts\",\\\n      \"stepsCount\": 3,\\\n      \"status\": \"idle\"\\\n    }\\\n  ]\n}\n\n```\n\n**cURL Example:**\n\n```codeBlockLines_e6Vv\ncurl http://localhost:3141/workflows\n\n```\n\n### Execute Workflow [â€‹](https://voltagent.dev/docs/api/overview/\\#execute-workflow \"Direct link to Execute Workflow\")\n\n**`POST /workflows/{id}/execute`**\n\nExecutes a workflow with the provided input data. The workflow runs to completion or until it suspends.\n\n**Request Body:**\n\n```codeBlockLines_e6Vv\n{\n  \"input\": any,  // Workflow-specific input data\n  \"options\": {\n    \"userId\": \"string\",         // Optional: User ID for tracking\n    \"conversationId\": \"string\", // Optional: Conversation ID\n    \"userContext\": {}          // Optional: Custom context data\n  }\n}\n\n```\n\n**Response (Completed):**\n\n```codeBlockLines_e6Vv\n{\n  \"success\": true,\n  \"data\": {\n    \"executionId\": \"exec_1234567890_abc123\",\n    \"startAt\": \"2024-01-15T10:00:00.000Z\",\n    \"endAt\": \"2024-01-15T10:00:05.123Z\",\n    \"status\": \"completed\",\n    \"result\": {\n      // Workflow-specific output\n    }\n  }\n}\n\n```\n\n**Response (Suspended):**\n\n```codeBlockLines_e6Vv\n{\n  \"success\": true,\n  \"data\": {\n    \"executionId\": \"exec_1234567890_abc123\",\n    \"startAt\": \"2024-01-15T10:00:00.000Z\",\n    \"endAt\": null,\n    \"status\": \"suspended\",\n    \"result\": null,\n    \"suspension\": {\n      \"suspendedAt\": \"2024-01-15T10:00:02.500Z\",\n      \"reason\": \"Waiting for manager approval\",\n      \"suspendedStepIndex\": 2\n    }\n  }\n}\n\n```\n\n**Example:**\n\n```codeBlockLines_e6Vv\ncurl -X POST http://localhost:3141/workflows/order-approval/execute \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"input\": {\n         \"orderId\": \"order-123\",\n         \"amount\": 5000,\n         \"customerEmail\": \"customer@example.com\"\n       },\n       \"options\": {\n         \"userId\": \"user-456\"\n       }\n     }'\n\n```\n\n### Stream Workflow Execution [â€‹](https://voltagent.dev/docs/api/overview/\\#stream-workflow-execution \"Direct link to Stream Workflow Execution\")\n\n**`POST /workflows/{id}/stream`**\n\nExecute a workflow and receive real-time events via Server-Sent Events (SSE). This endpoint is perfect for monitoring workflow execution progress in real-time.\n\nCurrent Limitation\n\nThe REST API currently does not support continuous streaming across suspend/resume cycles:\n\n- **Initial execution**: Streamed via SSE in real-time âœ…\n- **When suspended**: Stream closes with a suspension event âš ï¸\n- **Resume operation**: Returns complete result (not streamed) âš ï¸\n\n**Coming Soon:** WebSocket-based continuous streaming is being considered for future releases. If you need this feature, please [open an issue](https://github.com/VoltAgent/voltagent/issues) with your use case.\n\n**Request Body:**\n\n```codeBlockLines_e6Vv\n{\n  \"input\": any,           // Workflow input data (validated against workflow's input schema)\n  \"options\": {\n    \"userId\": \"string\",          // Optional: User ID for context\n    \"conversationId\": \"string\",  // Optional: Conversation ID\n    \"executionId\": \"string\",     // Optional: Custom execution ID\n    \"userContext\": object        // Optional: Additional context\n  }\n}\n\n```\n\n**Response:** Server-Sent Events stream\n\nEach event is formatted as:\n\n```codeBlockLines_e6Vv\ndata: {\"type\":\"event-type\",\"executionId\":\"...\",\"from\":\"...\",\"status\":\"...\",\"timestamp\":\"...\"}\\n\\n\n\n```\n\n**Event Types:**\n\n- `workflow-start` \\- Workflow execution started\n- `step-start` \\- Step execution started\n- `step-complete` \\- Step completed successfully\n- `workflow-suspended` \\- Workflow suspended (stream closes after this)\n- `workflow-complete` \\- Workflow completed successfully\n- `workflow-error` \\- Workflow encountered an error\n- `workflow-result` \\- Final execution result\n\n**Complete Example with Suspend/Resume:**\n\n```codeBlockLines_e6Vv\nasync function executeWorkflowWithStreaming() {\n  const workflowId = \"expense-approval\";\n  let executionId = null;\n\n  // Phase 1: Stream initial execution\n  console.log(\"Starting workflow stream...\");\n  const response = await fetch(`/workflows/${workflowId}/stream`, {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify({\n      input: {\n        employeeId: \"emp-123\",\n        amount: 5000,\n        category: \"travel\",\n        description: \"Conference trip\",\n      },\n    }),\n  });\n\n  // Process SSE events\n  const reader = response.body.getReader();\n  const decoder = new TextDecoder();\n  let buffer = \"\";\n\n  while (true) {\n    const { done, value } = await reader.read();\n    if (done) break;\n\n    buffer += decoder.decode(value, { stream: true });\n    const lines = buffer.split(\"\\n\");\n    buffer = lines.pop() || \"\";\n\n    for (const line of lines) {\n      if (line.startsWith(\"data: \")) {\n        const event = JSON.parse(line.slice(6));\n        console.log(`[${event.type}] ${event.from || \"\"}`);\n\n        if (event.executionId) {\n          executionId = event.executionId;\n        }\n\n        // Stream closes on suspension\n        if (event.type === \"workflow-suspended\") {\n          console.log(\"Workflow suspended, stream closed\");\n          console.log(\"Suspension reason:\", event.metadata?.reason);\n        }\n      }\n    }\n  }\n\n  // Phase 2: Resume via standard endpoint (not streamed)\n  if (executionId) {\n    console.log(\"Approving expense...\");\n    const resumeResponse = await fetch(\n      `/workflows/${workflowId}/executions/${executionId}/resume`,\n      {\n        method: \"POST\",\n        headers: { \"Content-Type\": \"application/json\" },\n        body: JSON.stringify({\n          resumeData: {\n            approved: true,\n            managerId: \"mgr-456\",\n            comments: \"Approved for business travel\",\n          },\n        }),\n      }\n    );\n\n    const result = await resumeResponse.json();\n    console.log(\"Resume completed:\", result);\n    // Note: Resume returns complete result, not streamed events\n  }\n}\n\n```\n\n**Current Architecture Benefits:**\n\n1. **Stateless**: Each request is independent, no server state required\n2. **Scalable**: Works seamlessly with load balancers and horizontal scaling\n3. **Simple**: Clear separation between streaming (monitoring) and execution (business logic)\n4. **Reliable**: Server restarts don't affect resumed executions\n\n**Future Enhancement:**\nWe're exploring WebSocket-based continuous streaming to maintain connections across suspend/resume cycles. Help us prioritize this feature by [sharing your use case on GitHub](https://github.com/VoltAgent/voltagent/issues).\n\n### Suspend Running Workflow [â€‹](https://voltagent.dev/docs/api/overview/\\#suspend-running-workflow \"Direct link to Suspend Running Workflow\")\n\n**`POST /workflows/{id}/executions/{executionId}/suspend`**\n\nSuspends a currently running workflow execution. This is useful for pausing long-running workflows or when external intervention is needed.\n\n**Request Body:**\n\n```codeBlockLines_e6Vv\n{\n  \"reason\": \"string\" // Optional: Reason for suspension\n}\n\n```\n\n**Response:**\n\n```codeBlockLines_e6Vv\n{\n  \"success\": true,\n  \"data\": {\n    \"executionId\": \"exec_1234567890_abc123\",\n    \"status\": \"suspended\",\n    \"suspension\": {\n      \"suspendedAt\": \"2024-01-15T10:30:45.123Z\",\n      \"reason\": \"User clicked pause button\"\n    }\n  }\n}\n\n```\n\n**Error Responses:**\n\n- `404`: Workflow execution not found\n- `400`: Cannot suspend workflow in current state (e.g., already completed or suspended)\n\n**Example:**\n\n```codeBlockLines_e6Vv\ncurl -X POST http://localhost:3141/workflows/data-processing/executions/exec_1234567890_abc123/suspend \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"reason\": \"System maintenance required\"}'\n\n```\n\n### Resume Suspended Workflow [â€‹](https://voltagent.dev/docs/api/overview/\\#resume-suspended-workflow \"Direct link to Resume Suspended Workflow\")\n\n**`POST /workflows/{id}/executions/{executionId}/resume`**\n\nResumes a suspended workflow execution. You can provide data to the suspended step and optionally specify which step to resume from.\n\n**Request Body:**\n\n```codeBlockLines_e6Vv\n{\n  \"resumeData\": any,      // Optional: Data to pass to the resumed step\n  \"options\": {\n    \"stepId\": \"string\"    // Optional: Specific step ID to resume from\n  }\n}\n\n```\n\n**Response:**\n\n```codeBlockLines_e6Vv\n{\n  \"success\": true,\n  \"data\": {\n    \"executionId\": \"exec_1234567890_abc123\",\n    \"startAt\": \"2024-01-15T10:00:00.000Z\",\n    \"endAt\": \"2024-01-15T10:35:20.456Z\",\n    \"status\": \"completed\",\n    \"result\": {\n      // Final workflow output\n    }\n  }\n}\n\n```\n\n**Error Responses:**\n\n- `404`: Workflow execution not found or not in suspended state\n- `400`: Invalid resume data (fails schema validation)\n\n**Examples:**\n\nSimple resume:\n\n```codeBlockLines_e6Vv\ncurl -X POST http://localhost:3141/workflows/order-approval/executions/exec_1234567890_abc123/resume \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"resumeData\": {\n         \"approved\": true,\n         \"approvedBy\": \"manager@company.com\"\n       }\n     }'\n\n```\n\nResume from specific step:\n\n```codeBlockLines_e6Vv\ncurl -X POST http://localhost:3141/workflows/multi-step/executions/exec_9876543210_xyz789/resume \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"resumeData\": {\n         \"retryWithNewData\": true\n       },\n       \"options\": {\n         \"stepId\": \"step-3\"\n       }\n     }'\n\n```\n\n### Complete Workflow Management Example [â€‹](https://voltagent.dev/docs/api/overview/\\#complete-workflow-management-example \"Direct link to Complete Workflow Management Example\")\n\nHere's a complete example showing the full lifecycle of workflow execution via REST API:\n\n```codeBlockLines_e6Vv\nconst API_BASE = \"http://localhost:3141\";\n\nclass WorkflowClient {\n  // List available workflows\n  async listWorkflows() {\n    const response = await fetch(`${API_BASE}/workflows`);\n    const result = await response.json();\n    return result.data;\n  }\n\n  // Execute a workflow\n  async executeWorkflow(workflowId, input, options = {}) {\n    const response = await fetch(`${API_BASE}/workflows/${workflowId}/execute`, {\n      method: \"POST\",\n      headers: { \"Content-Type\": \"application/json\" },\n      body: JSON.stringify({ input, options }),\n    });\n\n    const result = await response.json();\n    if (!result.success) {\n      throw new Error(result.error);\n    }\n\n    return result.data;\n  }\n\n  // Suspend a running workflow\n  async suspendWorkflow(workflowId, executionId, reason) {\n    const response = await fetch(\n      `${API_BASE}/workflows/${workflowId}/executions/${executionId}/suspend`,\n      {\n        method: \"POST\",\n        headers: { \"Content-Type\": \"application/json\" },\n        body: JSON.stringify({ reason }),\n      }\n    );\n\n    const result = await response.json();\n    if (!result.success) {\n      throw new Error(result.error);\n    }\n\n    return result.data;\n  }\n\n  // Resume a suspended workflow\n  async resumeWorkflow(workflowId, executionId, resumeData, stepId) {\n    const body = { resumeData };\n    if (stepId) {\n      body.options = { stepId };\n    }\n\n    const response = await fetch(\n      `${API_BASE}/workflows/${workflowId}/executions/${executionId}/resume`,\n      {\n        method: \"POST\",\n        headers: { \"Content-Type\": \"application/json\" },\n        body: JSON.stringify(body),\n      }\n    );\n\n    const result = await response.json();\n    if (!result.success) {\n      throw new Error(result.error);\n    }\n\n    return result.data;\n  }\n}\n\n// Usage example\nasync function handleOrderApproval() {\n  const client = new WorkflowClient();\n\n  try {\n    // 1. Start the workflow\n    console.log(\"Starting order approval workflow...\");\n    const execution = await client.executeWorkflow(\n      \"order-approval\",\n      {\n        orderId: \"order-789\",\n        amount: 15000,\n        customerType: \"premium\",\n      },\n      {\n        userId: \"user-123\",\n        userContext: { department: \"sales\" },\n      }\n    );\n\n    console.log(\"Execution ID:\", execution.executionId);\n\n    // 2. Check if workflow is suspended\n    if (execution.status === \"suspended\") {\n      console.log(\"Workflow suspended:\", execution.suspension.reason);\n\n      // 3. Simulate manager approval after 5 seconds\n      setTimeout(async () => {\n        console.log(\"Manager approved the order\");\n\n        const result = await client.resumeWorkflow(\"order-approval\", execution.executionId, {\n          approved: true,\n          managerId: \"mgr-456\",\n          comments: \"Approved for VIP customer\",\n        });\n\n        console.log(\"Final result:\", result);\n      }, 5000);\n    } else {\n      console.log(\"Workflow completed immediately:\", execution.result);\n    }\n  } catch (error) {\n    console.error(\"Workflow error:\", error.message);\n  }\n}\n\n// Run the example\nhandleOrderApproval();\n\n```\n\n### Workflow Status Values [â€‹](https://voltagent.dev/docs/api/overview/\\#workflow-status-values \"Direct link to Workflow Status Values\")\n\nWorkflows can have the following status values:\n\n- **`idle`**: Workflow is registered but not currently executing\n- **`running`**: Workflow is actively executing\n- **`suspended`**: Workflow is paused and waiting for resume\n- **`completed`**: Workflow finished successfully\n- **`error`**: Workflow terminated with an error\n\n### Best Practices [â€‹](https://voltagent.dev/docs/api/overview/\\#best-practices \"Direct link to Best Practices\")\n\n1. **Always save the executionId**: You'll need it for suspend/resume operations\n2. **Handle suspended status**: Check if a workflow suspended after execution\n3. **Validate resume data**: Ensure resume data matches the workflow's schema\n4. **Use meaningful suspension reasons**: This helps with debugging and UI display\n5. **Implement proper error handling**: Handle 404s and 400s appropriately\n6. **Consider timeout scenarios**: Suspended workflows might expire based on your business logic\n\n## Authentication [â€‹](https://voltagent.dev/docs/api/overview/\\#authentication \"Direct link to Authentication\")\n\nCurrently, the Core API does not implement built-in authentication routes. Ensure that your API server is deployed in a secure environment or protected by appropriate network-level security (e.g., firewall rules, reverse proxy authentication) if exposing it outside your local machine.\n\n## Error Handling [â€‹](https://voltagent.dev/docs/api/overview/\\#error-handling \"Direct link to Error Handling\")\n\nThe VoltAgent Core API provides comprehensive error handling for both regular HTTP endpoints and streaming endpoints.\n\n### Regular Endpoints (Non-Streaming) [â€‹](https://voltagent.dev/docs/api/overview/\\#regular-endpoints-non-streaming \"Direct link to Regular Endpoints (Non-Streaming)\")\n\nFor regular endpoints like `/text` and `/object`, errors are returned as standard HTTP responses:\n\n```codeBlockLines_e6Vv\n{\n  \"success\": false,\n  \"error\": \"Error message describing what went wrong\"\n}\n\n```\n\nCommon HTTP status codes:\n\n- `404`: Agent not found\n- `500`: Internal server error (e.g., invalid schema, agent processing error)\n- **Request cancelled**: When using `AbortSignal`, the request will be cancelled according to standard fetch abort behavior\n\n## Passing User Context for Dynamic Agents [â€‹](https://voltagent.dev/docs/api/overview/\\#passing-user-context-for-dynamic-agents \"Direct link to Passing User Context for Dynamic Agents\")\n\nFor dynamic agents that adapt their behavior based on user context, you can pass a `userContext` object in the request options. This allows agents to dynamically adjust their instructions, models, and tools based on user roles, subscription tiers, languages, or any other contextual information.\n\n### User Context Format [â€‹](https://voltagent.dev/docs/api/overview/\\#user-context-format \"Direct link to User Context Format\")\n\nThe `userContext` should be a flat key-value object where keys are strings and values can be any JSON-serializable data:\n\n```codeBlockLines_e6Vv\n{\n  \"input\": \"Help me with my account\",\n  \"options\": {\n    \"userContext\": {\n      \"role\": \"premium_user\",\n      \"language\": \"Spanish\",\n      \"tier\": \"pro\",\n      \"userId\": \"user-123\",\n      \"company\": \"TechCorp\"\n    },\n    \"temperature\": 0.7,\n    \"maxTokens\": 500\n  }\n}\n\n```\n\n### Example API Calls with User Context [â€‹](https://voltagent.dev/docs/api/overview/\\#example-api-calls-with-user-context \"Direct link to Example API Calls with User Context\")\n\n**Text Generation with User Context:**\n\n```codeBlockLines_e6Vv\ncurl -X POST http://localhost:3141/agents/dynamic-agent/text \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"input\": \"I need help with system administration\",\n       \"options\": {\n         \"userContext\": {\n           \"role\": \"admin\",\n           \"language\": \"English\",\n           \"tier\": \"enterprise\"\n         },\n         \"temperature\": 0.8\n       }\n     }'\n\n```\n\n**Streaming with User Context:**\n\n```codeBlockLines_e6Vv\ncurl -N -X POST http://localhost:3141/agents/dynamic-agent/stream \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"input\": \"What are my available options?\",\n       \"options\": {\n         \"userContext\": {\n           \"role\": \"customer\",\n           \"language\": \"French\",\n           \"tier\": \"basic\"\n         }\n       }\n     }'\n\n```\n\n**Object Generation with User Context:**\n\n```codeBlockLines_e6Vv\ncurl -X POST http://localhost:3141/agents/dynamic-agent/object \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"input\": \"Extract user information from: John is a premium admin from TechCorp\",\n       \"schema\": {\n         \"type\": \"object\",\n         \"properties\": {\n           \"name\": {\"type\": \"string\"},\n           \"role\": {\"type\": \"string\"},\n           \"tier\": {\"type\": \"string\"}\n         }\n       },\n       \"options\": {\n         \"userContext\": {\n           \"extractionMode\": \"detailed\",\n           \"language\": \"English\"\n         }\n       }\n     }'\n\n```\n\nThe dynamic agent will receive this context and adapt its behavior accordingly - using different instructions, models, or tools based on the provided context values.\n\n### Streaming Endpoints (SSE) [â€‹](https://voltagent.dev/docs/api/overview/\\#streaming-endpoints-sse \"Direct link to Streaming Endpoints (SSE)\")\n\nFor streaming endpoints like `/stream` and `/stream-object`, errors are delivered as Server-Sent Events within the stream itself. This allows real-time error reporting during long-running operations.\n\n#### Error Event Format [â€‹](https://voltagent.dev/docs/api/overview/\\#error-event-format \"Direct link to Error Event Format\")\n\nWhen an error occurs during streaming, you'll receive an SSE event with `type: \"error\"`:\n\n```codeBlockLines_e6Vv\ndata: {\n  \"type\": \"error\",\n  \"error\": \"Error message describing what went wrong\",\n  \"code\": \"ERROR_CODE\",\n  \"timestamp\": \"2024-01-15T10:30:45.123Z\"\n}\n\n```\n\n#### Error Types and Codes [â€‹](https://voltagent.dev/docs/api/overview/\\#error-types-and-codes \"Direct link to Error Types and Codes\")\n\n| Error Code | Description | When it occurs |\n| --- | --- | --- |\n| `SETUP_ERROR` | Error during initial setup | Agent initialization or configuration issues |\n| `STREAM_ERROR` | Generic streaming error | LLM provider errors, network issues, invalid API keys |\n| `ITERATION_ERROR` | Error during stream processing | Issues while processing stream chunks |\n| `USER_CANCELLED` | Operation cancelled by user | When `AbortSignal` is triggered by client |\n\n#### Streaming Event Flow [â€‹](https://voltagent.dev/docs/api/overview/\\#streaming-event-flow \"Direct link to Streaming Event Flow\")\n\nA typical successful stream contains these event types:\n\n1. `text` or `object` events (data chunks)\n2. `completion` event (stream finished successfully)\n\nA stream with errors will contain:\n\n1. `text` or `object` events (if any data was processed)\n2. `error` event (when error occurs)\n3. Stream closes after error event\n\n#### Example Error Scenarios [â€‹](https://voltagent.dev/docs/api/overview/\\#example-error-scenarios \"Direct link to Example Error Scenarios\")\n\n**Invalid API Key:**\n\n```codeBlockLines_e6Vv\ndata: {\n  \"type\": \"error\",\n  \"error\": \"Incorrect API key provided: sk-proj-...\",\n  \"code\": \"STREAM_ERROR\",\n  \"timestamp\": \"2024-01-15T10:30:45.123Z\"\n}\n\n```\n\n**Schema Validation Error (Object Streaming):**\n\n```codeBlockLines_e6Vv\ndata: {\n  \"type\": \"error\",\n  \"error\": \"Schema validation failed: Expected string, received number\",\n  \"code\": \"STREAM_ERROR\",\n  \"timestamp\": \"2024-01-15T10:30:45.123Z\"\n}\n\n```\n\n#### Handling Errors in Client Code [â€‹](https://voltagent.dev/docs/api/overview/\\#handling-errors-in-client-code \"Direct link to Handling Errors in Client Code\")\n\n**JavaScript/TypeScript Example:**\n\n```codeBlockLines_e6Vv\n// Fetch-based SSE streaming (supports POST with request body)\nconst streamUrl = \"/agents/your-agent-id/stream\";\nconst response = await fetch(streamUrl, {\n  method: \"POST\",\n  headers: {\n    \"Content-Type\": \"application/json\",\n  },\n  body: JSON.stringify({\n    input: \"Tell me a joke!\",\n    options: { temperature: 0.7, maxTokens: 100 },\n  }),\n});\n\nif (!response.ok) {\n  throw new Error(`Stream request failed: ${response.status}`);\n}\n\nconst reader = response.body.getReader();\nconst decoder = new TextDecoder();\nlet buffer = \"\";\n\nwhile (true) {\n  const { done, value } = await reader.read();\n  if (done) break;\n\n  buffer += decoder.decode(value, { stream: true });\n  const lines = buffer.split(\"\\n\\n\");\n  buffer = lines.pop() || \"\";\n\n  for (const line of lines) {\n    if (line.startsWith(\"data: \")) {\n      try {\n        const data = JSON.parse(line.substring(6));\n\n        switch (data.type) {\n          case \"text\":\n            // Handle text chunk\n            console.log(\"Text:\", data.text);\n            break;\n\n          case \"object\":\n            // Handle object chunk\n            console.log(\"Object:\", data.object);\n            break;\n\n          case \"error\":\n            // Handle error\n            console.error(\"Stream error:\", data.error);\n            console.error(\"Error code:\", data.code);\n            return; // Exit on error\n\n          case \"completion\":\n            // Handle completion\n            console.log(\"Stream completed successfully\");\n            return;\n        }\n      } catch (error) {\n        console.error(\"Error parsing SSE data:\", error);\n      }\n    }\n  }\n}\n\n```\n\n**cURL Example (Streaming with Error):**\n\n```codeBlockLines_e6Vv\n# This will show error events in the stream if API key is invalid\ncurl -N -X POST http://localhost:3141/agents/your-agent-id/stream \\\n     -H \"Content-Type: application/json\" \\\n     -d '{ \"input\": \"Hello!\", \"options\": { \"temperature\": 0.7 } }'\n\n# Example output with error:\n# data: {\"type\":\"error\",\"error\":\"Incorrect API key provided\",\"code\":\"STREAM_ERROR\",\"timestamp\":\"2024-01-15T10:30:45.123Z\"}\n\n```\n\n## Basic Example (Using cURL) [â€‹](https://voltagent.dev/docs/api/overview/\\#basic-example-using-curl \"Direct link to Basic Example (Using cURL)\")\n\nYou can quickly test the API using `curl`. Below are examples for key endpoints. You can optionally include `userId` and `conversationId` in the `options` object for context tracking, as shown in the second example for each generation endpoint.\n\n**List all agents:**\n\n```codeBlockLines_e6Vv\ncurl http://localhost:3141/agents\n\n```\n\n**Generate text (Basic):**\n\n```codeBlockLines_e6Vv\ncurl -X POST http://localhost:3141/agents/your-agent-id/text \\\n     -H \"Content-Type: application/json\" \\\n     -d '{ \"input\": \"Tell me a joke!\" }'\n\n```\n\n**Generate text (With Options):**\n\n```codeBlockLines_e6Vv\ncurl -X POST http://localhost:3141/agents/your-agent-id/text \\\n     -H \"Content-Type: application/json\" \\\n     -d '{ \"input\": \"Tell me a joke!\", \"options\": { \"userId\": \"user-123\", \"conversationId\": \"your-unique-conversation-id\" } }'\n\n```\n\n**Generate text (With maxSteps Control):**\n\n```codeBlockLines_e6Vv\ncurl -X POST http://localhost:3141/agents/your-agent-id/text \\\n     -H \"Content-Type: application/json\" \\\n     -d '{ \"input\": \"Use tools to research and analyze this topic\", \"options\": { \"maxSteps\": 5, \"temperature\": 0.7 } }'\n\n```\n\n**Stream text (Basic):**\n\n```codeBlockLines_e6Vv\n# Note: SSE streams are continuous. This command will keep the connection open.\ncurl -N -X POST http://localhost:3141/agents/your-agent-id/stream \\\n     -H \"Content-Type: application/json\" \\\n     -d '{ \"input\": \"Tell me a joke!\" }'\n\n```\n\n**Stream text (With Options):**\n\n```codeBlockLines_e6Vv\n# Note: SSE streams are continuous. This command will keep the connection open.\ncurl -N -X POST http://localhost:3141/agents/your-agent-id/stream \\\n     -H \"Content-Type: application/json\" \\\n     -d '{ \"input\": \"Tell me a joke!\", \"options\": { \"userId\": \"user-123\", \"conversationId\": \"your-unique-conversation-id\" } }'\n\n```\n\n**Stream text (With maxSteps Control for Complex Workflows):**\n\n```codeBlockLines_e6Vv\n# Example for agents with tools or sub-agents - limits iteration steps\ncurl -N -X POST http://localhost:3141/agents/supervisor-agent-id/stream \\\n     -H \"Content-Type: application/json\" \\\n     -d '{ \"input\": \"Coordinate research and writing workflow\", \"options\": { \"maxSteps\": 15, \"temperature\": 0.8 } }'\n\n```\n\n**Generate object (Basic - requires a Zod schema JSON representation, see warning above):**\n\n```codeBlockLines_e6Vv\n# Replace '{\"type\":\"object\", ...}' with the JSON representation of your Zod schema\ncurl -X POST http://localhost:3141/agents/your-agent-id/object \\\n     -H \"Content-Type: application/json\" \\\n     -d '{ \"input\": \"Extract the name and age from: John Doe is 30 years old.\", \"schema\": {\"type\":\"object\", \"properties\": {\"name\": {\"type\": \"string\"}, \"age\": {\"type\": \"number\"}}, \"required\": [\"name\", \"age\"]} }'\n\n```\n\n**Generate object (With Options - requires a Zod schema JSON representation, see warning above):**\n\n```codeBlockLines_e6Vv\n# Replace '{\"type\":\"object\", ...}' with the JSON representation of your Zod schema\ncurl -X POST http://localhost:3141/agents/your-agent-id/object \\\n     -H \"Content-Type: application/json\" \\\n     -d '{ \"input\": \"Extract the name and age from: John Doe is 30 years old.\", \"schema\": {\"type\":\"object\", \"properties\": {\"name\": {\"type\": \"string\"}, \"age\": {\"type\": \"number\"}}, \"required\": [\"name\", \"age\"]}, \"options\": { \"userId\": \"user-123\", \"conversationId\": \"your-unique-conversation-id\" } }'\n\n```\n\n**Stream object parts (Basic - requires a Zod schema JSON representation, see warning above):**\n\n```codeBlockLines_e6Vv\n# Note: SSE streams are continuous.\n# Replace '{\"type\":\"object\", ...}' with the JSON representation of your Zod schema\ncurl -N -X POST http://localhost:3141/agents/your-agent-id/stream-object \\\n     -H \"Content-Type: application/json\" \\\n     -d '{ \"input\": \"Generate user profile: Name: Alice, City: Wonderland\", \"schema\": {\"type\":\"object\", \"properties\": {\"name\": {\"type\": \"string\"}, \"city\": {\"type\": \"string\"}}, \"required\": [\"name\", \"city\"]} }'\n\n```\n\n**Stream object parts (With Options - requires a Zod schema JSON representation, see warning above):**\n\n```codeBlockLines_e6Vv\n# Note: SSE streams are continuous.\n# Replace '{\"type\":\"object\", ...}' with the JSON representation of your Zod schema\ncurl -N -X POST http://localhost:3141/agents/your-agent-id/stream-object \\\n     -H \"Content-Type: application/json\" \\\n     -d '{ \"input\": \"Generate user profile: Name: Alice, City: Wonderland\", \"schema\": {\"type\":\"object\", \"properties\": {\"name\": {\"type\": \"string\"}, \"city\": {\"type\": \"string\"}}, \"required\": [\"name\", \"city\"]}, \"options\": { \"userId\": \"user-123\", \"conversationId\": \"your-unique-conversation-id\" } }'\n\n```\n\n**Execute workflow:**\n\n```codeBlockLines_e6Vv\ncurl -X POST http://localhost:3141/workflows/order-approval/execute \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"input\": {\n         \"orderId\": \"order-123\",\n         \"amount\": 5000,\n         \"items\": [\"laptop\", \"mouse\", \"keyboard\"]\n       },\n       \"options\": {\n         \"userId\": \"user-456\",\n         \"conversationId\": \"conv-789\"\n       }\n     }'\n\n# Response:\n# {\n#   \"success\": true,\n#   \"data\": {\n#     \"executionId\": \"exec_1234567890_abc123\",\n#     \"startAt\": \"2024-01-15T10:00:00.000Z\",\n#     \"endAt\": \"2024-01-15T10:00:05.123Z\",\n#     \"status\": \"completed\",\n#     \"result\": {\n#       \"approved\": true,\n#       \"processedBy\": \"system\"\n#     }\n#   }\n# }\n\n```\n\n## Abort Signal Examples [â€‹](https://voltagent.dev/docs/api/overview/\\#abort-signal-examples \"Direct link to Abort Signal Examples\")\n\n**JavaScript with Abort Signal:**\n\n```codeBlockLines_e6Vv\n// Create abort controller\nconst abortController = new AbortController();\n\n// Cancel after 5 seconds\nsetTimeout(() => abortController.abort(), 5000);\n\n// Stream with cancellation support\ntry {\n  const response = await fetch(\"http://localhost:3141/agents/your-agent-id/stream\", {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify({\n      input: \"Write a very long story...\",\n      options: { maxTokens: 4000 },\n    }),\n    signal: abortController.signal,\n  });\n\n  // Process stream...\n  const reader = response.body.getReader();\n  // ... stream processing code ...\n} catch (error) {\n  if (error.name === \"AbortError\") {\n    console.log(\"Request was cancelled\");\n  }\n}\n\n```\n\n**cURL with timeout (simulating cancellation):**\n\n```codeBlockLines_e6Vv\n# Cancel stream after 3 seconds using timeout\ntimeout 3s curl -N -X POST http://localhost:3141/agents/your-agent-id/stream \\\n     -H \"Content-Type: application/json\" \\\n     -d '{ \"input\": \"Write a very long story...\", \"options\": { \"maxTokens\": 4000 } }'\n\n```\n\n(Replace `your-agent-id` with the actual ID of one of your agents)\n\n* * *\n\nExplore the **Swagger UI at `/ui`** for detailed information on all endpoints, parameters, and schemas!\n\n### Table of Contents\n\n- [Getting Started](https://voltagent.dev/docs/api/overview/#getting-started)\n- [Interactive API Documentation (Swagger UI)](https://voltagent.dev/docs/api/overview/#interactive-api-documentation-swagger-ui)\n  - [Swagger UI Configuration](https://voltagent.dev/docs/api/overview/#swagger-ui-configuration)\n- [Common Generation Options](https://voltagent.dev/docs/api/overview/#common-generation-options)\n  - [Understanding maxSteps](https://voltagent.dev/docs/api/overview/#understanding-maxsteps)\n- [Abort Signal Support](https://voltagent.dev/docs/api/overview/#abort-signal-support)\n  - [Client-Side Cancellation](https://voltagent.dev/docs/api/overview/#client-side-cancellation)\n  - [Supported Endpoints](https://voltagent.dev/docs/api/overview/#supported-endpoints)\n  - [Cancellation Behavior](https://voltagent.dev/docs/api/overview/#cancellation-behavior)\n  - [Error Handling with Abort](https://voltagent.dev/docs/api/overview/#error-handling-with-abort)\n- [OpenAPI Specification](https://voltagent.dev/docs/api/overview/#openapi-specification)\n- [Key Endpoints (via Swagger UI)](https://voltagent.dev/docs/api/overview/#key-endpoints-via-swagger-ui)\n- [Custom REST Endpoints](https://voltagent.dev/docs/api/overview/#custom-rest-endpoints)\n  - [Overview](https://voltagent.dev/docs/api/overview/#overview)\n  - [Server Configuration](https://voltagent.dev/docs/api/overview/#server-configuration)\n  - [Registration Methods](https://voltagent.dev/docs/api/overview/#registration-methods)\n  - [Endpoint Definition Structure](https://voltagent.dev/docs/api/overview/#endpoint-definition-structure)\n  - [Path Patterns](https://voltagent.dev/docs/api/overview/#path-patterns)\n  - [Handler Functions](https://voltagent.dev/docs/api/overview/#handler-functions)\n  - [Request/Response Utilities](https://voltagent.dev/docs/api/overview/#requestresponse-utilities)\n- [Workflow Endpoints](https://voltagent.dev/docs/api/overview/#workflow-endpoints)\n  - [List All Workflows](https://voltagent.dev/docs/api/overview/#list-all-workflows)\n  - [Execute Workflow](https://voltagent.dev/docs/api/overview/#execute-workflow)\n  - [Stream Workflow Execution](https://voltagent.dev/docs/api/overview/#stream-workflow-execution)\n  - [Suspend Running Workflow](https://voltagent.dev/docs/api/overview/#suspend-running-workflow)\n  - [Resume Suspended Workflow](https://voltagent.dev/docs/api/overview/#resume-suspended-workflow)\n  - [Complete Workflow Management Example](https://voltagent.dev/docs/api/overview/#complete-workflow-management-example)\n  - [Workflow Status Values](https://voltagent.dev/docs/api/overview/#workflow-status-values)\n  - [Best Practices](https://voltagent.dev/docs/api/overview/#best-practices)\n- [Authentication](https://voltagent.dev/docs/api/overview/#authentication)\n- [Error Handling](https://voltagent.dev/docs/api/overview/#error-handling)\n  - [Regular Endpoints (Non-Streaming)](https://voltagent.dev/docs/api/overview/#regular-endpoints-non-streaming)\n- [Passing User Context for Dynamic Agents](https://voltagent.dev/docs/api/overview/#passing-user-context-for-dynamic-agents)\n  - [User Context Format](https://voltagent.dev/docs/api/overview/#user-context-format)\n  - [Example API Calls with User Context](https://voltagent.dev/docs/api/overview/#example-api-calls-with-user-context)\n  - [Streaming Endpoints (SSE)](https://voltagent.dev/docs/api/overview/#streaming-endpoints-sse)\n- [Basic Example (Using cURL)](https://voltagent.dev/docs/api/overview/#basic-example-using-curl)\n- [Abort Signal Examples](https://voltagent.dev/docs/api/overview/#abort-signal-examples)",
      "metadata": {
        "docsearch:docusaurus_tag": "docs-default-current",
        "docusaurus_locale": "en",
        "og:locale": "en",
        "docusaurus_version": "current",
        "og:title": "API Overview | VoltAgent",
        "og:description": "The VoltAgent Core API provides a programmatic interface to manage and interact with your VoltAgents. It allows you to list agents, generate text or structured object responses, manage agent history, check for updates, and more.",
        "language": "en",
        "twitter:card": "summary_large_image",
        "docsearch:language": "en",
        "ogLocale": "en",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "ogTitle": "API Overview | VoltAgent",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "viewport": "width=device-width, initial-scale=1.0",
        "title": "API Overview | VoltAgent",
        "ogDescription": "The VoltAgent Core API provides a programmatic interface to manage and interact with your VoltAgents. It allows you to list agents, generate text or structured object responses, manage agent history, check for updates, and more.",
        "ogUrl": "https://voltagent.dev/docs/api/overview/",
        "generator": "Docusaurus v3.1.1",
        "og:image": "https://voltagent.dev/img/social3.png",
        "og:url": "https://voltagent.dev/docs/api/overview/",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "docusaurus_tag": "docs-default-current",
        "description": "The VoltAgent Core API provides a programmatic interface to manage and interact with your VoltAgents. It allows you to list agents, generate text or structured object responses, manage agent history, check for updates, and more.",
        "docsearch:version": "current",
        "scrapeId": "f477e0d1-50de-4ab4-a1bb-ad801f92cf71",
        "sourceURL": "https://voltagent.dev/docs/api/overview/",
        "url": "https://voltagent.dev/docs/api/overview/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:59.067Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/observability/langfuse/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\nVoltAgent offers built-in OpenTelemetry support, making it easy to send traces and logs to observability platforms like Langfuse. This guide shows you how to integrate VoltAgent with Langfuse using the dedicated `@voltagent/langfuse-exporter` package.\n\n## Prerequisites [â€‹](https://voltagent.dev/docs/observability/langfuse/\\#prerequisites \"Direct link to Prerequisites\")\n\n- You have a [Langfuse](https://langfuse.com/) account and project. Get your API keys (Public Key and Secret Key) and Base URL from your Langfuse project settings.\n- You have a basic VoltAgent application setup.\n\n## Installation [â€‹](https://voltagent.dev/docs/observability/langfuse/\\#installation \"Direct link to Installation\")\n\nFirst, install the necessary packages:\n\n```codeBlockLines_e6Vv\nnpm install @voltagent/langfuse-exporter\n\n```\n\n## Setup [â€‹](https://voltagent.dev/docs/observability/langfuse/\\#setup \"Direct link to Setup\")\n\n## Import `VoltAgent` and `LangfuseExporter` [â€‹](https://voltagent.dev/docs/observability/langfuse/\\#import-voltagent-and-langfuseexporter \"Direct link to import-voltagent-and-langfuseexporter\")\n\nIn your main application file (e.g., `index.ts`), import the required classes.\n\n```codeBlockLines_e6Vv\nimport { Agent, VoltAgent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nimport { LangfuseExporter } from \"@voltagent/langfuse-exporter\";\n// ... other imports like your LLM provider and tools\n\n```\n\n## Configure the Exporter [â€‹](https://voltagent.dev/docs/observability/langfuse/\\#configure-the-exporter \"Direct link to Configure the Exporter\")\n\nCreate an instance of `LangfuseExporter`. It's best practice to use environment variables for your Langfuse credentials.\n\n```codeBlockLines_e6Vv\nconst langfuseExporter = new LangfuseExporter({\n  publicKey: process.env.LANGFUSE_PUBLIC_KEY, // Your Langfuse Public Key\n  secretKey: process.env.LANGFUSE_SECRET_KEY, // Your Langfuse Secret Key\n  baseUrl: process.env.LANGFUSE_BASE_URL, // Optional: Defaults to Langfuse Cloud URL\n  // debug: true, // Optional: Enable detailed logging from the exporter\n});\n\n```\n\nEnsure you have set the `LANGFUSE_PUBLIC_KEY` and `LANGFUSE_SECRET_KEY` environment variables.\n\n## Pass Exporter to `VoltAgent` [â€‹](https://voltagent.dev/docs/observability/langfuse/\\#pass-exporter-to-voltagent \"Direct link to pass-exporter-to-voltagent\")\n\nWhen creating your main `VoltAgent` instance, pass the configured `langfuseExporter` to the `telemetryExporter` option.\n\n```codeBlockLines_e6Vv\n// Define your agent(s)\nconst agent = new Agent({\n  name: \"my-voltagent-app\",\n  instructions: \"A helpful assistant that answers questions without using tools\",\n  llm: new VercelAIProvider(),\n});\n\n// Initialize VoltAgent with the exporter\nnew VoltAgent({\n  agents: {\n    agent, // Register your agent(s)\n  },\n  telemetryExporter: langfuseExporter, // Pass the exporter instance\n});\n\n```\n\n## How it Works [â€‹](https://voltagent.dev/docs/observability/langfuse/\\#how-it-works \"Direct link to How it Works\")\n\nBy providing the `telemetryExporter` to `VoltAgent`, you activate VoltAgent's automatic OpenTelemetry integration:\n\n- A global OpenTelemetry `NodeTracerProvider` is configured.\n- The provided exporter(s) are attached using `BatchSpanProcessor` s (recommended for production).\n- All operations within any `Agent` instance managed by this `VoltAgent` (including sub-agents called via delegation) will automatically create and export OpenTelemetry spans.\n- The `@voltagent/langfuse-exporter` specifically transforms these OpenTelemetry spans into Langfuse traces, generations, and spans, mapping relevant attributes like prompts, responses, tool calls, usage data, user IDs, and session IDs.\n\n## Using Multiple Exporters [â€‹](https://voltagent.dev/docs/observability/langfuse/\\#using-multiple-exporters \"Direct link to Using Multiple Exporters\")\n\nThe `telemetryExporter` option accepts either a single exporter instance or an array of exporters. This allows you to send telemetry data to multiple systems simultaneously.\n\n```codeBlockLines_e6Vv\nimport { ConsoleSpanExporter } from \"@opentelemetry/sdk-trace-base\"; // Example: OTEL Console Exporter\n\nnew VoltAgent({\n  agents: { agent },\n  telemetryExporter: [\\\n    new LangfuseExporter({\\\n      /* ... config ... */\\\n    }),\\\n    new ConsoleSpanExporter(), // Also log spans to the console\\\n    // new OtherExporter({ /* ... config ... */ }),\\\n  ],\n});\n\n```\n\nNow your VoltAgent setup will automatically send detailed traces to Langfuse! Check your Langfuse project to see the incoming data.\n\n### Table of Contents\n\n- [Prerequisites](https://voltagent.dev/docs/observability/langfuse/#prerequisites)\n- [Installation](https://voltagent.dev/docs/observability/langfuse/#installation)\n- [Setup](https://voltagent.dev/docs/observability/langfuse/#setup)\n- [Import `VoltAgent` and `LangfuseExporter`](https://voltagent.dev/docs/observability/langfuse/#import-voltagent-and-langfuseexporter)\n- [Configure the Exporter](https://voltagent.dev/docs/observability/langfuse/#configure-the-exporter)\n- [Pass Exporter to `VoltAgent`](https://voltagent.dev/docs/observability/langfuse/#pass-exporter-to-voltagent)\n- [How it Works](https://voltagent.dev/docs/observability/langfuse/#how-it-works)\n- [Using Multiple Exporters](https://voltagent.dev/docs/observability/langfuse/#using-multiple-exporters)",
      "metadata": {
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "title": "Langfuse Integration | VoltAgent",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "og:locale": "en",
        "docusaurus_locale": "en",
        "ogDescription": "VoltAgent offers built-in OpenTelemetry support, making it easy to send traces and logs to observability platforms like Langfuse. This guide shows you how to integrate VoltAgent with Langfuse using the dedicated @voltagent/langfuse-exporter package.",
        "generator": "Docusaurus v3.1.1",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_tag": "docs-default-current",
        "ogLocale": "en",
        "docsearch:docusaurus_tag": "docs-default-current",
        "docsearch:language": "en",
        "ogUrl": "https://voltagent.dev/docs/observability/langfuse/",
        "docusaurus_version": "current",
        "og:image": "https://voltagent.dev/img/social3.png",
        "og:title": "Langfuse Integration | VoltAgent",
        "og:description": "VoltAgent offers built-in OpenTelemetry support, making it easy to send traces and logs to observability platforms like Langfuse. This guide shows you how to integrate VoltAgent with Langfuse using the dedicated @voltagent/langfuse-exporter package.",
        "docsearch:version": "current",
        "description": "VoltAgent offers built-in OpenTelemetry support, making it easy to send traces and logs to observability platforms like Langfuse. This guide shows you how to integrate VoltAgent with Langfuse using the dedicated @voltagent/langfuse-exporter package.",
        "ogTitle": "Langfuse Integration | VoltAgent",
        "twitter:card": "summary_large_image",
        "language": "en",
        "og:url": "https://voltagent.dev/docs/observability/langfuse/",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "scrapeId": "be1497bb-5118-46b9-80bb-258119cf0954",
        "sourceURL": "https://voltagent.dev/docs/observability/langfuse/",
        "url": "https://voltagent.dev/docs/observability/langfuse/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:34.165Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/agents/memory/libsql/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# LibSQL / Turso / SQLite Memory\n\nVoltAgent's core package ( `@voltagent/core`) includes a built-in memory provider, `LibSQLStorage`, which uses [LibSQL](https://github.com/tursodatabase/libsql) for persistent storage. LibSQL is an open-source fork of SQLite.\n\nThis provider is versatile and can connect to:\n\n- **Local SQLite files:** Ideal for development, testing, and simple deployments.\n- **[Turso](https://turso.tech/):** A distributed database platform built on LibSQL, offering a globally available edge database.\n- **Self-hosted `sqld` instances:** If you run your own LibSQL server.\n\n## Setup [â€‹](https://voltagent.dev/docs/agents/memory/libsql/\\#setup \"Direct link to Setup\")\n\n`LibSQLStorage` is part of `@voltagent/core`, so no separate installation is needed beyond the core package.\n\nIf you plan to use Turso, you might need the Turso CLI for setup: `npm install -g @tursodatabase/cli`\n\n## Configuration [â€‹](https://voltagent.dev/docs/agents/memory/libsql/\\#configuration \"Direct link to Configuration\")\n\nInitialize `LibSQLStorage` and pass it to your `Agent` configuration:\n\n```codeBlockLines_e6Vv\nimport { Agent, LibSQLStorage } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Configure LibSQLStorage\nconst memoryStorage = new LibSQLStorage({\n  // Required: Connection URL\n  url: process.env.DATABASE_URL || \"file:./voltagent-memory.db\", // Example: Env var for Turso, fallback to local file\n\n  // Required for Turso / Remote sqld (if not using TLS or auth is needed)\n  authToken: process.env.DATABASE_AUTH_TOKEN,\n\n  // Optional: Prefix for database table names\n  tablePrefix: \"my_agent_memory\", // Defaults to 'voltagent_memory'\n\n  // Optional: Storage limit (max number of messages per user/conversation)\n  // storageLimit: 100, // Defaults to 100\n\n  // Optional: Enable debug logging for the storage provider\n  // debug: true, // Defaults to false\n});\n\nconst agent = new Agent({\n  name: \"LibSQL Memory Agent\",\n  instructions: \"An agent using LibSQL for memory.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  memory: memoryStorage,\n});\n\n```\n\n**Configuration Options:**\n\n- `url` (string, required): The connection URL for your LibSQL database.\n\n  - **Local SQLite:** Use `file:<path-to-db-file>`.\n\n    - `file:memory.db`: Creates/uses `memory.db` in the current working directory.\n    - `file:.voltagent/memory.db`: Creates/uses `memory.db` inside a `.voltagent` subdirectory (created automatically if it doesn't exist).\n    - `file:/path/to/your/database.db`: Absolute path.\n  - **Turso:** Use the `libsql://your-database-name-username.turso.io` URL provided in your Turso dashboard.\n  - **Remote `sqld`:** Use the appropriate `libsql://` or `http(s)://` URL for your server.\n- `authToken` (string, optional): Required for authenticated connections to Turso or remote `sqld` instances.\n- `tablePrefix` (string, optional): A prefix added to all database tables created by this provider (e.g., `my_prefix_messages`, `my_prefix_conversations`). Defaults to `voltagent_memory`.\n- `storageLimit` (number, optional): The maximum number of messages to retain per user/conversation thread. Older messages are automatically pruned when the limit is exceeded. Defaults to `100`.\n- `debug` (boolean, optional): Enables detailed logging from the storage provider to the console. Defaults to `false`.\n\n## Conversation Management [â€‹](https://voltagent.dev/docs/agents/memory/libsql/\\#conversation-management \"Direct link to Conversation Management\")\n\nThe LibSQL provider includes enhanced support for managing conversations across multiple users:\n\n```codeBlockLines_e6Vv\n// Get conversations for a specific user\nconst conversations = await memoryStorage.getConversationsByUserId(\"user-123\", {\n  limit: 50,\n  orderBy: \"updated_at\",\n  orderDirection: \"DESC\",\n});\n\n// Query builder pattern for complex queries\nconst recentConversations = await memoryStorage\n  .getUserConversations(\"user-123\")\n  .limit(10)\n  .orderBy(\"updated_at\", \"DESC\")\n  .execute();\n\n// Pagination support\nconst page1 = await memoryStorage.getPaginatedUserConversations(\"user-123\", 1, 20);\nconsole.log(page1.conversations); // Array of conversations\nconsole.log(page1.hasMore); // Boolean indicating if more pages exist\n\n// Get conversation with user validation\nconst conversation = await memoryStorage.getUserConversation(\"conversation-id\", \"user-123\");\n\n// Create and update conversations\nconst newConversation = await memoryStorage.createConversation({\n  id: \"conversation-id\",\n  resourceId: \"app-resource-1\",\n  userId: \"user-123\",\n  title: \"New Chat Session\",\n  metadata: { source: \"web-app\" },\n});\n\nawait memoryStorage.updateConversation(\"conversation-id\", {\n  title: \"Updated Title\",\n});\n\n```\n\n## Querying Conversations [â€‹](https://voltagent.dev/docs/agents/memory/libsql/\\#querying-conversations \"Direct link to Querying Conversations\")\n\nThe LibSQL storage provides powerful conversation querying capabilities with filtering, pagination, and sorting options:\n\n```codeBlockLines_e6Vv\n// Query with multiple filters\nconst workConversations = await memoryStorage.queryConversations({\n  userId: \"user-123\",\n  resourceId: \"work-agent\",\n  limit: 25,\n  offset: 0,\n  orderBy: \"created_at\",\n  orderDirection: \"DESC\",\n});\n\n// Get all conversations for a user\nconst userConversations = await memoryStorage.queryConversations({\n  userId: \"user-123\",\n  limit: 50,\n});\n\n// Get conversations for a specific resource\nconst resourceConversations = await memoryStorage.queryConversations({\n  resourceId: \"chatbot-v1\",\n  limit: 100,\n  orderBy: \"updated_at\",\n});\n\n// Admin view - get all conversations\nconst allConversations = await memoryStorage.queryConversations({\n  limit: 200,\n  orderBy: \"created_at\",\n  orderDirection: \"ASC\",\n});\n\n```\n\n**Query Options:**\n\n- `userId` (optional): Filter conversations by specific user\n- `resourceId` (optional): Filter conversations by specific resource\n- `limit` (optional): Maximum number of conversations to return (default: 50)\n- `offset` (optional): Number of conversations to skip for pagination (default: 0)\n- `orderBy` (optional): Field to sort by: 'created\\_at', 'updated\\_at', or 'title' (default: 'updated\\_at')\n- `orderDirection` (optional): Sort direction: 'ASC' or 'DESC' (default: 'DESC')\n\n## Getting Conversation Messages [â€‹](https://voltagent.dev/docs/agents/memory/libsql/\\#getting-conversation-messages \"Direct link to Getting Conversation Messages\")\n\nRetrieve messages for a specific conversation with pagination support:\n\n```codeBlockLines_e6Vv\n// Get all messages for a conversation\nconst messages = await memoryStorage.getConversationMessages(\"conversation-456\");\n\n// Get messages with pagination\nconst firstBatch = await memoryStorage.getConversationMessages(\"conversation-456\", {\n  limit: 50,\n  offset: 0,\n});\n\n// Get next batch\nconst nextBatch = await memoryStorage.getConversationMessages(\"conversation-456\", {\n  limit: 50,\n  offset: 50,\n});\n\n// Process messages in batches for large conversations\nconst batchSize = 100;\nlet offset = 0;\nlet hasMore = true;\n\nwhile (hasMore) {\n  const batch = await memoryStorage.getConversationMessages(\"conversation-456\", {\n    limit: batchSize,\n    offset: offset,\n  });\n\n  // Process batch\n  processBatch(batch);\n\n  hasMore = batch.length === batchSize;\n  offset += batchSize;\n}\n\n```\n\n**Message Query Options:**\n\n- `limit` (optional): Maximum number of messages to return (default: 100)\n- `offset` (optional): Number of messages to skip for pagination (default: 0)\n\nMessages are returned in chronological order (oldest first) for natural conversation flow.\n\n## Automatic Table Creation [â€‹](https://voltagent.dev/docs/agents/memory/libsql/\\#automatic-table-creation \"Direct link to Automatic Table Creation\")\n\nUnlike some other database providers, `LibSQLStorage` **automatically creates** the necessary tables ( `messages`, `conversations`, `agent_history`, etc., with the configured `tablePrefix`) in the target database if they don't already exist. This simplifies setup, especially for local development using SQLite files.\n\nThe provider also **automatically migrates** existing databases to new schemas when you update VoltAgent, ensuring backward compatibility.\n\n## Use Cases [â€‹](https://voltagent.dev/docs/agents/memory/libsql/\\#use-cases \"Direct link to Use Cases\")\n\n- **Local Development & Testing:** Quickly set up persistent memory using a local SQLite file without needing external database services.\n- **Serverless & Edge Functions:** SQLite databases (via LibSQL) can often be used effectively in serverless environments.\n- **Turso Integration:** Leverage Turso's distributed edge database for low-latency memory access for globally distributed applications.\n- **Simple Deployments:** Suitable for applications where managing a separate database server is overkill.\n\n### Table of Contents\n\n- [Setup](https://voltagent.dev/docs/agents/memory/libsql/#setup)\n- [Configuration](https://voltagent.dev/docs/agents/memory/libsql/#configuration)\n- [Conversation Management](https://voltagent.dev/docs/agents/memory/libsql/#conversation-management)\n- [Querying Conversations](https://voltagent.dev/docs/agents/memory/libsql/#querying-conversations)\n- [Getting Conversation Messages](https://voltagent.dev/docs/agents/memory/libsql/#getting-conversation-messages)\n- [Automatic Table Creation](https://voltagent.dev/docs/agents/memory/libsql/#automatic-table-creation)\n- [Use Cases](https://voltagent.dev/docs/agents/memory/libsql/#use-cases)",
      "metadata": {
        "og:url": "https://voltagent.dev/docs/agents/memory/libsql/",
        "og:description": "VoltAgent's core package (@voltagent/core) includes a built-in memory provider, LibSQLStorage, which uses LibSQL for persistent storage. LibSQL is an open-source fork of SQLite.",
        "docusaurus_version": "current",
        "og:title": "LibSQL / Turso / SQLite Memory | VoltAgent",
        "language": "en",
        "ogUrl": "https://voltagent.dev/docs/agents/memory/libsql/",
        "title": "LibSQL / Turso / SQLite Memory | VoltAgent",
        "og:image": "https://voltagent.dev/img/social3.png",
        "docsearch:docusaurus_tag": "docs-default-current",
        "twitter:card": "summary_large_image",
        "docusaurus_locale": "en",
        "docusaurus_tag": "docs-default-current",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "ogTitle": "LibSQL / Turso / SQLite Memory | VoltAgent",
        "ogLocale": "en",
        "generator": "Docusaurus v3.1.1",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "og:locale": "en",
        "docsearch:version": "current",
        "docsearch:language": "en",
        "description": "VoltAgent's core package (@voltagent/core) includes a built-in memory provider, LibSQLStorage, which uses LibSQL for persistent storage. LibSQL is an open-source fork of SQLite.",
        "viewport": "width=device-width, initial-scale=1.0",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "ogDescription": "VoltAgent's core package (@voltagent/core) includes a built-in memory provider, LibSQLStorage, which uses LibSQL for persistent storage. LibSQL is an open-source fork of SQLite.",
        "scrapeId": "9bf5ad24-7cd9-44e9-a42e-b9f0519cb9ef",
        "sourceURL": "https://voltagent.dev/docs/agents/memory/libsql/",
        "url": "https://voltagent.dev/docs/agents/memory/libsql/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:48.138Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/community/overview/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\n# Join Our Community!\n\nReady to connect with other VoltAgent developers, showcase your amazing projects, ask burning questions, or even lend a hand to the project? Our Discord server is the place to be!\n\nJoin us on Discord: [**VoltAgent**](https://s.voltagent.dev/discord)\n\nFollow us on X: [**@voltagent\\_dev**](https://x.com/voltagent_dev)",
      "metadata": {
        "docusaurus_locale": "en",
        "og:locale": "en",
        "viewport": "width=device-width, initial-scale=1.0",
        "generator": "Docusaurus v3.1.1",
        "docsearch:version": "current",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "docusaurus_version": "current",
        "og:url": "https://voltagent.dev/docs/community/overview/",
        "title": "Join Our Community! | VoltAgent",
        "ogUrl": "https://voltagent.dev/docs/community/overview/",
        "ogDescription": "Ready to connect with other VoltAgent developers, showcase your amazing projects, ask burning questions, or even lend a hand to the project? Our Discord server is the place to be!",
        "ogTitle": "Join Our Community! | VoltAgent",
        "twitter:card": "summary_large_image",
        "docsearch:language": "en",
        "docusaurus_tag": "docs-default-current",
        "language": "en",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:image": "https://voltagent.dev/img/social3.png",
        "ogLocale": "en",
        "description": "Ready to connect with other VoltAgent developers, showcase your amazing projects, ask burning questions, or even lend a hand to the project? Our Discord server is the place to be!",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "og:title": "Join Our Community! | VoltAgent",
        "og:description": "Ready to connect with other VoltAgent developers, showcase your amazing projects, ask burning questions, or even lend a hand to the project? Our Discord server is the place to be!",
        "scrapeId": "33a23621-f429-43a5-ac5d-6780abb76c1d",
        "sourceURL": "https://voltagent.dev/docs/community/overview/",
        "url": "https://voltagent.dev/docs/community/overview/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:25.606Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/agents/voice/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Voice\n\nThe `@voltagent/voice` package provides text-to-speech (TTS) and speech-to-text (STT) capabilities through various providers. It allows your applications to speak text and transcribe audio with minimal setup.\n\n## Installation [â€‹](https://voltagent.dev/docs/agents/voice/\\#installation \"Direct link to Installation\")\n\nInstall the package using your preferred package manager:\n\n- npm\n- yarn\n- pnpm\n\n```codeBlockLines_e6Vv\nnpm install @voltagent/voice\n\n```\n\n## Supported Providers [â€‹](https://voltagent.dev/docs/agents/voice/\\#supported-providers \"Direct link to Supported Providers\")\n\n- **OpenAI**: High-quality voices and transcription.\n- **ElevenLabs**: Realistic, customizable voices.\n- **xsAI**: Lightweight OpenAI-compatible voice API.\n\n## Basic Usage [â€‹](https://voltagent.dev/docs/agents/voice/\\#basic-usage \"Direct link to Basic Usage\")\n\nFirst, initialize a voice provider instance.\n\n### Initialize a Voice Provider [â€‹](https://voltagent.dev/docs/agents/voice/\\#initialize-a-voice-provider \"Direct link to Initialize a Voice Provider\")\n\n```codeBlockLines_e6Vv\n// Initialize with OpenAI\nimport { OpenAIVoiceProvider } from \"@voltagent/voice\";\n\nconst openAIVoice = new OpenAIVoiceProvider({\n  apiKey: process.env.OPENAI_API_KEY, // Ensure API key is set in environment variables\n  ttsModel: \"tts-1\",\n  voice: \"alloy\", // Available voices: alloy, echo, fable, onyx, nova, shimmer\n});\n\n// Or initialize with ElevenLabs\nimport { ElevenLabsVoiceProvider } from \"@voltagent/voice\";\n\nconst elevenLabsVoice = new ElevenLabsVoiceProvider({\n  apiKey: process.env.ELEVENLABS_API_KEY, // Ensure API key is set\n  ttsModel: \"eleven_multilingual_v2\",\n  voice: \"Rachel\", // Example voice ID\n});\n\n// Or initialize with xsAI\nimport { XsAIVoiceProvider } from \"@voltagent/voice\";\n\nconst xsAIVoice = new XsAIVoiceProvider({\n  apiKey: process.env.OPENAI_API_KEY!,\n  ttsModel: \"tts-1\",\n  voice: \"alloy\",\n  // If you are not using OpenAI, simply specify the `baseURL`\n});\n\n```\n\n**Note:** It's recommended to manage API keys securely, for example, using environment variables.\n\n### Text-to-Speech (TTS) [â€‹](https://voltagent.dev/docs/agents/voice/\\#text-to-speech-tts \"Direct link to Text-to-Speech (TTS)\")\n\nConvert text into an audio stream. You can then process this stream, for example, by saving it to a file.\n\n```codeBlockLines_e6Vv\nimport { createWriteStream } from \"node:fs\";\nimport { PassThrough } from \"node:stream\";\nimport { pipeline } from \"node:stream/promises\"; // Use pipeline for better error handling\n\n// --- Example 1: Basic Speak and Save to File ---\n\nconsole.log(\"Generating audio...\");\n// Get the audio stream for the text\nconst audioStream = await openAIVoice.speak(\"Hello from VoltAgent!\");\n\nconsole.log(\"Saving audio to output.mp3...\");\n// Create a file stream to write the audio\nconst fileStream = createWriteStream(\"output.mp3\");\n\ntry {\n  // Pipe the audio stream to the file stream and wait for completion\n  await pipeline(audioStream, fileStream);\n  console.log(\"Audio successfully saved to output.mp3\");\n} catch (error) {\n  console.error(\"Failed to save audio:\", error);\n}\n\n// --- Example 2: Speak with Options and Save ---\n\nconsole.log(\"Generating custom audio...\");\nconst customAudioStream = await elevenLabsVoice.speak(\"Speaking faster now.\", {\n  // Provider-specific options can be passed here.\n  // For OpenAI, you might use:\n  // voice: \"nova\", // Override the default voice\n  // speed: 1.5,    // Adjust speaking speed (1.0 is default)\n});\n\nconsole.log(\"Saving custom audio to custom_output.mp3...\");\nconst customFileStream = createWriteStream(\"custom_output.mp3\");\n\ntry {\n  // Pipe the custom audio stream to the file stream\n  await pipeline(customAudioStream, customFileStream);\n  console.log(\"Custom audio successfully saved to custom_output.mp3\");\n} catch (error) {\n  console.error(\"Failed to save custom audio:\", error);\n}\n\n// Note: The audioStream is a standard Node.js Readable stream.\n// You can pipe it to other destinations or process it directly.\n\n```\n\n### Speech-to-Text (STT) [â€‹](https://voltagent.dev/docs/agents/voice/\\#speech-to-text-stt \"Direct link to Speech-to-Text (STT)\")\n\nTranscribe audio from a stream into text.\n\n```codeBlockLines_e6Vv\nimport { createReadStream } from \"node:fs\";\n\n// Ensure you have an audio file (e.g., input.mp3)\nconst audioFileStream = createReadStream(\"input.mp3\");\n\n// Basic transcription with OpenAI\nconst transcribedText = await openAIVoice.listen(audioFileStream);\nconsole.log(\"Transcription:\", transcribedText);\n\n// Transcription with options (e.g., language hint)\nconst transcribedSpanish = await openAIVoice.listen(audioFileStream, {\n  language: \"es\", // Specify the language code\n});\nconsole.log(\"Spanish Transcription:\", transcribedSpanish);\n\n// Streaming transcription (Provider-dependent, e.g., OpenAI)\ntry {\n  const streamingTranscription = await openAIVoice.listen(audioFileStream, {\n    stream: true, // Enable streaming\n  });\n\n  for await (const chunk of streamingTranscription) {\n    // Process transcription chunks as they arrive\n    // The structure of 'chunk' depends on the provider\n    console.log(\"Stream Chunk:\", chunk);\n  }\n} catch (error) {\n  console.error(\"Streaming transcription failed:\", error);\n}\n\n```\n\n### List Available Voices [â€‹](https://voltagent.dev/docs/agents/voice/\\#list-available-voices \"Direct link to List Available Voices\")\n\nFetch the list of voices supported by the provider.\n\n```codeBlockLines_e6Vv\n// Using the initialized openAIVoice instance\nconst availableVoices = await openAIVoice.getVoices();\nconsole.log(\"Available OpenAI Voices:\", availableVoices);\n/* Example Output:\n[\\\n  { id: 'alloy', name: 'Alloy', language: 'en', gender: 'neutral' },\\\n  { id: 'echo', name: 'Echo', language: 'en', gender: 'male' },\\\n  // ... other voices\\\n]\n*/\n\nconst elevenLabsVoices = await elevenLabsVoice.getVoices();\nconsole.log(\"Available ElevenLabs Voices:\", elevenLabsVoices); // Structure might differ\n\n```\n\n## Integrating with Agent [â€‹](https://voltagent.dev/docs/agents/voice/\\#integrating-with-agent \"Direct link to Integrating with Agent\")\n\nYou can integrate the voice provider directly into an `Agent` instance.\n\n```codeBlockLines_e6Vv\nimport { Agent, OpenAIAgentProvider } from \"@voltagent/core\";\nimport { OpenAIVoiceProvider } from \"@voltagent/voice\";\n\n// Initialize the voice provider\nconst voice = new OpenAIVoiceProvider({\n  apiKey: process.env.OPENAI_API_KEY,\n  ttsModel: \"tts-1\",\n  voice: \"nova\",\n});\n\n// Initialize the agent provider\nconst provider = new OpenAIAgentProvider({\n  apiKey: process.env.OPENAI_API_KEY,\n});\n\n// Create the agent, passing the voice instance\nconst voiceEnabledAgent = new Agent({\n  name: \"VoiceBot\",\n  instructions: \"An agent that can speak.\",\n  provider,\n  model: \"gpt-4o\", // Choose an appropriate model\n  voice: voice, // Assign the voice provider here\n});\n\n// Now the agent instance potentially uses the voice capabilities\n// (Specific usage within the agent depends on future VoltAgent features or custom implementations)\n\n// Example: Manually trigger speech from agent's response\n// const response = await voiceEnabledAgent.generateText(\"Tell me a short story.\");\n// if (voiceEnabledAgent.voice) {\n//   const audio = await voiceEnabledAgent.voice.speak(response.text);\n//   // Pipe audio to output\n//   audio.pipe(createWriteStream(\"story.mp3\"));\n// }\n\n```\n\n**Note:** The direct integration of `voice` within the `Agent`'s core methods ( `generateText`, `streamText`, etc.) for automatic speaking/listening is under development. Currently, you can access the `agent.voice` property to manually trigger TTS or STT.\n\n## Event Handling [â€‹](https://voltagent.dev/docs/agents/voice/\\#event-handling \"Direct link to Event Handling\")\n\nListen for events emitted by the voice provider instance.\n\n```codeBlockLines_e6Vv\n// Using the initialized openAIVoice instance\n\n// Listen for the start of speech synthesis\nopenAIVoice.on(\"speaking\", (data) => {\n  console.log(`[Speaking Started] Text: \"${data.text}\"`);\n});\n\n// Listen for the start of transcription\nopenAIVoice.on(\"listening\", (data) => {\n  // data might contain information about the audio stream\n  console.log(\"[Listening Started]\");\n});\n\n// Handle errors\nopenAIVoice.on(\"error\", (errorData) => {\n  console.error(\n    `[Voice Error] Code: ${errorData.code}, Message: ${errorData.message}`,\n    errorData.details\n  );\n});\n\n// Trigger an action that emits events\ntry {\n  await openAIVoice.speak(\"Testing event listeners.\");\n  // const audioInput = createReadStream(\"input.mp3\");\n  // await openAIVoice.listen(audioInput);\n} catch (error) {\n  // Errors caught here might also be emitted via the 'error' event\n  console.error(\"Direct action failed:\", error);\n}\n\n```\n\n## Creating a Custom Voice Provider [â€‹](https://voltagent.dev/docs/agents/voice/\\#creating-a-custom-voice-provider \"Direct link to Creating a Custom Voice Provider\")\n\nExtend the `BaseVoiceProvider` to integrate other TTS/STT services.\n\n```codeBlockLines_e6Vv\nimport {\n  BaseVoiceProvider,\n  VoiceProviderEvents,\n  VoiceMetadata,\n  VoiceSpeakOptions,\n  VoiceListenOptions,\n} from \"@voltagent/voice\";\nimport { PassThrough, Readable } from \"node:stream\"; // Import Readable\n\n// Define your custom provider options\ntype MyCustomProviderOptions = {\n  apiKey: string;\n  region?: string;\n  // Add other necessary options\n};\n\n// Define potential errors specific to your provider\nenum MyCustomErrorCode {\n  AuthError = \"AUTH_ERROR\",\n  ApiError = \"API_ERROR\",\n  InvalidInput = \"INVALID_INPUT\",\n}\n\nexport class MyCustomVoiceProvider extends BaseVoiceProvider<\n  MyCustomProviderOptions,\n  VoiceProviderEvents\n> {\n  private readonly apiKey: string;\n  private readonly region: string;\n  // Add client instances or other state needed\n\n  constructor(options: MyCustomProviderOptions) {\n    super(options); // Pass options to the base class\n    this.apiKey = options.apiKey;\n    this.region = options.region || \"default-region\";\n    // Initialize your API client here\n  }\n\n  /**\n   * Connect to the service if needed (e.g., WebSockets).\n   */\n  async connect(): Promise<void> {\n    console.log(\"Connecting to Custom Voice Service...\");\n    // Add connection logic if required\n    // Simulating async operation\n    await new Promise((resolve) => setTimeout(resolve, 100));\n    console.log(\"Connected.\");\n  }\n\n  /**\n   * Disconnect from the service.\n   */\n  disconnect(): void {\n    console.log(\"Disconnecting from Custom Voice Service...\");\n    // Add disconnection logic\n  }\n\n  /**\n   * Send audio data (e.g., for streaming STT).\n   */\n  async send(audioData: Readable): Promise<void> {\n    console.log(\"Sending audio data chunk...\");\n    // Implementation for sending streaming audio\n    // Read from audioData stream and send to your API\n    // Example: audioData.pipe(yourApiStream);\n    await new Promise((resolve) => setTimeout(resolve, 50)); // Simulate async send\n  }\n\n  /**\n   * Convert text to speech.\n   */\n  async speak(\n    text: string, // Assuming text is always string for simplicity here\n    options?: VoiceSpeakOptions // Use standardized options type\n  ): Promise<Readable> {\n    // Return standard Readable stream\n    this.emit(\"speaking\", { text }); // Emit standard event\n\n    try {\n      console.log(`Speaking text: \"${text}\" with voice: ${options?.voice}`);\n      // --- Your TTS API Call Logic ---\n      // const apiResponse = await yourTTSClient.synthesize({\n      //   text: text,\n      //   voice: options?.voice || 'default-voice',\n      //   apiKey: this.apiKey,\n      //   // map other options like speed if applicable\n      // });\n      // -----------------------------\n\n      // Simulate receiving audio data from API\n      await new Promise((resolve) => setTimeout(resolve, 500));\n      const audioBuffer = Buffer.from(`Simulated audio for: ${text}`);\n\n      // Return audio data as a Readable stream\n      const passThrough = new PassThrough();\n      passThrough.end(audioBuffer);\n      return passThrough;\n    } catch (error: any) {\n      const errorMessage = error.message || \"Unknown TTS error\";\n      this.emit(\"error\", {\n        message: errorMessage,\n        code: MyCustomErrorCode.ApiError, // Use your specific error codes\n        details: error,\n      });\n      throw new Error(`Custom TTS failed: ${errorMessage}`); // Re-throw a standard error\n    }\n  }\n\n  /**\n   * Convert speech to text.\n   */\n  async listen(\n    audio: Readable, // Expect a Readable stream\n    options?: VoiceListenOptions // Use standardized options type\n  ): Promise<string | AsyncIterable<any>> {\n    // Return string or stream based on options\n    this.emit(\"listening\", { audio }); // Emit standard event\n\n    try {\n      console.log(`Listening with language: ${options?.language}, stream: ${options?.stream}`);\n\n      // --- Your STT API Call Logic ---\n      // Handle both standard and streaming modes\n      if (options?.stream) {\n        // Implement streaming transcription logic\n        // Example: const transcriptStream = yourSTTClient.startStream(audio, { language: options.language });\n        // return transcriptStream; // Return the async iterable from your client\n\n        // --- Placeholder for streaming ---\n        async function* generateChunks() {\n          yield { delta: \"Simulated \" };\n          await new Promise((resolve) => setTimeout(resolve, 200));\n          yield { delta: \"streamed \" };\n          await new Promise((resolve) => setTimeout(resolve, 200));\n          yield { delta: \"transcript.\" };\n        }\n        return generateChunks();\n        // --- End Placeholder ---\n      } else {\n        // Implement non-streaming transcription logic\n        // Example: const result = await yourSTTClient.transcribe(audio, { language: options?.language });\n        // return result.text;\n\n        // --- Placeholder for non-streaming ---\n        // Simulate reading the stream and getting a result\n        let fullAudio = Buffer.alloc(0);\n        for await (const chunk of audio) {\n          fullAudio = Buffer.concat([fullAudio, chunk]);\n        }\n        await new Promise((resolve) => setTimeout(resolve, 500)); // Simulate API call\n        return \"Simulated full transcript of audio.\";\n        // --- End Placeholder ---\n      }\n      // -----------------------------\n    } catch (error: any) {\n      const errorMessage = error.message || \"Unknown STT error\";\n      this.emit(\"error\", {\n        message: errorMessage,\n        code: MyCustomErrorCode.ApiError, // Use your specific error codes\n        details: error,\n      });\n      throw new Error(`Custom STT failed: ${errorMessage}`); // Re-throw a standard error\n    }\n  }\n\n  /**\n   * Fetch available voices from your service.\n   */\n  async getVoices(): Promise<VoiceMetadata[]> {\n    try {\n      // --- Your API Call Logic to Get Voices ---\n      // const apiVoices = await yourClient.listVoices({ apiKey: this.apiKey });\n      // return apiVoices.map(v => ({ id: v.id, name: v.name, language: v.lang, gender: v.gender }));\n      // ---------------------------------------\n\n      // --- Placeholder ---\n      await new Promise((resolve) => setTimeout(resolve, 100)); // Simulate API call\n      return [\\\n        { id: \"custom-voice-1\", name: \"Custom Voice One\", language: \"en\", gender: \"female\" },\\\n        { id: \"custom-voice-2\", name: \"Custom Voice Two\", language: \"es\", gender: \"male\" },\\\n      ];\n      // --- End Placeholder ---\n    } catch (error: any) {\n      const errorMessage = error.message || \"Failed to fetch custom voices\";\n      this.emit(\"error\", {\n        message: errorMessage,\n        code: MyCustomErrorCode.ApiError,\n        details: error,\n      });\n      // Return empty array or throw, depending on desired behavior\n      return [];\n    }\n  }\n}\n\n// Example usage of the custom provider\n// const myVoice = new MyCustomVoiceProvider({ apiKey: \"YOUR_CUSTOM_API_KEY\" });\n// const audio = await myVoice.speak(\"Hello from my custom provider!\");\n// audio.pipe(createWriteStream(\"custom_output.mp3\"));\n\n```\n\nThis updated custom provider example uses standardized types like `VoiceSpeakOptions`, `VoiceListenOptions`, `VoiceMetadata`, and `Readable` stream types for better consistency and type safety. It also includes more detailed placeholders for API logic and error handling.\n\n### Table of Contents\n\n- [Installation](https://voltagent.dev/docs/agents/voice/#installation)\n- [Supported Providers](https://voltagent.dev/docs/agents/voice/#supported-providers)\n- [Basic Usage](https://voltagent.dev/docs/agents/voice/#basic-usage)\n  - [Initialize a Voice Provider](https://voltagent.dev/docs/agents/voice/#initialize-a-voice-provider)\n  - [Text-to-Speech (TTS)](https://voltagent.dev/docs/agents/voice/#text-to-speech-tts)\n  - [Speech-to-Text (STT)](https://voltagent.dev/docs/agents/voice/#speech-to-text-stt)\n  - [List Available Voices](https://voltagent.dev/docs/agents/voice/#list-available-voices)\n- [Integrating with Agent](https://voltagent.dev/docs/agents/voice/#integrating-with-agent)\n- [Event Handling](https://voltagent.dev/docs/agents/voice/#event-handling)\n- [Creating a Custom Voice Provider](https://voltagent.dev/docs/agents/voice/#creating-a-custom-voice-provider)",
      "metadata": {
        "og:image": "https://voltagent.dev/img/social3.png",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "language": "en",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_tag": "docs-default-current",
        "og:title": "Voice | VoltAgent",
        "ogTitle": "Voice | VoltAgent",
        "ogUrl": "https://voltagent.dev/docs/agents/voice/",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "og:url": "https://voltagent.dev/docs/agents/voice/",
        "ogDescription": "The @voltagent/voice package provides text-to-speech (TTS) and speech-to-text (STT) capabilities through various providers. It allows your applications to speak text and transcribe audio with minimal setup.",
        "title": "Voice | VoltAgent",
        "docusaurus_locale": "en",
        "generator": "Docusaurus v3.1.1",
        "docsearch:version": "current",
        "ogLocale": "en",
        "twitter:card": "summary_large_image",
        "docusaurus_version": "current",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:locale": "en",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "docsearch:language": "en",
        "description": "The @voltagent/voice package provides text-to-speech (TTS) and speech-to-text (STT) capabilities through various providers. It allows your applications to speak text and transcribe audio with minimal setup.",
        "og:description": "The @voltagent/voice package provides text-to-speech (TTS) and speech-to-text (STT) capabilities through various providers. It allows your applications to speak text and transcribe audio with minimal setup.",
        "scrapeId": "9ed303dc-285a-4e80-8c74-17cec593d68f",
        "sourceURL": "https://voltagent.dev/docs/agents/voice/",
        "url": "https://voltagent.dev/docs/agents/voice/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:37.642Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/agents/memory/in-memory/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# In-Memory Storage\n\nVoltAgent's core package ( `@voltagent/core`) includes `InMemoryStorage`, a simple memory provider that stores conversation history directly in the application's memory.\n\n## Overview [â€‹](https://voltagent.dev/docs/agents/memory/in-memory/\\#overview \"Direct link to Overview\")\n\n- **Use Case:** Development, testing, demos, or any scenario where persistent memory across application restarts is not required.\n- **Pros:** Zero external dependencies, extremely fast, easy to use.\n- **Cons:** All stored data (conversation history, agent state) is **lost** when the application stops or restarts.\n- **Availability:** Included directly in `@voltagent/core`.\n\n## Configuration [â€‹](https://voltagent.dev/docs/agents/memory/in-memory/\\#configuration \"Direct link to Configuration\")\n\nInitialize `InMemoryStorage` and pass it to your `Agent` configuration. It accepts optional configuration for limiting storage and enabling debugging.\n\n```codeBlockLines_e6Vv\nimport { Agent, InMemoryStorage } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Initialize InMemoryStorage\nconst memory = new InMemoryStorage({\n  // Optional: Limit the number of messages stored per conversation thread\n  storageLimit: 100, // Defaults to no limit if not specified\n\n  // Optional: Enable verbose debug logging from the memory provider\n  debug: true, // Defaults to false\n});\n\nconst agent = new Agent({\n  name: \"Ephemeral Agent\",\n  instructions: \"An agent using in-memory storage (history resets on restart).\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  memory: memory, // Assign the InMemoryStorage instance\n});\n\n// Interactions with this agent will use the in-memory store.\n// await agent.generateText(\"Remember this info.\", { userId: \"user1\", conversationId: \"conv1\" });\n// // If the app restarts here, the above message is lost.\n// await agent.generateText(\"Do you remember?\", { userId: \"user1\", conversationId: \"conv1\" });\n\n```\n\n**Configuration Options:**\n\n- `storageLimit` (number, optional): The maximum number of messages to retain per unique `userId`/ `conversationId` pair. When the limit is reached, the oldest messages are discarded to make room for new ones. Defaults to `Infinity` (no limit).\n- `debug` (boolean, optional): Enables detailed logging from the `InMemoryStorage` provider to the console, useful for understanding memory operations during development. Defaults to `false`.\n\n## When to Use [â€‹](https://voltagent.dev/docs/agents/memory/in-memory/\\#when-to-use \"Direct link to When to Use\")\n\n- **Development & Testing:** Quickly test agent logic without setting up a database.\n- **Stateless Use Cases:** When conversation history is not needed between sessions or application runs.\n- **Demos & Examples:** Simple setup for showcasing agent capabilities.\n- **Caching Layers:** Could potentially be used as a short-term cache in more complex memory strategies (though not its primary design).\n\nAvoid using `InMemoryStorage` in production environments where conversation history needs to be persistent.\n\n### Table of Contents\n\n- [Overview](https://voltagent.dev/docs/agents/memory/in-memory/#overview)\n- [Configuration](https://voltagent.dev/docs/agents/memory/in-memory/#configuration)\n- [When to Use](https://voltagent.dev/docs/agents/memory/in-memory/#when-to-use)",
      "metadata": {
        "description": "VoltAgent's core package (@voltagent/core) includes InMemoryStorage, a simple memory provider that stores conversation history directly in the application's memory.",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "ogTitle": "In-Memory Storage | VoltAgent",
        "og:title": "In-Memory Storage | VoltAgent",
        "og:url": "https://voltagent.dev/docs/agents/memory/in-memory/",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_tag": "docs-default-current",
        "ogUrl": "https://voltagent.dev/docs/agents/memory/in-memory/",
        "ogLocale": "en",
        "docsearch:language": "en",
        "docusaurus_version": "current",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "generator": "Docusaurus v3.1.1",
        "docsearch:version": "current",
        "docusaurus_locale": "en",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:image": "https://voltagent.dev/img/social3.png",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "ogDescription": "VoltAgent's core package (@voltagent/core) includes InMemoryStorage, a simple memory provider that stores conversation history directly in the application's memory.",
        "og:locale": "en",
        "language": "en",
        "title": "In-Memory Storage | VoltAgent",
        "twitter:card": "summary_large_image",
        "og:description": "VoltAgent's core package (@voltagent/core) includes InMemoryStorage, a simple memory provider that stores conversation history directly in the application's memory.",
        "scrapeId": "22843115-5fa5-4837-a2d4-c08192f0462b",
        "sourceURL": "https://voltagent.dev/docs/agents/memory/in-memory/",
        "url": "https://voltagent.dev/docs/agents/memory/in-memory/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:13.936Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/tools/reasoning-tool/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Reasoning Tools ( `think` & `analyze`)\n\nVoltAgent offers `think` and `analyze` tools, bundled via a `Toolkit` helper, to give agents step-by-step reasoning abilities. This helps agents break down problems, plan, analyze results internally, and structure their thought process before responding.\n\n## What are the `think` and `analyze` tools? [â€‹](https://voltagent.dev/docs/tools/reasoning-tool/\\#what-are-the-think-and-analyze-tools \"Direct link to what-are-the-think-and-analyze-tools\")\n\nInspired by structured reasoning techniques, these tools allow the agent to perform an internal monologue (\"stop and think\") during complex tasks. Instead of attempting a direct response, the agent performs explicit reasoning steps:\n\n- **Break Down Complexity:** Deconstruct multi-step problems or unclear requests using `think`.\n- **Plan Actions:** Decide the next steps, necessary tool calls, or required information using `think`.\n- **Analyze Information:** Evaluate information gathered from other tools or previous steps using `analyze`.\n- **Improve Reliability:** Verify intermediate steps and logic to reduce errors before finalizing the response.\n- **Handle Complex Instructions:** Follow detailed guidelines or policies step-by-step using `think` and `analyze`.\n\n**When to Use:**\n\nUse the `reasoning_tools` toolkit when the agent needs to:\n\n1. **Perform Sequential Tool Calls:** Plan sequences ( `think`) and evaluate intermediate results ( `analyze`).\n2. **Analyze Tool Outputs Carefully:** Process, verify, or synthesize results from tools before proceeding ( `analyze`).\n3. **Navigate Complex Rules/Policies:** Use `think` to understand rules and plan compliant actions, then `analyze` to check outcomes.\n4. **Make Sequential Decisions:** Reduce errors in multi-step processes (e.g., complex bookings, calculations, data processing).\n5. **Plan Complex Tasks:** Break down ambiguous problems and determine how to gather information incrementally ( `think`).\n\n**When Less Necessary:**\n\n- Simple, single-step tasks that require only one tool call or a direct answer.\n- Straightforward instructions without complex decisions or dependencies.\n\n## The `createReasoningTools` Helper [â€‹](https://voltagent.dev/docs/tools/reasoning-tool/\\#the-createreasoningtools-helper \"Direct link to the-createreasoningtools-helper\")\n\nUse the `@voltagent/core` helper `createReasoningTools` to easily add the reasoning tools to your agent:\n\n```codeBlockLines_e6Vv\nimport { createReasoningTools, type Toolkit } from \"@voltagent/core\";\n\n// Basic usage - includes both tools and adds instructions/examples\nconst reasoningToolkit: Toolkit = createReasoningTools();\n\n// Customized usage - e.g., only include 'think' and don't add instructions\nconst thinkOnlyToolkit: Toolkit = createReasoningTools({\n  analyze: false,\n  addInstructions: false,\n});\n\n```\n\nThis returns a `Toolkit` named `\"reasoning_tools\"`. Toolkits are a convenient way to bundle related tools and manage shared instructions. The `reasoning_tools` toolkit contains:\n\n1. **`think` Tool:** An internal scratchpad for the agent to plan, outline steps, and structure its thoughts.\n2. **`analyze` Tool:** A tool for the agent to evaluate results (from `think` or other tools) and decide the next move ( `continue`, `validate`, or `final_answer`).\n3. **Detailed Instructions & Examples (Optional):** Explains how the agent should use the tools iteratively. These are added to the agent's system prompt if `addInstructions: true` (which is the default).\n\n### Options for `createReasoningTools` [â€‹](https://voltagent.dev/docs/tools/reasoning-tool/\\#options-for-createreasoningtools \"Direct link to options-for-createreasoningtools\")\n\n```codeBlockLines_e6Vv\ntype CreateReasoningToolsOptions = {\n  /**\n   * Add detailed instructions and few-shot examples to the agent's system prompt.\n   * @default true\n   */\n  addInstructions?: boolean;\n  /**\n   * Include the 'think' tool in the toolkit.\n   * @default true\n   */\n  think?: boolean;\n  /**\n   * Include the 'analyze' tool in the toolkit.\n   * @default true\n   */\n  analyze?: boolean;\n  /**\n   * Include default few-shot examples along with instructions (if addInstructions is true).\n   * @default true\n   */\n  addFewShot?: boolean;\n  /**\n   * Provide custom few-shot examples instead of the default ones.\n   * Ignored if addInstructions or addFewShot is false.\n   * @default Predefined examples (see code)\n   */\n  fewShotExamples?: string;\n};\n\n```\n\n## Key Usage Instructions & Guidelines [â€‹](https://voltagent.dev/docs/tools/reasoning-tool/\\#key-usage-instructions--guidelines \"Direct link to Key Usage Instructions & Guidelines\")\n\nIf `addInstructions` is `true` (default), the agent's system prompt is augmented with guidance. Key guidelines include:\n\n> - **Always Think First:** You MUST use the 'think' tool before making other tool calls or generating a response, unless the request is extremely simple. Use 'think' multiple times to break down complex problems.\n> - **Iterate to Solve:** Use the 'think' and 'analyze' tools iteratively. The typical flow is `Think` -\\> \\[ `Think` -> ...\\] -\\> \\[Tool Calls if needed\\] -> \\[ `Analyze` if needed\\] -> ... -> `final_answer`. Repeat this cycle until you reach a satisfactory conclusion.\n> - **Make multiple tool calls in parallel:** After a 'think' step planning multiple actions, you can make multiple tool calls in parallel if needed.\n> - **Keep Thoughts Internal:** The reasoning steps (thoughts and analyses) are for your internal process only. Do not share them directly with the user unless asked to explain your reasoning.\n> - **Conclude Clearly:** When your analysis determines the `next_action` is `final_answer`, provide a concise and accurate final answer to the user based on your reasoning steps.\n\n_(These instructions are accompanied by few-shot examples demonstrating the flow if `addFewShot` is `true`)_.\n\n## How the Agent Uses the Tools (Internal Flow) [â€‹](https://voltagent.dev/docs/tools/reasoning-tool/\\#how-the-agent-uses-the-tools-internal-flow \"Direct link to How the Agent Uses the Tools (Internal Flow)\")\n\nThe power of these tools lies in how the agent uses them _internally_ before generating a response for the user. Here's a simplified example based on the default few-shot examples provided to the agent:\n\n**User Request:** What is the capital of France and its current population?\n\n**Agent's Internal Process (simplified):**\n\n1. **Initial Thought:** The agent calls `think` to break down the request.\n\n   - `think({ title: \"Plan Information Retrieval\", thought: \"User needs two facts: capital and population. First, find the capital.\", action: \"Search for capital of France\" })`\n2. **(Optional) External Tool Call:** The agent might call a search tool: `search({ query: \"capital of France\" })`. Assume the result is \"Paris\".\n3. **Analysis & Next Step:** The agent calls `analyze` to process the result.\n\n   - `analyze({ title: \"Analyze Capital Result\", result: \"Search result: Paris\", analysis: \"Got the capital (Paris). Now need population.\", next_action: \"continue\" })`\n4. **Further Thought:** Since the `next_action` was `continue`, the agent calls `think` again.\n\n   - `think({ title: \"Plan Population Retrieval\", thought: \"Next step: find population of Paris.\", action: \"Search for population of Paris\" })`\n5. **(Optional) External Tool Call:** Agent calls `search({ query: \"population of Paris\" })`. Assume result is \"~2.1 million\".\n6. **Final Analysis:** Agent analyzes the second result.\n\n   - `analyze({ title: \"Analyze Population Result\", result: \"Search result: ~2.1 million\", analysis: \"Have both capital and population. Ready to answer.\", next_action: \"final_answer\" })`\n\n**Agent's Final Answer to User:** (Generated _after_ the internal reasoning)\n\n> The capital of France is Paris. Its estimated population is approximately 2.1 million.\n\n### Key Tool Parameters [â€‹](https://voltagent.dev/docs/tools/reasoning-tool/\\#key-tool-parameters \"Direct link to Key Tool Parameters\")\n\nWhen the agent calls `think` or `analyze`, it uses parameters like:\n\n- `title`: A short label for the reasoning step (useful for tracing).\n- `thought` ( `think` only): The agent's detailed reasoning or plan.\n- `action` ( `think` only): The intended next step (e.g., call a specific tool, formulate the final answer).\n- `result` ( `analyze` only): The outcome being analyzed (e.g., output from another tool).\n- `analysis` ( `analyze` only): The agent's evaluation of the `result`.\n- `next_action` ( `analyze` only): The crucial decision: `continue` (more steps needed), `validate` (seek external confirmation), or `final_answer` (ready to respond to user).\n- `confidence`: An optional score (0.0-1.0) indicating the agent's confidence in its thought or analysis.\n\n## Example Agent Setup [â€‹](https://voltagent.dev/docs/tools/reasoning-tool/\\#example-agent-setup \"Direct link to Example Agent Setup\")\n\n![River Crossing Puzzle](https://cdn.voltagent.dev/docs/reasoning-demo.gif)\n\n```codeBlockLines_e6Vv\nimport { Agent, createReasoningTools, type Toolkit } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Get toolkit, automatically adding instructions & examples to system prompt\nconst reasoningToolkit: Toolkit = createReasoningTools(); // Uses defaults\n\nconst agent = new Agent({\n  name: \"ThinkingAgent\",\n  description: `\n    You are an AI assistant designed for complex problem-solving using structured reasoning.\n    You MUST use the 'think' and 'analyze' tools internally to break down problems, plan steps,\n    evaluate information, and decide on the best course of action before responding.\n    Always think step-by-step.\n  `,\n  // Agent description reinforced to use the tools\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"), // Ensure model supports tool use\n  tools: [\\\n    reasoningToolkit,\\\n    // ... add other tools the agent can call after thinking/analyzing\\\n    // e.g., searchTool, databaseQueryTool, etc.\\\n  ],\n  markdown: true,\n});\n\n// Example invocation (River Crossing Puzzle)\nconst result = await agent.generateText(`\n  Three project managers (PMs) and three engineers (ENGs) need to cross a river.\n  The boat holds only two people. At no point, on either river bank, can the engineers\n  outnumber the project managers (otherwise, chaos ensues!). How can they all cross safely?\n`);\n\nconsole.log(result); // The agent will perform think/analyze steps internally\n\n```\n\n[GitHub LogoGet the code example for this article on GitHub](https://github.com/VoltAgent/voltagent/tree/main/examples/with-thinking-tool)\n\nTo run this example locally:\n\n`npm create voltagent-app@latest -- --example with-thinking-tool`\n\nUsing these tools encourages a structured, internal thought process, leading to more reliable and explainable agent behavior, especially for complex tasks.\n\n## Best Practices [â€‹](https://voltagent.dev/docs/tools/reasoning-tool/\\#best-practices \"Direct link to Best Practices\")\n\n1. **Leverage Defaults:** Start with `createReasoningTools()` which enables all features ( `think`, `analyze`, instructions, examples). This provides the best initial guidance to the agent.\n2. **Reinforce in Agent Description:** Briefly mention in the agent's `description` that it should use the `think` and `analyze` tools for structured reasoning, complementing the detailed instructions added to the system prompt.\n3. **Provide Other Tools:** Reasoning tools are most effective when the agent can plan ( `think`) to use _other_ tools (like search, database access, calculations) and then evaluate ( `analyze`) their results.\n4. **Use Capable Models:** Ensure the underlying LLM ( `model`) is proficient at following instructions and using tools effectively (e.g., GPT-4, Claude 3).\n5. **Custom Examples for Nuance:** If the default few-shot examples aren't sufficient for your specific domain or complex workflows, provide tailored examples using the `fewShotExamples` option.\n6. **Monitor and Refine:** Observe the agent's internal reasoning steps (tool calls like `think` and `analyze`) using tools like the [VoltAgent VoltOps Platform](https://voltagent.dev/docs/observability/developer-console/) to identify areas where its logic could be improved. Refine the agent's `description` or provide custom `fewShotExamples` based on these observations.\n7. **Start with Complex Cases:** Introduce reasoning tools for tasks where the agent struggles with multi-step logic, planning, or managing information from multiple sources.\n\n### Table of Contents\n\n- [What are the `think` and `analyze` tools?](https://voltagent.dev/docs/tools/reasoning-tool/#what-are-the-think-and-analyze-tools)\n- [The `createReasoningTools` Helper](https://voltagent.dev/docs/tools/reasoning-tool/#the-createreasoningtools-helper)\n  - [Options for `createReasoningTools`](https://voltagent.dev/docs/tools/reasoning-tool/#options-for-createreasoningtools)\n- [Key Usage Instructions & Guidelines](https://voltagent.dev/docs/tools/reasoning-tool/#key-usage-instructions--guidelines)\n- [How the Agent Uses the Tools (Internal Flow)](https://voltagent.dev/docs/tools/reasoning-tool/#how-the-agent-uses-the-tools-internal-flow)\n  - [Key Tool Parameters](https://voltagent.dev/docs/tools/reasoning-tool/#key-tool-parameters)\n- [Example Agent Setup](https://voltagent.dev/docs/tools/reasoning-tool/#example-agent-setup)\n- [Best Practices](https://voltagent.dev/docs/tools/reasoning-tool/#best-practices)",
      "metadata": {
        "ogTitle": "Reasoning Tools (think & analyze) | VoltAgent",
        "description": "VoltAgent offers think and analyze tools, bundled via a Toolkit helper, to give agents step-by-step reasoning abilities. This helps agents break down problems, plan, analyze results internally, and structure their thought process before responding.",
        "generator": "Docusaurus v3.1.1",
        "docusaurus_locale": "en",
        "og:title": "Reasoning Tools (think & analyze) | VoltAgent",
        "og:description": "VoltAgent offers think and analyze tools, bundled via a Toolkit helper, to give agents step-by-step reasoning abilities. This helps agents break down problems, plan, analyze results internally, and structure their thought process before responding.",
        "docusaurus_tag": "docs-default-current",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "docusaurus_version": "current",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "og:url": "https://voltagent.dev/docs/tools/reasoning-tool/",
        "og:locale": "en",
        "ogLocale": "en",
        "title": "Reasoning Tools (think & analyze) | VoltAgent",
        "ogUrl": "https://voltagent.dev/docs/tools/reasoning-tool/",
        "ogDescription": "VoltAgent offers think and analyze tools, bundled via a Toolkit helper, to give agents step-by-step reasoning abilities. This helps agents break down problems, plan, analyze results internally, and structure their thought process before responding.",
        "docsearch:language": "en",
        "docsearch:version": "current",
        "twitter:card": "summary_large_image",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:image": "https://voltagent.dev/img/social3.png",
        "viewport": "width=device-width, initial-scale=1.0",
        "language": "en",
        "scrapeId": "d72d112c-2b8d-4ee6-80f3-f5abfa287c28",
        "sourceURL": "https://voltagent.dev/docs/tools/reasoning-tool/",
        "url": "https://voltagent.dev/docs/tools/reasoning-tool/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:23.166Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/observability/developer-console/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\nThe VoltAgent VoltOps Platform is a web-based tool designed to help you observe and debug your AI agents during development.\n\n![VoltOps LLM Observability Platform](https://cdn.voltagent.dev/readme/demo.gif)\n\n### Accessing the Console [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#accessing-the-console \"Direct link to Accessing the Console\")\n\nYou can access the hosted VoltOps Platform at:\n[https://console.voltagent.dev/](https://console.voltagent.dev/)\n\n### How it Works [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#how-it-works \"Direct link to How it Works\")\n\nWhen you run a VoltAgent application locally with observability enabled, it exposes a local server (typically on port `3141`). The VoltOps Platform connects directly to this local server via your browser.\n\n**Key Features (Local Debugging):**\n\n- **Local Connection:** The console communicates directly with your local agent process. No data is sent to or stored on any external servers for this local debugging mode. Your agent's execution data remains entirely on your machine.\n- **Real-time Visualization:** See the agent's execution flow, including function calls, tool usage, and message history, as it happens.\n- **Debugging Tools:** Inspect the details of each step, view logs, and analyze the agent's state at different points in time.\n\n**Important Note on Data:** The VoltOps Platform at [https://console.voltagent.dev/](https://console.voltagent.dev/) when connected to your `localhost` is for **local debugging only**. It does not store your data remotely.\n\n### Getting Started [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#getting-started \"Direct link to Getting Started\")\n\n1. Ensure your VoltAgent application has observability enabled and is running locally.\nYou should see output similar to this in your terminal, confirming the server is ready:\n\n\n\n\n\n```codeBlockLines_e6Vv\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n     VOLTAGENT SERVER STARTED SUCCESSFULLY\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n     âœ“ HTTP Server: http://localhost:3141\n\n     VoltOps Platform:    https://console.voltagent.dev\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n[VoltAgent] All packages are up to date\n\n```\n\n2. Open [https://console.voltagent.dev/](https://console.voltagent.dev/) in your browser.\n\n3. The console should automatically attempt to connect to `http://localhost:3141`. If your agent is running on a different port, you can configure the connection URL in the console's settings.\n\n\n### Production Tracing with VoltOpsClient [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#production-tracing-with-voltopsclient \"Direct link to Production Tracing with VoltOpsClient\")\n\nWhile the VoltOps Platform is excellent for local development and real-time debugging, VoltAgent also provides a way to capture and persist observability data for your agents running in production environments. This is achieved using the `VoltOpsClient`.\n\nThe `VoltOpsClient` is a unified client that provides both observability export and prompt management functionality. It allows you to:\n\n- Monitor deployed agents in production\n- Analyze behavior over time with detailed tracing\n- Debug issues that occur in production environments\n- Store a history of agent interactions\n- Use dynamic prompts managed from the VoltOps dashboard\n\nTo use the `VoltOpsClient`, you'll need to:\n\n1. **Create a project:** Sign up or log in at [https://console.voltagent.dev/tracing-setup](https://console.voltagent.dev/tracing-setup) to create a new project. This will provide you with a Public Key and a Secret Key.\n2. **Configure your VoltAgent application:** Add the `VoltOpsClient` to your `VoltAgent` configuration with your keys.\n\n![VoltAgent Client Configuration](https://cdn.voltagent.dev/docs/voltagent-console-team.gif)\n\nHere's an example of how to set up the `VoltOpsClient` in your TypeScript application:\n\n```codeBlockLines_e6Vv\nimport { Agent, VoltAgent, VoltOpsClient } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  name: \"My Production Agent\",\n  instructions: \"You are a helpful assistant designed for production.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n});\n\nconst voltOpsPublicKey = process.env.VOLTAGENT_PUBLIC_KEY;\nconst voltOpsSecretKey = process.env.VOLTAGENT_SECRET_KEY;\n\nnew VoltAgent({\n  agents: {\n    mainAgent: agent,\n  },\n  voltOpsClient: new VoltOpsClient({\n    publicKey: voltOpsPublicKey,\n    secretKey: voltOpsSecretKey,\n  }),\n});\n\n// Your agent is now configured for full observability in the VoltOps cloud\n// and can use dynamic prompts from the VoltOps dashboard.\n\n```\n\n#### Advanced VoltOpsClient Configuration [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#advanced-voltopsclient-configuration \"Direct link to Advanced VoltOpsClient Configuration\")\n\nThe `VoltOpsClient` offers several configuration options:\n\n```codeBlockLines_e6Vv\nconst voltOpsClient = new VoltOpsClient({\n  publicKey: process.env.VOLTAGENT_PUBLIC_KEY,\n  secretKey: process.env.VOLTAGENT_SECRET_KEY,\n  baseUrl: \"https://api.voltagent.dev\", // Optional: Custom API endpoint\n  observability: true, // Enable/disable observability export\n  prompts: true, // Enable/disable prompt management\n  promptCache: {\n    enabled: true, // Enable prompt caching\n    ttl: 300, // Cache TTL in seconds (5 minutes)\n    maxSize: 100, // Maximum cache entries\n  },\n  fetch: customFetch, // Optional: Custom fetch implementation\n});\n\n```\n\nYou can also configure `VoltOpsClient` per agent for more granular control:\n\n```codeBlockLines_e6Vv\nconst specificAgent = new Agent({\n  name: \"Specialized Agent\",\n  instructions: \"You are a specialized assistant.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  voltOpsClient: new VoltOpsClient({\n    publicKey: process.env.SPECIALIZED_PUBLIC_KEY,\n    secretKey: process.env.SPECIALIZED_SECRET_KEY,\n    // This agent has its own VoltOps configuration\n  }),\n});\n\n```\n\nThis setup ensures that your agent's activities are securely transmitted and stored with full observability, providing valuable insights for production monitoring and analysis, plus the ability to use dynamic prompts managed from the VoltOps dashboard.\n\n### Exploring the Console Features [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#exploring-the-console-features \"Direct link to Exploring the Console Features\")\n\nOnce connected, the VoltOps Platform provides several views to help you understand your agent's behavior:\n\n#### Agent List View [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#agent-list-view \"Direct link to Agent List View\")\n\nThe main view often displays a list of active or recent agent sessions. This allows you to get a quick overview of agents that have run or are currently running.\n\n#### Agent Detail View [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#agent-detail-view \"Direct link to Agent Detail View\")\n\nClicking on an agent session in the list will take you to the detail view. This is where you can dive deep into a single agent's execution.\n\n#### Execution Trace/Timeline [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#execution-tracetimeline \"Direct link to Execution Trace/Timeline\")\n\nWithin the detail view, you'll typically find a visual representation of the agent's execution flow. This might be a timeline or a graph showing:\n\n- The sequence of steps the agent took.\n- Which functions or tools were called at each step.\n- The inputs and outputs of each step.\n\n#### Message & Log Inspection [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#message--log-inspection \"Direct link to Message & Log Inspection\")\n\nYou can usually select individual steps in the execution trace to inspect the details, such as:\n\n- The exact messages exchanged (e.g., prompts sent to an LLM, responses received).\n- Internal logs or state information recorded by the agent during that step.\n- Tool inputs and outputs.\n\n#### Connection Management [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#connection-management \"Direct link to Connection Management\")\n\nThe console provides feedback on its connection status to your local VoltAgent server (e.g., `http://localhost:3141`). Look for indicators (like the `ConnectionAlert` component) showing whether the connection is active or if there are issues. You might also find settings to change the target URL if your agent isn't running on the default `http://localhost:3141`.\n\nRemember, this connection is for local debugging. For sending data to the VoltAgent cloud for persistent storage and production monitoring, you should configure the `VoltOpsClient` in your application code.\n\n### Migration Guide: From telemetryExporter to VoltOpsClient [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#migration-guide-from-telemetryexporter-to-voltopsclient \"Direct link to Migration Guide: From telemetryExporter to VoltOpsClient\")\n\nIf you're currently using the deprecated `telemetryExporter` configuration, here's how to migrate to the new `VoltOpsClient`:\n\n#### Before (Deprecated âŒ) [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#before-deprecated- \"Direct link to Before (Deprecated âŒ)\")\n\n```codeBlockLines_e6Vv\nimport { Agent, VoltAgent, VoltAgentExporter } from \"@voltagent/core\";\n\nnew VoltAgent({\n  agents: { mainAgent: agent },\n  // âŒ This approach is deprecated\n  telemetryExporter: new VoltAgentExporter({\n    publicKey: process.env.VOLTAGENT_PUBLIC_KEY,\n    secretKey: process.env.VOLTAGENT_SECRET_KEY,\n    baseUrl: \"https://api.voltagent.dev\",\n  }),\n});\n\n```\n\n#### After (Current âœ…) [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#after-current- \"Direct link to After (Current âœ…)\")\n\n```codeBlockLines_e6Vv\nimport { Agent, VoltAgent, VoltOpsClient } from \"@voltagent/core\";\n\nnew VoltAgent({\n  agents: { mainAgent: agent },\n  // âœ… Use VoltOpsClient instead\n  voltOpsClient: new VoltOpsClient({\n    publicKey: process.env.VOLTAGENT_PUBLIC_KEY,\n    secretKey: process.env.VOLTAGENT_SECRET_KEY,\n    baseUrl: \"https://api.voltagent.dev\", // Optional, this is the default\n    observability: true, // Enable observability (default: true)\n    prompts: false, // Disable prompts if you don't need them\n  }),\n});\n\n```\n\n#### Migration Steps [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#migration-steps \"Direct link to Migration Steps\")\n\n1. **Replace the import:** Change `VoltAgentExporter` to `VoltOpsClient`\n2. **Update the configuration key:** Change `telemetryExporter` to `voltOpsClient`\n3. **Update the constructor:** Use `new VoltOpsClient()` instead of `new VoltAgentExporter()`\n4. **Optional configuration:** Add `observability: true` to explicitly enable observability if needed\n\n#### Why Migrate? [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#why-migrate \"Direct link to Why Migrate?\")\n\n- **Unified client:** VoltOpsClient handles both observability and prompt management\n- **Better performance:** Improved caching and connection management\n- **New features:** Access to dynamic prompts and enhanced observability\n- **Future-proof:** The `VoltAgentExporter` will be removed in future versions\n\n#### Environment Variables [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#environment-variables \"Direct link to Environment Variables\")\n\nThe environment variable names remain the same:\n\n```codeBlockLines_e6Vv\n# .env file\nVOLTAGENT_PUBLIC_KEY=your_public_key_here\nVOLTAGENT_SECRET_KEY=your_secret_key_here\n\n```\n\n#### Troubleshooting [â€‹](https://voltagent.dev/docs/observability/developer-console/\\#troubleshooting \"Direct link to Troubleshooting\")\n\n**Common migration issues:**\n\n- **Import error:** Make sure you're importing `VoltOpsClient` instead of `VoltAgentExporter`\n- **Configuration error:** Ensure you're using `voltOpsClient` property instead of `telemetryExporter`\n- **Missing features:** If you only need observability, set `prompts: false` to disable prompt management\n\n### Table of Contents\n\n- [Accessing the Console](https://voltagent.dev/docs/observability/developer-console/#accessing-the-console)\n- [How it Works](https://voltagent.dev/docs/observability/developer-console/#how-it-works)\n- [Getting Started](https://voltagent.dev/docs/observability/developer-console/#getting-started)\n- [Production Tracing with VoltOpsClient](https://voltagent.dev/docs/observability/developer-console/#production-tracing-with-voltopsclient)\n- [Exploring the Console Features](https://voltagent.dev/docs/observability/developer-console/#exploring-the-console-features)\n- [Migration Guide: From telemetryExporter to VoltOpsClient](https://voltagent.dev/docs/observability/developer-console/#migration-guide-from-telemetryexporter-to-voltopsclient)",
      "metadata": {
        "docsearch:version": "current",
        "docsearch:docusaurus_tag": "docs-default-current",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "ogTitle": "VoltOps Platform | VoltAgent",
        "viewport": "width=device-width, initial-scale=1.0",
        "og:locale": "en",
        "ogUrl": "https://voltagent.dev/docs/observability/developer-console/",
        "description": "The VoltAgent VoltOps Platform is a web-based tool designed to help you observe and debug your AI agents during development.",
        "generator": "Docusaurus v3.1.1",
        "og:url": "https://voltagent.dev/docs/observability/developer-console/",
        "twitter:card": "summary_large_image",
        "docusaurus_tag": "docs-default-current",
        "docsearch:language": "en",
        "ogLocale": "en",
        "language": "en",
        "og:description": "The VoltAgent VoltOps Platform is a web-based tool designed to help you observe and debug your AI agents during development.",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "og:title": "VoltOps Platform | VoltAgent",
        "docusaurus_version": "current",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "og:image": "https://voltagent.dev/img/social3.png",
        "title": "VoltOps Platform | VoltAgent",
        "ogDescription": "The VoltAgent VoltOps Platform is a web-based tool designed to help you observe and debug your AI agents during development.",
        "docusaurus_locale": "en",
        "scrapeId": "dc352631-5cc6-4aed-82b5-3038ac982207",
        "sourceURL": "https://voltagent.dev/docs/observability/developer-console/",
        "url": "https://voltagent.dev/docs/observability/developer-console/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:47.747Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/providers/anthropic-ai/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\nDeprecated Package\n\n**This provider is deprecated.** We recommend using the [Vercel AI SDK's Anthropic provider](https://ai-sdk.dev/providers/ai-sdk-providers/anthropic) instead with `@voltagent/vercel-ai`.\n\n**Migration Guide:**\n\n```codeBlockLines_e6Vv\n// Old (deprecated)\nimport { AnthropicProvider } from \"@voltagent/anthropic-ai\";\nconst provider = new AnthropicProvider({ apiKey: \"...\" });\n\n// New (recommended)\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { anthropic } from \"@ai-sdk/anthropic\";\nconst provider = new VercelAIProvider();\n// Use with: model: anthropic(\"claude-opus-4-1\")\n\n```\n\nFor the latest models and features, please see our [Providers & Models guide](https://voltagent.dev/docs/getting-started/providers-models/).\n\n# Anthropic AI Provider ( `@voltagent/anthropic-ai`)\n\nThe Anthropic AI Provider integrates VoltAgent with Anthropic's Claude models. It wraps the official [`@anthropic-ai/sdk`](https://github.com/anthropics/anthropic-sdk-typescript) SDK.\n\n**Key Characteristics:**\n\n- **Claude Models:** Supports all Claude models through the Anthropic API.\n- **Model Agnostic:** Accepts standard Claude model identifier strings (e.g., `'claude-opus-4-1'`, `'claude-3-opus-20240229'`).\n- **Core Functionality:** Focuses on text generation, streaming, and structured object generation using the underlying Anthropic SDK.\n\n## Installation [â€‹](https://voltagent.dev/docs/providers/anthropic-ai/\\#installation \"Direct link to Installation\")\n\n- npm\n- yarn\n- pnpm\n\n```codeBlockLines_e6Vv\nnpm install @voltagent/core @voltagent/anthropic-ai zod\n\n```\n\n_Note: `@anthropic-ai/sdk` is a peer dependency. `zod` is required if using `generateObject`._\n\n## Configuration [â€‹](https://voltagent.dev/docs/providers/anthropic-ai/\\#configuration \"Direct link to Configuration\")\n\nThe `AnthropicProvider` requires an API key, which can be provided directly or through an environment variable.\n\n```codeBlockLines_e6Vv\nimport { AnthropicProvider } from \"@voltagent/anthropic-ai\";\n\n// Option 1: Direct API Key\nconst anthropicProvider = new AnthropicProvider({\n  apiKey: \"YOUR_ANTHROPIC_API_KEY\",\n});\n\n// Option 2: Environment Variable (ANTHROPIC_API_KEY)\n// Ensure process.env.ANTHROPIC_API_KEY is set\nconst anthropicProvider = new AnthropicProvider({});\n\n```\n\n## Usage [â€‹](https://voltagent.dev/docs/providers/anthropic-ai/\\#usage \"Direct link to Usage\")\n\nInstantiate your `Agent` with the configured `AnthropicProvider`:\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { AnthropicProvider } from \"@voltagent/anthropic-ai\";\n\nconst anthropicProvider = new AnthropicProvider({ apiKey: \"YOUR_ANTHROPIC_API_KEY\" });\n\nconst agent = new Agent({\n  name: \"Claude Agent\",\n  instructions: \"An agent powered by Claude\",\n  llm: anthropicProvider,\n  model: \"claude-opus-4-1\", // Specify the desired Claude model\n});\n\n// Example call\nasync function run() {\n  const response = await agent.generateText(\"What is the capital of France?\");\n  console.log(response.text);\n}\n\nrun();\n\n```\n\n## Supported Methods [â€‹](https://voltagent.dev/docs/providers/anthropic-ai/\\#supported-methods \"Direct link to Supported Methods\")\n\n- **`generateText`**: âœ… Supported. Calls Anthropic SDK's `messages.create`.\n- **`streamText`**: âœ… Supported. Calls Anthropic SDK's `messages.create` with `stream: true`.\n- **`generateObject`**: âœ… Supported. Uses Anthropic's structured output capabilities with Zod schema validation.\n- **`streamObject`**: âœ… Supported. Streams structured objects with schema validation.\n\n## Tool Calling Support [â€‹](https://voltagent.dev/docs/providers/anthropic-ai/\\#tool-calling-support \"Direct link to Tool Calling Support\")\n\nâœ… **Supported.**\n\nThe `@voltagent/anthropic-ai` provider supports tool calling through the MCP (Model Control Protocol) format:\n\n```codeBlockLines_e6Vv\nimport { createTool } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\nconst weatherTool = createTool({\n  name: \"get_current_weather\",\n  description: \"Get the current weather in a location\",\n  parameters: z.object({\n    location: z.string().describe(\"The location to get weather for\"),\n  }),\n  execute: async (input) => {\n    return {\n      location: input.location,\n      temperature: 72,\n      condition: \"sunny\",\n    };\n  },\n});\n\nconst agent = new Agent({\n  name: \"weather-agent\",\n  instructions: \"A helpful weather assistant\",\n  llm: new AnthropicProvider(),\n  model: \"claude-opus-4-1\",\n  tools: [weatherTool],\n});\n\n```\n\n## Model Selection & Options [â€‹](https://voltagent.dev/docs/providers/anthropic-ai/\\#model-selection--options \"Direct link to Model Selection & Options\")\n\nThe specific Claude model (e.g., `'claude-opus-4-1'`, `'claude-3-opus-20240229'`) is set via the `model` property during `Agent` instantiation.\n\nYou can override or provide additional Anthropic-specific generation parameters (like `temperature`, `max_tokens`, `top_p`, `stop_sequences`, etc.) per-request using the `provider` key within the options object of `generateText`, `streamText`, or `generateObject`.\n\n```codeBlockLines_e6Vv\n// Example: Overriding temperature for a specific call\nconst response = await agent.generateText(\"Write a creative story.\", {\n  provider: {\n    temperature: 0.9,\n    max_tokens: 1024,\n    // Any other valid Anthropic parameters\n  },\n});\n\n```\n\nRefer to the [Anthropic API documentation](https://docs.anthropic.com/claude/reference/messages_post) for the full list of available configuration parameters.\n\n### Table of Contents\n\n- [Installation](https://voltagent.dev/docs/providers/anthropic-ai/#installation)\n- [Configuration](https://voltagent.dev/docs/providers/anthropic-ai/#configuration)\n- [Usage](https://voltagent.dev/docs/providers/anthropic-ai/#usage)\n- [Supported Methods](https://voltagent.dev/docs/providers/anthropic-ai/#supported-methods)\n- [Tool Calling Support](https://voltagent.dev/docs/providers/anthropic-ai/#tool-calling-support)\n- [Model Selection & Options](https://voltagent.dev/docs/providers/anthropic-ai/#model-selection--options)",
      "metadata": {
        "ogImage": "https://voltagent.dev/img/social3.png",
        "title": "Anthropic AI (Claude) | VoltAgent",
        "docsearch:docusaurus_tag": "docs-default-current",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "docusaurus_version": "current",
        "og:description": "This provider is deprecated. We recommend using the Vercel AI SDK's Anthropic provider instead with @voltagent/vercel-ai.",
        "viewport": "width=device-width, initial-scale=1.0",
        "twitter:card": "summary_large_image",
        "og:locale": "en",
        "og:url": "https://voltagent.dev/docs/providers/anthropic-ai/",
        "generator": "Docusaurus v3.1.1",
        "ogDescription": "This provider is deprecated. We recommend using the Vercel AI SDK's Anthropic provider instead with @voltagent/vercel-ai.",
        "docusaurus_locale": "en",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "ogUrl": "https://voltagent.dev/docs/providers/anthropic-ai/",
        "og:image": "https://voltagent.dev/img/social3.png",
        "docsearch:language": "en",
        "language": "en",
        "docusaurus_tag": "docs-default-current",
        "docsearch:version": "current",
        "og:title": "Anthropic AI (Claude) | VoltAgent",
        "description": "This provider is deprecated. We recommend using the Vercel AI SDK's Anthropic provider instead with @voltagent/vercel-ai.",
        "ogTitle": "Anthropic AI (Claude) | VoltAgent",
        "ogLocale": "en",
        "scrapeId": "e8b1d836-397d-4ce4-9651-125656c58fc7",
        "sourceURL": "https://voltagent.dev/docs/providers/anthropic-ai/",
        "url": "https://voltagent.dev/docs/providers/anthropic-ai/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:46.943Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/utils/create-prompt/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# `createPrompt`\n\nThe `createPrompt` utility provides a type-safe and flexible way to manage and generate dynamic prompt strings. It allows you to define templates with placeholders ( `{{variableName}}`) and inject variables at runtime.\n\nIt achieves type safety by automatically inferring variable names from the template string itself. This enables TypeScript to verify that all necessary variables are provided when creating or calling the prompt function, preventing potential runtime errors caused by missing or misspelled variables.\n\n## Key Concepts [â€‹](https://voltagent.dev/docs/utils/create-prompt/\\#key-concepts \"Direct link to Key Concepts\")\n\n### Templates [â€‹](https://voltagent.dev/docs/utils/create-prompt/\\#templates \"Direct link to Templates\")\n\nPrompts are defined using template strings. Placeholders for dynamic content are specified using double curly braces: `{{variableName}}`.\n\n```codeBlockLines_e6Vv\nconst template = \"You are a helpful assistant that {{role}}. Task: {{task}}\";\n\n```\n\n### Variables [â€‹](https://voltagent.dev/docs/utils/create-prompt/\\#variables \"Direct link to Variables\")\n\nVariables provide the actual content for the placeholders. The `createPrompt` function requires you to provide default values for all variables defined in the template. You can override these defaults later when calling the generated prompt function.\n\n- **Default Variables:** Defined when creating the prompt function. **Required** for all placeholders in the template.\n- **Custom Variables:** Provided when calling the generated function to override default values.\n\nCustom variables always take precedence over default variables. If a placeholder doesn't have a corresponding variable in either the defaults or customs, it's replaced with an empty string.\n\n## Usage [â€‹](https://voltagent.dev/docs/utils/create-prompt/\\#usage \"Direct link to Usage\")\n\n### Importing [â€‹](https://voltagent.dev/docs/utils/create-prompt/\\#importing \"Direct link to Importing\")\n\n```codeBlockLines_e6Vv\nimport { createPrompt, PromptTemplate, PromptCreator } from \"@voltagent/core\";\n// Other helper types like TemplateVariables, ExtractVariableNames, AllowedVariableValue are also exported.\n\n```\n\n### Basic Example [â€‹](https://voltagent.dev/docs/utils/create-prompt/\\#basic-example \"Direct link to Basic Example\")\n\nDefine a template with default variables.\n\n```codeBlockLines_e6Vv\nimport { createPrompt, Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Define the prompt template and default variables\nconst basicPrompt = createPrompt({\n  template: `You are a helpful assistant that {{role}}.\nTask: {{task}}`,\n  variables: { role: \"simplifies complex topics\", task: \"summarize text\" },\n});\n\n// Generate prompt using only default variables\nconst prompt1 = basicPrompt();\nconsole.log(prompt1);\n/*\nOutput:\nYou are a helpful assistant that simplifies complex topics.\nTask: summarize text\n*/\n\nconst agent = new Agent({\n  name: \"Basic Assistant\",\n  // Use the generated prompt in the description field\n  description: prompt1,\n  llm: new VercelAIProvider(), // Example provider\n  model: openai(\"gpt-4o-mini\"), // Example model\n});\n\n```\n\n### Overriding Defaults [â€‹](https://voltagent.dev/docs/utils/create-prompt/\\#overriding-defaults \"Direct link to Overriding Defaults\")\n\nProvide custom variables when calling the generated function.\n\n```codeBlockLines_e6Vv\n// Generate prompt with a custom 'task'\nconst prompt2 = basicPrompt({ task: \"Explain quantum computing to a 10-year-old\" });\nconsole.log(prompt2);\n/*\nOutput:\nYou are a helpful assistant that simplifies complex topics.\nTask: Explain quantum computing to a 10-year-old\n*/\n\n// Override both 'role' and 'task'\nconst prompt3 = basicPrompt({\n  role: \"translates languages\",\n  task: \"Translate 'hello' to French\",\n});\nconsole.log(prompt3);\n/*\nOutput:\nYou are a helpful assistant that translates languages.\nTask: Translate 'hello' to French\n*/\n\n```\n\n### More Complex Example (Agent Prompt) [â€‹](https://voltagent.dev/docs/utils/create-prompt/\\#more-complex-example-agent-prompt \"Direct link to More Complex Example (Agent Prompt)\")\n\n`createPrompt` is useful for structuring complex prompts, like those for AI agents.\n\n```codeBlockLines_e6Vv\nimport { createPrompt } from \"@voltagent/core\";\n\nconst agentPrompt = createPrompt({\n  template: `You are an AI agent with the following capabilities: {{capabilities}}.\nYour current goal is: {{goal}}\nAvailable context: {{context}}\nTask: {{task}}`,\n  variables: {\n    capabilities: \"web search, code execution\",\n    goal: \"Answer user queries\",\n    context: \"No specific context yet\",\n    task: \"\", // Default task is empty\n  },\n});\n\nconst agentTaskPrompt = agentPrompt({\n  goal: \"Help the user solve a programming problem\",\n  context: \"User is working with Node.js and Express\",\n  task: \"Debug an error in a REST API endpoint\",\n});\n\nconsole.log(agentTaskPrompt);\n/*\nOutput:\nYou are an AI agent with the following capabilities: web search, code execution.\nYour current goal is: Help the user solve a programming problem\nAvailable context: User is working with Node.js and Express\nTask: Debug an error in a REST API endpoint\n*/\n\n```\n\n## API Reference [â€‹](https://voltagent.dev/docs/utils/create-prompt/\\#api-reference \"Direct link to API Reference\")\n\n### `createPrompt<T extends string>(options: PromptTemplate<T>): PromptCreator<T>` [â€‹](https://voltagent.dev/docs/utils/create-prompt/\\#createpromptt-extends-stringoptions-prompttemplatet-promptcreatort \"Direct link to createpromptt-extends-stringoptions-prompttemplatet-promptcreatort\")\n\nCreates a type-safe, reusable prompt generation function based on a template string literal `T`.\n\n- **`T`**: A string literal type representing the template. Variable names are inferred from this type.\n- \\*\\* `options`\n\n### Table of Contents\n\n- [Key Concepts](https://voltagent.dev/docs/utils/create-prompt/#key-concepts)\n  - [Templates](https://voltagent.dev/docs/utils/create-prompt/#templates)\n  - [Variables](https://voltagent.dev/docs/utils/create-prompt/#variables)\n- [Usage](https://voltagent.dev/docs/utils/create-prompt/#usage)\n  - [Importing](https://voltagent.dev/docs/utils/create-prompt/#importing)\n  - [Basic Example](https://voltagent.dev/docs/utils/create-prompt/#basic-example)\n  - [Overriding Defaults](https://voltagent.dev/docs/utils/create-prompt/#overriding-defaults)\n  - [More Complex Example (Agent Prompt)](https://voltagent.dev/docs/utils/create-prompt/#more-complex-example-agent-prompt)\n- [API Reference](https://voltagent.dev/docs/utils/create-prompt/#api-reference)\n  - [`createPrompt<T extends string>(options: PromptTemplate<T>): PromptCreator<T>`](https://voltagent.dev/docs/utils/create-prompt/#createpromptt-extends-stringoptions-prompttemplatet-promptcreatort)",
      "metadata": {
        "og:image": "https://voltagent.dev/img/social3.png",
        "viewport": "width=device-width, initial-scale=1.0",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "ogDescription": "The createPrompt utility provides a type-safe and flexible way to manage and generate dynamic prompt strings. It allows you to define templates with placeholders ({}) and inject variables at runtime.",
        "ogLocale": "en",
        "og:locale": "en",
        "twitter:card": "summary_large_image",
        "og:description": "The createPrompt utility provides a type-safe and flexible way to manage and generate dynamic prompt strings. It allows you to define templates with placeholders ({}) and inject variables at runtime.",
        "docsearch:language": "en",
        "ogTitle": "Create a Prompt | VoltAgent",
        "language": "en",
        "generator": "Docusaurus v3.1.1",
        "docusaurus_locale": "en",
        "ogUrl": "https://voltagent.dev/docs/utils/create-prompt/",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "og:url": "https://voltagent.dev/docs/utils/create-prompt/",
        "docusaurus_tag": "docs-default-current",
        "docsearch:version": "current",
        "docsearch:docusaurus_tag": "docs-default-current",
        "title": "Create a Prompt | VoltAgent",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "og:title": "Create a Prompt | VoltAgent",
        "description": "The createPrompt utility provides a type-safe and flexible way to manage and generate dynamic prompt strings. It allows you to define templates with placeholders ({}) and inject variables at runtime.",
        "docusaurus_version": "current",
        "scrapeId": "d65adb18-689e-49fb-8f66-7eaa161b2b3a",
        "sourceURL": "https://voltagent.dev/docs/utils/create-prompt/",
        "url": "https://voltagent.dev/docs/utils/create-prompt/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:33.079Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/providers/groq-ai/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\nDeprecated Package\n\n**This provider is deprecated.** We recommend using the [Vercel AI SDK's Groq provider](https://ai-sdk.dev/providers/ai-sdk-providers/groq) instead with `@voltagent/vercel-ai`.\n\n**Migration Guide:**\n\n```codeBlockLines_e6Vv\n// Old (deprecated)\nimport { GroqProvider } from \"@voltagent/groq-ai\";\nconst provider = new GroqProvider({ apiKey: \"...\" });\n\n// New (recommended)\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { groq } from \"@ai-sdk/groq\";\nconst provider = new VercelAIProvider();\n// Use with: model: groq(\"llama-3.3-70b-versatile\")\n\n```\n\nFor the latest models and features, please see our [Providers & Models guide](https://voltagent.dev/docs/getting-started/providers-models/).\n\n# Groq AI Provider ( `@voltagent/groq-ai`)\n\nThe Groq AI Provider connects VoltAgent to the Groq API, enabling the use of language models hosted on Groq's high-performance infrastructure. It utilizes the [`groq-sdk`](https://github.com/groq/groq-typescript) Node.js library.\n\n**Key Characteristics:**\n\n- **High-Speed Inference:** Leverages Groq's LPUâ„¢ Inference Engine for fast response times.\n- **API Key Authentication:** Uses Groq API keys for authentication.\n- **OpenAI-Compatible API:** Primarily interacts with Groq's chat completions endpoint, which shares similarities with the OpenAI API structure.\n\n## Installation [â€‹](https://voltagent.dev/docs/providers/groq-ai/\\#installation \"Direct link to Installation\")\n\n- npm\n- yarn\n- pnpm\n\n```codeBlockLines_e6Vv\nnpm install @voltagent/core @voltagent/groq-ai zod\n\n```\n\n_Note: `groq-sdk` is a peer dependency. `zod` is required if using `generateObject`._\n\n## Configuration [â€‹](https://voltagent.dev/docs/providers/groq-ai/\\#configuration \"Direct link to Configuration\")\n\nThe `GroqProvider` requires your Groq API key.\n\nYou can provide the API key directly during instantiation or set the `GROQ_API_KEY` environment variable.\n\n```codeBlockLines_e6Vv\nimport { GroqProvider } from \"@voltagent/groq-ai\";\n\n// Option 1: Direct API Key\nconst groqProviderDirect = new GroqProvider({\n  apiKey: \"YOUR_GROQ_API_KEY\",\n});\n\n// Option 2: Environment Variable (GROQ_API_KEY)\n// Ensure process.env.GROQ_API_KEY is set\nconst groqProviderEnv = new GroqProvider();\n\n```\n\nGet your API key from the [GroqCloud Console](https://console.groq.com/keys).\n\n## Full Runnable Example [â€‹](https://voltagent.dev/docs/providers/groq-ai/\\#full-runnable-example \"Direct link to Full Runnable Example\")\n\nFor a complete, runnable example demonstrating the use of this provider, please see:\n\n- **Groq AI:** [`examples/with-groq-ai`](https://github.com/VoltAgent/voltagent/tree/main/examples/with-groq-ai)\n\n## Usage [â€‹](https://voltagent.dev/docs/providers/groq-ai/\\#usage \"Direct link to Usage\")\n\nInstantiate your `Agent` with the configured `GroqProvider`:\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { GroqProvider } from \"@voltagent/groq-ai\";\n\n// Using environment variable configuration from above\nconst groqProvider = new GroqProvider();\n\nconst agent = new Agent({\n  name: \"Groq Speed Agent\",\n  instructions: \"An agent powered by Groq's fast inference\",\n  llm: groqProvider,\n  // Specify the desired Groq model ID (e.g., Llama3, Mixtral)\n  // Find available models: https://console.groq.com/docs/models\n  model: \"llama3-8b-8192\",\n});\n\n// Example call\nasync function run() {\n  const response = await agent.generateText(\"Explain what makes Groq's inference engine fast.\");\n  console.log(response.text);\n}\n\nrun();\n\n```\n\n## Supported Methods [â€‹](https://voltagent.dev/docs/providers/groq-ai/\\#supported-methods \"Direct link to Supported Methods\")\n\n- **`generateText`**: Supported. Calls Groq SDK's `chat.completions.create`.\n- **`streamText`**: Supported. Calls Groq SDK's `chat.completions.create` with `stream: true`.\n- **`generateObject`**: Supported. Calls Groq SDK's `chat.completions.create` with `response_format: { type: 'json_object' }`. Requires a `z.ZodObject` schema and a model that supports JSON mode.\n- **`streamObject`**: âŒ **Not Supported.** This provider currently does not implement object streaming.\n\n## Multi-modal Support [â€‹](https://voltagent.dev/docs/providers/groq-ai/\\#multi-modal-support \"Direct link to Multi-modal Support\")\n\nâŒ **Not Supported.**\n\nThe provider currently only handles string content within `BaseMessage` objects. Multi-modal inputs (like images) are not processed.\n\n## Tool Calling Support [â€‹](https://voltagent.dev/docs/providers/groq-ai/\\#tool-calling-support \"Direct link to Tool Calling Support\")\n\nâœ… **Supported!**\n\nNative tool calling support for the `@voltagent/groq-ai` provider is now available as of version `0.1.4`. This allows you to define tools (functions) that Groq AI models can invoke as part of their response generation, using VoltAgent's `generateText` or `streamText` methods with tool definitions.\n\nThis functionality was made possible by the contributions from [@TheEmi](https://github.com/TheEmi) in [Release v0.1.4](https://github.com/VoltAgent/voltagent/releases/tag/%40voltagent%2Fgroq-ai%400.1.4).\n\nFor examples and further details on how to define and use tools with VoltAgent, please refer to the general VoltAgent documentation on [Tool Calling](https://voltagent.dev/docs/tools/overview/).\n\nMake sure your `@voltagent/groq-ai` package is updated to `0.1.4` or later to use this feature.\n\n## Model Selection & Options [â€‹](https://voltagent.dev/docs/providers/groq-ai/\\#model-selection--options \"Direct link to Model Selection & Options\")\n\nThe specific Groq model ID (e.g., `'llama3-70b-8192'`, `'mixtral-8x7b-32768'`) is set via the `model` property during `Agent` instantiation. Refer to the [Groq Models Documentation](https://console.groq.com/docs/models) for available model IDs.\n\nYou can override or provide additional Groq-specific generation parameters (like `temperature`, `max_tokens`, `top_p`, `stop`, etc.) per-request using the `provider` key within the options object of `generateText`, `streamText`, or `generateObject`.\n\n```codeBlockLines_e6Vv\n// Example: Overriding temperature and max_tokens for a specific call\nconst response = await agent.generateText(\"Write a short story about a futuristic city.\", {\n  provider: {\n    temperature: 0.8,\n    maxTokens: 500,\n    // Other Groq-specific parameters (max_tokens, top_p, etc.)\n  },\n});\n\n```\n\nRefer to the [`groq-sdk` documentation](https://github.com/groq/groq-typescript) or the [Groq API Reference](https://console.groq.com/docs/api-reference#chat-create) for the full list of available parameters.\n\n## Code Examples [â€‹](https://voltagent.dev/docs/providers/groq-ai/\\#code-examples \"Direct link to Code Examples\")\n\n### Text Generation ( `generateText`) [â€‹](https://voltagent.dev/docs/providers/groq-ai/\\#text-generation-generatetext \"Direct link to text-generation-generatetext\")\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { GroqProvider } from \"@voltagent/groq-ai\";\n\nasync function main() {\n  // Assumes GROQ_API_KEY is set in environment variables\n  const groqProvider = new GroqProvider();\n\n  const agent = new Agent({\n    name: \"Groq Text Agent\",\n    instructions: \"Generates text using Groq AI\",\n    llm: groqProvider,\n    model: \"mixtral-8x7b-32768\", // Example model\n  });\n\n  const prompt = \"What is the capital of France?\";\n\n  try {\n    const response = await agent.generateText(prompt);\n    console.log(`Agent response to \"${prompt}\":`);\n    console.log(response.text);\n    console.log(\"Usage:\", response.usage);\n    console.log(\"Finish Reason:\", response.finishReason);\n  } catch (error) {\n    console.error(\"Error generating text:\", error);\n  }\n}\n\nmain();\n\n```\n\n### Streaming Text ( `streamText`) [â€‹](https://voltagent.dev/docs/providers/groq-ai/\\#streaming-text-streamtext \"Direct link to streaming-text-streamtext\")\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { GroqProvider } from \"@voltagent/groq-ai\";\n\nasync function main() {\n  const groqProvider = new GroqProvider({\n    // Or provide apiKey directly\n    // apiKey: 'YOUR_GROQ_API_KEY'\n  });\n\n  const agent = new Agent({\n    name: \"Groq Streaming Agent\",\n    instructions: \"Streams text using Groq AI\",\n    llm: groqProvider,\n    model: \"llama3-8b-8192\", // Example model\n  });\n\n  const prompt = \"Write a haiku about speed.\";\n\n  try {\n    const streamResponse = await agent.streamText(prompt);\n\n    console.log(`Streaming agent response to \"${prompt}\":`);\n    let fullText = \"\";\n    for await (const chunk of streamResponse.textStream) {\n      fullText += chunk;\n      process.stdout.write(chunk);\n    }\n    console.log(\"\\n--- Stream Finished ---\");\n    // Note: Usage info might be available via callbacks (onFinish/onStepFinish)\n    // or attached to the stream result in the provider implementation.\n    // Check GroqProvider source for specifics if needed.\n  } catch (error) {\n    console.error(\"Error streaming text:\", error);\n  }\n}\n\nmain();\n\n```\n\n### Generating Structured Objects ( `generateObject`) [â€‹](https://voltagent.dev/docs/providers/groq-ai/\\#generating-structured-objects-generateobject \"Direct link to generating-structured-objects-generateobject\")\n\n_Requires a model that supports JSON mode (e.g., Llama3 models on Groq)._ Find compatible models on the [Groq models page](https://console.groq.com/docs/models).\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { GroqProvider } from \"@voltagent/groq-ai\";\nimport { z } from \"zod\"; // Import Zod\n\n// Define a Zod schema for the desired object structure\nconst citySchema = z.object({\n  name: z.string().describe(\"The city name\"),\n  country: z.string().describe(\"The country the city is in\"),\n  population: z.number().int().positive().describe(\"Estimated population\"),\n  landmarks: z.array(z.string()).describe(\"List of famous landmarks\"),\n});\n\nasync function main() {\n  const groqProvider = new GroqProvider();\n\n  // Use a model supporting JSON mode\n  const agent = new Agent({\n    name: \"Groq Object Agent\",\n    instructions: \"Generates structured data using Groq AI\",\n    llm: groqProvider,\n    model: \"llama3-70b-8192\",\n  });\n\n  const prompt = \"Generate details for Paris, France.\";\n\n  try {\n    // Call generateObject with the prompt and Zod schema\n    const response = await agent.generateObject(prompt, citySchema, {\n      provider: {\n        temperature: 0.1, // Low temperature for JSON mode\n      },\n    });\n\n    console.log(\"Generated Object:\");\n    console.log(response.object);\n    console.log(\"Usage:\", response.usage);\n    console.log(\"Finish Reason:\", response.finishReason);\n  } catch (error) {\n    console.error(\"Error generating object:\", error);\n  }\n}\n\nmain();\n\n```\n\n### Table of Contents\n\n- [Installation](https://voltagent.dev/docs/providers/groq-ai/#installation)\n- [Configuration](https://voltagent.dev/docs/providers/groq-ai/#configuration)\n- [Full Runnable Example](https://voltagent.dev/docs/providers/groq-ai/#full-runnable-example)\n- [Usage](https://voltagent.dev/docs/providers/groq-ai/#usage)\n- [Supported Methods](https://voltagent.dev/docs/providers/groq-ai/#supported-methods)\n- [Multi-modal Support](https://voltagent.dev/docs/providers/groq-ai/#multi-modal-support)\n- [Tool Calling Support](https://voltagent.dev/docs/providers/groq-ai/#tool-calling-support)\n- [Model Selection & Options](https://voltagent.dev/docs/providers/groq-ai/#model-selection--options)\n- [Code Examples](https://voltagent.dev/docs/providers/groq-ai/#code-examples)\n  - [Text Generation ( `generateText`)](https://voltagent.dev/docs/providers/groq-ai/#text-generation-generatetext)\n  - [Streaming Text ( `streamText`)](https://voltagent.dev/docs/providers/groq-ai/#streaming-text-streamtext)\n  - [Generating Structured Objects ( `generateObject`)](https://voltagent.dev/docs/providers/groq-ai/#generating-structured-objects-generateobject)",
      "metadata": {
        "docusaurus_locale": "en",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:title": "Groq AI | VoltAgent",
        "language": "en",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "description": "This provider is deprecated. We recommend using the Vercel AI SDK's Groq provider instead with @voltagent/vercel-ai.",
        "ogUrl": "https://voltagent.dev/docs/providers/groq-ai/",
        "og:url": "https://voltagent.dev/docs/providers/groq-ai/",
        "twitter:card": "summary_large_image",
        "og:description": "This provider is deprecated. We recommend using the Vercel AI SDK's Groq provider instead with @voltagent/vercel-ai.",
        "title": "Groq AI | VoltAgent",
        "og:locale": "en",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "generator": "Docusaurus v3.1.1",
        "docsearch:version": "current",
        "ogTitle": "Groq AI | VoltAgent",
        "docsearch:language": "en",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_version": "current",
        "ogLocale": "en",
        "docusaurus_tag": "docs-default-current",
        "ogDescription": "This provider is deprecated. We recommend using the Vercel AI SDK's Groq provider instead with @voltagent/vercel-ai.",
        "og:image": "https://voltagent.dev/img/social3.png",
        "scrapeId": "2c2d00f4-60e4-447d-bcb9-a42321bffb8a",
        "sourceURL": "https://voltagent.dev/docs/providers/groq-ai/",
        "url": "https://voltagent.dev/docs/providers/groq-ai/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:49.766Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/rag/chroma/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# VoltAgent with Chroma\n\n[Chroma](https://www.trychroma.com/) is an AI-native open-source vector database designed to make it easy to build applications with embeddings. It handles the complexity of vector storage and search while providing a simple API for semantic search capabilities.\n\n## Prerequisites [â€‹](https://voltagent.dev/docs/rag/chroma/\\#prerequisites \"Direct link to Prerequisites\")\n\nBefore starting, ensure you have:\n\n- Node.js 18+ installed\n- OpenAI API key (for embeddings)\n\n**Note**: Docker or Python are no longer required since Chroma CLI is now bundled with the JS/TS package.\n\n## Installation [â€‹](https://voltagent.dev/docs/rag/chroma/\\#installation \"Direct link to Installation\")\n\nCreate a new VoltAgent project with Chroma integration:\n\n```codeBlockLines_e6Vv\nnpm create voltagent-app@latest -- --example with-chroma\ncd with-chroma\n\n```\n\nThis creates a complete VoltAgent + Chroma setup with sample data and two different agent configurations.\n\nInstall the dependencies:\n\n- npm\n- pnpm\n- yarn\n\n```codeBlockLines_e6Vv\nnpm install\n\n```\n\n## Start Chroma Server [â€‹](https://voltagent.dev/docs/rag/chroma/\\#start-chroma-server \"Direct link to Start Chroma Server\")\n\nSimply run the following command:\n\n```codeBlockLines_e6Vv\nnpm run chroma run\n\n```\n\nThis will start the Chroma server at `http://localhost:8000`.\n\n**Note**: For production deployments, you might prefer [Chroma Cloud](https://www.trychroma.com/), a fully managed hosted service. See the Environment Setup section below for cloud configuration.\n\n## Environment Setup [â€‹](https://voltagent.dev/docs/rag/chroma/\\#environment-setup \"Direct link to Environment Setup\")\n\nCreate a `.env` file with your configuration:\n\n### Option 1: Local Chroma Server [â€‹](https://voltagent.dev/docs/rag/chroma/\\#option-1-local-chroma-server \"Direct link to Option 1: Local Chroma Server\")\n\n```codeBlockLines_e6Vv\n# OpenAI API key for embeddings and LLM\nOPENAI_API_KEY=your-openai-api-key-here\n\n# Local Chroma server configuration (optional - defaults shown)\nCHROMA_HOST=localhost\nCHROMA_PORT=8000\n\n```\n\n### Option 2: [Chroma Cloud](https://www.trychroma.com/) [â€‹](https://voltagent.dev/docs/rag/chroma/\\#option-2-chroma-cloud \"Direct link to option-2-chroma-cloud\")\n\n```codeBlockLines_e6Vv\n# OpenAI API key for embeddings and LLM\nOPENAI_API_KEY=your-openai-api-key-here\n\n# Chroma Cloud configuration\nCHROMA_API_KEY=your-chroma-cloud-api-key\nCHROMA_TENANT=your-tenant-name\nCHROMA_DATABASE=your-database-name\n\n```\n\nThe code will automatically detect which configuration to use based on the presence of `CHROMA_API_KEY`.\n\n## Run Your Application [â€‹](https://voltagent.dev/docs/rag/chroma/\\#run-your-application \"Direct link to Run Your Application\")\n\nStart your VoltAgent application:\n\n- npm\n- pnpm\n- yarn\n\n```codeBlockLines_e6Vv\nnpm run dev\n\n```\n\nYou'll see:\n\n```codeBlockLines_e6Vv\nðŸš€ VoltAgent with Chroma is running!\nðŸ“š Sample knowledge base initialized with 5 documents\nðŸ“š Two different agents are ready:\n  1ï¸âƒ£ Assistant with Retriever - Automatic semantic search on every interaction\n  2ï¸âƒ£ Assistant with Tools - LLM decides when to search autonomously\n\nðŸ’¡ Chroma server started easily with npm run chroma run  (no Docker/Python needed!)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  VOLTAGENT SERVER STARTED SUCCESSFULLY\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  âœ“ HTTP Server: http://localhost:3141\n\n  VoltOps Platform:    https://console.voltagent.dev\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n```\n\n## Interact with Your Agents [â€‹](https://voltagent.dev/docs/rag/chroma/\\#interact-with-your-agents \"Direct link to Interact with Your Agents\")\n\nYour agents are now running! To interact with them:\n\n1. **Open the Console:** Click the [`https://console.voltagent.dev`](https://console.voltagent.dev/) link in your terminal output (or copy-paste it into your browser).\n2. **Find Your Agents:** On the VoltOps LLM Observability Platform page, you should see both agents listed:\n\n   - \"Assistant with Retriever\"\n   - \"Assistant with Tools\"\n3. **Open Agent Details:** Click on either agent's name.\n4. **Start Chatting:** On the agent detail page, click the chat icon in the bottom right corner to open the chat window.\n5. **Test RAG Capabilities:** Try questions like:\n\n   - \"What is VoltAgent?\"\n   - \"Tell me about vector databases\"\n   - \"How does TypeScript help with development?\"\n\n![VoltAgent with Chroma Demo](https://cdn.voltagent.dev/docs/chroma-rag-example.gif)\n\nYou should receive responses from your AI agents that include relevant information from your Chroma knowledge base, along with source references showing which documents were used to generate the response.\n\n## How It Works [â€‹](https://voltagent.dev/docs/rag/chroma/\\#how-it-works \"Direct link to How It Works\")\n\nThe following sections explain how this example is built and how you can customize it.\n\n### Create the Chroma Retriever [â€‹](https://voltagent.dev/docs/rag/chroma/\\#create-the-chroma-retriever \"Direct link to Create the Chroma Retriever\")\n\nCreate `src/retriever/index.ts`:\n\n```codeBlockLines_e6Vv\nimport { BaseRetriever, type BaseMessage, type RetrieveOptions } from \"@voltagent/core\";\nimport { ChromaClient, CloudClient, type QueryRowResult, type Metadata } from \"chromadb\";\nimport { OpenAIEmbeddingFunction } from \"@chroma-core/openai\";\n\n// Initialize Chroma client - supports both local and cloud\nconst chromaClient = process.env.CHROMA_API_KEY\n  ? new CloudClient() // Uses CHROMA_API_KEY, CHROMA_TENANT, CHROMA_DATABASE env vars\n  : new ChromaClient({\n      host: process.env.CHROMA_HOST || \"localhost\",\n      port: parseInt(process.env.CHROMA_PORT || \"8000\"),\n    });\n\n// Configure OpenAI embeddings\nconst embeddingFunction = new OpenAIEmbeddingFunction({\n  apiKey: process.env.OPENAI_API_KEY,\n  modelName: \"text-embedding-3-small\", // Efficient and cost-effective\n});\n\nconst collectionName = \"voltagent-knowledge-base\";\n\n```\n\n**Key Components Explained**:\n\n- **ChromaClient/CloudClient**: Connects to your local Chroma server or Chroma Cloud\n- **Automatic Detection**: Uses CloudClient if CHROMA\\_API\\_KEY is set, otherwise falls back to local ChromaClient\n- **OpenAIEmbeddingFunction**: Uses OpenAI's embedding models to convert text into vectors\n- **Collection**: A named container for your documents and their embeddings\n\n### Initialize Sample Data [â€‹](https://voltagent.dev/docs/rag/chroma/\\#initialize-sample-data \"Direct link to Initialize Sample Data\")\n\nAdd sample documents to get started:\n\n```codeBlockLines_e6Vv\nasync function initializeCollection() {\n  try {\n    const collection = await chromaClient.getOrCreateCollection({\n      name: collectionName,\n      embeddingFunction: embeddingFunction,\n    });\n\n    // Sample documents about your domain\n    const sampleDocuments = [\\\n      \"VoltAgent is a TypeScript framework for building AI agents with modular components.\",\\\n      \"Chroma is an AI-native open-source vector database that handles embeddings automatically.\",\\\n      \"Vector databases store high-dimensional vectors and enable semantic search capabilities.\",\\\n      \"Retrieval-Augmented Generation (RAG) combines information retrieval with language generation.\",\\\n      \"TypeScript provides static typing for JavaScript, making code more reliable and maintainable.\",\\\n    ];\n\n    const sampleIds = sampleDocuments.map((_, index) => `sample_${index + 1}`);\n\n    // Use upsert to avoid duplicates\n    await collection.upsert({\n      documents: sampleDocuments,\n      ids: sampleIds,\n      metadatas: sampleDocuments.map((_, index) => ({\n        type: \"sample\",\n        index: index + 1,\n        topic: index < 2 ? \"frameworks\" : index < 4 ? \"databases\" : \"programming\",\n      })),\n    });\n\n    console.log(\"ðŸ“š Sample knowledge base initialized\");\n  } catch (error) {\n    console.error(\"Error initializing collection:\", error);\n  }\n}\n\n// Initialize when module loads\ninitializeCollection();\n\n```\n\n**What This Does**:\n\n- Creates a collection with OpenAI embedding function\n- Adds sample documents with metadata\n- Uses `upsert` to avoid duplicate documents\n- Automatically generates embeddings for each document\n\n### Implement the Retriever Class [â€‹](https://voltagent.dev/docs/rag/chroma/\\#implement-the-retriever-class \"Direct link to Implement the Retriever Class\")\n\nCreate the main retriever class:\n\n```codeBlockLines_e6Vv\nasync function retrieveDocuments(query: string, nResults = 3) {\n  try {\n    const collection = await chromaClient.getOrCreateCollection({\n      name: collectionName,\n      embeddingFunction: embeddingFunction,\n    });\n\n    const results = await collection.query({\n      queryTexts: [query],\n      nResults,\n    });\n\n    // Use the new .rows() method for cleaner data access\n    const rows = results.rows();\n\n    if (!rows || rows.length === 0 || !rows[0]) {\n      return [];\n    }\n\n    // Format results - rows[0] contains the actual row data\n    return rows[0].map((row: QueryRowResult<Metadata>, index: number) => ({\n      content: row.document || \"\",\n      metadata: row.metadata || {},\n      distance: results.distances?.[0]?.[index] || 0, // Distance still comes from the original results\n      id: row.id,\n    }));\n  } catch (error) {\n    console.error(\"Error retrieving documents:\", error);\n    return [];\n  }\n}\n\nexport class ChromaRetriever extends BaseRetriever {\n  async retrieve(input: string | BaseMessage[], options: RetrieveOptions): Promise<string> {\n    // Convert input to searchable string\n    let searchText = \"\";\n\n    if (typeof input === \"string\") {\n      searchText = input;\n    } else if (Array.isArray(input) && input.length > 0) {\n      const lastMessage = input[input.length - 1];\n\n      // Handle different content formats\n      if (Array.isArray(lastMessage.content)) {\n        const textParts = lastMessage.content\n          .filter((part: any) => part.type === \"text\")\n          .map((part: any) => part.text);\n        searchText = textParts.join(\" \");\n      } else {\n        searchText = lastMessage.content as string;\n      }\n    }\n\n    // Perform semantic search\n    const results = await retrieveDocuments(searchText, 3);\n\n    // Add references to userContext for tracking\n    if (options.userContext && results.length > 0) {\n      const references = results.map((doc, index) => ({\n        id: doc.id,\n        title: doc.metadata.title || `Document ${index + 1}`,\n        source: \"Chroma Knowledge Base\",\n        distance: doc.distance,\n      }));\n\n      options.userContext.set(\"references\", references);\n    }\n\n    // Format results for the LLM\n    if (results.length === 0) {\n      return \"No relevant documents found in the knowledge base.\";\n    }\n\n    return results\n      .map(\n        (doc, index) =>\n          `Document ${index + 1} (ID: ${doc.id}, Distance: ${doc.distance.toFixed(4)}):\\n${doc.content}`\n      )\n      .join(\"\\n\\n---\\n\\n\");\n  }\n}\n\nexport const retriever = new ChromaRetriever();\n\n```\n\n**Key Features**:\n\n- **Input Handling**: Supports both string and message array inputs\n- **Semantic Search**: Uses Chroma's vector similarity search\n- **User Context**: Tracks references for transparency\n- **Error Handling**: Graceful fallbacks for search failures\n\n### Create Your Agents [â€‹](https://voltagent.dev/docs/rag/chroma/\\#create-your-agents \"Direct link to Create Your Agents\")\n\nNow create agents using different retrieval patterns in `src/index.ts`:\n\n```codeBlockLines_e6Vv\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent, VoltAgent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { retriever } from \"./retriever/index.js\";\n\n// Agent 1: Automatic retrieval on every interaction\nconst agentWithRetriever = new Agent({\n  name: \"Assistant with Retriever\",\n  description:\n    \"A helpful assistant that automatically searches the knowledge base for relevant information\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  retriever: retriever,\n});\n\n// Agent 2: LLM decides when to search\nconst agentWithTools = new Agent({\n  name: \"Assistant with Tools\",\n  description: \"A helpful assistant that can search the knowledge base when needed\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  tools: [retriever.tool],\n});\n\nnew VoltAgent({\n  agents: {\n    agentWithRetriever,\n    agentWithTools,\n  },\n});\n\n```\n\n## Usage Patterns [â€‹](https://voltagent.dev/docs/rag/chroma/\\#usage-patterns \"Direct link to Usage Patterns\")\n\n### Automatic Retrieval [â€‹](https://voltagent.dev/docs/rag/chroma/\\#automatic-retrieval \"Direct link to Automatic Retrieval\")\n\nThe first agent automatically searches before every response:\n\n```codeBlockLines_e6Vv\nUser: \"What is VoltAgent?\"\nAgent: Based on the knowledge base, VoltAgent is a TypeScript framework for building AI agents with modular components...\n\nSources:\n- Document 1 (ID: sample_1, Distance: 0.1234): Chroma Knowledge Base\n- Document 2 (ID: sample_2, Distance: 0.2456): Chroma Knowledge Base\n\n```\n\n### Tool-Based Retrieval [â€‹](https://voltagent.dev/docs/rag/chroma/\\#tool-based-retrieval \"Direct link to Tool-Based Retrieval\")\n\nThe second agent only searches when it determines it's necessary:\n\n```codeBlockLines_e6Vv\nUser: \"Tell me about TypeScript\"\nAgent: Let me search for relevant information about TypeScript.\n[Searches knowledge base]\nAccording to the search results, TypeScript provides static typing for JavaScript, making code more reliable and maintainable...\n\nSources:\n- Document 5 (ID: sample_5, Distance: 0.0987): Chroma Knowledge Base\n\n```\n\n### Accessing Sources in Your Code [â€‹](https://voltagent.dev/docs/rag/chroma/\\#accessing-sources-in-your-code \"Direct link to Accessing Sources in Your Code\")\n\nYou can access the sources that were used in the retrieval from the response:\n\n```codeBlockLines_e6Vv\n// After generating a response\nconst response = await agent.generateText(\"What is VoltAgent?\");\nconsole.log(\"Answer:\", response.text);\n\n// Check what sources were used\nconst references = response.userContext?.get(\"references\");\nif (references) {\n  console.log(\"Used sources:\", references);\n  references.forEach((ref) => {\n    console.log(`- ${ref.title} (ID: ${ref.id}, Distance: ${ref.distance})`);\n  });\n}\n// Output: [{ id: \"sample_1\", title: \"Document 1\", source: \"Chroma Knowledge Base\", distance: 0.1234 }]\n\n```\n\nOr when using streamText:\n\n```codeBlockLines_e6Vv\nconst result = await agent.streamText(\"Tell me about vector databases\");\n\nfor await (const textPart of result.textStream) {\n  process.stdout.write(textPart);\n}\n\n// Access sources after streaming completes\nconst references = result.userContext?.get(\"references\");\nif (references) {\n  console.log(\"\\nSources used:\", references);\n}\n\n```\n\n## Customization Options [â€‹](https://voltagent.dev/docs/rag/chroma/\\#customization-options \"Direct link to Customization Options\")\n\n### Different Embedding Models [â€‹](https://voltagent.dev/docs/rag/chroma/\\#different-embedding-models \"Direct link to Different Embedding Models\")\n\nYou can use different OpenAI embedding models:\n\n```codeBlockLines_e6Vv\n// More powerful but more expensive\nconst embeddingFunction = new OpenAIEmbeddingFunction({\n  apiKey: process.env.OPENAI_API_KEY,\n  modelName: \"text-embedding-3-large\",\n});\n\n// Balanced option\nconst embeddingFunction = new OpenAIEmbeddingFunction({\n  apiKey: process.env.OPENAI_API_KEY,\n  modelName: \"text-embedding-3-small\",\n});\n\n```\n\n### Adding Your Own Documents [â€‹](https://voltagent.dev/docs/rag/chroma/\\#adding-your-own-documents \"Direct link to Adding Your Own Documents\")\n\nTo add documents programmatically:\n\n```codeBlockLines_e6Vv\nasync function addDocument(content: string, metadata: Record<string, any> = {}) {\n  const collection = await chromaClient.getOrCreateCollection({\n    name: collectionName,\n    embeddingFunction: embeddingFunction,\n  });\n\n  const id = `doc_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n\n  await collection.add({\n    documents: [content],\n    ids: [id],\n    metadatas: [{ ...metadata, timestamp: new Date().toISOString() }],\n  });\n\n  return id;\n}\n\n```\n\n### Filtering Search Results [â€‹](https://voltagent.dev/docs/rag/chroma/\\#filtering-search-results \"Direct link to Filtering Search Results\")\n\nChroma supports metadata filtering:\n\n```codeBlockLines_e6Vv\nconst results = await collection.query({\n  queryTexts: [query],\n  nResults: 5,\n  where: { type: \"documentation\" }, // Only search docs of this type\n});\n\n```\n\n## Best Practices [â€‹](https://voltagent.dev/docs/rag/chroma/\\#best-practices \"Direct link to Best Practices\")\n\n**Embedding Strategy**:\n\n- Use `text-embedding-3-small` for cost efficiency\n- Use `text-embedding-3-large` for maximum quality\n- Keep embedding model consistent across documents\n\n**Document Management**:\n\n- Include relevant metadata for filtering\n- Use meaningful document IDs\n- Consider document chunking for large texts\n\n**Performance**:\n\n- Limit search results (3-5 documents typically sufficient)\n- Use metadata filtering to narrow searches\n- Consider caching for frequently accessed documents\n\n**Development**:\n\n- Start with sample data to test your setup\n- Monitor embedding costs in production\n- Implement proper error handling for network issues\n\n## Troubleshooting [â€‹](https://voltagent.dev/docs/rag/chroma/\\#troubleshooting \"Direct link to Troubleshooting\")\n\n**Chroma Connection Issues**:\n\n```codeBlockLines_e6Vv\n# Check if Chroma is running\ncurl http://localhost:8000/api/v1/heartbeat\n\n# Restart Chroma if needed\n# If using npm run chroma run, simply stop (Ctrl+C) and restart:\nnpm run chroma run\n\n# If using Docker:\ndocker restart <chroma-container-id>\n\n```\n\n**Embedding Errors**:\n\n- Verify your OpenAI API key is valid\n- Check API quota and billing\n- Ensure network connectivity to OpenAI\n\n**No Search Results**:\n\n- Verify documents were added successfully\n- Check embedding function configuration\n- Try broader search queries\n\nThis integration provides a solid foundation for adding semantic search capabilities to your VoltAgent applications. The combination of VoltAgent's flexible architecture and Chroma's powerful vector search creates a robust RAG system that can handle real-world knowledge retrieval needs.\n\n### Table of Contents\n\n- [Prerequisites](https://voltagent.dev/docs/rag/chroma/#prerequisites)\n- [Installation](https://voltagent.dev/docs/rag/chroma/#installation)\n- [Start Chroma Server](https://voltagent.dev/docs/rag/chroma/#start-chroma-server)\n- [Environment Setup](https://voltagent.dev/docs/rag/chroma/#environment-setup)\n  - [Option 1: Local Chroma Server](https://voltagent.dev/docs/rag/chroma/#option-1-local-chroma-server)\n  - [Option 2: Chroma Cloud](https://voltagent.dev/docs/rag/chroma/#option-2-chroma-cloud)\n- [Run Your Application](https://voltagent.dev/docs/rag/chroma/#run-your-application)\n- [Interact with Your Agents](https://voltagent.dev/docs/rag/chroma/#interact-with-your-agents)\n- [How It Works](https://voltagent.dev/docs/rag/chroma/#how-it-works)\n  - [Create the Chroma Retriever](https://voltagent.dev/docs/rag/chroma/#create-the-chroma-retriever)\n  - [Initialize Sample Data](https://voltagent.dev/docs/rag/chroma/#initialize-sample-data)\n  - [Implement the Retriever Class](https://voltagent.dev/docs/rag/chroma/#implement-the-retriever-class)\n  - [Create Your Agents](https://voltagent.dev/docs/rag/chroma/#create-your-agents)\n- [Usage Patterns](https://voltagent.dev/docs/rag/chroma/#usage-patterns)\n  - [Automatic Retrieval](https://voltagent.dev/docs/rag/chroma/#automatic-retrieval)\n  - [Tool-Based Retrieval](https://voltagent.dev/docs/rag/chroma/#tool-based-retrieval)\n  - [Accessing Sources in Your Code](https://voltagent.dev/docs/rag/chroma/#accessing-sources-in-your-code)\n- [Customization Options](https://voltagent.dev/docs/rag/chroma/#customization-options)\n  - [Different Embedding Models](https://voltagent.dev/docs/rag/chroma/#different-embedding-models)\n  - [Adding Your Own Documents](https://voltagent.dev/docs/rag/chroma/#adding-your-own-documents)\n  - [Filtering Search Results](https://voltagent.dev/docs/rag/chroma/#filtering-search-results)\n- [Best Practices](https://voltagent.dev/docs/rag/chroma/#best-practices)\n- [Troubleshooting](https://voltagent.dev/docs/rag/chroma/#troubleshooting)",
      "metadata": {
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "og:locale": "en",
        "docsearch:version": "current",
        "description": "Chroma is an AI-native open-source vector database designed to make it easy to build applications with embeddings. It handles the complexity of vector storage and search while providing a simple API for semantic search capabilities.",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "og:url": "https://voltagent.dev/docs/rag/chroma/",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "ogLocale": "en",
        "ogUrl": "https://voltagent.dev/docs/rag/chroma/",
        "ogDescription": "Chroma is an AI-native open-source vector database designed to make it easy to build applications with embeddings. It handles the complexity of vector storage and search while providing a simple API for semantic search capabilities.",
        "title": "Chroma Integration | VoltAgent",
        "og:description": "Chroma is an AI-native open-source vector database designed to make it easy to build applications with embeddings. It handles the complexity of vector storage and search while providing a simple API for semantic search capabilities.",
        "og:title": "Chroma Integration | VoltAgent",
        "docusaurus_locale": "en",
        "docusaurus_tag": "docs-default-current",
        "docsearch:language": "en",
        "ogTitle": "Chroma Integration | VoltAgent",
        "twitter:card": "summary_large_image",
        "generator": "Docusaurus v3.1.1",
        "og:image": "https://voltagent.dev/img/social3.png",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_version": "current",
        "docsearch:docusaurus_tag": "docs-default-current",
        "language": "en",
        "scrapeId": "90a34101-9c0d-4e56-ae8b-9de98145ade2",
        "sourceURL": "https://voltagent.dev/docs/rag/chroma/",
        "url": "https://voltagent.dev/docs/rag/chroma/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:17.771Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/integrations/overview/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\nVoltAgent packages function like standard Node.js packages, making them easily integrable into various JavaScript and TypeScript environments. They don't require special handling beyond typical package management.\n\nFor specific framework integrations, we provide guides to streamline the setup process.\n\n## Framework Guides [â€‹](https://voltagent.dev/docs/integrations/overview/\\#framework-guides \"Direct link to Framework Guides\")\n\n- **[Next.js](https://voltagent.dev/docs/integrations/nextjs/):** Learn how to integrate VoltAgent seamlessly into your Next.js applications, leveraging Server Actions and the Vercel AI SDK.\n\n### Table of Contents\n\n- [Framework Guides](https://voltagent.dev/docs/integrations/overview/#framework-guides)",
      "metadata": {
        "docsearch:language": "en",
        "viewport": "width=device-width, initial-scale=1.0",
        "docsearch:docusaurus_tag": "docs-default-current",
        "description": "This guide provides an overview of the various frameworks and platforms that VoltAgent can be integrated into.",
        "og:url": "https://voltagent.dev/docs/integrations/overview/",
        "docusaurus_version": "current",
        "ogTitle": "Overview | VoltAgent",
        "og:image": "https://voltagent.dev/img/social3.png",
        "og:title": "Overview | VoltAgent",
        "docusaurus_tag": "docs-default-current",
        "docusaurus_locale": "en",
        "ogUrl": "https://voltagent.dev/docs/integrations/overview/",
        "title": "Overview | VoltAgent",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "language": "en",
        "ogDescription": "This guide provides an overview of the various frameworks and platforms that VoltAgent can be integrated into.",
        "ogLocale": "en",
        "docsearch:version": "current",
        "og:description": "This guide provides an overview of the various frameworks and platforms that VoltAgent can be integrated into.",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "generator": "Docusaurus v3.1.1",
        "og:locale": "en",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "twitter:card": "summary_large_image",
        "scrapeId": "49d0ccda-c5b9-4464-9815-d5065a8d69ae",
        "sourceURL": "https://voltagent.dev/docs/integrations/overview/",
        "url": "https://voltagent.dev/docs/integrations/overview/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:39:45.510Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/getting-started/providers-models/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Providers & Models\n\nVoltAgent leverages the [Vercel AI SDK](https://ai-sdk.dev/) to provide seamless integration with a wide range of AI providers and models. The AI SDK offers a standardized approach to interacting with LLMs through a unified interface that allows you to switch between providers with ease.\n\n## Recommended Approach [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#recommended-approach \"Direct link to Recommended Approach\")\n\nWe strongly recommend using the Vercel AI SDK providers directly with VoltAgent's `@voltagent/vercel-ai` provider. This gives you access to:\n\n- **30+ AI providers** with consistent APIs\n- **Automatic updates** with the latest models\n- **Built-in support** for streaming, tool calling, and structured outputs\n- **Community-driven** provider ecosystem\n\n### Custom Providers [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#custom-providers \"Direct link to Custom Providers\")\n\nWhile the Vercel AI SDK covers most use cases, VoltAgent also supports **custom provider implementation** for advanced scenarios. You can create your own provider by implementing the `LLMProvider` interface.\n\n**When to use custom providers:**\n\n- Integration with proprietary or internal LLM services\n- Advanced control over request/response handling\n- Special authentication mechanisms\n- Custom retry logic or rate limiting\n- Integration with legacy systems\n\n**For most use cases**, the Vercel AI SDK providers are sufficient and recommended as they offer:\n\n- Battle-tested implementations\n- Regular updates and improvements\n- Wide community support\n- Consistent API across all providers\n\n> **Tip:** Before implementing a custom provider, check if your use case can be covered by the 30+ providers available through Vercel AI SDK, including OpenAI-compatible providers that work with custom endpoints.\n\n## Installation [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#installation \"Direct link to Installation\")\n\nFirst, install the Vercel AI provider for VoltAgent:\n\n- npm\n- yarn\n- pnpm\n\n```codeBlockLines_e6Vv\nnpm install @voltagent/vercel-ai\n\n```\n\nThen install the specific AI SDK provider you want to use:\n\n- npm\n- yarn\n- pnpm\n\n```codeBlockLines_e6Vv\n# For example, to use OpenAI:\nnpm install @ai-sdk/openai\n\n# Or Anthropic:\nnpm install @ai-sdk/anthropic\n\n# Or Google:\nnpm install @ai-sdk/google\n\n```\n\n## Usage Example [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#usage-example \"Direct link to Usage Example\")\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst provider = new VercelAIProvider();\n\nconst agent = new Agent({\n  name: \"my-agent\",\n  instructions: \"You are a helpful assistant\",\n  llm: provider,\n  model: openai(\"gpt-4-turbo\"),\n});\n\n```\n\n## Available Providers [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#available-providers \"Direct link to Available Providers\")\n\n### First-Party AI SDK Providers [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#first-party-ai-sdk-providers \"Direct link to First-Party AI SDK Providers\")\n\nThese providers are maintained by Vercel and offer the highest level of support and integration:\n\n#### Foundation Models [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#foundation-models \"Direct link to Foundation Models\")\n\n| Provider | Package | Documentation | Key Models |\n| --- | --- | --- | --- |\n| **xAI Grok** | `@ai-sdk/xai` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/xai) | grok-4, grok-3, grok-2-vision |\n| **OpenAI** | `@ai-sdk/openai` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/openai) | gpt-4.1, gpt-4o, o3, o1 |\n| **Anthropic** | `@ai-sdk/anthropic` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/anthropic) | claude-opus-4, claude-sonnet-4, claude-3.5 |\n| **Google Generative AI** | `@ai-sdk/google` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/google-generative-ai) | gemini-2.0-flash, gemini-1.5-pro |\n| **Google Vertex** | `@ai-sdk/google-vertex` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/google-vertex) | gemini models, claude models via Vertex |\n| **Mistral** | `@ai-sdk/mistral` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/mistral) | mistral-large, pixtral-large, mistral-medium |\n\n#### Cloud Platforms [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#cloud-platforms \"Direct link to Cloud Platforms\")\n\n| Provider | Package | Documentation | Description |\n| --- | --- | --- | --- |\n| **Amazon Bedrock** | `@ai-sdk/amazon-bedrock` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/amazon-bedrock) | Access to various models via AWS |\n| **Azure OpenAI** | `@ai-sdk/azure` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/azure) | OpenAI models via Azure |\n| **Vercel** | `@ai-sdk/vercel` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/vercel) | v0 model for code generation |\n\n#### Specialized Providers [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#specialized-providers \"Direct link to Specialized Providers\")\n\n| Provider | Package | Documentation | Specialization |\n| --- | --- | --- | --- |\n| **Groq** | `@ai-sdk/groq` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/groq) | Ultra-fast inference |\n| **Together.ai** | `@ai-sdk/togetherai` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/togetherai) | Open-source models |\n| **Cohere** | `@ai-sdk/cohere` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/cohere) | Enterprise search & generation |\n| **Fireworks** | `@ai-sdk/fireworks` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/fireworks) | Fast open-source models |\n| **DeepInfra** | `@ai-sdk/deepinfra` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/deepinfra) | Affordable inference |\n| **DeepSeek** | `@ai-sdk/deepseek` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/deepseek) | DeepSeek models including reasoner |\n| **Cerebras** | `@ai-sdk/cerebras` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/cerebras) | Fast Llama models |\n| **Perplexity** | `@ai-sdk/perplexity` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/perplexity) | Search-enhanced responses |\n\n#### Audio & Speech Providers [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#audio--speech-providers \"Direct link to Audio & Speech Providers\")\n\n| Provider | Package | Documentation | Specialization |\n| --- | --- | --- | --- |\n| **ElevenLabs** | `@ai-sdk/elevenlabs` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/elevenlabs) | Text-to-speech |\n| **LMNT** | `@ai-sdk/lmnt` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/lmnt) | Voice synthesis |\n| **Hume** | `@ai-sdk/hume` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/hume) | Emotional intelligence |\n| **Rev.ai** | `@ai-sdk/revai` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/revai) | Speech recognition |\n| **Deepgram** | `@ai-sdk/deepgram` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/deepgram) | Speech-to-text |\n| **Gladia** | `@ai-sdk/gladia` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/gladia) | Audio intelligence |\n| **AssemblyAI** | `@ai-sdk/assemblyai` | [Docs](https://ai-sdk.dev/providers/ai-sdk-providers/assemblyai) | Speech recognition & understanding |\n\n### Community Providers [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#community-providers \"Direct link to Community Providers\")\n\nThese providers are created and maintained by the open-source community:\n\n| Provider | Package | Documentation | Description |\n| --- | --- | --- | --- |\n| **Ollama** | `ollama-ai-provider` | [Docs](https://ai-sdk.dev/providers/community-providers/ollama) | Local model execution |\n| **FriendliAI** | `@friendliai/ai-provider` | [Docs](https://ai-sdk.dev/providers/community-providers/friendliai) | Optimized inference |\n| **Portkey** | `@portkey-ai/vercel-provider` | [Docs](https://ai-sdk.dev/providers/community-providers/portkey) | LLM gateway & observability |\n| **Cloudflare Workers AI** | `workers-ai-provider` | [Docs](https://ai-sdk.dev/providers/community-providers/cloudflare-workers-ai) | Edge AI inference |\n| **OpenRouter** | `@openrouter/ai-sdk-provider` | [Docs](https://ai-sdk.dev/providers/community-providers/openrouter) | Unified API for multiple providers |\n| **Requesty** | `@requesty/ai-sdk` | [Docs](https://ai-sdk.dev/providers/community-providers/requesty) | Request management |\n| **Crosshatch** | `@crosshatch/ai-provider` | [Docs](https://ai-sdk.dev/providers/community-providers/crosshatch) | Specialized models |\n| **Mixedbread** | `mixedbread-ai-provider` | [Docs](https://ai-sdk.dev/providers/community-providers/mixedbread) | Embedding models |\n| **Voyage AI** | `voyage-ai-provider` | [Docs](https://ai-sdk.dev/providers/community-providers/voyage-ai) | Embedding models |\n| **Mem0** | `@mem0/vercel-ai-provider` | [Docs](https://ai-sdk.dev/providers/community-providers/mem0) | Memory-enhanced AI |\n| **Letta** | `@letta-ai/vercel-ai-sdk-provider` | [Docs](https://ai-sdk.dev/providers/community-providers/letta) | Stateful agents |\n| **Spark** | `spark-ai-provider` | [Docs](https://ai-sdk.dev/providers/community-providers/spark) | Chinese language models |\n| **AnthropicVertex** | `anthropic-vertex-ai` | [Docs](https://ai-sdk.dev/providers/community-providers/anthropic-vertex-ai) | Claude via Vertex AI |\n| **LangDB** | `@langdb/vercel-provider` | [Docs](https://ai-sdk.dev/providers/community-providers/langdb) | Database-aware AI |\n| **Dify** | `dify-ai-provider` | [Docs](https://ai-sdk.dev/providers/community-providers/dify) | LLMOps platform |\n| **Sarvam** | `sarvam-ai-provider` | [Docs](https://ai-sdk.dev/providers/community-providers/sarvam) | Indian language models |\n| **Claude Code** | `ai-sdk-provider-claude-code` | [Docs](https://ai-sdk.dev/providers/community-providers/claude-code) | Code-optimized Claude |\n| **Built-in AI** | `built-in-ai` | [Docs](https://ai-sdk.dev/providers/community-providers/built-in-ai) | Browser-native AI |\n| **Gemini CLI** | `ai-sdk-provider-gemini-cli` | [Docs](https://ai-sdk.dev/providers/community-providers/gemini-cli) | CLI-based Gemini |\n| **A2A** | `a2a-ai-provider` | [Docs](https://ai-sdk.dev/providers/community-providers/a2a) | Specialized models |\n| **SAP-AI** | `@mymediset/sap-ai-provider` | [Docs](https://ai-sdk.dev/providers/community-providers/sap-ai) | SAP AI Core integration |\n\n### OpenAI-Compatible Providers [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#openai-compatible-providers \"Direct link to OpenAI-Compatible Providers\")\n\nFor providers that follow the OpenAI API specification:\n\n| Provider | Documentation | Description |\n| --- | --- | --- |\n| **LM Studio** | [Docs](https://ai-sdk.dev/providers/openai-compatible-providers/lmstudio) | Local model execution with GUI |\n| **Baseten** | [Docs](https://ai-sdk.dev/providers/openai-compatible-providers/baseten) | Model deployment platform |\n| **Any OpenAI-compatible API** | [Docs](https://ai-sdk.dev/providers/openai-compatible-providers) | Custom endpoints |\n\n## Model Capabilities [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#model-capabilities \"Direct link to Model Capabilities\")\n\nThe AI providers support different language models with various capabilities. Here are the capabilities of popular models:\n\n| Provider | Model | Image Input | Object Generation | Tool Usage | Tool Streaming |\n| --- | --- | --- | --- | --- | --- |\n| **xAI Grok** | `grok-4` | âŒ | âœ… | âœ… | âœ… |\n| **xAI Grok** | `grok-3` | âŒ | âœ… | âœ… | âœ… |\n| **xAI Grok** | `grok-3-fast` | âŒ | âœ… | âœ… | âœ… |\n| **xAI Grok** | `grok-3-mini` | âŒ | âœ… | âœ… | âœ… |\n| **xAI Grok** | `grok-3-mini-fast` | âŒ | âœ… | âœ… | âœ… |\n| **xAI Grok** | `grok-2-1212` | âŒ | âœ… | âœ… | âœ… |\n| **xAI Grok** | `grok-2-vision-1212` | âœ… | âœ… | âœ… | âœ… |\n| **xAI Grok** | `grok-beta` | âŒ | âœ… | âœ… | âœ… |\n| **xAI Grok** | `grok-vision-beta` | âœ… | âŒ | âŒ | âŒ |\n| **Vercel** | `v0-1.0-md` | âœ… | âœ… | âœ… | âœ… |\n| **OpenAI** | `gpt-4.1` | âœ… | âœ… | âœ… | âœ… |\n| **OpenAI** | `gpt-4.1-mini` | âœ… | âœ… | âœ… | âœ… |\n| **OpenAI** | `gpt-4.1-nano` | âœ… | âœ… | âœ… | âœ… |\n| **OpenAI** | `gpt-4o` | âœ… | âœ… | âœ… | âœ… |\n| **OpenAI** | `gpt-4o-mini` | âœ… | âœ… | âœ… | âœ… |\n| **OpenAI** | `gpt-4` | âŒ | âœ… | âœ… | âœ… |\n| **OpenAI** | `o3-mini` | âŒ | âŒ | âœ… | âœ… |\n| **OpenAI** | `o3` | âŒ | âŒ | âœ… | âœ… |\n| **OpenAI** | `o4-mini` | âŒ | âŒ | âœ… | âœ… |\n| **OpenAI** | `o1` | âœ… | âŒ | âœ… | âœ… |\n| **OpenAI** | `o1-mini` | âœ… | âŒ | âœ… | âœ… |\n| **OpenAI** | `o1-preview` | âŒ | âŒ | âŒ | âŒ |\n| **Anthropic** | `claude-opus-4-20250514` | âœ… | âœ… | âœ… | âœ… |\n| **Anthropic** | `claude-sonnet-4-20250514` | âœ… | âœ… | âœ… | âœ… |\n| **Anthropic** | `claude-3-7-sonnet-20250219` | âœ… | âœ… | âœ… | âœ… |\n| **Anthropic** | `claude-3-5-sonnet-20241022` | âœ… | âœ… | âœ… | âœ… |\n| **Anthropic** | `claude-3-5-sonnet-20240620` | âœ… | âœ… | âœ… | âœ… |\n| **Anthropic** | `claude-3-5-haiku-20241022` | âœ… | âœ… | âœ… | âœ… |\n| **Mistral** | `pixtral-large-latest` | âœ… | âœ… | âœ… | âœ… |\n| **Mistral** | `mistral-large-latest` | âŒ | âœ… | âœ… | âœ… |\n| **Mistral** | `mistral-medium-latest` | âŒ | âœ… | âœ… | âœ… |\n| **Mistral** | `mistral-medium-2505` | âŒ | âœ… | âœ… | âœ… |\n| **Mistral** | `mistral-small-latest` | âŒ | âœ… | âœ… | âœ… |\n| **Mistral** | `pixtral-12b-2409` | âœ… | âœ… | âœ… | âœ… |\n| **Google Generative AI** | `gemini-2.0-flash-exp` | âœ… | âœ… | âœ… | âœ… |\n| **Google Generative AI** | `gemini-1.5-flash` | âœ… | âœ… | âœ… | âœ… |\n| **Google Generative AI** | `gemini-1.5-pro` | âœ… | âœ… | âœ… | âœ… |\n| **Google Vertex** | `gemini-2.0-flash-exp` | âœ… | âœ… | âœ… | âœ… |\n| **Google Vertex** | `gemini-1.5-flash` | âœ… | âœ… | âœ… | âœ… |\n| **Google Vertex** | `gemini-1.5-pro` | âœ… | âœ… | âœ… | âœ… |\n| **DeepSeek** | `deepseek-chat` | âŒ | âœ… | âœ… | âœ… |\n| **DeepSeek** | `deepseek-reasoner` | âŒ | âŒ | âŒ | âŒ |\n| **Cerebras** | `llama3.1-8b` | âŒ | âœ… | âœ… | âœ… |\n| **Cerebras** | `llama3.1-70b` | âŒ | âœ… | âœ… | âœ… |\n| **Cerebras** | `llama3.3-70b` | âŒ | âœ… | âœ… | âœ… |\n| **Groq** | `meta-llama/llama-4-scout-17b-16e-instruct` | âœ… | âœ… | âœ… | âœ… |\n| **Groq** | `llama-3.3-70b-versatile` | âŒ | âœ… | âœ… | âœ… |\n| **Groq** | `llama-3.1-8b-instant` | âŒ | âœ… | âœ… | âœ… |\n| **Groq** | `mixtral-8x7b-32768` | âŒ | âœ… | âœ… | âœ… |\n| **Groq** | `gemma2-9b-it` | âŒ | âœ… | âœ… | âœ… |\n\n> **Note:** This table is not exhaustive. Additional models can be found in the provider documentation pages and on the provider websites.\n\n## Migration from Deprecated Providers [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#migration-from-deprecated-providers \"Direct link to Migration from Deprecated Providers\")\n\nIf you're currently using VoltAgent's native providers ( `@voltagent/anthropic-ai`, `@voltagent/google-ai`, `@voltagent/groq-ai`), we recommend migrating to the Vercel AI SDK providers:\n\n### Before (Deprecated): [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#before-deprecated \"Direct link to Before (Deprecated):\")\n\n```codeBlockLines_e6Vv\nimport { AnthropicProvider } from \"@voltagent/anthropic-ai\";\n\nconst provider = new AnthropicProvider({ apiKey: \"...\" });\nconst agent = new Agent({\n  llm: provider,\n  model: \"claude-opus-4-1\",\n});\n\n```\n\n### After (Recommended): [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#after-recommended \"Direct link to After (Recommended):\")\n\n```codeBlockLines_e6Vv\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { anthropic } from \"@ai-sdk/anthropic\";\n\nconst provider = new VercelAIProvider();\nconst agent = new Agent({\n  llm: provider,\n  model: anthropic(\"claude-opus-4-1\"),\n});\n\n```\n\n## Environment Variables [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#environment-variables \"Direct link to Environment Variables\")\n\nMost providers use environment variables for API keys:\n\n```codeBlockLines_e6Vv\n# OpenAI\nOPENAI_API_KEY=your-key\n\n# Anthropic\nANTHROPIC_API_KEY=your-key\n\n# Google\nGOOGLE_GENERATIVE_AI_API_KEY=your-key\n\n# Groq\nGROQ_API_KEY=your-key\n\n# And so on...\n\n```\n\n## Next Steps [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#next-steps \"Direct link to Next Steps\")\n\n1. Choose a provider based on your needs (performance, cost, capabilities)\n2. Install the corresponding package\n3. Configure your API keys\n4. Start building with VoltAgent!\n\nFor detailed information about each provider, visit the [Vercel AI SDK documentation](https://ai-sdk.dev/docs/foundations/providers-and-models).\n\n* * *\n\n## Acknowledgments [â€‹](https://voltagent.dev/docs/getting-started/providers-models/\\#acknowledgments \"Direct link to Acknowledgments\")\n\n> The provider lists and model capabilities in this documentation are sourced from the [Vercel AI SDK documentation](https://ai-sdk.dev/docs/foundations/providers-and-models).\n>\n> **A special thanks to the Vercel AI SDK maintainers and community** for creating and maintaining this comprehensive ecosystem of AI providers. Their work enables developers to seamlessly integrate with 30+ AI providers through a unified, well-designed interface.\n>\n> VoltAgent builds upon this excellent foundation to provide a complete framework for building AI agents and workflows.\n\n### Table of Contents\n\n- [Recommended Approach](https://voltagent.dev/docs/getting-started/providers-models/#recommended-approach)\n  - [Custom Providers](https://voltagent.dev/docs/getting-started/providers-models/#custom-providers)\n- [Installation](https://voltagent.dev/docs/getting-started/providers-models/#installation)\n- [Usage Example](https://voltagent.dev/docs/getting-started/providers-models/#usage-example)\n- [Available Providers](https://voltagent.dev/docs/getting-started/providers-models/#available-providers)\n  - [First-Party AI SDK Providers](https://voltagent.dev/docs/getting-started/providers-models/#first-party-ai-sdk-providers)\n  - [Community Providers](https://voltagent.dev/docs/getting-started/providers-models/#community-providers)\n  - [OpenAI-Compatible Providers](https://voltagent.dev/docs/getting-started/providers-models/#openai-compatible-providers)\n- [Model Capabilities](https://voltagent.dev/docs/getting-started/providers-models/#model-capabilities)\n- [Migration from Deprecated Providers](https://voltagent.dev/docs/getting-started/providers-models/#migration-from-deprecated-providers)\n  - [Before (Deprecated):](https://voltagent.dev/docs/getting-started/providers-models/#before-deprecated)\n  - [After (Recommended):](https://voltagent.dev/docs/getting-started/providers-models/#after-recommended)\n- [Environment Variables](https://voltagent.dev/docs/getting-started/providers-models/#environment-variables)\n- [Next Steps](https://voltagent.dev/docs/getting-started/providers-models/#next-steps)\n- [Acknowledgments](https://voltagent.dev/docs/getting-started/providers-models/#acknowledgments)",
      "metadata": {
        "og:image": "https://voltagent.dev/img/social3.png",
        "title": "Providers & Models | VoltAgent",
        "og:description": "VoltAgent leverages the Vercel AI SDK to provide seamless integration with a wide range of AI providers and models. The AI SDK offers a standardized approach to interacting with LLMs through a unified interface that allows you to switch between providers with ease.",
        "docsearch:version": "current",
        "ogTitle": "Providers & Models | VoltAgent",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "og:url": "https://voltagent.dev/docs/getting-started/providers-models/",
        "viewport": "width=device-width, initial-scale=1.0",
        "docsearch:docusaurus_tag": "docs-default-current",
        "ogDescription": "VoltAgent leverages the Vercel AI SDK to provide seamless integration with a wide range of AI providers and models. The AI SDK offers a standardized approach to interacting with LLMs through a unified interface that allows you to switch between providers with ease.",
        "docusaurus_locale": "en",
        "description": "VoltAgent leverages the Vercel AI SDK to provide seamless integration with a wide range of AI providers and models. The AI SDK offers a standardized approach to interacting with LLMs through a unified interface that allows you to switch between providers with ease.",
        "ogLocale": "en",
        "twitter:card": "summary_large_image",
        "generator": "Docusaurus v3.1.1",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "og:locale": "en",
        "docsearch:language": "en",
        "ogUrl": "https://voltagent.dev/docs/getting-started/providers-models/",
        "docusaurus_version": "current",
        "docusaurus_tag": "docs-default-current",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "og:title": "Providers & Models | VoltAgent",
        "language": "en",
        "scrapeId": "43ed47c5-6860-4c50-aa9f-926ace9bcd55",
        "sourceURL": "https://voltagent.dev/docs/getting-started/providers-models/",
        "url": "https://voltagent.dev/docs/getting-started/providers-models/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:05.358Z",
        "creditsUsed": 1
      },
      "warning": "This scrape job was throttled at your current concurrency limit. If you'd like to scrape faster, you can upgrade your plan."
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/observability/logging/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\nVoltAgent provides automatic logging for all agent and workflow events. By default, it uses a simple console logger for quick prototyping, but for production use, you should use the powerful Pino-based logger from `@voltagent/logger` package which offers pretty formatting, file transports, and advanced features.\n\n## Global Logger Configuration [â€‹](https://voltagent.dev/docs/observability/logging/\\#global-logger-configuration \"Direct link to Global Logger Configuration\")\n\nWhen creating a VoltAgent instance, you can configure logging globally for all agents and workflows:\n\n```codeBlockLines_e6Vv\nimport { VoltAgent } from \"@voltagent/core\";\nimport { createPinoLogger } from \"@voltagent/logger\";\n\n// Option 1: Use built-in console logger (basic, for development only)\nconst voltAgent = new VoltAgent({\n  agents: [myAgent],\n  workflows: [myWorkflow],\n});\n// âš ï¸ This uses a simple console logger with basic formatting\n// Output: [2024-01-20T10:30:45.123Z] INFO {component: \"voltagent\"}: Agent started\n\n// Option 2: Use Pino logger (recommended for production)\nconst logger = createPinoLogger({\n  level: \"debug\", // More verbose logging (allowed: \"trace\" | \"debug\" | \"info\" | \"warn\" | \"error\" | \"fatal\" | \"silent\")\n  format: \"pretty\", // Human-readable format in development. defaults to \"json\" in production\n  name: \"my-app\", // Add app name to all logs\n});\n\nconst voltAgent = new VoltAgent({\n  logger: logger,\n  agents: { myAgent },\n  workflows: { myWorkflow },\n});\n// âœ… This uses Pino with pretty formatting, transports, and all advanced features\n\n```\n\nInstalling @voltagent/logger\n\nFor existing projects using the default ConsoleLogger, install `@voltagent/logger` to access advanced features like pretty formatting, file transports, and Pino integration:\n\n- npm\n- pnpm\n- yarn\n\n```codeBlockLines_e6Vv\nnpm install @voltagent/logger\n\n```\n\nThen import and use:\n\n```codeBlockLines_e6Vv\nimport { createPinoLogger } from \"@voltagent/logger\";\n\nconst logger = createPinoLogger({ level: \"info\", name: \"my-app\" });\n\n```\n\n## Default Logger Behavior [â€‹](https://voltagent.dev/docs/observability/logging/\\#default-logger-behavior \"Direct link to Default Logger Behavior\")\n\nWhen you don't provide a logger to VoltAgent, it uses a built-in `ConsoleLogger` from `@voltagent/core`:\n\n### ConsoleLogger Features: [â€‹](https://voltagent.dev/docs/observability/logging/\\#consolelogger-features \"Direct link to ConsoleLogger Features:\")\n\n- âœ… Basic console output with timestamps\n- âœ… Standard log levels (trace, debug, info, warn, error, fatal)\n- âœ… Respects `VOLTAGENT_LOG_LEVEL` or `LOG_LEVEL` environment variables\n- âœ… Simple JSON context display\n\n### ConsoleLogger Limitations: [â€‹](https://voltagent.dev/docs/observability/logging/\\#consolelogger-limitations \"Direct link to ConsoleLogger Limitations:\")\n\n- âŒ No pretty formatting or colors\n- âŒ No file transports or custom outputs\n- âŒ No log buffering or streaming\n- âŒ No advanced Pino features\n- âŒ Basic output format: `[timestamp] LEVEL {context}: message`\n\n### When to Use Each Logger: [â€‹](https://voltagent.dev/docs/observability/logging/\\#when-to-use-each-logger \"Direct link to When to Use Each Logger:\")\n\n| Use Case | Logger Choice | Example |\n| --- | --- | --- |\n| Quick prototyping | Default ConsoleLogger | `new VoltAgent({ agents })` |\n| Development with nice output | Pino with pretty format | `createPinoLogger({ format: \"pretty\" })` |\n| Production with file logging | Pino with transports | `createPinoLogger({ pinoOptions: { transport: {...} } })` |\n| VoltOps Platform integration | Any logger (logs always sent) | Both work with VoltOps |\n\nðŸ’¡ **Tip**: Always use `createPinoLogger` for production applications to get proper formatting, performance, and transport options.\n\n## Using Pino Logger with Advanced Features [â€‹](https://voltagent.dev/docs/observability/logging/\\#using-pino-logger-with-advanced-features \"Direct link to Using Pino Logger with Advanced Features\")\n\nFor advanced use cases, you can use `createPinoLogger` which provides access to all Pino features including custom transports:\n\n```codeBlockLines_e6Vv\nimport { createPinoLogger } from \"@voltagent/logger\";\n\n// Basic Pino logger with our defaults\nconst logger = createPinoLogger({\n  level: \"debug\", // allowed: \"trace\" | \"debug\" | \"info\" | \"warn\" | \"error\" | \"fatal\" | \"silent\"\n  name: \"my-app\",\n});\n\n// Advanced: With custom Pino options\nconst logger = createPinoLogger({\n  level: \"info\",\n  pinoOptions: {\n    // Any Pino-specific option can go here\n    serializers: {\n      req: (req) => ({ method: req.method, url: req.url }),\n    },\n    hooks: {\n      logMethod(args, method) {\n        // Custom hook logic\n        method.apply(this, args);\n      },\n    },\n  },\n});\n\nconst voltAgent = new VoltAgent({\n  logger,\n  agents: [myAgent],\n});\n\n```\n\n## Agent-Level Logging [â€‹](https://voltagent.dev/docs/observability/logging/\\#agent-level-logging \"Direct link to Agent-Level Logging\")\n\nEach agent can have its own logger configuration that overrides the global settings:\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { createPinoLogger } from \"@voltagent/logger\";\n\nconst agent = new Agent({\n  name: \"CustomerSupport\",\n  llm: anthropic,\n  model: \"claude-3-sonnet\",\n  instructions: \"You are a helpful customer support agent\",\n\n  // This agent needs more detailed logs\n  logger: createPinoLogger({\n    level: \"debug\",\n    name: \"customer-support\",\n  }),\n});\n\n// The agent automatically logs:\n// - When it starts processing\n// - Tool calls and their results\n// - Errors and retries\n// - Completion events\n\n```\n\nVoltAgent automatically adds context to agent logs:\n\n- `agentId` \\- Unique identifier for the agent\n- `agentName` \\- The name you gave the agent\n- `modelName` \\- Which AI model is being used\n- `conversationId` \\- Current conversation context\n\n## Workflow-Level Logging [â€‹](https://voltagent.dev/docs/observability/logging/\\#workflow-level-logging \"Direct link to Workflow-Level Logging\")\n\nWorkflows can also have custom logger configuration:\n\n```codeBlockLines_e6Vv\nimport { createWorkflow } from \"@voltagent/core\";\nimport { createPinoLogger } from \"@voltagent/logger\";\n\nconst processOrderWorkflow = createWorkflow(\n  {\n    name: \"ProcessOrder\",\n    inputSchema: z.object({ orderId: z.string() }),\n    resultSchema: z.object({ status: z.string() }),\n\n    // More verbose logging for this critical workflow\n    logger: createPinoLogger({\n      level: \"info\",\n      name: \"order-processing\",\n    }),\n  },\n  andThen(validateOrder),\n  andAgent(orderAgent),\n  andThen(updateDatabase)\n);\n\n// Workflows automatically log:\n// - Workflow start and completion\n// - Each step execution\n// - Step results and errors\n// - Suspension and resume events\n\n```\n\nWorkflow logs include:\n\n- `workflowId` \\- Unique workflow identifier\n- `executionId` \\- Specific execution instance\n- `stepId` \\- Current step being executed\n- `stepType` \\- Type of step (andThen, andAgent, etc.)\n\n## Custom Transports and File Logging [â€‹](https://voltagent.dev/docs/observability/logging/\\#custom-transports-and-file-logging \"Direct link to Custom Transports and File Logging\")\n\nâš ï¸ **IMPORTANT**: When you specify a custom transport, it **COMPLETELY OVERRIDES** the default console output. This means your logs will **NOT** appear in the console unless you explicitly include pino-pretty.\n\n### File-Only Logging (No Console Output) [â€‹](https://voltagent.dev/docs/observability/logging/\\#file-only-logging-no-console-output \"Direct link to File-Only Logging (No Console Output)\")\n\n```codeBlockLines_e6Vv\nimport { createPinoLogger } from \"@voltagent/logger\";\n\nconst fileOnlyLogger = createPinoLogger({\n  level: \"info\",\n  pinoOptions: {\n    transport: {\n      target: \"pino/file\",\n      options: { destination: \"./app.log\" },\n    },\n  },\n});\n\n// âš ï¸ This will ONLY write to file, NOT to console!\nfileOnlyLogger.info(\"This goes to file only\");\n\n```\n\n### Console + File Logging (Recommended) [â€‹](https://voltagent.dev/docs/observability/logging/\\#console--file-logging-recommended \"Direct link to Console + File Logging (Recommended)\")\n\nTo keep console output AND add file logging, you must specify BOTH transports:\n\n```codeBlockLines_e6Vv\nconst logger = createPinoLogger({\n  level: \"info\",\n  pinoOptions: {\n    transport: {\n      targets: [\\\n        // Console output with our default configuration\\\n        {\\\n          target: \"pino-pretty\",\\\n          options: {\\\n            colorize: true,\\\n            translateTime: \"yyyy-MM-dd HH:mm:ss.l o\",\\\n            ignore: \"pid,hostname,env,component\",\\\n            messageFormat:\\\n              \"{msg}{if userId} | user={userId}{end}{if conversationId} | conv={conversationId}{end}{if executionId} | exec={executionId}{end}\",\\\n            errorLikeObjectKeys: [\"err\", \"error\", \"exception\"],\\\n            errorProps: \"\",\\\n            singleLine: true, // Set to false for debug/trace levels\\\n            messageKey: \"msg\",\\\n          },\\\n        },\\\n        // File output\\\n        {\\\n          target: \"pino/file\",\\\n          options: {\\\n            destination: \"./app.log\",\\\n            mkdir: true, // Create directory if it doesn't exist\\\n          },\\\n        },\\\n      ],\n    },\n  },\n});\n\n// âœ… This will write to BOTH console and file\nlogger.info(\"This appears in console AND file\");\n\n```\n\n### Our Default Console Configuration [â€‹](https://voltagent.dev/docs/observability/logging/\\#our-default-console-configuration \"Direct link to Our Default Console Configuration\")\n\nWhen you don't specify any transport, we use this pino-pretty configuration in development:\n\n```codeBlockLines_e6Vv\n{\n  target: \"pino-pretty\",\n  options: {\n    colorize: true,\n    translateTime: \"yyyy-MM-dd HH:mm:ss.l o\", // Example: 2024-01-20 14:30:45.123 +0300\n    ignore: \"pid,hostname,env,component\",      // Hide these fields from output\n    messageFormat: \"{msg}{if userId} | user={userId}{end}{if conversationId} | conv={conversationId}{end}{if executionId} | exec={executionId}{end}\",\n    errorLikeObjectKeys: [\"err\", \"error\", \"exception\"],\n    errorProps: \"\",\n    singleLine: true,  // Single line for info/warn/error\n    messageKey: \"msg\",\n  },\n}\n\n```\n\n### Multiple Log Files Example [â€‹](https://voltagent.dev/docs/observability/logging/\\#multiple-log-files-example \"Direct link to Multiple Log Files Example\")\n\n```codeBlockLines_e6Vv\nconst logger = createPinoLogger({\n  level: \"debug\",\n  pinoOptions: {\n    transport: {\n      targets: [\\\n        // Console for all logs\\\n        {\\\n          target: \"pino-pretty\",\\\n          options: { colorize: true },\\\n        },\\\n        // Error logs to separate file\\\n        {\\\n          target: \"pino/file\",\\\n          options: { destination: \"./error.log\" },\\\n          level: \"error\",\\\n        },\\\n        // All logs to general file\\\n        {\\\n          target: \"pino/file\",\\\n          options: { destination: \"./app.log\" },\\\n        },\\\n      ],\n    },\n  },\n});\n\n```\n\n## Environment Variables [â€‹](https://voltagent.dev/docs/observability/logging/\\#environment-variables \"Direct link to Environment Variables\")\n\nConfigure logging without changing code using environment variables:\n\n| Variable | Description | Default | Options |\n| --- | --- | --- | --- |\n| `VOLTAGENT_LOG_LEVEL` | Minimum log level to display | `error` (prod), `info` (dev) | `trace`, `debug`, `info`, `warn`, `error`, `fatal`, `silent` |\n| `LOG_LEVEL` | Alternative to VOLTAGENT\\_LOG\\_LEVEL (lower priority) | `error` (prod), `info` (dev) | Same as above |\n| `VOLTAGENT_LOG_FORMAT` | Output format (Pino only) | `json` (prod), `pretty` (dev) | `json`, `pretty` |\n| `VOLTAGENT_LOG_BUFFER_SIZE` | Number of logs to keep in memory | `1000` | Any positive number |\n\n**Note**: Both ConsoleLogger and PinoLogger check environment variables in this order:\n\n1. `VOLTAGENT_LOG_LEVEL` (recommended, takes precedence)\n2. `LOG_LEVEL` (fallback for compatibility)\n3. Default based on NODE\\_ENV\n\nExample:\n\n```codeBlockLines_e6Vv\n# Using VoltAgent-specific variable (recommended)\nVOLTAGENT_LOG_LEVEL=debug npm run dev\n\n# Using generic variable (also works)\nLOG_LEVEL=debug npm run dev\n\n# Production with specific level\nVOLTAGENT_LOG_LEVEL=warn VOLTAGENT_LOG_FORMAT=json npm start\n\n```\n\n## Log Levels [â€‹](https://voltagent.dev/docs/observability/logging/\\#log-levels \"Direct link to Log Levels\")\n\nUse appropriate log levels for different scenarios:\n\n| Level | When to Use | Example |\n| --- | --- | --- |\n| `trace` | Very detailed debugging info | Function entry/exit points |\n| `debug` | Debugging information | Variable values, decision logic |\n| `info` | Important events | Agent started, workflow completed |\n| `warn` | Warning conditions | Retry attempts, fallback behavior |\n| `error` | Error conditions | API failures, invalid inputs |\n| `fatal` | Critical failures | System crashes, unrecoverable errors |\n| `silent` | Disable all logging | Testing or special scenarios |\n\n## What Events Are Logged at Each Level [â€‹](https://voltagent.dev/docs/observability/logging/\\#what-events-are-logged-at-each-level \"Direct link to What Events Are Logged at Each Level\")\n\nThis table shows which events and information are visible at each log level across VoltAgent components:\n\n### Trace Level (Most Detailed) [â€‹](https://voltagent.dev/docs/observability/logging/\\#trace-level-most-detailed \"Direct link to Trace Level (Most Detailed)\")\n\n| Component | Events Logged | Information Included |\n| --- | --- | --- |\n| **Workflow** | â€¢ Workflow execution creation/updates<br>â€¢ Step recording (start/end)<br>â€¢ Timeline events<br>â€¢ Suspension checkpoints<br>â€¢ Cleanup operations | `workflowId`, `executionId`, `stepId`, `status`, `metadata`, `suspensionMetadata` |\n| **Memory** | â€¢ Context loading<br>â€¢ Conversation updates<br>â€¢ Message saves<br>â€¢ SQL query execution<br>â€¢ History operations | `conversationId`, `userId`, `agentId`, `messageId`, SQL queries with parameters |\n| **API** | â€¢ Suspension operations<br>â€¢ Execution state tracking | `[API]` prefix, `executionId`, operation details |\n| **Core** | â€¢ External logger connections<br>â€¢ Registry initialization | Connection status, buffer information |\n\n### Debug Level [â€‹](https://voltagent.dev/docs/observability/logging/\\#debug-level \"Direct link to Debug Level\")\n\n| Component | Events Logged | Information Included |\n| --- | --- | --- |\n| **Agent** | â€¢ Agent creation<br>â€¢ VoltOps client initialization<br>â€¢ Subagent completion (streaming) | `agentId`, `agentName`, `modelName`, `event: LogEvents.AGENT_CREATED` |\n| **Workflow** | â€¢ Resume attempts<br>â€¢ Shutdown suspension | `workflowId`, `executionId`, suspension context |\n| **Memory** | â€¢ Message fetching<br>â€¢ Conversation creation<br>â€¢ Batch saves | `conversationId`, message count, operation type |\n| **Tools** | â€¢ Tool/toolkit registration<br>â€¢ Tool removal | `toolName`, `toolkitName`, tool count |\n| **MCP** | â€¢ Connection fallbacks (HTTPâ†’SSE) | Connection type, fallback reason |\n| **API** | â€¢ Update checks | Check results, version information |\n\n### Info Level [â€‹](https://voltagent.dev/docs/observability/logging/\\#info-level \"Direct link to Info Level\")\n\n| Component | Events Logged | Information Included |\n| --- | --- | --- |\n| **Core** | â€¢ Server startup/shutdown<br>â€¢ Graceful shutdown signals<br>â€¢ Update notifications | `[VoltAgent]` prefix, signal type, shutdown status |\n| **Memory** | â€¢ Migration success | Migration details, affected records |\n| **API** | â€¢ Server already running | Server status |\n\n### Warn Level [â€‹](https://voltagent.dev/docs/observability/logging/\\#warn-level \"Direct link to Warn Level\")\n\n| Component | Events Logged | Information Included |\n| --- | --- | --- |\n| **Agent** | â€¢ Memory preparation errors<br>â€¢ Missing operation context<br>â€¢ OTEL span conflicts<br>â€¢ Context retrieval failures<br>â€¢ Deprecation warnings | Error details, `agentId`, conflict information |\n| **Workflow** | â€¢ Missing memory managers<br>â€¢ Missing executions | `executionId`, manager type |\n| **Tools** | â€¢ Duplicate tools<br>â€¢ Invalid items | Tool names, conflict resolution |\n| **API** | â€¢ Schema conversion failures<br>â€¢ Missing executions | `stepId`, conversion errors |\n| **Core** | â€¢ Telemetry re-initialization | Warning messages |\n\n### Error Level [â€‹](https://voltagent.dev/docs/observability/logging/\\#error-level \"Direct link to Error Level\")\n\n| Component | Events Logged | Information Included |\n| --- | --- | --- |\n| **Agent** | â€¢ Tool execution failures | `toolName`, `agentId`, error object, `event: LogEvents.TOOL_EXECUTION_FAILED` |\n| **Workflow** | â€¢ Execution failures<br>â€¢ Missing workflows<br>â€¢ Suspension failures<br>â€¢ Checkpoint storage failures | `workflowId`, `executionId`, full error details |\n| **Memory** | â€¢ Context load failures<br>â€¢ Conversation setup failures<br>â€¢ History operation failures | Operation context, error details, affected IDs |\n| **MCP** | â€¢ Remote tool execution failures<br>â€¢ Tool wrapper creation failures | Tool names, error objects |\n| **API** | â€¢ Request handling failures<br>â€¢ Stream errors | Error timestamps, request details |\n| **Core** | â€¢ Server start failures<br>â€¢ Endpoint registration failures<br>â€¢ Telemetry initialization failures | Error messages, failure context |\n\n### Key Patterns [â€‹](https://voltagent.dev/docs/observability/logging/\\#key-patterns \"Direct link to Key Patterns\")\n\n1. **Structured Events**: Many logs include a semantic `event` field using `LogEvents` constants (e.g., `LogEvents.AGENT_CREATED`, `LogEvents.TOOL_EXECUTION_FAILED`)\n2. **Contextual IDs**: All logs include relevant IDs ( `agentId`, `workflowId`, `executionId`, `conversationId`, etc.)\n3. **Error Objects**: Error logs always include the full error object for debugging\n4. **Component Prefixes**: Some components use prefixes like `[API]` or `[VoltAgent]` for easy filtering\n5. **Operation Context**: Logs include operation type and status for tracking state transitions\n\n## Understanding Log Event Names [â€‹](https://voltagent.dev/docs/observability/logging/\\#understanding-log-event-names \"Direct link to Understanding Log Event Names\")\n\nVoltAgent uses semantic event names following the pattern `component.action.status`:\n\n- **Component**: `agent`, `workflow`, `memory`, `tool`, `mcp`, `api`, `event`\n- **Action**: `generation`, `stream`, `execution`, `operation`, etc.\n- **Status**: `started`, `completed`, `failed`, `suspended`, etc.\n\nExamples:\n\n- `agent.generation.started` \\- Agent begins generating a response\n- `tool.execution.failed` \\- Tool execution encountered an error\n- `workflow.step.completed` \\- Workflow step finished successfully\n- `memory.conversation.saved` \\- Conversation saved to memory\n\n## Accessing Logs [â€‹](https://voltagent.dev/docs/observability/logging/\\#accessing-logs \"Direct link to Accessing Logs\")\n\n### Console Output [â€‹](https://voltagent.dev/docs/observability/logging/\\#console-output \"Direct link to Console Output\")\n\nDuring development, logs appear in your console with color coding and formatting:\n\n```codeBlockLines_e6Vv\n[2024-01-20 10:30:45] INFO (CustomerSupport): Agent started processing\n  agentId: \"agent_abc123\"\n  conversationId: \"conv_xyz789\"\n  modelName: \"claude-3-sonnet\"\n\n```\n\n### API Endpoint [â€‹](https://voltagent.dev/docs/observability/logging/\\#api-endpoint \"Direct link to API Endpoint\")\n\nQuery logs programmatically via the API:\n\n```codeBlockLines_e6Vv\n// Get recent logs\nGET http://localhost:3141/api/logs\n\n// Filter by agent\nGET http://localhost:3141/api/logs?agentId=agent_abc123\n\n// Filter by level and time\nGET http://localhost:3141/api/logs?level=error&since=2024-01-20T10:00:00Z\n\n// Available query parameters:\n// - level: Filter by log level (\"trace\" | \"debug\" | \"info\" | \"warn\" | \"error\" | \"fatal\" | \"silent\")\n// - agentId: Filter by specific agent\n// - workflowId: Filter by workflow\n// - executionId: Filter by workflow execution\n// - conversationId: Filter by conversation\n// - since/until: Time range filters\n// - limit: Maximum number of logs (default: 100)\n\n```\n\n### VoltOps Console [â€‹](https://voltagent.dev/docs/observability/logging/\\#voltops-console \"Direct link to VoltOps Console\")\n\nWhen using VoltOps Platform, logs are automatically streamed to the web interface with advanced filtering and real-time updates.\n\nðŸŽ¯ **Important**: VoltOps Console receives **ALL logs** regardless of your local transport configuration. Even if you configure file-only transport, your logs will still appear in VoltOps Console UI!\n\n```codeBlockLines_e6Vv\n// Example: File-only transport locally\nconst logger = createPinoLogger({\n  pinoOptions: {\n    transport: {\n      target: \"pino/file\",\n      options: { destination: \"./app.log\" },\n    },\n  },\n});\n\n// âœ… This will appear in VoltOps Console even though it's not in your local console!\nlogger.info(\"This goes to file locally, but still visible in VoltOps Console\");\n\n```\n\nðŸ“ **Current Limitations**:\n\n- Logs are currently stored **in memory only**\n- Logs are **lost on page refresh**\n- Maximum of 5000 logs are kept in memory\n\nðŸš€ **Coming Soon**:\n\n- Persistent log storage in VoltOps Platform\n- Historical log search and analysis\n- Log export capabilities\n\n## Common Pitfalls for Beginners [â€‹](https://voltagent.dev/docs/observability/logging/\\#common-pitfalls-for-beginners \"Direct link to Common Pitfalls for Beginners\")\n\n### 1\\. My Console Logs Disappeared! [â€‹](https://voltagent.dev/docs/observability/logging/\\#1-my-console-logs-disappeared \"Direct link to 1. My Console Logs Disappeared!\")\n\n**Problem**: After adding file transport, logs no longer appear in console.\n\n```codeBlockLines_e6Vv\n// âŒ This removes console output!\nconst logger = createPinoLogger({\n  pinoOptions: {\n    transport: {\n      target: \"pino/file\",\n      options: { destination: \"./app.log\" },\n    },\n  },\n});\n\n```\n\n**Solution**: Include pino-pretty for console output:\n\n```codeBlockLines_e6Vv\n// âœ… This keeps console output\nconst logger = createPinoLogger({\n  pinoOptions: {\n    transport: {\n      targets: [\\\n        { target: \"pino-pretty\", options: { colorize: true } },\\\n        { target: \"pino/file\", options: { destination: \"./app.log\" } },\\\n      ],\n    },\n  },\n});\n\n```\n\n### 2\\. Logs Not Showing in Production [â€‹](https://voltagent.dev/docs/observability/logging/\\#2-logs-not-showing-in-production \"Direct link to 2. Logs Not Showing in Production\")\n\n**Problem**: Pretty logs don't appear in production.\n\n**Solution**: By default, pino-pretty is disabled in production. Either:\n\n- Set `format: \"pretty\"` explicitly\n- Use `NODE_ENV=development`\n- Configure transport manually\n\n### 3\\. Log Level Not Working [â€‹](https://voltagent.dev/docs/observability/logging/\\#3-log-level-not-working \"Direct link to 3. Log Level Not Working\")\n\n**Problem**: Debug logs not showing even with `level: \"debug\"`.\n\n**Solution**: Check these in order:\n\n1. Environment variable `VOLTAGENT_LOG_LEVEL` might override your setting\n2. Individual transports can have their own levels\n3. Parent logger level affects child loggers\n\n### 4\\. VoltOps Console vs Local Console [â€‹](https://voltagent.dev/docs/observability/logging/\\#4-voltops-console-vs-local-console \"Direct link to 4. VoltOps Console vs Local Console\")\n\n**Remember**:\n\n- VoltOps Console shows ALL logs regardless of local transport\n- Local console only shows logs if pino-pretty is configured\n- They are independent systems!\n\n## Execution-Scoped Logging in Tools and Workflows [â€‹](https://voltagent.dev/docs/observability/logging/\\#execution-scoped-logging-in-tools-and-workflows \"Direct link to Execution-Scoped Logging in Tools and Workflows\")\n\nWhen your tools, workflows, and retrievers are executed from an agent or workflow context, they automatically receive an execution-scoped logger. This logger includes all the relevant context (userId, conversationId, executionId) for proper log correlation.\n\n### Using Logger in Custom Tools [â€‹](https://voltagent.dev/docs/observability/logging/\\#using-logger-in-custom-tools \"Direct link to Using Logger in Custom Tools\")\n\nTools receive a logger instance through the operation context in their execution options:\n\n```codeBlockLines_e6Vv\nimport { createTool } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\nconst weatherTool = createTool({\n  name: \"get_weather\",\n  description: \"Get weather for a location\",\n  parameters: z.object({\n    location: z.string(),\n  }),\n  execute: async ({ location }, options) => {\n    const logger = options?.operationContext?.logger;\n\n    // Log with full execution context\n    logger?.info(\"Fetching weather data\", { location });\n\n    try {\n      const weather = await fetchWeatherAPI(location);\n      logger?.debug(\"Weather data retrieved\", { location, temperature: weather.temp });\n      return weather;\n    } catch (error) {\n      logger?.error(\"Failed to fetch weather\", { location, error });\n      throw error;\n    }\n  },\n});\n\n```\n\n### Using Logger in Workflow Steps [â€‹](https://voltagent.dev/docs/observability/logging/\\#using-logger-in-workflow-steps \"Direct link to Using Logger in Workflow Steps\")\n\nWorkflow steps have access to the logger through the execution context:\n\n```codeBlockLines_e6Vv\nimport { createWorkflow, andThen } from \"@voltagent/core\";\n\nconst workflow = createWorkflow(\n  {\n    name: \"DataProcessing\",\n    inputSchema: z.object({ data: z.array(z.string()) }),\n    resultSchema: z.object({ processed: z.number() }),\n  },\n  andThen(async (context) => {\n    const { data, logger } = context;\n\n    logger.info(\"Starting data processing\", { itemCount: data.data.length });\n\n    for (const item of data.data) {\n      logger.debug(\"Processing item\", { item });\n      // Process item...\n    }\n\n    logger.info(\"Data processing completed\");\n    return { processed: data.data.length };\n  })\n);\n\n```\n\n### Using Logger in Custom Retrievers [â€‹](https://voltagent.dev/docs/observability/logging/\\#using-logger-in-custom-retrievers \"Direct link to Using Logger in Custom Retrievers\")\n\nRetrievers receive a logger in their retrieve options:\n\n```codeBlockLines_e6Vv\nclass CustomRetriever {\n  async retrieve(query, options) {\n    const logger = options?.logger;\n\n    logger?.info(\"Starting retrieval\", { query });\n\n    try {\n      const results = await this.searchDatabase(query);\n      logger?.debug(\"Retrieved documents\", { count: results.length });\n      return results.join(\"\\n\");\n    } catch (error) {\n      logger?.error(\"Retrieval failed\", { query, error });\n      throw error;\n    }\n  }\n}\n\n```\n\n### Logger Context Inheritance [â€‹](https://voltagent.dev/docs/observability/logging/\\#logger-context-inheritance \"Direct link to Logger Context Inheritance\")\n\nThe execution-scoped logger automatically includes all relevant context from the parent operation:\n\n- `userId` \\- User making the request\n- `conversationId` \\- Active conversation\n- `executionId` \\- Current execution ID\n- `agentId` \\- When executed from an agent\n- `workflowId` \\- When executed from a workflow\n- `stepId` \\- Current workflow step\n\nThis ensures all logs are properly correlated and can be traced through the entire execution flow.\n\n### Table of Contents\n\n- [Global Logger Configuration](https://voltagent.dev/docs/observability/logging/#global-logger-configuration)\n- [Default Logger Behavior](https://voltagent.dev/docs/observability/logging/#default-logger-behavior)\n  - [ConsoleLogger Features:](https://voltagent.dev/docs/observability/logging/#consolelogger-features)\n  - [ConsoleLogger Limitations:](https://voltagent.dev/docs/observability/logging/#consolelogger-limitations)\n  - [When to Use Each Logger:](https://voltagent.dev/docs/observability/logging/#when-to-use-each-logger)\n- [Using Pino Logger with Advanced Features](https://voltagent.dev/docs/observability/logging/#using-pino-logger-with-advanced-features)\n- [Agent-Level Logging](https://voltagent.dev/docs/observability/logging/#agent-level-logging)\n- [Workflow-Level Logging](https://voltagent.dev/docs/observability/logging/#workflow-level-logging)\n- [Custom Transports and File Logging](https://voltagent.dev/docs/observability/logging/#custom-transports-and-file-logging)\n  - [File-Only Logging (No Console Output)](https://voltagent.dev/docs/observability/logging/#file-only-logging-no-console-output)\n  - [Console + File Logging (Recommended)](https://voltagent.dev/docs/observability/logging/#console--file-logging-recommended)\n  - [Our Default Console Configuration](https://voltagent.dev/docs/observability/logging/#our-default-console-configuration)\n  - [Multiple Log Files Example](https://voltagent.dev/docs/observability/logging/#multiple-log-files-example)\n- [Environment Variables](https://voltagent.dev/docs/observability/logging/#environment-variables)\n- [Log Levels](https://voltagent.dev/docs/observability/logging/#log-levels)\n- [What Events Are Logged at Each Level](https://voltagent.dev/docs/observability/logging/#what-events-are-logged-at-each-level)\n  - [Trace Level (Most Detailed)](https://voltagent.dev/docs/observability/logging/#trace-level-most-detailed)\n  - [Debug Level](https://voltagent.dev/docs/observability/logging/#debug-level)\n  - [Info Level](https://voltagent.dev/docs/observability/logging/#info-level)\n  - [Warn Level](https://voltagent.dev/docs/observability/logging/#warn-level)\n  - [Error Level](https://voltagent.dev/docs/observability/logging/#error-level)\n  - [Key Patterns](https://voltagent.dev/docs/observability/logging/#key-patterns)\n- [Understanding Log Event Names](https://voltagent.dev/docs/observability/logging/#understanding-log-event-names)\n- [Accessing Logs](https://voltagent.dev/docs/observability/logging/#accessing-logs)\n  - [Console Output](https://voltagent.dev/docs/observability/logging/#console-output)\n  - [API Endpoint](https://voltagent.dev/docs/observability/logging/#api-endpoint)\n  - [VoltOps Console](https://voltagent.dev/docs/observability/logging/#voltops-console)\n- [Common Pitfalls for Beginners](https://voltagent.dev/docs/observability/logging/#common-pitfalls-for-beginners)\n  - [1\\. My Console Logs Disappeared!](https://voltagent.dev/docs/observability/logging/#1-my-console-logs-disappeared)\n  - [2\\. Logs Not Showing in Production](https://voltagent.dev/docs/observability/logging/#2-logs-not-showing-in-production)\n  - [3\\. Log Level Not Working](https://voltagent.dev/docs/observability/logging/#3-log-level-not-working)\n  - [4\\. VoltOps Console vs Local Console](https://voltagent.dev/docs/observability/logging/#4-voltops-console-vs-local-console)\n- [Execution-Scoped Logging in Tools and Workflows](https://voltagent.dev/docs/observability/logging/#execution-scoped-logging-in-tools-and-workflows)\n  - [Using Logger in Custom Tools](https://voltagent.dev/docs/observability/logging/#using-logger-in-custom-tools)\n  - [Using Logger in Workflow Steps](https://voltagent.dev/docs/observability/logging/#using-logger-in-workflow-steps)\n  - [Using Logger in Custom Retrievers](https://voltagent.dev/docs/observability/logging/#using-logger-in-custom-retrievers)\n  - [Logger Context Inheritance](https://voltagent.dev/docs/observability/logging/#logger-context-inheritance)",
      "metadata": {
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "docusaurus_tag": "docs-default-current",
        "og:url": "https://voltagent.dev/docs/observability/logging/",
        "ogUrl": "https://voltagent.dev/docs/observability/logging/",
        "language": "en",
        "ogTitle": "Logging | VoltAgent",
        "generator": "Docusaurus v3.1.1",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_version": "current",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:title": "Logging | VoltAgent",
        "ogDescription": "VoltAgent provides automatic logging for all agent and workflow events. By default, it uses a simple console logger for quick prototyping, but for production use, you should use the powerful Pino-based logger from @voltagent/logger package which offers pretty formatting, file transports, and advanced features.",
        "twitter:card": "summary_large_image",
        "og:image": "https://voltagent.dev/img/social3.png",
        "ogLocale": "en",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "docusaurus_locale": "en",
        "docsearch:language": "en",
        "docsearch:version": "current",
        "title": "Logging | VoltAgent",
        "og:locale": "en",
        "description": "VoltAgent provides automatic logging for all agent and workflow events. By default, it uses a simple console logger for quick prototyping, but for production use, you should use the powerful Pino-based logger from @voltagent/logger package which offers pretty formatting, file transports, and advanced features.",
        "og:description": "VoltAgent provides automatic logging for all agent and workflow events. By default, it uses a simple console logger for quick prototyping, but for production use, you should use the powerful Pino-based logger from @voltagent/logger package which offers pretty formatting, file transports, and advanced features.",
        "scrapeId": "6a933fd4-300d-46bb-b82a-e7e10d474185",
        "sourceURL": "https://voltagent.dev/docs/observability/logging/",
        "url": "https://voltagent.dev/docs/observability/logging/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:15.664Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/agents/mcp/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Model Context Protocol (MCP)\n\nThe [Model Context Protocol](https://modelcontextprotocol.io/introduction) (MCP) provides a **standardized way** for large language models (LLMs) and AI agents to interact with external tools and services. VoltAgent implements MCP client capabilities, enabling your agents to seamlessly access diverse functionalities like filesystem operations, browser automation, database interactions, specific AI models hosted externally, and more, provided they adhere to the MCP specification.\n\n## Transport Types [â€‹](https://voltagent.dev/docs/agents/mcp/\\#transport-types \"Direct link to Transport Types\")\n\nVoltAgent supports multiple transport types for MCP connections:\n\n- **`streamable-http`**: Modern streamable HTTP transport for efficient bidirectional communication\n- **`http`**: Smart transport that attempts streamable HTTP first and automatically falls back to SSE for compatibility\n- **`sse`**: Server-Sent Events transport for servers that explicitly use SSE\n- **`stdio`**: Standard input/output for local processes and CLI tools\n\n## Getting Started with MCPConfiguration [â€‹](https://voltagent.dev/docs/agents/mcp/\\#getting-started-with-mcpconfiguration \"Direct link to Getting Started with MCPConfiguration\")\n\nThe `MCPConfiguration` class is the central point for managing connections to one or more MCP servers. It handles the connection process and makes the tools offered by these servers available to your agents.\n\n```codeBlockLines_e6Vv\nimport { MCPConfiguration } from \"@voltagent/core\";\nimport path from \"node:path\"; // Used for filesystem path example\n\n// Create MCP Configuration with multiple types of servers\nconst mcpConfig = new MCPConfiguration({\n  servers: {\n    // Example 1: Streamable HTTP transport (modern, efficient)\n    github: {\n      type: \"streamable-http\",\n      url: \"https://api.githubcopilot.com/mcp\",\n      // Optional: Request timeout in milliseconds (default: 30000)\n      timeout: 15000,\n    },\n\n    // Example 2: HTTP with automatic fallback (recommended for compatibility)\n    reddit: {\n      type: \"http\", // Tries streamable HTTP first, falls back to SSE if needed\n      url: \"https://mcp.composio.dev/reddit/your-api-key-here\", // URL of the MCP endpoint\n      // Optional: Custom headers or options for the initial fetch request\n      requestInit: {\n        headers: { \"Custom-Header\": \"value\" },\n      },\n      // Optional: Custom options for the EventSource connection used for streaming\n      eventSourceInit: { withCredentials: true },\n      // Optional: Request timeout in milliseconds (default: 30000)\n      timeout: 20000,\n    },\n\n    // Example 3: SSE transport (explicit Server-Sent Events)\n    linear: {\n      type: \"sse\",\n      url: \"https://mcp.linear.app/sse\",\n      // Optional: Request timeout in milliseconds (default: 30000)\n      timeout: 25000,\n    },\n\n    // Example 4: stdio-based server (e.g., a local script or application)\n    filesystem: {\n      type: \"stdio\", // Connects via standard input/output\n      command: \"npx\", // The command to execute\n      args: [\\\n        // Arguments for the command\\\n        \"-y\",\\\n        \"@modelcontextprotocol/server-filesystem\", // Example: A filesystem server package\\\n        // Optional arguments for the server itself, like specifying allowed paths:\\\n        path.join(process.env.HOME || \"\", \"Desktop\"),\\\n      ],\n      // Optional: Specify the working directory for the command\n      cwd: process.env.HOME,\n      // Optional: Provide environment variables to the spawned process\n      env: { NODE_ENV: \"production\" },\n      // Optional: Request timeout in milliseconds (default: 30000)\n      timeout: 10000,\n    },\n  },\n});\n\n```\n\n## Working with MCP Tools [â€‹](https://voltagent.dev/docs/agents/mcp/\\#working-with-mcp-tools \"Direct link to Working with MCP Tools\")\n\nOnce configured, you can retrieve the tools offered by the MCP servers. These fetched tools are standard `AgentTool` objects, fully compatible with the VoltAgent `Agent`.\n\n### Get All Tools as Flat Array ( `getTools()`) [â€‹](https://voltagent.dev/docs/agents/mcp/\\#get-all-tools-as-flat-array-gettools \"Direct link to get-all-tools-as-flat-array-gettools\")\n\nUse `getTools()` when you want a single list containing all tools from all configured MCP servers. This is useful if you want to provide one agent with the combined capabilities of all connected services.\n\n```codeBlockLines_e6Vv\n// Fetch all tools from all configured MCP servers into a flat array\nconst allTools = await mcpConfig.getTools();\n\n// Use these tools when interacting with an agent\n// const response = await agent.generateText(\"What are the top posts on r/programming?\", {\n//   userId: \"user123\",\n//   tools: allTools, // Pass the combined list of tools\n// });\n\n// Remember to disconnect later\n// await mcpConfig.disconnect();\n\n```\n\n### Get Tools Organized by Server ( `getToolsets()`) [â€‹](https://voltagent.dev/docs/agents/mcp/\\#get-tools-organized-by-server-gettoolsets \"Direct link to get-tools-organized-by-server-gettoolsets\")\n\nUse `getToolsets()` when you need to access tools grouped by the server they originate from. This returns an object where keys are your server names (e.g., `\"reddit\"`, `\"filesystem\"`) and values are toolset objects, each containing a `getTools()` method for that specific server's tools. This is useful for creating specialized agents that only use tools from a particular source.\n\n```codeBlockLines_e6Vv\n// Fetch tools organized by server name\nconst toolsets = await mcpConfig.getToolsets();\n\n// Access tools specifically from the filesystem server\nconst filesystemTools = toolsets.filesystem.getTools();\n\n// Use only filesystem tools with an agent\n// const filesystemResponse = await agent.generateText(\n//   \"List all files in my Desktop folder and create a summary.txt file\",\n//   {\n//     userId: \"user123\",\n//     tools: filesystemTools, // Pass only the filesystem tools\n//   }\n// );\n\n// Remember to disconnect later\n// await mcpConfig.disconnect();\n\n```\n\n## Event Handling [â€‹](https://voltagent.dev/docs/agents/mcp/\\#event-handling \"Direct link to Event Handling\")\n\nMonitoring the status and activity of MCP connections can be important for robust applications. You can access the underlying client instances to listen for connection events, errors, or specific MCP messages.\n\n```codeBlockLines_e6Vv\n// Get the client instances (ensure connection is established first, e.g., after getTools)\nconst clients = await mcpConfig.getClients();\n\n// Example: Listen for connection event on the 'reddit' client\nif (clients.reddit) {\n  clients.reddit.on(\"connect\", () => {\n    console.log(\"Connected to Reddit MCP server\");\n  });\n\n  // Example: Handle errors centrally for the 'reddit' client\n  clients.reddit.on(\"error\", (error) => {\n    console.error(\"Reddit MCP server connection error:\", error.message);\n  });\n}\n\n```\n\n## Cleanup ( `disconnect()`) [â€‹](https://voltagent.dev/docs/agents/mcp/\\#cleanup-disconnect \"Direct link to cleanup-disconnect\")\n\nIt is **crucial** to disconnect MCP clients when they are no longer needed, especially for `stdio` based servers, as this terminates the underlying child processes. Failure to disconnect can leave processes running in the background.\n\n```codeBlockLines_e6Vv\n// Disconnect all clients managed by this configuration\nawait mcpConfig.disconnect();\nconsole.log(\"MCP clients disconnected.\");\n\n```\n\n## Adding MCP Tools to an Agent [â€‹](https://voltagent.dev/docs/agents/mcp/\\#adding-mcp-tools-to-an-agent \"Direct link to Adding MCP Tools to an Agent\")\n\nFetched MCP tools (which are `AgentTool` compatible) can be provided to a VoltAgent `Agent` in two primary ways:\n\n### 1\\. At Agent Initialization [â€‹](https://voltagent.dev/docs/agents/mcp/\\#1-at-agent-initialization \"Direct link to 1. At Agent Initialization\")\n\nProvide the tools via the `tools` array in the `Agent` constructor. These tools will be available to the agent by default for all interactions, unless overridden at request time.\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n// Assume mcpConfig is configured and allTools fetched as shown above\n\nconst allTools = await mcpConfig.getTools();\n\nconst agent = new Agent({\n  name: \"MCP Aware Agent\",\n  instructions: \"An assistant that can use MCP tools configured at startup\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  tools: allTools, // Add MCP tools during initialization\n});\n\n// Now the agent can use MCP tools in its interactions\n// await agent.generateText(...);\n\n// Remember to disconnect mcpConfig eventually\n// await mcpConfig.disconnect();\n\n```\n\n### 2\\. At Request Time [â€‹](https://voltagent.dev/docs/agents/mcp/\\#2-at-request-time \"Direct link to 2. At Request Time\")\n\nProvide tools via the `tools` option in the specific agent method call ( `generateText`, `streamText`, etc.). This allows you to dynamically provide tools for a single interaction, potentially overriding the tools defined during agent initialization for that specific request.\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\n// Assume agent is initialized without MCP tools, and mcpConfig is configured\n\nconst agent = new Agent({\n  /* ... basic config ... */\n});\nconst allTools = await mcpConfig.getTools();\n\n// Provide MCP tools only for this specific request\n// const response = await agent.generateText(\"What are the top posts on r/programming?\", {\n//   userId: \"user123\",\n//   tools: allTools, // Add MCP tools at request time\n// });\n\n// Remember to disconnect mcpConfig eventually\n// await mcpConfig.disconnect();\n\n```\n\n## Error Handling [â€‹](https://voltagent.dev/docs/agents/mcp/\\#error-handling \"Direct link to Error Handling\")\n\nInteracting with MCP servers involves external processes or network requests, which can fail. Consider these error handling strategies:\n\n- **Connection/Tool Fetching:** Wrap calls to `mcpConfig.getTools()` or `mcpConfig.getToolsets()` in `try...catch` blocks to handle errors during initial connection or tool discovery.\n- **Client Events:** Use the `client.on('error', ...)` event listener (shown in Event Handling section) to react to connection errors or protocol issues reported by a specific client.\n- **Agent Interaction:** When an agent uses an MCP tool, the execution happens within the agent's standard tool-handling flow. Errors during the tool's execution should be handled within the agent's interaction (e.g., using `try...catch` around `agent.generateText` or the agent's `onError` hook/callback if applicable, although MCP tool errors might manifest differently depending on the server implementation).\n\n## Typical Lifecycle Summary [â€‹](https://voltagent.dev/docs/agents/mcp/\\#typical-lifecycle-summary \"Direct link to Typical Lifecycle Summary\")\n\n1. **Configure:** Create an `MCPConfiguration` instance defining your servers.\n2. **Fetch Tools:** Use `await mcpConfig.getTools()` or `await mcpConfig.getToolsets()` to establish connections and retrieve available tools.\n3. **Use with Agent:** Pass the fetched tools to an `Agent` either during initialization or at request time.\n4. **Interact:** Call agent methods like `generateText` or `streamText`. The agent may decide to use the MCP tools.\n5. **(Optional) Monitor:** Use `mcpConfig.getClients()` to attach event listeners for monitoring.\n6. **Disconnect:** Call `await mcpConfig.disconnect()` when done to clean up resources.\n\n### Table of Contents\n\n- [Transport Types](https://voltagent.dev/docs/agents/mcp/#transport-types)\n- [Getting Started with MCPConfiguration](https://voltagent.dev/docs/agents/mcp/#getting-started-with-mcpconfiguration)\n- [Working with MCP Tools](https://voltagent.dev/docs/agents/mcp/#working-with-mcp-tools)\n  - [Get All Tools as Flat Array ( `getTools()`)](https://voltagent.dev/docs/agents/mcp/#get-all-tools-as-flat-array-gettools)\n  - [Get Tools Organized by Server ( `getToolsets()`)](https://voltagent.dev/docs/agents/mcp/#get-tools-organized-by-server-gettoolsets)\n- [Event Handling](https://voltagent.dev/docs/agents/mcp/#event-handling)\n- [Cleanup ( `disconnect()`)](https://voltagent.dev/docs/agents/mcp/#cleanup-disconnect)\n- [Adding MCP Tools to an Agent](https://voltagent.dev/docs/agents/mcp/#adding-mcp-tools-to-an-agent)\n  - [1\\. At Agent Initialization](https://voltagent.dev/docs/agents/mcp/#1-at-agent-initialization)\n  - [2\\. At Request Time](https://voltagent.dev/docs/agents/mcp/#2-at-request-time)\n- [Error Handling](https://voltagent.dev/docs/agents/mcp/#error-handling)\n- [Typical Lifecycle Summary](https://voltagent.dev/docs/agents/mcp/#typical-lifecycle-summary)",
      "metadata": {
        "og:locale": "en",
        "docsearch:version": "current",
        "docsearch:language": "en",
        "twitter:card": "summary_large_image",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "ogUrl": "https://voltagent.dev/docs/agents/mcp/",
        "docusaurus_tag": "docs-default-current",
        "ogLocale": "en",
        "og:url": "https://voltagent.dev/docs/agents/mcp/",
        "generator": "Docusaurus v3.1.1",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "docusaurus_locale": "en",
        "language": "en",
        "ogTitle": "Model Context Protocol (MCP) | VoltAgent",
        "viewport": "width=device-width, initial-scale=1.0",
        "og:title": "Model Context Protocol (MCP) | VoltAgent",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "title": "Model Context Protocol (MCP) | VoltAgent",
        "ogDescription": "The Model Context Protocol (MCP) provides a standardized way for large language models (LLMs) and AI agents to interact with external tools and services. VoltAgent implements MCP client capabilities, enabling your agents to seamlessly access diverse functionalities like filesystem operations, browser automation, database interactions, specific AI models hosted externally, and more, provided they adhere to the MCP specification.",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:description": "The Model Context Protocol (MCP) provides a standardized way for large language models (LLMs) and AI agents to interact with external tools and services. VoltAgent implements MCP client capabilities, enabling your agents to seamlessly access diverse functionalities like filesystem operations, browser automation, database interactions, specific AI models hosted externally, and more, provided they adhere to the MCP specification.",
        "og:image": "https://voltagent.dev/img/social3.png",
        "description": "The Model Context Protocol (MCP) provides a standardized way for large language models (LLMs) and AI agents to interact with external tools and services. VoltAgent implements MCP client capabilities, enabling your agents to seamlessly access diverse functionalities like filesystem operations, browser automation, database interactions, specific AI models hosted externally, and more, provided they adhere to the MCP specification.",
        "docusaurus_version": "current",
        "scrapeId": "4d51bdb9-f7a2-41a1-9d2d-638177072041",
        "sourceURL": "https://voltagent.dev/docs/agents/mcp/",
        "url": "https://voltagent.dev/docs/agents/mcp/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:53.181Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/workflows/overview/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Overview\n\n> **Note: Workflows are in Preview**\n> The Workflows API is currently in a preview state. This means it is stable and usable, but there may be breaking changes in future releases as we gather feedback and refine the developer experience.\n\n> **Build powerful, type-safe AI workflows.** Go from a simple chain of functions to a complex, multi-step process that combines your code, AI models, and conditional logic with ease.\n\n## What are Workflows? [â€‹](https://voltagent.dev/docs/workflows/overview/\\#what-are-workflows \"Direct link to What are Workflows?\")\n\nA workflow is a chain of steps. Each step does something and passes its result to the next step.\n\n```codeBlockLines_e6Vv\nworkflow = step1 â†’ step2 â†’ step3 â†’ result\n\n```\n\nThat's it. The power comes from what each step can do: run code, call AI, make decisions, run in parallel.\n\n## Get Started in 2 Minutes [â€‹](https://voltagent.dev/docs/workflows/overview/\\#get-started-in-2-minutes \"Direct link to Get Started in 2 Minutes\")\n\nLet's build a workflow from scratch. We'll start with a simple function, add AI, and then introduce conditional logic. Each step will show the complete, runnable code.\n\n### 1\\. Create a Basic Workflow [â€‹](https://voltagent.dev/docs/workflows/overview/\\#1-create-a-basic-workflow \"Direct link to 1. Create a Basic Workflow\")\n\nFirst, create a workflow that takes a name and returns a greeting. This is the simplest form of a workflow: a single step that processes some data.\n\n```codeBlockLines_e6Vv\nimport { createWorkflowChain } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\n// Define the workflow's shape: its inputs and final output\nconst workflow = createWorkflowChain({\n  id: \"greeter\",\n  name: \"Greeter Workflow\",\n  // A detailed description for VoltOps or team clarity\n  purpose: \"A simple workflow to generate a greeting for a given name.\",\n  input: z.object({ name: z.string() }),\n  result: z.object({ greeting: z.string() }),\n})\n  // Add the first step: a function to create the greeting\n  .andThen({\n    id: \"create-greeting\",\n    execute: async ({ data }) => {\n      return { greeting: `Hello, ${data.name}!` };\n    },\n  });\n\n// Run it!\nconst result = await workflow.run({ name: \"World\" });\n\nconsole.log(result.result);\n// Output: { greeting: 'Hello, World!' }\n\n```\n\n### 2\\. Add AI Intelligence [â€‹](https://voltagent.dev/docs/workflows/overview/\\#2-add-ai-intelligence \"Direct link to 2. Add AI Intelligence\")\n\nNow, let's enhance our workflow. We'll add an AI agent to analyze the sentiment of the greeting message. Notice how we add new imports, define an agent, and chain the `.andAgent()` step.\n\n```codeBlockLines_e6Vv\nimport { createWorkflowChain, Agent } from \"@voltagent/core\";\nimport { z } from \"zod\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Define an AI agent to use in our workflow\nconst agent = new Agent({\n  name: \"Analyzer\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  instructions: \"You are a text analyzer.\",\n});\n\nconst workflow = createWorkflowChain({\n  id: \"greeter\",\n  name: \"Greeter Workflow\",\n  input: z.object({ name: z.string() }),\n  // The final result now includes the sentiment\n  result: z.object({\n    greeting: z.string(),\n    sentiment: z.string(),\n  }),\n})\n  .andThen({\n    id: \"create-greeting\",\n    execute: async ({ data }) => {\n      return { greeting: `Hello, ${data.name}!` };\n    },\n  })\n  // Add the new AI step to the chain\n  .andAgent(({ data }) => `Analyze the sentiment of this greeting: \"${data.greeting}\"`, agent, {\n    schema: z.object({ sentiment: z.string().describe(\"e.g., positive, neutral, negative\") }),\n  });\n\n// Run the enhanced workflow\nconst result = await workflow.run({ name: \"World\" });\n\nconsole.log(result.result);\n// Output: { greeting: 'Hello, World!', sentiment: 'positive' }\n\n```\n\n### 3\\. Add Conditional Logic [â€‹](https://voltagent.dev/docs/workflows/overview/\\#3-add-conditional-logic \"Direct link to 3. Add Conditional Logic\")\n\nFinally, let's add a step that only runs if a condition is met. We'll check if the input name is long and add a flag. The `.andWhen()` step is perfect for this. We also update the final `result` schema to include the new optional field.\n\n```codeBlockLines_e6Vv\nimport { createWorkflowChain, Agent, andThen } from \"@voltagent/core\";\nimport { z } from \"zod\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  name: \"Analyzer\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  instructions: \"You are a text analyzer.\",\n});\n\nconst workflow = createWorkflowChain({\n  id: \"greeter\",\n  name: \"Greeter Workflow\",\n  input: z.object({ name: z.string() }),\n  // The final result now includes an optional 'isLongName' field\n  result: z.object({\n    greeting: z.string(),\n    sentiment: z.string(),\n    isLongName: z.boolean().optional(),\n  }),\n})\n  .andThen({\n    id: \"create-greeting\",\n    execute: async ({ data }) => {\n      return { greeting: `Hello, ${data.name}!` };\n    },\n  })\n  .andAgent(({ data }) => `Analyze the sentiment of this greeting: \"${data.greeting}\"`, agent, {\n    schema: z.object({ sentiment: z.string().describe(\"e.g., positive, neutral, negative\") }),\n  })\n  // Add a conditional step\n  .andWhen({\n    id: \"check-name-length\",\n    condition: ({ data }) => data.name.length > 10,\n    step: andThen({\n      id: \"set-long-name-flag\",\n      execute: async ({ data }) => ({ ...data, isLongName: true }),\n    }),\n  });\n\n// Run with a long name to trigger the conditional step\nconst longNameResult = await workflow.run({ name: \"Alexanderson\" });\nconsole.log(longNameResult.result);\n// Output: { greeting: 'Hello, Alexanderson!', sentiment: 'positive', isLongName: true }\n\n// Run with a short name to skip the conditional step\nconst shortNameResult = await workflow.run({ name: \"Alex\" });\nconsole.log(shortNameResult.result);\n// Output: { greeting: 'Hello, Alex!', sentiment: 'positive' }\n\n```\n\n## How It Works [â€‹](https://voltagent.dev/docs/workflows/overview/\\#how-it-works \"Direct link to How It Works\")\n\nWorkflows are built on three core principles:\n\n### 1\\. A Chain of Steps [â€‹](https://voltagent.dev/docs/workflows/overview/\\#1-a-chain-of-steps \"Direct link to 1. A Chain of Steps\")\n\nYou build a workflow by chaining steps together using methods like `.andThen()`, `.andAgent()`, and `.andWhen()`. Each step performs a specific action, like running code, calling an AI, or making a decision.\n\n```codeBlockLines_e6Vv\ncreateWorkflowChain(...)\n  .andThen(...) // Step 1: Run some code\n  .andAgent(...) // Step 2: Call an AI\n  .andWhen(...)  // Step 3: Maybe run another step\n\n```\n\n### 2\\. Data Flows Through the Chain [â€‹](https://voltagent.dev/docs/workflows/overview/\\#2-data-flows-through-the-chain \"Direct link to 2. Data Flows Through the Chain\")\n\nThe output of one step becomes the input for the next. The data object is automatically merged, so you can access results from all previous steps.\n\nInput: { name: 'World' }\n\nStep 1: andThen\n\nData: { name: 'World',\n\ngreeting: 'Hello, World!' }\n\nStep 2: andAgent\n\nData: { name: 'World',\n\ngreeting: 'Hello, World!',\n\nsentiment: 'positive' }\n\nFinal Result\n\n### 3\\. Automatic Type Safety [â€‹](https://voltagent.dev/docs/workflows/overview/\\#3-automatic-type-safety \"Direct link to 3. Automatic Type Safety\")\n\nAs data flows through the workflow, TypeScript types are automatically inferred and updated at each step. This means you get full autocompletion and type-checking, preventing common errors.\n\n```codeBlockLines_e6Vv\nimport { z } from \"zod\";\nimport { Agent, createWorkflowChain } from \"@voltagent/core\";\n\ndeclare const agent: Agent<any>;\n\ncreateWorkflowChain({\n  id: \"type-safe-workflow\",\n  name: \"Type-Safe Workflow\",\n  input: z.object({ email: z.string() }),\n  result: z.object({ success: z.boolean() }),\n})\n  // `data` is typed as { email: string }\n  .andThen({\n    id: \"add-user-id\",\n    execute: async ({ data }) => {\n      // data.email is available and type-safe\n      return { ...data, userId: \"user-123\" };\n    },\n  })\n  // `data` is now typed as { email: string, userId: string }\n  .andAgent(\n    ({ data }) => `Welcome ${data.userId}`, // data.userId is available!\n    agent,\n    {\n      schema: z.object({ welcomeMessage: z.string() }),\n    }\n  )\n  // `data` is now typed as { ..., welcomeMessage: string }\n  .andThen({\n    id: \"finalize\",\n    execute: async ({ data }) => {\n      // data.welcomeMessage is available!\n      return { success: true };\n    },\n  });\n\n```\n\n## Builder vs. Runnable: `toWorkflow()` [â€‹](https://voltagent.dev/docs/workflows/overview/\\#builder-vs-runnable-toworkflow \"Direct link to builder-vs-runnable-toworkflow\")\n\nWhen you use `createWorkflowChain`, you are creating a **builder** object ( `WorkflowChain`). Each call to `.andThen()`, `.andAgent()`, etc., modifies this builder and returns it, allowing you to chain methods.\n\nThis builder is not the final, runnable workflow itself. It's the blueprint.\n\nThere are two ways to run your workflow:\n\n**1\\. The Shortcut: `.run()`**\n\nCalling `.run()` directly on the chain is a convenient shortcut. Behind the scenes, it first converts your chain into a runnable workflow and then immediately executes it. This is great for most use cases.\n\n```codeBlockLines_e6Vv\n// .run() builds and executes in one step\nconst result = await workflow.run({ name: \"World\" });\n\n```\n\n**2\\. The Reusable Way: `.toWorkflow()`**\n\nThe `WorkflowChain` builder has a `.toWorkflow()` method that converts your blueprint into a permanent, reusable `Workflow` object. You can store this object, pass it to other functions, or run it multiple times without rebuilding the chain.\n\nThis is powerful for creating modular and testable code.\n\n```codeBlockLines_e6Vv\nimport { createWorkflowChain } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\n// 1. Define the chain (the builder)\nconst greeterChain = createWorkflowChain({\n  id: \"reusable-greeter\",\n  name: \"Reusable Greeter\",\n  input: z.object({ name: z.string() }),\n  result: z.object({ greeting: z.string() }),\n}).andThen({\n  id: \"create-greeting\",\n  execute: async ({ name }) => ({ greeting: `Hello, ${name}!` }),\n});\n\n// 2. Convert the builder into a runnable, reusable workflow object\nconst runnableGreeter = greeterChain.toWorkflow();\n\n// 3. Now you can run it as many times as you want\nconst result1 = await runnableGreeter.run({ name: \"Alice\" });\nconsole.log(result1.result); // { greeting: 'Hello, Alice!' }\n\nconst result2 = await runnableGreeter.run({ name: \"Bob\" });\nconsole.log(result2.result); // { greeting: 'Hello, Bob!' }\n\n```\n\nThis distinction allows you to define your workflow logic once and execute it in different contexts or at different times.\n\n### Accessing Execution State [â€‹](https://voltagent.dev/docs/workflows/overview/\\#accessing-execution-state \"Direct link to Accessing Execution State\")\n\nYou can pass run-specific data to your workflow, such as a user ID or other contextual information. This state is available in every step, allowing you to build dynamic, user-aware workflows.\n\n**1\\. Pass State During `.run()`**\n\nProvide the initial state in the second argument of the `.run()` method.\n\n```codeBlockLines_e6Vv\nconst result = await workflow.run(\n  { name: \"State\" },\n  {\n    userId: \"user-abc-123\",\n    conversationId: \"conv-xyz-456\",\n    userContext: new Map([[\"plan\", \"premium\"]]),\n  }\n);\n\n```\n\n**2\\. Access and Modify State in Steps**\n\nThe `execute` function can accept a second argument containing the execution state. You can also modify the `userContext` map, and the changes will be available in subsequent steps.\n\n```codeBlockLines_e6Vv\nimport { createWorkflowChain } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\nconst workflow = createWorkflowChain({\n  id: \"state-demo\",\n  name: \"State Demo\",\n  input: z.object({ name: z.string() }),\n  result: z.object({ greeting: z.string(), permissions: z.string() }),\n})\n  .andThen({\n    id: \"check-initial-plan\",\n    execute: async (data, state) => {\n      const userId = state.userId;\n      const plan = state.userContext.get(\"plan\");\n\n      console.log(`Step 1: User ${userId} is on the ${plan} plan.`);\n\n      // Modify userContext for subsequent steps\n      if (plan === \"premium\") {\n        state.userContext.set(\"permissions\", \"unlimited\");\n        console.log(`Step 1: Granted 'unlimited' permissions.`);\n      }\n\n      return data; // Pass the original data through\n    },\n  })\n  .andThen({\n    id: \"use-modified-state\",\n    execute: async (data, state) => {\n      const permissions = state.userContext.get(\"permissions\");\n      console.log(`Step 2: User now has '${permissions}' permissions.`);\n\n      // Return the final result\n      return {\n        greeting: `Hello, ${data.name}!`,\n        permissions: permissions as string,\n      };\n    },\n  });\n\n// Run it with an initial state\nawait workflow.run(\n  { name: \"Alex\" },\n  {\n    userId: \"user-alex-789\",\n    userContext: new Map([[\"plan\", \"premium\"]]),\n  }\n);\n\n// Console Output:\n// Step 1: User user-alex-789 is on the premium plan.\n// Step 1: Granted 'unlimited' permissions.\n// Step 2: User now has 'unlimited' permissions.\n\n```\n\n### Using State with AI Agents [â€‹](https://voltagent.dev/docs/workflows/overview/\\#using-state-with-ai-agents \"Direct link to Using State with AI Agents\")\n\nThe execution state is particularly powerful when used with `andAgent`. VoltAgent automatically uses the `userId` and `conversationId` from the state to scope the agent's memory.\n\nThis allows the agent to maintain a persistent, contextual conversation with each user, remembering past interactions within the same conversation without any extra configuration.\n\n```codeBlockLines_e6Vv\n// ... inside a workflow chain\n.andAgent(\n  (data) => `Based on our previous discussion, what should we do next?`,\n  agent,\n  {\n    schema: z.object({ nextStep: z.string() }),\n  }\n)\n// The `userId` and `conversationId` from the run state are automatically\n// used by the agent's memory to provide context-aware responses.\n\n```\n\n### Workflow History & Observability [â€‹](https://voltagent.dev/docs/workflows/overview/\\#workflow-history--observability \"Direct link to Workflow History & Observability\")\n\n![VoltOps Workflow Observability](https://cdn.voltagent.dev/docs/workflow-observability-demo.gif)\n\nOne of the most powerful features of VoltAgent is its built-in observability layer. Every workflow automatically records its execution history, a detailed trace of every step, its inputs, outputs, status, and timing. This history is crucial for debugging and can be visualized in real-time using the [**VoltOps Console**](https://console.voltagent.dev/).\n\nThis execution history is stored using a **memory provider**. By default, VoltAgent uses a file-based `LibSQL` database ( `memory.db` in your project's root).\n\nThe `memory` property in the `createWorkflowChain` configuration allows you to **override this default storage mechanism**. This is useful when moving to production or if you want to use a different storage solution.\nw\nYou can use several providers to store workflow history:\n\n- **Built-in Providers** (from `@voltagent/core`):\n\n  - `LibSQLStorage`: The default provider, which uses a file-based SQLite database ( `memory.db`).\n  - `InMemoryStorage`: A non-persistent store, ideal for tests where history does not need to be saved.\n- **External Packages**:\n\n  - `@voltagent/postgres`: Provides `PostgresStorage` for production environments.\n  - `@voltagent/supabase`: Provides `SupabaseStorage` for Supabase integration.\n\n```codeBlockLines_e6Vv\nimport { createWorkflowChain } from \"@voltagent/core\";\nimport { z } from \"zod\";\nimport { PostgresStorage } from \"@voltagent/postgres\";\n\n// Example of overriding the default history storage for production\nconst workflow = createWorkflowChain({\n  id: \"production-workflow\",\n  name: \"Production Workflow\",\n  input: z.object({ id: z.string() }),\n  result: z.object({ success: z.boolean() }),\n  // Store workflow run history in a PostgreSQL database\n  memory: new PostgresStorage({ connectionString: process.env.DATABASE_URL }),\n}).andThen(/*... your steps ...*/);\n\n```\n\n> **Important Distinction:** The workflow's `memory` property is for storing **execution history** (the trace of the run). It is separate from an **Agent's conversational memory**, which is configured on the Agent instance itself and allows it to remember past conversations.\n\n### Registering Workflows for Observability [â€‹](https://voltagent.dev/docs/workflows/overview/\\#registering-workflows-for-observability \"Direct link to Registering Workflows for Observability\")\n\nStoring a workflow's history is the first step. To make that history visible in an observability tool like **VoltOps**, you need to register your workflow with a central `VoltAgent` instance.\n\nThis is typically done in your application's main entry point. By passing your workflow objects to the `workflows` property of the `VoltAgent` constructor, you make them discoverable. Once registered, you can:\n\n1. Run your local application.\n2. Open the [**VoltOps Console**](https://console.voltagent.dev/).\n3. Find your workflow listed by its name (e.g., \"my-workflow\").\n4. Click on it to see a detailed, visual trace of every run.\n\n```codeBlockLines_e6Vv\nimport { VoltAgent, createWorkflowChain } from \"@voltagent/core\";\n// ... other imports\n// ... (define myWorkflow and anotherWorkflow using createWorkflowChain)\n\n// 3. Register them with the VoltAgent instance\nnew VoltAgent({\n  agents: { myAgent },\n  workflows: {\n    myWorkflow,\n    anotherWorkflow,\n  },\n});\n\n// After running the workflows, their execution traces will be visible in your VoltOps dashboard.\n\n```\n\nThis registration step is what connects your locally executed workflows to the broader observability layer, allowing you to monitor, debug, and manage them from a central location.\n\n### Executing Workflows via REST API [â€‹](https://voltagent.dev/docs/workflows/overview/\\#executing-workflows-via-rest-api \"Direct link to Executing Workflows via REST API\")\n\nOnce your workflows are registered with VoltAgent, they can also be executed through the REST API. This is useful for triggering workflows from web applications, mobile apps, or any external system.\n\n**Execute Workflow Endpoint:** `POST /workflows/{id}/execute`\n\n```codeBlockLines_e6Vv\ncurl -X POST http://localhost:3141/workflows/my-workflow/execute \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"input\": {\n         \"email\": \"user@example.com\",\n         \"name\": \"John Doe\"\n       },\n       \"options\": {\n         \"userId\": \"user-123\",\n         \"conversationId\": \"conv-456\"\n       }\n     }'\n\n```\n\n**Response:**\n\n```codeBlockLines_e6Vv\n{\n  \"success\": true,\n  \"data\": {\n    \"executionId\": \"exec_1234567890_abc123\",\n    \"startAt\": \"2024-01-15T10:00:00.000Z\",\n    \"endAt\": \"2024-01-15T10:00:05.123Z\",\n    \"status\": \"completed\",\n    \"result\": {\n      \"userId\": \"usr_generated_123\",\n      \"welcome\": \"Welcome John!\"\n    }\n  }\n}\n\n```\n\nThe workflow can also suspend during execution and be resumed later. For detailed information about suspending and resuming workflows via REST API, see the [Suspend & Resume documentation](https://voltagent.dev/docs/workflows/suspend-resume/#rest-api-usage).\n\n## Workflow Hooks [â€‹](https://voltagent.dev/docs/workflows/overview/\\#workflow-hooks \"Direct link to Workflow Hooks\")\n\nWorkflows provide hooks that allow you to tap into the lifecycle of a workflow run. You can execute custom logic at key points, such as before and after a step or at the beginning and end of the entire workflow. This is useful for logging, metrics, or any other side effects you want to perform.\n\n| Hook | Trigger |\n| --- | --- |\n| `onStart` | Before the workflow begins execution. |\n| `onEnd` | After the workflow finishes (success or error). |\n| `onStepStart` | Before each individual step starts. |\n| `onStepEnd` | After each individual step completes. |\n\nFor more details, see the [Workflow Hooks](https://voltagent.dev/docs/workflows/hooks/) documentation.\n\n## Core Step Types [â€‹](https://voltagent.dev/docs/workflows/overview/\\#core-step-types \"Direct link to Core Step Types\")\n\n| Step | Purpose | Example Use Case |\n| --- | --- | --- |\n| **`andThen`** | Execute any TypeScript function | Data processing, API calls |\n| **`andAgent`** | Run an AI agent | Text analysis, content generation |\n| **`andWhen`** | Execute a step conditionally | Branching logic based on data |\n| **`andAll`** | Run steps in parallel (wait all) | Batch processing, multiple API calls |\n| **`andRace`** | Run steps in parallel (first wins) | Fallbacks, cache vs. API race |\n\n## Workflow Schemas [â€‹](https://voltagent.dev/docs/workflows/overview/\\#workflow-schemas \"Direct link to Workflow Schemas\")\n\nWorkflows can validate data at key points using schemas:\n\n```codeBlockLines_e6Vv\nconst workflow = createWorkflowChain({\n  id: \"user-onboarding\",\n  name: \"User Onboarding\",\n  // Validates initial input\n  input: z.object({ email: z.string().email() }),\n  // Validates final result\n  result: z.object({ userId: z.string(), welcome: z.string() }),\n  // Validates data when workflow suspends\n  suspendSchema: z.object({ waitingFor: z.string() }),\n  // Validates data when workflow resumes\n  resumeSchema: z.object({ approved: z.boolean() }),\n});\n\n```\n\nEach step can also have its own schemas that override the workflow defaults. This ensures type safety throughout your workflow.\n\n## Next Steps [â€‹](https://voltagent.dev/docs/workflows/overview/\\#next-steps \"Direct link to Next Steps\")\n\n1. **Explore the Step Types**: Dive deeper into each step, starting with [`andThen`](https://voltagent.dev/docs/workflows/steps/and-then/).\n2. **Learn about Hooks**: Understand how to use [Workflow Hooks](https://voltagent.dev/docs/workflows/hooks/) to add custom logic to your workflows.\n3. **Check out Example**: See [with-workflow](https://github.com/VoltAgent/voltagent/tree/main/examples/with-workflow) example.\n4. **REST API Integration**: Learn how to [execute, suspend, and resume workflows via REST API](https://voltagent.dev/docs/api/overview/#workflow-endpoints).\n\n### Table of Contents\n\n- [What are Workflows?](https://voltagent.dev/docs/workflows/overview/#what-are-workflows)\n- [Get Started in 2 Minutes](https://voltagent.dev/docs/workflows/overview/#get-started-in-2-minutes)\n  - [1\\. Create a Basic Workflow](https://voltagent.dev/docs/workflows/overview/#1-create-a-basic-workflow)\n  - [2\\. Add AI Intelligence](https://voltagent.dev/docs/workflows/overview/#2-add-ai-intelligence)\n  - [3\\. Add Conditional Logic](https://voltagent.dev/docs/workflows/overview/#3-add-conditional-logic)\n- [How It Works](https://voltagent.dev/docs/workflows/overview/#how-it-works)\n  - [1\\. A Chain of Steps](https://voltagent.dev/docs/workflows/overview/#1-a-chain-of-steps)\n  - [2\\. Data Flows Through the Chain](https://voltagent.dev/docs/workflows/overview/#2-data-flows-through-the-chain)\n  - [3\\. Automatic Type Safety](https://voltagent.dev/docs/workflows/overview/#3-automatic-type-safety)\n- [Builder vs. Runnable: `toWorkflow()`](https://voltagent.dev/docs/workflows/overview/#builder-vs-runnable-toworkflow)\n  - [Accessing Execution State](https://voltagent.dev/docs/workflows/overview/#accessing-execution-state)\n  - [Using State with AI Agents](https://voltagent.dev/docs/workflows/overview/#using-state-with-ai-agents)\n  - [Workflow History & Observability](https://voltagent.dev/docs/workflows/overview/#workflow-history--observability)\n  - [Registering Workflows for Observability](https://voltagent.dev/docs/workflows/overview/#registering-workflows-for-observability)\n  - [Executing Workflows via REST API](https://voltagent.dev/docs/workflows/overview/#executing-workflows-via-rest-api)\n- [Workflow Hooks](https://voltagent.dev/docs/workflows/overview/#workflow-hooks)\n- [Core Step Types](https://voltagent.dev/docs/workflows/overview/#core-step-types)\n- [Workflow Schemas](https://voltagent.dev/docs/workflows/overview/#workflow-schemas)\n- [Next Steps](https://voltagent.dev/docs/workflows/overview/#next-steps)",
      "metadata": {
        "docsearch:docusaurus_tag": "docs-default-current",
        "docusaurus_tag": "docs-default-current",
        "generator": "Docusaurus v3.1.1",
        "og:description": "Note: Workflows are in Preview",
        "viewport": "width=device-width, initial-scale=1.0",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "docsearch:language": "en",
        "title": "Overview | VoltAgent",
        "twitter:card": "summary_large_image",
        "og:url": "https://voltagent.dev/docs/workflows/overview/",
        "og:title": "Overview | VoltAgent",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "ogLocale": "en",
        "docusaurus_locale": "en",
        "docsearch:version": "current",
        "og:locale": "en",
        "ogUrl": "https://voltagent.dev/docs/workflows/overview/",
        "ogTitle": "Overview | VoltAgent",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "language": "en",
        "ogDescription": "Note: Workflows are in Preview",
        "og:image": "https://voltagent.dev/img/social3.png",
        "docusaurus_version": "current",
        "description": "Note: Workflows are in Preview",
        "scrapeId": "ef48277e-e8a7-4b84-bd4b-66563706a544",
        "sourceURL": "https://voltagent.dev/docs/workflows/overview/",
        "url": "https://voltagent.dev/docs/workflows/overview/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:46.329Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/evals/overview/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Evals Overview\n\nEvaluation (evals) helps you measure and improve your AI agent's performance. VoltAgent uses [**Viteval**](https://github.com/viteval/viteval) as its official evaluation framework, providing a simple yet powerful way to test your agents.\n\n## Why Evals Matter [â€‹](https://voltagent.dev/docs/evals/overview/\\#why-evals-matter \"Direct link to Why Evals Matter\")\n\nWithout evaluation, you're building agents blindfolded. Evals help you:\n\n- **Ensure Quality**: Catch issues before users do\n- **Track Performance**: See if changes improve or break your agent\n- **Build Confidence**: Know your agent works as expected\n- **Meet Standards**: Validate safety and accuracy requirements\n\n## What Gets Evaluated [â€‹](https://voltagent.dev/docs/evals/overview/\\#what-gets-evaluated \"Direct link to What Gets Evaluated\")\n\n### Agent Responses [â€‹](https://voltagent.dev/docs/evals/overview/\\#agent-responses \"Direct link to Agent Responses\")\n\n- **Accuracy**: Are the facts correct?\n- **Relevance**: Does it answer the question?\n- **Helpfulness**: Is it useful to the user?\n- **Safety**: No harmful or inappropriate content?\n\n### Agent Behavior [â€‹](https://voltagent.dev/docs/evals/overview/\\#agent-behavior \"Direct link to Agent Behavior\")\n\n- **Tool Usage**: Does it use the right tools correctly?\n- **Following Instructions**: Does it stick to its role?\n- **Consistency**: Similar inputs get similar outputs?\n\n## Viteval Integration [â€‹](https://voltagent.dev/docs/evals/overview/\\#viteval-integration \"Direct link to Viteval Integration\")\n\nVoltAgent works seamlessly with Viteval:\n\n```codeBlockLines_e6Vv\n// In your agent file (e.g., src/agents/support.ts)\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nexport const supportAgent = new Agent({\n  name: \"Support Agent\",\n  instructions: \"Help customers with their questions\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n});\n\n// In your eval file (e.g., src/agents/support.eval.ts)\nimport { evaluate, scorers } from \"viteval\";\nimport { supportAgent } from \"./support\";\nimport supportDataset from \"./support.dataset\";\n\nevaluate(\"Support Agent\", {\n  description: \"Evaluates customer support capabilities\",\n  data: supportDataset,\n  task: async ({ input }) => {\n    const result = await supportAgent.generateText(input);\n    return result.text;\n  },\n  scorers: [scorers.answerCorrectness, scorers.answerRelevancy],\n  threshold: 0.7,\n});\n\n```\n\n## Getting Started [â€‹](https://voltagent.dev/docs/evals/overview/\\#getting-started \"Direct link to Getting Started\")\n\nReady to start evaluating? Our [Quick Start Guide](https://voltagent.dev/docs/evals/quick-start/) will have you running evals in minutes.\n\n## Learn More [â€‹](https://voltagent.dev/docs/evals/overview/\\#learn-more \"Direct link to Learn More\")\n\n- [**Quick Start**](https://voltagent.dev/docs/evals/quick-start/): Your first evaluation in 5 minutes\n- [**Viteval Concepts**](https://viteval.dev/guide/concepts?ref=voltagent): Understanding Viteval concepts\n- [**Viteval Scorers**](https://viteval.dev/api/scorers?ref=voltagent): Understanding evaluation metrics\n\n### Table of Contents\n\n- [Why Evals Matter](https://voltagent.dev/docs/evals/overview/#why-evals-matter)\n- [What Gets Evaluated](https://voltagent.dev/docs/evals/overview/#what-gets-evaluated)\n  - [Agent Responses](https://voltagent.dev/docs/evals/overview/#agent-responses)\n  - [Agent Behavior](https://voltagent.dev/docs/evals/overview/#agent-behavior)\n- [Viteval Integration](https://voltagent.dev/docs/evals/overview/#viteval-integration)\n- [Getting Started](https://voltagent.dev/docs/evals/overview/#getting-started)\n- [Learn More](https://voltagent.dev/docs/evals/overview/#learn-more)",
      "metadata": {
        "ogDescription": "Evaluation (evals) helps you measure and improve your AI agent's performance. VoltAgent uses Viteval as its official evaluation framework, providing a simple yet powerful way to test your agents.",
        "og:url": "https://voltagent.dev/docs/evals/overview/",
        "ogUrl": "https://voltagent.dev/docs/evals/overview/",
        "title": "Overview | VoltAgent",
        "docusaurus_tag": "docs-default-current",
        "docsearch:language": "en",
        "og:title": "Overview | VoltAgent",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "docsearch:docusaurus_tag": "docs-default-current",
        "twitter:card": "summary_large_image",
        "og:locale": "en",
        "description": "Evaluation (evals) helps you measure and improve your AI agent's performance. VoltAgent uses Viteval as its official evaluation framework, providing a simple yet powerful way to test your agents.",
        "language": "en",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "generator": "Docusaurus v3.1.1",
        "og:image": "https://voltagent.dev/img/social3.png",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_locale": "en",
        "ogLocale": "en",
        "docusaurus_version": "current",
        "docsearch:version": "current",
        "og:description": "Evaluation (evals) helps you measure and improve your AI agent's performance. VoltAgent uses Viteval as its official evaluation framework, providing a simple yet powerful way to test your agents.",
        "ogTitle": "Overview | VoltAgent",
        "scrapeId": "abeccc36-ad6a-47f4-8cf3-42d148779d67",
        "sourceURL": "https://voltagent.dev/docs/evals/overview/",
        "url": "https://voltagent.dev/docs/evals/overview/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:30.202Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/agents/memory/postgres/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# PostgreSQL Memory\n\nThe `@voltagent/postgres` package provides a `PostgresStorage` provider that uses PostgreSQL for persistent storage of agent memory.\n\nThis is ideal for production applications requiring enterprise-grade database storage, complex queries, or integration with existing PostgreSQL infrastructure.\n\n## Setup [â€‹](https://voltagent.dev/docs/agents/memory/postgres/\\#setup \"Direct link to Setup\")\n\n### Install Package [â€‹](https://voltagent.dev/docs/agents/memory/postgres/\\#install-package \"Direct link to Install Package\")\n\nFirst, install the necessary packages:\n\n- npm\n- yarn\n- pnpm\n\n```codeBlockLines_e6Vv\nnpm install @voltagent/postgres\n\n```\n\n### Database Requirements [â€‹](https://voltagent.dev/docs/agents/memory/postgres/\\#database-requirements \"Direct link to Database Requirements\")\n\nYou need a PostgreSQL server (version 12 or higher recommended). The provider **automatically creates** all necessary tables and indexes when initialized, so no manual SQL setup is required.\n\n### Credentials [â€‹](https://voltagent.dev/docs/agents/memory/postgres/\\#credentials \"Direct link to Credentials\")\n\nYou'll need your PostgreSQL connection details:\n\n- **Host:** Your PostgreSQL server hostname\n- **Port:** Usually 5432\n- **Database:** Database name\n- **User:** Database username\n- **Password:** Database password\n\nStore these credentials securely, typically as environment variables or use a connection string format.\n\n## Configuration [â€‹](https://voltagent.dev/docs/agents/memory/postgres/\\#configuration \"Direct link to Configuration\")\n\nImport `PostgresStorage` and initialize it with your credentials:\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { PostgresStorage } from \"@voltagent/postgres\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Using connection string (recommended)\nconst memory = new PostgresStorage({\n  connection: process.env.DATABASE_URL || \"postgresql://postgres:password@localhost:5432/mydb\",\n  // Optional: Adjust connection pool size\n  maxConnections: 10,\n  // Optional: Specify a custom base table name prefix\n  tablePrefix: \"voltagent_memory\", // Defaults to 'voltagent_memory'\n  // Optional: Storage limit (max number of messages per user/conversation)\n  storageLimit: 100, // Defaults to 100\n});\n\n// Alternative: Using connection object\nconst memory = new PostgresStorage({\n  connection: {\n    host: process.env.DB_HOST || \"localhost\",\n    port: parseInt(process.env.DB_PORT || \"5432\"),\n    database: process.env.DB_NAME || \"mydb\",\n    user: process.env.DB_USER || \"postgres\",\n    password: process.env.DB_PASSWORD,\n    ssl: process.env.NODE_ENV === \"production\", // Enable SSL for production\n  },\n  maxConnections: 10,\n  tablePrefix: \"voltagent_memory\",\n  storageLimit: 100,\n});\n\nconst agent = new Agent({\n  name: \"PostgreSQL Memory Agent\",\n  instructions: \"An agent using PostgreSQL for memory.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  memory: memory, // Assign the memory provider instance\n});\n\n```\n\n**Configuration Options:**\n\n- `connection` (string or object, required): Database connection details.\n\n  - **Connection string:** `\"postgresql://user:password@host:port/database\"`\n  - **Connection object:** `{ host, port, database, user, password, ssl }`\n- `maxConnections` (number, optional): Maximum connections in the pool. Defaults to `10`.\n- `tablePrefix` (string, optional): Prefix for database table names. Defaults to `voltagent_memory`.\n- `storageLimit` (number, optional): Maximum messages to retain per conversation. Defaults to `100`.\n- `debug` (boolean, optional): Enable debug logging. Defaults to `false`.\n\n## Conversation Management [â€‹](https://voltagent.dev/docs/agents/memory/postgres/\\#conversation-management \"Direct link to Conversation Management\")\n\n### Get User's Conversations [â€‹](https://voltagent.dev/docs/agents/memory/postgres/\\#get-users-conversations \"Direct link to Get User's Conversations\")\n\n```codeBlockLines_e6Vv\n// Get recent conversations for a user\nconst conversations = await storage.getConversationsByUserId(\"user-123\", {\n  limit: 50,\n  orderBy: \"updated_at\",\n  orderDirection: \"DESC\",\n});\n\n// Display in sidebar like ChatGPT\nconversations.forEach((conv) => {\n  console.log(`${conv.title} - ${conv.updatedAt}`);\n});\n\n```\n\n### Advanced Query Builder [â€‹](https://voltagent.dev/docs/agents/memory/postgres/\\#advanced-query-builder \"Direct link to Advanced Query Builder\")\n\n```codeBlockLines_e6Vv\n// Fluent query interface\nconst recentChats = await storage\n  .getUserConversations(\"user-123\")\n  .limit(20)\n  .orderBy(\"updated_at\", \"DESC\")\n  .execute();\n\n// Get paginated conversations\nconst page1 = await storage.getPaginatedUserConversations(\"user-123\", 1, 10);\nconsole.log(`Page 1 of ${page1.hasMore ? \"many\" : page1.conversations.length}`);\n\n```\n\n## Querying Conversations [â€‹](https://voltagent.dev/docs/agents/memory/postgres/\\#querying-conversations \"Direct link to Querying Conversations\")\n\nThe PostgreSQL storage provides powerful conversation querying capabilities with filtering, pagination, and sorting options:\n\n```codeBlockLines_e6Vv\n// Query with multiple filters\nconst workConversations = await storage.queryConversations({\n  userId: \"user-123\",\n  resourceId: \"work-agent\",\n  limit: 25,\n  offset: 0,\n  orderBy: \"created_at\",\n  orderDirection: \"DESC\",\n});\n\n// Get all conversations for a user\nconst userConversations = await storage.queryConversations({\n  userId: \"user-123\",\n  limit: 50,\n});\n\n// Get conversations for a specific resource\nconst resourceConversations = await storage.queryConversations({\n  resourceId: \"chatbot-v1\",\n  limit: 100,\n  orderBy: \"updated_at\",\n});\n\n// Admin view - get all conversations\nconst allConversations = await storage.queryConversations({\n  limit: 200,\n  orderBy: \"created_at\",\n  orderDirection: \"ASC\",\n});\n\n```\n\n**Query Options:**\n\n- `userId` (optional): Filter conversations by specific user\n- `resourceId` (optional): Filter conversations by specific resource\n- `limit` (optional): Maximum number of conversations to return (default: 50)\n- `offset` (optional): Number of conversations to skip for pagination (default: 0)\n- `orderBy` (optional): Field to sort by: 'created\\_at', 'updated\\_at', or 'title' (default: 'updated\\_at')\n- `orderDirection` (optional): Sort direction: 'ASC' or 'DESC' (default: 'DESC')\n\n## Getting Conversation Messages [â€‹](https://voltagent.dev/docs/agents/memory/postgres/\\#getting-conversation-messages \"Direct link to Getting Conversation Messages\")\n\nRetrieve messages for a specific conversation with pagination support:\n\n```codeBlockLines_e6Vv\n// Get all messages for a conversation\nconst messages = await storage.getConversationMessages(\"conversation-456\");\n\n// Get messages with pagination\nconst firstBatch = await storage.getConversationMessages(\"conversation-456\", {\n  limit: 50,\n  offset: 0,\n});\n\n// Get next batch\nconst nextBatch = await storage.getConversationMessages(\"conversation-456\", {\n  limit: 50,\n  offset: 50,\n});\n\n// Process messages in batches for large conversations\nconst batchSize = 100;\nlet offset = 0;\nlet hasMore = true;\n\nwhile (hasMore) {\n  const batch = await storage.getConversationMessages(\"conversation-456\", {\n    limit: batchSize,\n    offset: offset,\n  });\n\n  // Process batch\n  processBatch(batch);\n\n  hasMore = batch.length === batchSize;\n  offset += batchSize;\n}\n\n```\n\n**Message Query Options:**\n\n- `limit` (optional): Maximum number of messages to return (default: 100)\n- `offset` (optional): Number of messages to skip for pagination (default: 0)\n\nMessages are returned in chronological order (oldest first) for natural conversation flow.\n\n## Automatic Table Creation [â€‹](https://voltagent.dev/docs/agents/memory/postgres/\\#automatic-table-creation \"Direct link to Automatic Table Creation\")\n\nUnlike manual database setup, `PostgresStorage` **automatically creates** the necessary tables ( `messages`, `conversations`, `agent_history`, `agent_history_steps`, `agent_history_timeline_events`, with the configured `tablePrefix`) and indexes in your PostgreSQL database if they don't already exist. This simplifies setup for both development and production.\n\n## Production Considerations [â€‹](https://voltagent.dev/docs/agents/memory/postgres/\\#production-considerations \"Direct link to Production Considerations\")\n\nFor production applications, consider:\n\n- **SSL Connections:** Enable SSL by setting `ssl: true` in your connection configuration.\n- **Connection Pooling:** Adjust `maxConnections` based on your application's concurrent usage.\n- **Environment Variables:** Store database credentials securely using environment variables.\n- **Database Backups:** Implement regular backup strategies for your PostgreSQL database.\n\n## Use Cases [â€‹](https://voltagent.dev/docs/agents/memory/postgres/\\#use-cases \"Direct link to Use Cases\")\n\n- **Production Applications:** Enterprise-grade applications requiring robust, scalable database storage.\n- **Existing PostgreSQL Infrastructure:** Applications already using PostgreSQL for other data.\n- **Complex Queries:** Scenarios requiring advanced SQL capabilities or data analytics.\n- **High Availability:** Applications requiring database replication and failover capabilities.\n- **Team Collaboration:** Multi-user applications where conversation data needs to be shared or analyzed.\n\n## Error Handling [â€‹](https://voltagent.dev/docs/agents/memory/postgres/\\#error-handling \"Direct link to Error Handling\")\n\n```codeBlockLines_e6Vv\ntry {\n  await storage.addMessage(message, userId, conversationId);\n} catch (error) {\n  if (error.message.includes(\"foreign key constraint\")) {\n    console.error(\"Conversation does not exist\");\n  } else {\n    console.error(\"Database error:\", error);\n  }\n}\n\n```\n\n### Table of Contents\n\n- [Setup](https://voltagent.dev/docs/agents/memory/postgres/#setup)\n  - [Install Package](https://voltagent.dev/docs/agents/memory/postgres/#install-package)\n  - [Database Requirements](https://voltagent.dev/docs/agents/memory/postgres/#database-requirements)\n  - [Credentials](https://voltagent.dev/docs/agents/memory/postgres/#credentials)\n- [Configuration](https://voltagent.dev/docs/agents/memory/postgres/#configuration)\n- [Conversation Management](https://voltagent.dev/docs/agents/memory/postgres/#conversation-management)\n  - [Get User's Conversations](https://voltagent.dev/docs/agents/memory/postgres/#get-users-conversations)\n  - [Advanced Query Builder](https://voltagent.dev/docs/agents/memory/postgres/#advanced-query-builder)\n- [Querying Conversations](https://voltagent.dev/docs/agents/memory/postgres/#querying-conversations)\n- [Getting Conversation Messages](https://voltagent.dev/docs/agents/memory/postgres/#getting-conversation-messages)\n- [Automatic Table Creation](https://voltagent.dev/docs/agents/memory/postgres/#automatic-table-creation)\n- [Production Considerations](https://voltagent.dev/docs/agents/memory/postgres/#production-considerations)\n- [Use Cases](https://voltagent.dev/docs/agents/memory/postgres/#use-cases)\n- [Error Handling](https://voltagent.dev/docs/agents/memory/postgres/#error-handling)",
      "metadata": {
        "og:description": "The @voltagent/postgres package provides a PostgresStorage provider that uses PostgreSQL for persistent storage of agent memory.",
        "docsearch:language": "en",
        "docusaurus_locale": "en",
        "generator": "Docusaurus v3.1.1",
        "og:locale": "en",
        "og:url": "https://voltagent.dev/docs/agents/memory/postgres/",
        "twitter:card": "summary_large_image",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_version": "current",
        "docsearch:version": "current",
        "language": "en",
        "title": "PostgreSQL Memory | VoltAgent",
        "ogLocale": "en",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:title": "PostgreSQL Memory | VoltAgent",
        "description": "The @voltagent/postgres package provides a PostgresStorage provider that uses PostgreSQL for persistent storage of agent memory.",
        "docusaurus_tag": "docs-default-current",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "ogDescription": "The @voltagent/postgres package provides a PostgresStorage provider that uses PostgreSQL for persistent storage of agent memory.",
        "ogUrl": "https://voltagent.dev/docs/agents/memory/postgres/",
        "og:image": "https://voltagent.dev/img/social3.png",
        "ogTitle": "PostgreSQL Memory | VoltAgent",
        "scrapeId": "c0c5fc2b-75f0-48e6-9367-6c7b944d5318",
        "sourceURL": "https://voltagent.dev/docs/agents/memory/postgres/",
        "url": "https://voltagent.dev/docs/agents/memory/postgres/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:26.187Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/tools/overview/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Tools & Toolkits\n\nVoltAgent allows you to extend the capabilities of your AI agents by providing them with **Tools**. Tools enable agents to interact with external APIs, perform calculations, access databases, or execute virtually any custom code. This guide covers how to define and use individual tools and the new `Toolkit` concept for managing related tools.\n\n## Defining a Single Tool [â€‹](https://voltagent.dev/docs/tools/overview/\\#defining-a-single-tool \"Direct link to Defining a Single Tool\")\n\nThe most basic way to define a tool is using the `createTool` helper function (or instantiating the `Tool` class directly).\n\nA tool requires:\n\n- `name`: A unique name for the tool (used by the LLM to call it).\n- `description`: A clear description of what the tool does (used by the LLM to decide when to use it).\n- `parameters`: A Zod schema defining the input arguments the tool expects.\n- `execute`: An asynchronous function that contains the tool's logic, taking the validated arguments as input.\n- `outputSchema` (optional): A Zod schema defining the expected output format. When provided, the tool's output will be validated against this schema.\n\n```codeBlockLines_e6Vv\nimport { Agent, createTool } from \"@voltagent/core\";\nimport { z } from \"zod\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Define a simple weather tool\nconst getWeatherTool = createTool({\n  name: \"get_weather\",\n  description: \"Fetches the current weather for a given location.\",\n  parameters: z.object({\n    location: z.string().describe(\"The city and state, e.g., San Francisco, CA\"),\n  }),\n  execute: async ({ location }) => {\n    // In a real scenario, you would call a weather API here\n    console.log(`Fetching weather for ${location}...`);\n    if (location.toLowerCase().includes(\"tokyo\")) {\n      return { temperature: \"15Â°C\", condition: \"Cloudy\" };\n    }\n    return { temperature: \"22Â°C\", condition: \"Sunny\" };\n  },\n});\n\nconst agent = new Agent({\n  name: \"WeatherAgent\",\n  instructions: \"An agent that can fetch weather information.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  tools: [getWeatherTool], // Add the tool to the agent\n});\n\n// Now the agent can use the 'get_weather' tool when asked about weather.\n\n```\n\n## Tool Output Schema Validation [â€‹](https://voltagent.dev/docs/tools/overview/\\#tool-output-schema-validation \"Direct link to Tool Output Schema Validation\")\n\nVoltAgent supports optional output schema validation for tools. This feature ensures that tool outputs conform to a predefined structure, providing several benefits:\n\n- **Type Safety**: Tool outputs are typed based on the schema\n- **Runtime Validation**: Invalid outputs are caught immediately\n- **Error Recovery**: When validation fails, the LLM receives an error message and can retry with corrected output\n- **Consistency**: All tool responses follow the same structure\n- **Documentation**: Output schemas serve as API contracts\n\n### Example with Output Schema [â€‹](https://voltagent.dev/docs/tools/overview/\\#example-with-output-schema \"Direct link to Example with Output Schema\")\n\n```codeBlockLines_e6Vv\nimport { createTool } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\n// Define the output schema\nconst weatherOutputSchema = z.object({\n  location: z.string(),\n  temperature: z.number(),\n  condition: z.enum([\"sunny\", \"cloudy\", \"rainy\", \"snowy\"]),\n  humidity: z.number().min(0).max(100),\n  forecast: z.object({\n    high: z.number(),\n    low: z.number(),\n    description: z.string(),\n  }),\n});\n\n// Create a tool with output validation\nconst weatherTool = createTool({\n  name: \"get_weather\",\n  description: \"Get current weather with forecast\",\n  parameters: z.object({\n    location: z.string().describe(\"City name\"),\n  }),\n  outputSchema: weatherOutputSchema, // Optional output schema\n  execute: async ({ location }) => {\n    // This output will be validated against weatherOutputSchema\n    return {\n      location,\n      temperature: 22,\n      condition: \"sunny\",\n      humidity: 65,\n      forecast: {\n        high: 25,\n        low: 18,\n        description: \"Clear skies throughout the day\",\n      },\n    };\n  },\n});\n\n```\n\n### How Output Validation Works [â€‹](https://voltagent.dev/docs/tools/overview/\\#how-output-validation-works \"Direct link to How Output Validation Works\")\n\n1. When a tool is executed, its output is validated against the `outputSchema` if provided\n2. If validation succeeds, the validated output is returned\n3. If validation fails, an error object is returned to the LLM:\n\n\n\n\n\n```codeBlockLines_e6Vv\n{\n     \"error\": true,\n     \"message\": \"Output validation failed: Expected number, received string\",\n     \"validationErrors\": [...],\n     \"actualOutput\": {...}\n}\n\n```\n\n4. The LLM can see the validation error and potentially fix the issue by calling the tool again\n\n### Best Practices [â€‹](https://voltagent.dev/docs/tools/overview/\\#best-practices \"Direct link to Best Practices\")\n\n- Use output schemas for tools that need consistent response formats\n- Keep schemas focused and avoid overly complex nested structures\n- Use descriptive error messages in your schemas with `.describe()`\n- Consider making some fields optional with `.optional()` for flexibility\n- Output schemas are completely optional - tools without them work as before\n\n## Grouping Tools with Toolkits [â€‹](https://voltagent.dev/docs/tools/overview/\\#grouping-tools-with-toolkits \"Direct link to Grouping Tools with Toolkits\")\n\nOften, several tools work together logically. For instance, tools for step-by-step reasoning ( `think`, `analyze`) or a set of tools interacting with the same API. For these scenarios, VoltAgent provides **Toolkits**.\n\nA `Toolkit` allows you to:\n\n1. **Group related tools:** Keep your tool management organized.\n2. **Define shared instructions:** Provide common guidance to the LLM on how to use all tools within the toolkit.\n3. **Control instruction injection:** Decide if the toolkit's shared instructions should be automatically added to the agent's system prompt.\n\n### Defining a Toolkit [â€‹](https://voltagent.dev/docs/tools/overview/\\#defining-a-toolkit \"Direct link to Defining a Toolkit\")\n\nA `Toolkit` is an object with the following structure:\n\n```codeBlockLines_e6Vv\nimport { createTool, createToolkit, type Tool, type Toolkit } from \"@voltagent/core\";\n\nconst myCalculatorToolkit = createToolkit({\n  name: \"calculator_toolkit\",\n  description: \"Tools for performing basic arithmetic operations.\",\n  // Optional instructions for the LLM\n  instructions: `Use these tools for calculations. Always use 'add' for addition, 'subtract' for subtraction.`,\n  // Set to true to add the above instructions to the system prompt\n  addInstructions: true,\n  tools: [\\\n    createTool({\\\n      /* ... definition for 'add' tool ... */\\\n    }),\\\n    createTool({\\\n      /* ... definition for 'subtract' tool ... */\\\n    }),\\\n    // ... other calculator tools\\\n  ],\n});\n\n```\n\n**Important:** With the introduction of Toolkits, individual `Tool` instances no longer have their own `instructions` or `addInstructions` properties. Instructions are managed at the Toolkit level.\n\n### Adding Tools and Toolkits to an Agent [â€‹](https://voltagent.dev/docs/tools/overview/\\#adding-tools-and-toolkits-to-an-agent \"Direct link to Adding Tools and Toolkits to an Agent\")\n\nThe `tools` option in the `Agent` constructor now accepts an array containing both individual `Tool` objects and `Toolkit` objects. The `ToolManager` handles both seamlessly.\n\n```codeBlockLines_e6Vv\nimport { Agent, createTool, createToolkit, type Toolkit } from \"@voltagent/core\";\n// ... import other tools and toolkits ...\n\nconst agent = new Agent({\n    name: \"MultiToolAgent\",\n    instructions: \"An agent with various tools and toolkits.\",\n    llm: /* ... */,\n    model: /* ... */,\n    tools: [\\\n        getWeatherTool,      // Add an individual tool\\\n        myCalculatorToolkit, // Add a toolkit\\\n        // ... other tools or toolkits\\\n    ],\n});\n\n```\n\n### Automatic Instructions [â€‹](https://voltagent.dev/docs/tools/overview/\\#automatic-instructions \"Direct link to Automatic Instructions\")\n\nWhen an agent is initialized, its `getSystemMessage` method checks all the `Toolkit` s provided in the `tools` array. If a `Toolkit` has `addInstructions: true` and defines an `instructions` string, those instructions will be automatically appended to the agent's base description, forming part of the final system prompt sent to the LLM.\n\n## Next Steps [â€‹](https://voltagent.dev/docs/tools/overview/\\#next-steps \"Direct link to Next Steps\")\n\n- See the [Reasoning Tools](https://voltagent.dev/docs/tools/reasoning-tool/) documentation for a practical example of a pre-built toolkit.\n- Explore creating your own tools to connect agents to your specific data sources and APIs.\n\n### Table of Contents\n\n- [Defining a Single Tool](https://voltagent.dev/docs/tools/overview/#defining-a-single-tool)\n- [Tool Output Schema Validation](https://voltagent.dev/docs/tools/overview/#tool-output-schema-validation)\n  - [Example with Output Schema](https://voltagent.dev/docs/tools/overview/#example-with-output-schema)\n  - [How Output Validation Works](https://voltagent.dev/docs/tools/overview/#how-output-validation-works)\n  - [Best Practices](https://voltagent.dev/docs/tools/overview/#best-practices)\n- [Grouping Tools with Toolkits](https://voltagent.dev/docs/tools/overview/#grouping-tools-with-toolkits)\n  - [Defining a Toolkit](https://voltagent.dev/docs/tools/overview/#defining-a-toolkit)\n  - [Adding Tools and Toolkits to an Agent](https://voltagent.dev/docs/tools/overview/#adding-tools-and-toolkits-to-an-agent)\n  - [Automatic Instructions](https://voltagent.dev/docs/tools/overview/#automatic-instructions)\n- [Next Steps](https://voltagent.dev/docs/tools/overview/#next-steps)",
      "metadata": {
        "ogLocale": "en",
        "docusaurus_locale": "en",
        "viewport": "width=device-width, initial-scale=1.0",
        "ogUrl": "https://voltagent.dev/docs/tools/overview/",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "title": "Overview | VoltAgent",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "generator": "Docusaurus v3.1.1",
        "ogDescription": "VoltAgent allows you to extend the capabilities of your AI agents by providing them with Tools. Tools enable agents to interact with external APIs, perform calculations, access databases, or execute virtually any custom code. This guide covers how to define and use individual tools and the new Toolkit concept for managing related tools.",
        "og:locale": "en",
        "ogTitle": "Overview | VoltAgent",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "docsearch:language": "en",
        "docusaurus_version": "current",
        "docusaurus_tag": "docs-default-current",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:image": "https://voltagent.dev/img/social3.png",
        "og:title": "Overview | VoltAgent",
        "description": "VoltAgent allows you to extend the capabilities of your AI agents by providing them with Tools. Tools enable agents to interact with external APIs, perform calculations, access databases, or execute virtually any custom code. This guide covers how to define and use individual tools and the new Toolkit concept for managing related tools.",
        "twitter:card": "summary_large_image",
        "og:description": "VoltAgent allows you to extend the capabilities of your AI agents by providing them with Tools. Tools enable agents to interact with external APIs, perform calculations, access databases, or execute virtually any custom code. This guide covers how to define and use individual tools and the new Toolkit concept for managing related tools.",
        "docsearch:version": "current",
        "og:url": "https://voltagent.dev/docs/tools/overview/",
        "language": "en",
        "scrapeId": "fe6cec64-b3a0-4954-86cf-0dcf666d6a90",
        "sourceURL": "https://voltagent.dev/docs/tools/overview/",
        "url": "https://voltagent.dev/docs/tools/overview/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:21.853Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/agents/memory/overview/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Memory Overview\n\nConversational AI agents often need to remember past interactions to maintain context, understand user preferences, and provide more coherent and personalized responses. Without memory, each interaction would be treated in isolation, leading to repetitive questions and unnatural conversations.\n\nVoltAgent incorporates a flexible memory management system that allows agents to store and retrieve information from past interactions using **Memory Providers**.\n\n## Why Use Memory? [â€‹](https://voltagent.dev/docs/agents/memory/overview/\\#why-use-memory \"Direct link to Why Use Memory?\")\n\n- **Context Preservation:** Enables agents to recall previous messages in a conversation, understanding follow-up questions and references.\n- **Personalization:** Allows agents to remember user-specific details (like name, preferences, past requests) for a tailored experience.\n- **Coherence:** Ensures conversations flow naturally without the agent constantly losing track of the topic.\n- **Long-Term State:** Can be used to store summaries or key information extracted from conversations over extended periods.\n\n## Default Memory Behavior (Zero-Config Persistence) [â€‹](https://voltagent.dev/docs/agents/memory/overview/\\#default-memory-behavior-zero-config-persistence \"Direct link to Default Memory Behavior (Zero-Config Persistence)\")\n\nBy default, VoltAgent agents use **`LibSQLStorage`** for **zero-configuration local persistence**. If you don't explicitly provide a `memory` option when creating an `Agent`, VoltAgent automatically does the following:\n\n1. Creates a `.voltagent` folder in your project root (if it doesn't exist).\n2. Initializes `LibSQLStorage` pointing to a SQLite database file at `.voltagent/memory.db`.\n3. Uses this local database to store and retrieve conversation history.\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst agent = new Agent({\n  name: \"My Assistant\",\n  instructions: \"This agent automatically uses local file memory.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  // No memory provider specified - uses default LibSQLStorage to .voltagent/memory.db\n});\n\n```\n\nThis makes it easy to get started with stateful agents locally without any manual memory setup.\n\n## Disabling Memory [â€‹](https://voltagent.dev/docs/agents/memory/overview/\\#disabling-memory \"Direct link to Disabling Memory\")\n\nYou can completely disable memory persistence and retrieval by setting the `memory` property to `false` in the `Agent` constructor:\n\n```codeBlockLines_e6Vv\nconst agent = new Agent({\n  name: \"Stateless Assistant\",\n  instructions: \"This agent has no memory.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  memory: false, // Memory completely disabled\n});\n\n```\n\nWhen memory is disabled, the agent won't store or retrieve any conversation history, making it stateless for each interaction.\n\n## Separate Conversation and History Memory [â€‹](https://voltagent.dev/docs/agents/memory/overview/\\#separate-conversation-and-history-memory \"Direct link to Separate Conversation and History Memory\")\n\n_Available as of version `0.1.56`_\n\nVoltAgent uses two types of memory internally:\n\n- **Conversation Memory**: Stores chat messages for conversation continuity (configured via the `memory` option)\n- **History Memory**: Stores execution telemetry, timeline events, and debugging information (configured via the `historyMemory` option)\n\nBy default, history memory uses the same storage instance as conversation memory. This means if you configure `InMemoryStorage` for conversations, history will also use `InMemoryStorage` automatically:\n\n```codeBlockLines_e6Vv\nimport { Agent, InMemoryStorage } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Default behavior: history automatically uses same storage as conversation\nconst agent = new Agent({\n  name: \"Serverless Assistant\",\n  instructions: \"Assistant that works in read-only environments\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o\"),\n  memory: new InMemoryStorage({ storageLimit: 100 }), // Both conversation and history use this\n  // historyMemory not specified - automatically uses same as memory\n});\n\n```\n\n**When to use separate memory configurations:**\n\n- **Serverless/Read-only environments**: Use `InMemoryStorage` for both when filesystem access is restricted\n- **Different storage requirements**: Use `InMemoryStorage` for conversation memory and `LibSQLStorage` for persistent history\n- **Compliance**: Separate user data (conversations) from system data (execution logs) for regulatory requirements\n\n```codeBlockLines_e6Vv\n// Example: In-memory for conversations, persistent for history\nimport { InMemoryStorage, LibSQLStorage } from \"@voltagent/core\";\n\nconst agent = new Agent({\n  name: \"Hybrid Memory Assistant\",\n  // ... other config ...\n  memory: new InMemoryStorage({ storageLimit: 50 }), // Fast access for conversations\n  historyMemory: new LibSQLStorage({ url: \"file:history.db\" }), // Persistent execution logs\n});\n\n```\n\n**Default behavior**: If you don't specify `historyMemory`, it uses the same storage instance as `memory`. If conversation memory is disabled ( `memory: false`), history memory defaults to `LibSQLStorage`.\n\n## Memory Providers [â€‹](https://voltagent.dev/docs/agents/memory/overview/\\#memory-providers \"Direct link to Memory Providers\")\n\nVoltAgent achieves memory persistence through swappable **Memory Providers**. These are classes that implement the `Memory` interface defined in `@voltagent/core`. They handle the actual storage and retrieval logic, allowing you to choose the backend that best suits your needs.\n\nVoltAgent includes built-in providers and supports custom implementations:\n\n- **[`LibSQLStorage`](https://voltagent.dev/docs/agents/memory/libsql/):** (Default Provider) Uses LibSQL (including Turso and local SQLite files) for persistence. Ideal for easy setup, local development, and serverless deployments compatible with SQLite.\n- **[`@voltagent/postgres`](https://voltagent.dev/docs/agents/memory/postgres/):** Uses PostgreSQL for persistence. Ideal for production applications requiring enterprise-grade database storage, complex queries, or integration with existing PostgreSQL infrastructure.\n- **[`@voltagent/supabase`](https://voltagent.dev/docs/agents/memory/supabase/):** Uses Supabase (PostgreSQL) for persistence. Suitable for applications already using Supabase or requiring a robust, scalable PostgreSQL backend.\n- **[`InMemoryStorage`](https://voltagent.dev/docs/agents/memory/in-memory/):** Stores conversation history only in the application's memory. Useful for testing, development, or stateless scenarios. Data is lost on application restart.\n- **[Custom Providers](https://voltagent.dev/docs/agents/memory/overview/#implementing-custom-memory-providers):** You can implement the `Memory` interface to connect to any database or storage system (e.g., Redis, MongoDB, DynamoDB, etc.).\n\n## How Memory Works with Agents [â€‹](https://voltagent.dev/docs/agents/memory/overview/\\#how-memory-works-with-agents \"Direct link to How Memory Works with Agents\")\n\nWhen you configure an `Agent` with a memory provider instance (or use the default), VoltAgent's internal `MemoryManager` automatically handles:\n\n1. **Retrieval:** Before generating a response (e.g., during `agent.generateText()`), the manager fetches relevant conversation history or state from the memory provider based on the provided `userId` and `conversationId`.\n2. **Injection:** This retrieved context is typically formatted and added to the prompt sent to the LLM, giving it the necessary background information.\n3. **Saving:** After an interaction completes, the new messages (user input and agent response) are saved back to the memory provider, associated with the same `userId` and `conversationId`.\n\nThis process happens seamlessly behind the scenes when using the agent's core interaction methods ( `generateText`, `streamText`, `generateObject`, `streamObject`).\n\n## User and Conversation Identification [â€‹](https://voltagent.dev/docs/agents/memory/overview/\\#user-and-conversation-identification \"Direct link to User and Conversation Identification\")\n\nTo separate conversations for different users or different chat sessions within the same application, you **must** provide `userId` and `conversationId` in the options when calling agent methods directly in your code. If you are interacting with the agent via the [Core API](https://voltagent.dev/docs/api/overview/), you can pass these same identifiers within the `options` object in your request body. See the [API examples](https://voltagent.dev/docs/api/overview/#basic-example-using-curl) for details on the API usage.\n\nWhen calling agent methods directly:\n\n```codeBlockLines_e6Vv\nconst response = await agent.generateText(\"Hello, how can you help me?\", {\n  userId: \"user-123\", // Identifies the specific user\n  conversationId: \"chat-session-xyz\", // Identifies this specific conversation thread\n});\n\n```\n\nThese identifiers work consistently across all agent generation methods ( `generateText`, `streamText`, `generateObject`, `streamObject`).\n\n### How User and Conversation IDs Work [â€‹](https://voltagent.dev/docs/agents/memory/overview/\\#how-user-and-conversation-ids-work \"Direct link to How User and Conversation IDs Work\")\n\n- **`userId`**: A unique string identifying the end-user. This ensures memory isolation between different users. If omitted, it defaults to the string `\"default\"`.\n- **`conversationId`**: A unique string identifying a specific conversation thread for a user. This allows a single user to have multiple parallel conversations.\n\n  - **If provided:** The agent retrieves and saves messages associated with this specific thread.\n  - **If omitted:** A **new random UUID is generated for each request**, effectively starting a new, separate conversation every time. This is useful for one-off tasks or ensuring a clean slate for each interaction when context isn't needed.\n\n**Key Behaviors:**\n\n1. **Context Retrieval**: Before calling the LLM, the `MemoryManager` retrieves previous messages associated with the given `userId` and `conversationId` from the memory provider.\n2. **Message Storage**: After the interaction, new user input and agent responses are stored using the same `userId` and `conversationId`.\n3. **Continuity**: Providing the same `userId` and `conversationId` across multiple requests ensures the agent remembers the context of that specific thread.\n4. **New Conversations**: Omitting `conversationId` guarantees a fresh conversation context for each request.\n\n```codeBlockLines_e6Vv\n// To start a NEW conversation each time (or for single-turn interactions):\n// Omit conversationId; a new one is generated automatically.\nconst response1 = await agent.generateText(\"Help with account setup\", { userId: \"user-123\" });\nconst response2 = await agent.generateText(\"Question about billing issue\", { userId: \"user-123\" }); // Starts another new conversation\n\n// To MAINTAIN a continuous conversation across requests:\n// Always provide the SAME conversationId.\nconst SUPPORT_THREAD_ID = \"case-987-abc\";\nconst responseA = await agent.generateText(\"My router is not working.\", {\n  userId: \"user-456\",\n  conversationId: SUPPORT_THREAD_ID,\n});\n// Agent remembers the router issue for the next call with the same ID\nconst responseB = await agent.generateText(\"I tried restarting it, still no luck.\", {\n  userId: \"user-456\",\n  conversationId: SUPPORT_THREAD_ID,\n});\n\n```\n\n## Context Management [â€‹](https://voltagent.dev/docs/agents/memory/overview/\\#context-management \"Direct link to Context Management\")\n\nWhen interacting with an agent that has memory enabled, the `MemoryManager` automatically retrieves recent messages for the given `userId` and `conversationId` and includes them as context in the prompt sent to the LLM.\n\n```codeBlockLines_e6Vv\n// The agent automatically retrieves history for user-123/chat-session-xyz\n// and includes up to N recent messages (determined by the provider/manager) in the LLM prompt.\nconst response = await agent.generateText(\"What was the first thing I asked you?\", {\n  userId: \"user-123\",\n  conversationId: \"chat-session-xyz\",\n  // contextLimit: 10, // Note: contextLimit is typically managed by MemoryOptions now\n});\n\n```\n\nHow many messages are retrieved is often determined by the `storageLimit` configured on the Memory Provider or internal logic within the `MemoryManager`. This is crucial for:\n\n1. **Coherence**: Providing the LLM with enough history to understand the ongoing conversation.\n2. **Cost/Performance**: Limiting the context size to manage LLM token usage (cost) and potentially reduce latency.\n3. **Relevance**: Ensuring the context is relevant without overwhelming the LLM with excessive or old information.\n\n## Implementing Custom Memory Providers [â€‹](https://voltagent.dev/docs/agents/memory/overview/\\#implementing-custom-memory-providers \"Direct link to Implementing Custom Memory Providers\")\n\nFor specialized storage needs (e.g., using Redis, MongoDB, a different SQL database, or applying custom logic like summarization before storage), you can implement a custom memory provider.\n\nYour custom class must implement the `Memory` interface defined in `@voltagent/core`. This typically involves providing implementations for methods handling messages, conversations, and agent history entries (like runs, events, steps).\n\nRefer to the `Memory` type definition in `@voltagent/core/memory` for the full interface details. Key methods include:\n\n**Message Management:**\n\n- `addMessage(...)`: Stores a new message.\n- `getMessages(...)`: Retrieves messages for a conversation.\n- `clearMessages(...)`: Deletes messages for a specific conversation.\n\n**Conversation Management:**\n\n- `createConversation(...)`, `getConversation(...)`, `getConversations(...)`: Basic conversation operations.\n- `getConversationsByUserId(...)`: Get conversations for a specific user with query options.\n- `queryConversations(...)`: Advanced conversation querying with filtering and pagination.\n- `getConversationMessages(...)`: Get messages for a specific conversation with pagination.\n- `updateConversation(...)`, `deleteConversation(...)`: Update and delete conversations.\n\n**Agent History Management:**\n\n- `addHistoryEntry(...)`, `updateHistoryEntry(...)`, `getHistoryEntry(...)`: Manage agent run history entries.\n- `getAllHistoryEntriesByAgent(...)`: Get all history entries for an agent.\n- `addHistoryStep(...)`, `updateHistoryStep(...)`, `getHistoryStep(...)`: Manage steps within a history entry.\n- `addTimelineEvent(...)`: Add immutable timeline events for detailed execution tracking.\n\n**Workflow History Management:**\n\n- `storeWorkflowHistory(...)`: Stores a record of a complete workflow execution.\n- `getWorkflowHistory(...)`, `getWorkflowHistoryByWorkflowId(...)`: Retrieves workflow history records.\n- `updateWorkflowHistory(...)`, `deleteWorkflowHistory(...)`: Updates and deletes workflow history records.\n- `storeWorkflowStep(...)`, `getWorkflowSteps(...)`: Stores and retrieves the individual steps of a workflow run.\n- `updateWorkflowStep(...)`, `deleteWorkflowStep(...)`: Updates and deletes individual steps.\n- `storeWorkflowTimelineEvent(...)`, `getWorkflowTimelineEvents(...)`: Stores and retrieves fine-grained timeline events for detailed workflow observability.\n\n```codeBlockLines_e6Vv\nimport type {\n  Memory,\n  MemoryMessage,\n  Conversation,\n  CreateConversationInput,\n  MessageFilterOptions,\n  NewTimelineEvent,\n  WorkflowHistoryEntry,\n  WorkflowStepHistoryEntry,\n  ConversationQueryOptions /*...other types*/,\n} from \"@voltagent/core\";\n\n// Example Structure\nexport class MyCustomStorage implements Memory {\n  private dbClient: any; // Your database client instance\n\n  constructor(/* connection options */) {\n    // Initialize client\n  }\n\n  async addMessage(message: MemoryMessage, userId: string, conversationId: string): Promise<void> {\n    const key = `memory:${userId}:${conversationId}`;\n    // Logic to store message in your DB\n  }\n\n  async getMessages(options: MessageFilterOptions): Promise<MemoryMessage[]> {\n    const key = `memory:${options.userId}:${options.conversationId}`;\n    // Logic to retrieve messages from your DB, applying limit\n    return []; // Return retrieved messages\n  }\n\n  // ... implement all other methods from the Memory interface ...\n\n  async createConversation(conversation: CreateConversationInput): Promise<Conversation> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async getConversation(id: string): Promise<Conversation | null> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async getConversations(resourceId: string): Promise<Conversation[]> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async updateConversation(\n    id: string,\n    updates: Partial<Omit<Conversation, \"id\" | \"createdAt\" | \"updatedAt\">>\n  ): Promise<Conversation> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async deleteConversation(id: string): Promise<void> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async clearMessages(options: {\n    userId: string;\n    conversationId?: string | undefined;\n  }): Promise<void> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async addHistoryEntry(key: string, value: any, agentId: string): Promise<void> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async updateHistoryEntry(key: string, value: any, agentId: string): Promise<void> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async addTimelineEvent(\n    key: string,\n    value: NewTimelineEvent,\n    historyId: string,\n    agentId: string\n  ): Promise<void> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async addHistoryStep(key: string, value: any, historyId: string, agentId: string): Promise<void> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async updateHistoryStep(\n    key: string,\n    value: any,\n    historyId: string,\n    agentId: string\n  ): Promise<void> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async getHistoryEntry(key: string): Promise<any> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async getHistoryStep(key: string): Promise<any> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async getAllHistoryEntriesByAgent(agentId: string): Promise<any[]> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async getConversationsByUserId(\n    userId: string,\n    options?: Omit<ConversationQueryOptions, \"userId\">\n  ): Promise<Conversation[]> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async queryConversations(options: ConversationQueryOptions): Promise<Conversation[]> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async getConversationMessages(\n    conversationId: string,\n    options?: { limit?: number; offset?: number }\n  ): Promise<MemoryMessage[]> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n\n  // --- Workflow Methods ---\n  async storeWorkflowHistory(entry: WorkflowHistoryEntry): Promise<void> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async getWorkflowHistory(id: string): Promise<WorkflowHistoryEntry | null> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async getWorkflowHistoryByWorkflowId(workflowId: string): Promise<WorkflowHistoryEntry[]> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async updateWorkflowHistory(id: string, updates: Partial<WorkflowHistoryEntry>): Promise<void> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async deleteWorkflowHistory(id: string): Promise<void> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async storeWorkflowStep(step: WorkflowStepHistoryEntry): Promise<void> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async getWorkflowSteps(workflowHistoryId: string): Promise<WorkflowStepHistoryEntry[]> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async updateWorkflowStep(id: string, updates: Partial<WorkflowStepHistoryEntry>): Promise<void> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async deleteWorkflowStep(id: string): Promise<void> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async storeWorkflowTimelineEvent(event: any): Promise<void> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n  async getWorkflowTimelineEvents(workflowHistoryId: string): Promise<any[]> {\n    /* ... */ throw new Error(\"Not implemented\");\n  }\n}\n\n// Use your custom memory provider\nconst agent = new Agent({\n  // ... other options\n  memory: new MyCustomStorage(/* ... */),\n});\n\n```\n\n## Best Practices [â€‹](https://voltagent.dev/docs/agents/memory/overview/\\#best-practices \"Direct link to Best Practices\")\n\n1. **Choose the Right Provider**: Use `InMemoryStorage` for development/testing. Use `LibSQLStorage` (local/Turso) or a database-backed provider (like `@voltagent/supabase` or custom) for production persistence.\n2. **User Privacy**: Be mindful of storing conversation data. Implement clear data retention policies and provide mechanisms for users to manage or delete their history (e.g., using `deleteConversation` or custom logic) if required by privacy regulations.\n3. **Context Management**: While `contextLimit` is less directly used now, be aware of the `storageLimit` on your memory provider, as this often dictates the maximum history retrieved.\n4. **Memory Efficiency**: For high-volume applications using persistent storage, monitor database size and performance. Consider setting appropriate `storageLimit` values on your memory provider to prevent unbounded growth and ensure efficient retrieval.\n5. **Error Handling**: Wrap agent interactions in `try...catch` blocks, as memory operations (especially with external databases) can potentially fail.\n6. **Use `userId` and `conversationId`**: Always provide these identifiers in production applications to correctly scope memory and maintain context for individual users and conversation threads.\n\nExplore the specific documentation for each provider to learn more:\n\n- **[LibSQL / Turso / SQLite](https://voltagent.dev/docs/agents/memory/libsql/)**\n- **[In-Memory Storage](https://voltagent.dev/docs/agents/memory/in-memory/)**\n- **[Supabase](https://voltagent.dev/docs/agents/memory/supabase/)**\n\n### Table of Contents\n\n- [Why Use Memory?](https://voltagent.dev/docs/agents/memory/overview/#why-use-memory)\n- [Default Memory Behavior (Zero-Config Persistence)](https://voltagent.dev/docs/agents/memory/overview/#default-memory-behavior-zero-config-persistence)\n- [Disabling Memory](https://voltagent.dev/docs/agents/memory/overview/#disabling-memory)\n- [Separate Conversation and History Memory](https://voltagent.dev/docs/agents/memory/overview/#separate-conversation-and-history-memory)\n- [Memory Providers](https://voltagent.dev/docs/agents/memory/overview/#memory-providers)\n- [How Memory Works with Agents](https://voltagent.dev/docs/agents/memory/overview/#how-memory-works-with-agents)\n- [User and Conversation Identification](https://voltagent.dev/docs/agents/memory/overview/#user-and-conversation-identification)\n  - [How User and Conversation IDs Work](https://voltagent.dev/docs/agents/memory/overview/#how-user-and-conversation-ids-work)\n- [Context Management](https://voltagent.dev/docs/agents/memory/overview/#context-management)\n- [Implementing Custom Memory Providers](https://voltagent.dev/docs/agents/memory/overview/#implementing-custom-memory-providers)\n- [Best Practices](https://voltagent.dev/docs/agents/memory/overview/#best-practices)",
      "metadata": {
        "ogImage": "https://voltagent.dev/img/social3.png",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "docusaurus_tag": "docs-default-current",
        "ogTitle": "Overview | VoltAgent",
        "docsearch:docusaurus_tag": "docs-default-current",
        "docusaurus_locale": "en",
        "og:image": "https://voltagent.dev/img/social3.png",
        "language": "en",
        "docsearch:language": "en",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_version": "current",
        "twitter:card": "summary_large_image",
        "docsearch:version": "current",
        "ogUrl": "https://voltagent.dev/docs/agents/memory/overview/",
        "og:locale": "en",
        "description": "Conversational AI agents often need to remember past interactions to maintain context, understand user preferences, and provide more coherent and personalized responses. Without memory, each interaction would be treated in isolation, leading to repetitive questions and unnatural conversations.",
        "title": "Overview | VoltAgent",
        "ogDescription": "Conversational AI agents often need to remember past interactions to maintain context, understand user preferences, and provide more coherent and personalized responses. Without memory, each interaction would be treated in isolation, leading to repetitive questions and unnatural conversations.",
        "og:title": "Overview | VoltAgent",
        "og:description": "Conversational AI agents often need to remember past interactions to maintain context, understand user preferences, and provide more coherent and personalized responses. Without memory, each interaction would be treated in isolation, leading to repetitive questions and unnatural conversations.",
        "generator": "Docusaurus v3.1.1",
        "og:url": "https://voltagent.dev/docs/agents/memory/overview/",
        "ogLocale": "en",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "scrapeId": "df7e1b01-f008-490e-a9a8-95d42ce3646e",
        "sourceURL": "https://voltagent.dev/docs/agents/memory/overview/",
        "url": "https://voltagent.dev/docs/agents/memory/overview/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:24.838Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/rag/overview/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# RAG: Give Your AI Agent a Memory\n\nEver wished your AI agent could remember your company's documentation, search your database, or know about events that happened after its training? That's exactly what RAG (Retrieval-Augmented Generation) does.\n\n## The Problem [â€‹](https://voltagent.dev/docs/rag/overview/\\#the-problem \"Direct link to The Problem\")\n\nWithout RAG, your AI agent is like a smart person with amnesia:\n\n```codeBlockLines_e6Vv\n// âŒ Without RAG - agent only knows training data\nconst agent = new Agent({\n  name: \"Support Bot\",\n  instructions: \"Help customers with our product\",\n});\n\n// User: \"What's our return policy?\"\n// Agent: \"I don't have access to your specific return policy...\"\n\n```\n\n## The Solution [â€‹](https://voltagent.dev/docs/rag/overview/\\#the-solution \"Direct link to The Solution\")\n\nWith RAG, your agent can search and use your actual data:\n\n```codeBlockLines_e6Vv\n// âœ… With RAG - agent searches your knowledge base\nconst agent = new Agent({\n  name: \"Support Bot\",\n  instructions: \"Help customers with our product\",\n  retriever: myKnowledgeBase, // ðŸ”¥ This is the magic\n});\n\n// User: \"What's our return policy?\"\n// Agent: \"According to our policy document, you have 30 days...\"\n// Sources: [{ title: \"Return Policy\", url: \"docs/returns.md\" }]\n\n```\n\n## What You'll Build [â€‹](https://voltagent.dev/docs/rag/overview/\\#what-youll-build \"Direct link to What You'll Build\")\n\nBy the end of this guide, you'll have an AI agent that can:\n\n- Search through your documents instantly\n- Pull relevant info from databases\n- Give accurate answers with sources\n- Track where information came from\n- Stay up-to-date with your latest data\n\n## How It Works (2 Ways) [â€‹](https://voltagent.dev/docs/rag/overview/\\#how-it-works-2-ways \"Direct link to How It Works (2 Ways)\")\n\nVoltAgent gives you two ways to add RAG to your agents:\n\n### Option 1: Always-On Search [â€‹](https://voltagent.dev/docs/rag/overview/\\#option-1-always-on-search \"Direct link to Option 1: Always-On Search\")\n\n```codeBlockLines_e6Vv\nconst agent = new Agent({\n  name: \"Smart Assistant\",\n  retriever: mySearchEngine, // Searches before every response\n});\n\n```\n\n**When to use**: Support bots, documentation assistants, Q&A systems\n\n### Option 2: Search When Needed [â€‹](https://voltagent.dev/docs/rag/overview/\\#option-2-search-when-needed \"Direct link to Option 2: Search When Needed\")\n\n```codeBlockLines_e6Vv\nconst agent = new Agent({\n  name: \"Smart Assistant\",\n  tools: [mySearchEngine.tool], // Agent decides when to search\n});\n\n```\n\n**When to use**: General assistants, complex workflows, multi-step tasks\n\n## Works With Any Database [â€‹](https://voltagent.dev/docs/rag/overview/\\#works-with-any-database \"Direct link to Works With Any Database\")\n\nThe best part? VoltAgent doesn't lock you into any specific database. All retrievers extend the same `BaseRetriever` class, so switching is easy:\n\n```codeBlockLines_e6Vv\nimport { BaseRetriever } from \"@voltagent/core\";\n\n// Start with local files\nclass FileRetriever extends BaseRetriever {\n  async retrieve(input, options) {\n    const query = typeof input === \"string\" ? input : input[input.length - 1].content;\n    // Search local files\n    const results = await this.searchFiles(query);\n    return results.join(\"\\n\\n\");\n  }\n}\n\n// Later switch to PostgreSQL\nclass PostgreSQLRetriever extends BaseRetriever {\n  async retrieve(input, options) {\n    const query = typeof input === \"string\" ? input : input[input.length - 1].content;\n    // Search PostgreSQL with pgvector\n    const results = await this.searchPostgreSQL(query);\n    return results.map((row) => row.content).join(\"\\n\\n\");\n  }\n}\n\n// Agent code stays exactly the same! ðŸŽ‰\nconst agent = new Agent({\n  retriever: new FileRetriever(), // Just swap the class\n});\n\n```\n\n**Supported patterns:**\n\n- Vector DBs: Chroma, Pinecone, Weaviate, Qdrant\n- SQL: PostgreSQL, MySQL, SQLite\n- NoSQL: MongoDB, Redis\n- Search: Elasticsearch, Algolia\n- Files: PDF, Word, CSV, JSON\n- APIs: REST, GraphQL\n\n## Integration Examples [â€‹](https://voltagent.dev/docs/rag/overview/\\#integration-examples \"Direct link to Integration Examples\")\n\n### Build Your Own Retriever [â€‹](https://voltagent.dev/docs/rag/overview/\\#build-your-own-retriever \"Direct link to Build Your Own Retriever\")\n\nConnect to your own database, API, or files with a custom retriever.\n\n```codeBlockLines_e6Vv\nclass MyRetriever extends BaseRetriever {\n  async retrieve(input, options) {\n    const query = typeof input === \"string\" ? input : input[input.length - 1].content;\n    const results = await this.searchMyData(query);\n\n    // Track sources using userContext\n    if (options.userContext) {\n      options.userContext.set(\n        \"sources\",\n        results.map((r) => r.source)\n      );\n    }\n\n    return results.map((r) => r.content).join(\"\\n\\n\");\n  }\n}\n\n```\n\n[**â†’ Build Your Own Retriever**](https://voltagent.dev/docs/rag/custom-retrievers/)\n\n### Chroma Vector Database [â€‹](https://voltagent.dev/docs/rag/overview/\\#chroma-vector-database \"Direct link to Chroma Vector Database\")\n\nPerfect for beginners. Run locally with Docker and get started immediately.\n\n```codeBlockLines_e6Vv\n# Start Chroma server\nnpm run chroma run\n\n# Try the example\nnpm create voltagent-app@latest -- --example with-chroma\n\n```\n\n[**â†’ Full Chroma Guide**](https://voltagent.dev/docs/rag/chroma/)\n\n### Pinecone Vector Database [â€‹](https://voltagent.dev/docs/rag/overview/\\#pinecone-vector-database \"Direct link to Pinecone Vector Database\")\n\nProduction-ready managed vector database with serverless scaling and enterprise features.\n\n```codeBlockLines_e6Vv\n# No setup needed - fully managed service\n# Just get your API key and run\n\nnpm create voltagent-app@latest -- --example with-pinecone\n\n```\n\n[**â†’ Full Pinecone Guide**](https://voltagent.dev/docs/rag/pinecone/)\n\n### Qdrant Vector Database [â€‹](https://voltagent.dev/docs/rag/overview/\\#qdrant-vector-database \"Direct link to Qdrant Vector Database\")\n\nQdrant (read: quadrant) is an open-source vector search engine. It provides a production-ready service to store, search, and manage vectors with additional payload and extended filtering support.\n\n```codeBlockLines_e6Vv\nnpm create voltagent-app@latest -- --example with-qdrant\n\n```\n\n[**â†’ Full Qdrant Guide**](https://voltagent.dev/docs/rag/qdrant/)\n\n## Choose Your Path [â€‹](https://voltagent.dev/docs/rag/overview/\\#choose-your-path \"Direct link to Choose Your Path\")\n\n**I want to try locally** â†’ [Chroma Tutorial](https://voltagent.dev/docs/rag/chroma/) (10 mins)\n\n**I want production-ready** â†’ [Pinecone Tutorial](https://voltagent.dev/docs/rag/pinecone/) (15 mins)\n\n**I want open-source and production-ready** â†’ [Qdrant Tutorial](https://voltagent.dev/docs/rag/qdrant/) (10 mins)\n\n**I want to build custom** â†’ [Build Your Own Retriever](https://voltagent.dev/docs/rag/custom-retrievers/)\n\n**I want to see examples** â†’ [GitHub Examples](https://github.com/voltagent/voltagent/tree/main/examples)\n\n**I need help choosing** â†’ Join our [Discord](https://s.voltagent.dev/discord) and ask!\n\n### Table of Contents\n\n- [The Problem](https://voltagent.dev/docs/rag/overview/#the-problem)\n- [The Solution](https://voltagent.dev/docs/rag/overview/#the-solution)\n- [What You'll Build](https://voltagent.dev/docs/rag/overview/#what-youll-build)\n- [How It Works (2 Ways)](https://voltagent.dev/docs/rag/overview/#how-it-works-2-ways)\n  - [Option 1: Always-On Search](https://voltagent.dev/docs/rag/overview/#option-1-always-on-search)\n  - [Option 2: Search When Needed](https://voltagent.dev/docs/rag/overview/#option-2-search-when-needed)\n- [Works With Any Database](https://voltagent.dev/docs/rag/overview/#works-with-any-database)\n- [Integration Examples](https://voltagent.dev/docs/rag/overview/#integration-examples)\n  - [Build Your Own Retriever](https://voltagent.dev/docs/rag/overview/#build-your-own-retriever)\n  - [Chroma Vector Database](https://voltagent.dev/docs/rag/overview/#chroma-vector-database)\n  - [Pinecone Vector Database](https://voltagent.dev/docs/rag/overview/#pinecone-vector-database)\n  - [Qdrant Vector Database](https://voltagent.dev/docs/rag/overview/#qdrant-vector-database)\n- [Choose Your Path](https://voltagent.dev/docs/rag/overview/#choose-your-path)",
      "metadata": {
        "docusaurus_locale": "en",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "description": "Ever wished your AI agent could remember your company's documentation, search your database, or know about events that happened after its training? That's exactly what RAG (Retrieval-Augmented Generation) does.",
        "og:url": "https://voltagent.dev/docs/rag/overview/",
        "docsearch:version": "current",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_tag": "docs-default-current",
        "docsearch:language": "en",
        "docusaurus_version": "current",
        "og:title": "Overview | VoltAgent",
        "generator": "Docusaurus v3.1.1",
        "docsearch:docusaurus_tag": "docs-default-current",
        "ogTitle": "Overview | VoltAgent",
        "ogDescription": "Ever wished your AI agent could remember your company's documentation, search your database, or know about events that happened after its training? That's exactly what RAG (Retrieval-Augmented Generation) does.",
        "og:description": "Ever wished your AI agent could remember your company's documentation, search your database, or know about events that happened after its training? That's exactly what RAG (Retrieval-Augmented Generation) does.",
        "ogUrl": "https://voltagent.dev/docs/rag/overview/",
        "title": "Overview | VoltAgent",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "og:image": "https://voltagent.dev/img/social3.png",
        "language": "en",
        "og:locale": "en",
        "ogLocale": "en",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "twitter:card": "summary_large_image",
        "scrapeId": "dbac35de-0b86-407a-89e8-60cbce9f4eb2",
        "sourceURL": "https://voltagent.dev/docs/rag/overview/",
        "url": "https://voltagent.dev/docs/rag/overview/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:00.835Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/agents/sub-agents/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\n# Subagents\n\nSubagents are specialized agents that work under a supervisor agent to handle specific tasks. This architecture enables the creation of complex agent workflows where each subagent focuses on its area of expertise, coordinated by a supervisor.\n\n## Why Use Subagents? [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#why-use-subagents \"Direct link to Why Use Subagents?\")\n\n- **Specialization**: Create agents that excel at specific tasks (e.g., coding, translation, data analysis).\n- **Workflow Orchestration**: Build complex, multi-step workflows by having a supervisor delegate tasks to the appropriate specialized agents.\n- **Scalability**: Break down complex problems into smaller, manageable parts, making the overall system easier to develop and maintain.\n- **Improved Responses**: Achieve better results by leveraging the focused knowledge and capabilities of specialized agents for specific parts of a user request.\n- **Modularity**: Easily swap or add specialized agents without disrupting the entire system.\n\n## Creating and Using Subagents [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#creating-and-using-subagents \"Direct link to Creating and Using Subagents\")\n\n### Creating Individual Agents [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#creating-individual-agents \"Direct link to Creating Individual Agents\")\n\nFirst, create the specialized agents that will serve as subagents:\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Create a specialized agent for writing stories\nconst storyAgent = new Agent({\n  name: \"Story Agent\",\n  purpose: \"A story writer agent that creates original, engaging short stories.\",\n  instructions: \"You are a creative story writer. Create original, engaging short stories.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n});\n\n// Create a specialized agent for translation\nconst translatorAgent = new Agent({\n  name: \"Translator Agent\",\n  purpose: \"A translator agent that translates text accurately.\",\n  instructions: \"You are a skilled translator. Translate text accurately.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n});\n\n```\n\n### Creating a Supervisor Agent [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#creating-a-supervisor-agent \"Direct link to Creating a Supervisor Agent\")\n\nCreate a supervisor agent that will coordinate between subagents. Simply pass the specialized agents in the `subAgents` array during initialization:\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Create a supervisor agent with specialized agents as subagents\nconst supervisorAgent = new Agent({\n  name: \"Supervisor Agent\",\n  instructions: \"You manage a workflow between specialized agents.\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  // Specify subagents during initialization\n  subAgents: [storyAgent, translatorAgent],\n});\n\n```\n\nAdvanced SubAgent Configuration\n\nThe basic example above uses the default `streamText` method for subagents. For more control over how subagents execute tasks, you can specify different methods like `generateText`, `generateObject`, or `streamObject` with custom schemas and options.\n\n**Learn more:** [Advanced SubAgent Configuration](https://voltagent.dev/docs/agents/sub-agents/#advanced-subagent-configuration)\n\n## Customizing Supervisor Behavior [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#customizing-supervisor-behavior \"Direct link to Customizing Supervisor Behavior\")\n\nBy default, supervisor agents use an automatically generated system message that includes guidelines for managing subagents. However, you can customize this behavior using the `supervisorConfig` option for more control over how your supervisor agent behaves.\n\nDefault System Message\n\nTo see the current default supervisor system message template and understand how it works, check the [generateSupervisorSystemMessage implementation](https://github.com/VoltAgent/voltagent/blob/main/packages/core/src/agent/subagent/index.ts#L131) on GitHub.\n\nType Safety\n\nThe `supervisorConfig` option is only available when `subAgents` are provided. TypeScript will prevent you from using `supervisorConfig` on agents without subagents.\n\n### Basic Supervisor Configuration [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#basic-supervisor-configuration \"Direct link to Basic Supervisor Configuration\")\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst supervisorAgent = new Agent({\n  name: \"Content Supervisor\",\n  instructions: \"Coordinate content creation workflow\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  subAgents: [writerAgent, editorAgent],\n\n  // âœ… Basic supervisor customization\n  supervisorConfig: {\n    // Add custom guidelines to the default ones\n    customGuidelines: [\\\n      \"Always thank the user at the end\",\\\n      \"Keep responses concise and actionable\",\\\n      \"Prioritize user experience\",\\\n    ],\n\n    // Control whether to include previous agent interactions\n    includeAgentsMemory: true, // default: true\n  },\n});\n\n```\n\n### Stream Event Forwarding Configuration [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#stream-event-forwarding-configuration \"Direct link to Stream Event Forwarding Configuration\")\n\nControl which events from subagents are forwarded to the parent stream. By default, only `tool-call` and `tool-result` events are forwarded to keep the stream focused on meaningful actions.\n\n```codeBlockLines_e6Vv\nconst supervisorAgent = new Agent({\n  name: \"Content Supervisor\",\n  instructions: \"Coordinate content creation workflow\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  subAgents: [writerAgent, editorAgent],\n\n  supervisorConfig: {\n    // Configure which subagent events to forward\n    fullStreamEventForwarding: {\n      // Default: ['tool-call', 'tool-result']\n      // Enable all event types for complete visibility\n      types: [\"tool-call\", \"tool-result\", \"text-delta\", \"reasoning\", \"source\", \"error\", \"finish\"],\n\n      // Add subagent name as prefix to tool names (default: true)\n      // When true: \"WriterAgent: search_tool\"\n      // When false: \"search_tool\"\n      addSubAgentPrefix: true,\n    },\n  },\n});\n\n```\n\n**Common Configurations:**\n\n```codeBlockLines_e6Vv\n// Minimal - Only tool events (default)\nfullStreamEventForwarding: {\n  types: ['tool-call', 'tool-result'],\n}\n\n// Text + Tools - See what subagents are saying and doing\nfullStreamEventForwarding: {\n  types: ['tool-call', 'tool-result', 'text-delta'],\n}\n\n// Full visibility - All events including reasoning\nfullStreamEventForwarding: {\n  types: ['tool-call', 'tool-result', 'text-delta', 'reasoning', 'source', 'error', 'finish'],\n}\n\n// Clean tool names - No agent prefix\nfullStreamEventForwarding: {\n  types: ['tool-call', 'tool-result'],\n  addSubAgentPrefix: false,\n}\n\n```\n\nThis configuration helps you balance between stream performance and information richness, allowing you to see exactly what you need from subagent interactions.\n\n#### Using with fullStream [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#using-with-fullstream \"Direct link to Using with fullStream\")\n\nWhen using `fullStream` to get detailed streaming events, the configuration controls what you receive from subagents:\n\n```codeBlockLines_e6Vv\n// Stream with full event details\nconst result = await supervisorAgent.streamText(\"Create and edit content\", {\n  fullStream: true, // Enable full streaming to get all event types\n});\n\n// Process different event types\nfor await (const event of result.fullStream) {\n  switch (event.type) {\n    case \"tool-call\":\n      console.log(`Tool called: ${event.data.toolName}`);\n      break;\n    case \"tool-result\":\n      console.log(`Tool result: ${event.data.result}`);\n      break;\n    case \"text-delta\":\n      // Only appears if included in types array\n      console.log(`Text: ${event.data}`);\n      break;\n    case \"reasoning\":\n      // Only appears if included in types array\n      console.log(`Reasoning: ${event.data}`);\n      break;\n  }\n}\n\n```\n\n#### Filtering Subagent Events [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#filtering-subagent-events \"Direct link to Filtering Subagent Events\")\n\nYou can identify which events come from subagents by checking for `subAgentId` and `subAgentName` properties:\n\n```codeBlockLines_e6Vv\nconst result = await supervisorAgent.streamText(\"Create and edit content\", {\n  fullStream: true,\n});\n\nfor await (const event of result.fullStream) {\n  // Check if this event is from a subagent\n  if (event.subAgentId && event.subAgentName) {\n    console.log(`Event from subagent ${event.subAgentName}:`);\n    console.log(`  Type: ${event.type}`);\n    console.log(`  Data:`, event.data);\n\n    // Filter by specific subagent\n    if (event.subAgentName === \"WriterAgent\") {\n      // Handle writer agent events specifically\n    }\n  } else {\n    // This is from the supervisor agent itself\n    console.log(`Supervisor event: ${event.type}`);\n  }\n}\n\n```\n\nThis allows you to:\n\n- Distinguish between supervisor and subagent events\n- Filter events by specific subagent\n- Apply different handling logic based on the event source\n\n### Complete System Message Override [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#complete-system-message-override \"Direct link to Complete System Message Override\")\n\nFor complete control over the supervisor's behavior, you can provide a custom `systemMessage` that entirely replaces the default template:\n\n```codeBlockLines_e6Vv\nconst supervisorAgent = new Agent({\n  name: \"Custom Supervisor\",\n  instructions: \"This will be ignored when systemMessage is provided\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  subAgents: [writerAgent, editorAgent],\n\n  // âœ… Complete system message override\n  supervisorConfig: {\n    systemMessage: `\nYou are a professional content manager named \"ContentBot\".\n\nYour specialist team:\n- Writer: Creates original content\n- Editor: Reviews and improves content\n\nYour workflow:\n1. Analyze user requests carefully\n2. Use delegate_task to assign work to appropriate specialists\n3. Coordinate between specialists as needed\n4. Provide comprehensive final responses\n5. Always maintain a professional but friendly tone\n\nRemember: Use the delegate_task tool to assign tasks to your specialists.\n    `.trim(),\n\n    // Control memory inclusion even with custom system message\n    includeAgentsMemory: true,\n  },\n});\n\n```\n\n### Quick Usage [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#quick-usage \"Direct link to Quick Usage\")\n\n**Add custom rules:**\n\n```codeBlockLines_e6Vv\nsupervisorConfig: {\n  customGuidelines: [\"Verify sources\", \"Include confidence levels\"];\n}\n\n```\n\n**Override entire system message:**\n\n```codeBlockLines_e6Vv\nsupervisorConfig: {\n  systemMessage: \"You are TaskBot. Use delegate_task(task, [agentNames]) to assign work.\";\n}\n\n```\n\n**Control memory:**\n\n```codeBlockLines_e6Vv\nsupervisorConfig: {\n  includeAgentsMemory: false; // Fresh context each interaction (default: true)\n}\n\n```\n\n**Configure event forwarding:**\n\n```codeBlockLines_e6Vv\nsupervisorConfig: {\n  fullStreamEventForwarding: {\n    types: ['tool-call', 'tool-result', 'text-delta'], // Control which events to forward\n    addSubAgentPrefix: false // Remove agent name prefix from tools\n  }\n}\n\n```\n\n## How Subagents Work [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#how-subagents-work \"Direct link to How Subagents Work\")\n\nThe core mechanism involves the supervisor agent delegating tasks to its subagents using the automatically provided `delegate_task` tool.\n\n1. A user sends a request to the supervisor agent.\n2. The supervisor agent's LLM analyzes the request and its enhanced system prompt (which lists available subagents).\n3. Based on the task, the supervisor decides which subagent(s) are best suited to handle specific parts of the request.\n4. The supervisor uses the `delegate_task` tool to hand off the task(s).\n\n### The `delegate_task` Tool [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#the-delegate_task-tool \"Direct link to the-delegate_task-tool\")\n\nThis tool is the primary interface for delegation.\n\n- **Name**: `delegate_task`\n- **Description**: \"Delegate a task to one or more specialized agents\"\n- **Parameters**:\n\n  - `task` (string, required): The specific task description to be delegated.\n  - `targetAgents` (array of strings, required): A list of subagent **names** to delegate the task to. The supervisor can delegate to multiple agents simultaneously if appropriate.\n  - `context` (object, optional): Any additional context needed by the subagent(s) to perform the task.\n- **Execution**:\n\n  - The tool finds the corresponding subagent instances based on the provided names.\n  - It calls the `handoffTask` (or `handoffToMultiple`) method internally, which sends the task description and context to the target subagent(s).\n  - Crucially, it passes the supervisor's agent ID ( `parentAgentId`) and the current history entry ID ( `parentHistoryEntryId`) to the subagent's execution context. This is key for [Observability](https://voltagent.dev/docs/agents/sub-agents/#observability-and-event-tracking).\n- **Returns**: An array of objects, where each object contains the result from a delegated agent:\n\n\n\n\n\n```codeBlockLines_e6Vv\n[\\\n    {\\\n      agentName: string; // Name of the subagent that executed the task\\\n      response: string; // The text result returned by the subagent\\\n      conversationId: string; // The conversation ID used for the handoff\\\n    },\\\n    // ... potentially more results if multiple agents were targeted\\\n]\n\n```\n\n\n5. Subagents process their delegated tasks independently. They can use their own tools or even delegate further if they are also supervisors.\n6. Each subagent returns its result to the `delegate_task` tool execution context within the supervisor.\n7. The supervisor receives the results from the `delegate_task` tool.\n8. Based on its instructions and the received results, the supervisor synthesizes the final response and presents it to the user.\n\n## Complete Example [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#complete-example \"Direct link to Complete Example\")\n\n```codeBlockLines_e6Vv\nimport { Agent } from \"@voltagent/core\";\nimport { VercelAIProvider } from \"@voltagent/vercel-ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Create specialists\nconst writer = new Agent({\n  name: \"Writer\",\n  instructions: \"Write creative stories\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n});\n\nconst translator = new Agent({\n  name: \"Translator\",\n  instructions: \"Translate text accurately\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n});\n\n// Create supervisor\nconst supervisor = new Agent({\n  name: \"Supervisor\",\n  instructions: \"Coordinate story writing and translation\",\n  llm: new VercelAIProvider(),\n  model: openai(\"gpt-4o-mini\"),\n  subAgents: [writer, translator],\n});\n\n// Use it\nconst result = await supervisor.streamText(\"Write a story about AI and translate to Spanish\");\n\nfor await (const chunk of result.textStream) {\n  process.stdout.write(chunk);\n}\n\n```\n\n**What happens:**\n\n1. Supervisor analyzes request\n2. Calls `delegate_task` â†’ Writer creates story\n3. Calls `delegate_task` â†’ Translator translates\n4. Combines results and responds\n\n## Using Hooks [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#using-hooks \"Direct link to Using Hooks\")\n\nMonitor task delegation with the `onHandoff` hook:\n\n```codeBlockLines_e6Vv\nconst supervisor = new Agent({\n  name: \"Supervisor\",\n  subAgents: [writer, translator],\n  hooks: {\n    onHandoff: ({ agent, source }) => {\n      console.log(`${source.name} â†’ ${agent.name}`);\n    },\n  },\n});\n\n```\n\n## Context Sharing [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#context-sharing \"Direct link to Context Sharing\")\n\nSubAgents automatically inherit the supervisor's context:\n\n```codeBlockLines_e6Vv\n// Supervisor passes context\nconst response = await supervisor.streamText(\"Task\", {\n  userContext: new Map([[\"projectId\", \"123\"]]),\n});\n\n// SubAgent receives it automatically\nconst subAgent = new Agent({\n  hooks: {\n    onStart: ({ context }) => {\n      const projectId = context.userContext.get(\"projectId\"); // \"123\"\n    },\n  },\n});\n\n```\n\n## Step Control [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#step-control \"Direct link to Step Control\")\n\nControl workflow steps with `maxSteps`:\n\n```codeBlockLines_e6Vv\nconst supervisor = new Agent({\n  subAgents: [writer, editor],\n  maxSteps: 20, // Inherited by all subagents\n});\n\n// Override per request\nconst result = await supervisor.generateText(\"Task\", { maxSteps: 10 });\n\n```\n\n**Default:** `10 Ã— number_of_subagents` (prevents infinite loops)\n\n## Observability [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#observability \"Direct link to Observability\")\n\nSubAgent operations are automatically linked to their supervisor for complete traceability in monitoring tools.\n\n## Advanced Configuration [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#advanced-configuration \"Direct link to Advanced Configuration\")\n\nUse different execution methods for specialized subagents:\n\n```codeBlockLines_e6Vv\nimport { createSubagent } from \"@voltagent/core\";\nimport { z } from \"zod\";\n\nconst AnalysisSchema = z.object({\n  insights: z.array(z.string()),\n  confidence: z.number().min(0).max(1),\n});\n\nconst supervisor = new Agent({\n  subAgents: [\\\n    writer, // Default streamText\\\n    createSubagent({\\\n      agent: analyzer,\\\n      method: \"generateObject\",\\\n      schema: AnalysisSchema,\\\n      options: { temperature: 0.1 },\\\n    }),\\\n  ],\n});\n\n```\n\n**Available methods:**\n\n- `streamText` (default) - Real-time text streaming\n- `generateText` \\- Simple text generation\n- `generateObject` \\- Structured data with Zod schema\n- `streamObject` \\- Streaming structured data\n\n## Dynamic SubAgents [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#dynamic-subagents \"Direct link to Dynamic SubAgents\")\n\nAdd subagents after initialization:\n\n```codeBlockLines_e6Vv\nsupervisor.addSubAgent(newAgent);\n\n```\n\n## Remove SubAgents [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#remove-subagents \"Direct link to Remove SubAgents\")\n\n```codeBlockLines_e6Vv\nsupervisor.removeSubAgent(agentId);\n\n```\n\n## Troubleshooting [â€‹](https://voltagent.dev/docs/agents/sub-agents/\\#troubleshooting \"Direct link to Troubleshooting\")\n\n**SubAgent not being called?**\n\n- Check agent names match exactly\n- Make supervisor instructions explicit about when to delegate\n- Use `onHandoff` hook to debug delegation flow\n\n### Table of Contents\n\n- [Why Use Subagents?](https://voltagent.dev/docs/agents/sub-agents/#why-use-subagents)\n- [Creating and Using Subagents](https://voltagent.dev/docs/agents/sub-agents/#creating-and-using-subagents)\n  - [Creating Individual Agents](https://voltagent.dev/docs/agents/sub-agents/#creating-individual-agents)\n  - [Creating a Supervisor Agent](https://voltagent.dev/docs/agents/sub-agents/#creating-a-supervisor-agent)\n- [Customizing Supervisor Behavior](https://voltagent.dev/docs/agents/sub-agents/#customizing-supervisor-behavior)\n  - [Basic Supervisor Configuration](https://voltagent.dev/docs/agents/sub-agents/#basic-supervisor-configuration)\n  - [Stream Event Forwarding Configuration](https://voltagent.dev/docs/agents/sub-agents/#stream-event-forwarding-configuration)\n  - [Complete System Message Override](https://voltagent.dev/docs/agents/sub-agents/#complete-system-message-override)\n  - [Quick Usage](https://voltagent.dev/docs/agents/sub-agents/#quick-usage)\n- [How Subagents Work](https://voltagent.dev/docs/agents/sub-agents/#how-subagents-work)\n  - [The `delegate_task` Tool](https://voltagent.dev/docs/agents/sub-agents/#the-delegate_task-tool)\n- [Complete Example](https://voltagent.dev/docs/agents/sub-agents/#complete-example)\n- [Using Hooks](https://voltagent.dev/docs/agents/sub-agents/#using-hooks)\n- [Context Sharing](https://voltagent.dev/docs/agents/sub-agents/#context-sharing)\n- [Step Control](https://voltagent.dev/docs/agents/sub-agents/#step-control)\n- [Observability](https://voltagent.dev/docs/agents/sub-agents/#observability)\n- [Advanced Configuration](https://voltagent.dev/docs/agents/sub-agents/#advanced-configuration)\n- [Dynamic SubAgents](https://voltagent.dev/docs/agents/sub-agents/#dynamic-subagents)\n- [Remove SubAgents](https://voltagent.dev/docs/agents/sub-agents/#remove-subagents)\n- [Troubleshooting](https://voltagent.dev/docs/agents/sub-agents/#troubleshooting)",
      "metadata": {
        "ogUrl": "https://voltagent.dev/docs/agents/sub-agents/",
        "language": "en",
        "viewport": "width=device-width, initial-scale=1.0",
        "og:image": "https://voltagent.dev/img/social3.png",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "docusaurus_version": "current",
        "docsearch:version": "current",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:title": "Sub-agents | VoltAgent",
        "ogTitle": "Sub-agents | VoltAgent",
        "og:url": "https://voltagent.dev/docs/agents/sub-agents/",
        "title": "Sub-agents | VoltAgent",
        "ogDescription": "Subagents are specialized agents that work under a supervisor agent to handle specific tasks. This architecture enables the creation of complex agent workflows where each subagent focuses on its area of expertise, coordinated by a supervisor.",
        "og:description": "Subagents are specialized agents that work under a supervisor agent to handle specific tasks. This architecture enables the creation of complex agent workflows where each subagent focuses on its area of expertise, coordinated by a supervisor.",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "description": "Subagents are specialized agents that work under a supervisor agent to handle specific tasks. This architecture enables the creation of complex agent workflows where each subagent focuses on its area of expertise, coordinated by a supervisor.",
        "twitter:card": "summary_large_image",
        "ogLocale": "en",
        "generator": "Docusaurus v3.1.1",
        "docusaurus_locale": "en",
        "docusaurus_tag": "docs-default-current",
        "docsearch:language": "en",
        "og:locale": "en",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "scrapeId": "79ad99ea-d5dc-4132-9061-29ac005056a8",
        "sourceURL": "https://voltagent.dev/docs/agents/sub-agents/",
        "url": "https://voltagent.dev/docs/agents/sub-agents/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:42.967Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/community/contributing/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\nWe appreciate your interest in contributing to VoltAgent! VoltAgent aims to be a powerful and flexible backend framework focused on \\[mention core goals, e.g., building AI-powered applications, simplifying backend development, providing robust voice integration\\]. We value community contributions that help us achieve this vision.\n\nWe follow a [code of conduct](https://github.com/voltagent/voltagent/blob/main/CODE_OF_CONDUCT.md) when participating in the community. Please read it before you make any contributions.\n\n**Get in touch:**\n\n- If you plan to work on an issue, please mention so in the issue page before you start working.\n- If you plan to work on a new feature, consider creating an issue first to discuss it with other community members/maintainers.\n- Ask for help if you get stuck! Join our community at [Discord](https://s.voltagent.dev/discord).\n\n## Project Focus & Contribution Areas [â€‹](https://voltagent.dev/docs/community/contributing/\\#project-focus--contribution-areas \"Direct link to Project Focus & Contribution Areas\")\n\nAs a backend framework, we particularly welcome contributions in areas such as:\n\n- **Core Framework:** Improving the fundamental APIs, performance optimizations, middleware enhancements, and overall developer experience.\n- **CLI Tooling:** Adding new commands, improving existing ones, and enhancing the scaffolding process.\n- **AI/Voice Integration:** Contributing to the `@voltagent/xsai` and `@voltagent/voice` packages, improving integrations, or adding new capabilities.\n- **Integrations:** Developing adapters for databases, external services, or other tools.\n- **Examples & Use Cases:** Creating realistic examples demonstrating VoltAgent's features.\n- **Bug Fixes & Performance Improvements:** Addressing existing issues and optimizing code across all packages.\n- **Documentation:** Enhancing clarity, adding guides, and improving API references.\n\n## Our Packages [â€‹](https://voltagent.dev/docs/community/contributing/\\#our-packages \"Direct link to Our Packages\")\n\nVoltAgent is a monorepo containing several key packages:\n\n- `@voltagent/core`: The heart of the framework, containing the main APIs, request/response handling, middleware pipeline, etc. Contributions here often involve core feature development or architectural improvements.\n- `@voltagent/voice`: Handles voice input/output capabilities. Contributions could involve new STT/TTS integrations or improving voice interaction logic.\n- `@voltagent/anthropic-ai`: Provides integration with Anthropic's Claude AI models. Contributions could include improving model interactions, adding new Claude capabilities, or optimizing prompt handling.\n- `@voltagent/xsai`: Focuses on integrating AI functionalities (e.g., LLMs, vector stores). Contributions might include new AI service integrations or improving existing ones.\n- `@voltagent/vercel-ai`: Specific integrations for Vercel AI SDK.\n- `@voltagent/cli`: The command-line interface for creating and managing VoltAgent projects. Contributions typically involve adding/improving commands or developer workflows.\n- `@voltagent/create-voltagent-app`: The scaffolding tool used by `npm create voltagent-app@latest`.\n\nUnderstanding the purpose of each package helps in directing your contributions effectively.\n\n## Ways to contribute [â€‹](https://voltagent.dev/docs/community/contributing/\\#ways-to-contribute \"Direct link to Ways to contribute\")\n\n- **Stars on GitHub**: If you use VoltAgent and find it helpful, please star it on [GitHub](https://github.com/voltagent/voltagent)! ðŸŒŸ\n- **Improve documentation**: Good documentation is vital, especially for a backend framework. Help us by improving existing docs or adding new guides/API references.\n- **Give feedback**: Share your experiences, suggest features (especially backend-focused ones), or report issues via [GitHub Issues](https://github.com/voltagent/voltagent/issues) or our community channel [Discord](https://s.voltagent.dev/discord).\n- **Share VoltAgent**: Help spread the word about VoltAgent in the backend development community.\n- **Contribute to codebase**: Help us build the best backend framework! You can work on new features (see Focus Areas above) or fix [existing issues](https://github.com/voltagent/voltagent/issues).\n- **Share integrations/examples**: Built a cool backend service or integration with VoltAgent? Let us know!\n\n## Setting Up Your Environment for Development [â€‹](https://voltagent.dev/docs/community/contributing/\\#setting-up-your-environment-for-development \"Direct link to Setting Up Your Environment for Development\")\n\n### Requirements [â€‹](https://voltagent.dev/docs/community/contributing/\\#requirements \"Direct link to Requirements\")\n\n- [Node.js](https://nodejs.org/en/) version 20 or higher\n- [Git](https://git-scm.com/) and [GitHub](https://github.com/) account\n- [pnpm](https://pnpm.io/) version 8.10.5 or higher (as per `package.json`)\n\n### Cloning the Repository [â€‹](https://voltagent.dev/docs/community/contributing/\\#cloning-the-repository \"Direct link to Cloning the Repository\")\n\nFork the VoltAgent repository (link-to-your-repo/fork) and clone your fork:\n\n```codeBlockLines_e6Vv\ngit clone https://github.com/<your-github-username>/VoltAgent.git # Replace with your fork\ncd voltagent\n\n```\n\n### Installing Dependencies [â€‹](https://voltagent.dev/docs/community/contributing/\\#installing-dependencies \"Direct link to Installing Dependencies\")\n\nAfter cloning, install dependencies using pnpm. This command also links workspace packages.\n\nTerminal\n\n```codeBlockLines_e6Vv\npnpm install\n\n```\n\nYou can build all packages later with:\n\nTerminal\n\n```codeBlockLines_e6Vv\npnpm build\n\n```\n\nOr build specific packages:\n\nTerminal\n\n```codeBlockLines_e6Vv\n# Example: Build the core package\npnpm build --scope @voltagent/core\n\n```\n\n### Developing Packages [â€‹](https://voltagent.dev/docs/community/contributing/\\#developing-packages \"Direct link to Developing Packages\")\n\nRun the development server for specific backend packages you are working on:\n\nTerminal\n\n```codeBlockLines_e6Vv\n# Example: Develop core and cli packages\npnpm dev --scope @voltagent/core --scope @voltagent/cli\n\n```\n\nChanges in the specified packages will trigger recompilation.\n\nHow to add a dependency to a package?\n\nNavigate to the package directory and use `pnpm add`:\n\nTerminal\n\n```codeBlockLines_e6Vv\n# Example: Add 'lodash' to the core package\ncd packages/core\npnpm add lodash\n\n```\n\n### Running Tests [â€‹](https://voltagent.dev/docs/community/contributing/\\#running-tests \"Direct link to Running Tests\")\n\nUse `lerna run test` with `--scope` to run tests for the specific backend package(s) you modified:\n\nTerminal\n\n```codeBlockLines_e6Vv\n# Example: Run tests for the core package\npnpm test --scope @voltagent/core\n\n```\n\nTo run tests for all packages:\n\nTerminal\n\n```codeBlockLines_e6Vv\npnpm test:all\n\n```\n\nTo get coverage reports:\n\nTerminal\n\n```codeBlockLines_e6Vv\n# For a specific package\npnpm test --scope @voltagent/core -- --coverage\n\n# For all packages\npnpm test:all:coverage\n\n```\n\n## Working on Documentation [â€‹](https://voltagent.dev/docs/community/contributing/\\#working-on-documentation \"Direct link to Working on Documentation\")\n\nOur documentation likely resides in the `website` directory (confirm this structure if different) and may use a static site generator like Docusaurus.\n\nNavigate to the documentation directory and follow its setup instructions (update these steps based on your actual documentation setup):\n\nTerminal\n\n```codeBlockLines_e6Vv\ncd website # Or your actual documentation directory\npnpm install\npnpm start # Or the relevant dev script (e.g., dev, develop)\n\n```\n\n## Committing Your Work and Preparing a Pull Request [â€‹](https://voltagent.dev/docs/community/contributing/\\#committing-your-work-and-preparing-a-pull-request \"Direct link to Committing Your Work and Preparing a Pull Request\")\n\nWe use several tools to ensure code quality and a consistent contribution process.\n\n### Linting & Formatting [â€‹](https://voltagent.dev/docs/community/contributing/\\#linting--formatting \"Direct link to Linting & Formatting\")\n\nWe use [Biome](https://biomejs.dev/) for linting and formatting TypeScript/JavaScript/JSON files and [Prettier](https://prettier.io/) for Markdown.\n\n- **Check:** `pnpm lint` or `pnpm lint:ci`\n- **Fix:** `pnpm lint:fix`\n- **Format Markdown:** `pnpm format` (This also runs Prettier on Markdown)\n\nWe recommend installing the [Biome VSCode extension](https://biomejs.dev/reference/vscode/) and a Prettier extension for a smoother development experience.\n\n### Commit Convention [â€‹](https://voltagent.dev/docs/community/contributing/\\#commit-convention \"Direct link to Commit Convention\")\n\nWe follow the [Conventional Commits](https://www.conventionalcommits.org/en/v1.0.0/) specification. Commit messages should follow the format:\n\n```codeBlockLines_e6Vv\n<type>(<scope>): <description>\n\n```\n\nWhere `<scope>` is typically the package name (e.g., `core`, `cli`, `voice`, `docs`).\n\nExample: `feat(core): add new middleware feature` or `fix(cli): correct argument parsing`\n\n### Creating a Changeset [â€‹](https://voltagent.dev/docs/community/contributing/\\#creating-a-changeset \"Direct link to Creating a Changeset\")\n\nFor managing versioning and changelogs across our monorepo packages, we use [Changesets](https://github.com/changesets/changesets). Before committing changes that affect any package, create a changeset:\n\nTerminal\n\n```codeBlockLines_e6Vv\npnpm changeset\n\n```\n\nFollow the prompts:\n\n1. Select the package(s) you modified.\n2. Choose the appropriate semantic version bump ( `major`, `minor`, `patch`).\n3. Write a clear description of the change. Reference the relevant GitHub issue number (e.g., `Fixes #123`).\n\nCommit the generated `.changeset/*.md` file along with your code changes.\n\nExample changeset content:\n\n.changeset/cool-feature.md\n\n```codeBlockLines_e6Vv\n---\n\"@voltagent/core\": minor\n\"@voltagent/cli\": patch\n---\n\nfeat(core): Implement awesome feature X\n\nThis feature allows users to do Y.\n\nfix(cli): Correct flag parsing issue\n\nResolves #456\nFixes #789\n\n```\n\n### Creating a Pull Request [â€‹](https://voltagent.dev/docs/community/contributing/\\#creating-a-pull-request \"Direct link to Creating a Pull Request\")\n\n1. Push your changes (including the changeset file) to your forked repository.\n2. Create a Pull Request against the `main` branch of the main VoltAgent repository (link-to-your-repo).\n3. Ensure your PR title and description are clear. Reference any related issues.\n4. CI checks (linting, tests, commitlint, changeset validation) will run automatically. Please address any failures.\n5. Maintainers will review your PR. Be responsive to feedback.\n\nWe look forward to your contributions! ðŸŽ‰\n\n### Table of Contents\n\n- [Project Focus & Contribution Areas](https://voltagent.dev/docs/community/contributing/#project-focus--contribution-areas)\n- [Our Packages](https://voltagent.dev/docs/community/contributing/#our-packages)\n- [Ways to contribute](https://voltagent.dev/docs/community/contributing/#ways-to-contribute)\n- [Setting Up Your Environment for Development](https://voltagent.dev/docs/community/contributing/#setting-up-your-environment-for-development)\n  - [Requirements](https://voltagent.dev/docs/community/contributing/#requirements)\n  - [Cloning the Repository](https://voltagent.dev/docs/community/contributing/#cloning-the-repository)\n  - [Installing Dependencies](https://voltagent.dev/docs/community/contributing/#installing-dependencies)\n  - [Developing Packages](https://voltagent.dev/docs/community/contributing/#developing-packages)\n  - [Running Tests](https://voltagent.dev/docs/community/contributing/#running-tests)\n- [Working on Documentation](https://voltagent.dev/docs/community/contributing/#working-on-documentation)\n- [Committing Your Work and Preparing a Pull Request](https://voltagent.dev/docs/community/contributing/#committing-your-work-and-preparing-a-pull-request)\n  - [Linting & Formatting](https://voltagent.dev/docs/community/contributing/#linting--formatting)\n  - [Commit Convention](https://voltagent.dev/docs/community/contributing/#commit-convention)\n  - [Creating a Changeset](https://voltagent.dev/docs/community/contributing/#creating-a-changeset)\n  - [Creating a Pull Request](https://voltagent.dev/docs/community/contributing/#creating-a-pull-request)",
      "metadata": {
        "viewport": "width=device-width, initial-scale=1.0",
        "ogTitle": "Contributing | VoltAgent",
        "ogDescription": "We appreciate your interest in contributing to VoltAgent! VoltAgent aims to be a powerful and flexible backend framework focused on [mention core goals, e.g., building AI-powered applications, simplifying backend development, providing robust voice integration]. We value community contributions that help us achieve this vision.",
        "language": "en",
        "ogLocale": "en",
        "og:locale": "en",
        "og:image": "https://voltagent.dev/img/social3.png",
        "docusaurus_tag": "docs-default-current",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "og:url": "https://voltagent.dev/docs/community/contributing/",
        "title": "Contributing | VoltAgent",
        "ogUrl": "https://voltagent.dev/docs/community/contributing/",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "docusaurus_locale": "en",
        "docusaurus_version": "current",
        "twitter:card": "summary_large_image",
        "docsearch:language": "en",
        "docsearch:docusaurus_tag": "docs-default-current",
        "description": "We appreciate your interest in contributing to VoltAgent! VoltAgent aims to be a powerful and flexible backend framework focused on [mention core goals, e.g., building AI-powered applications, simplifying backend development, providing robust voice integration]. We value community contributions that help us achieve this vision.",
        "generator": "Docusaurus v3.1.1",
        "og:title": "Contributing | VoltAgent",
        "og:description": "We appreciate your interest in contributing to VoltAgent! VoltAgent aims to be a powerful and flexible backend framework focused on [mention core goals, e.g., building AI-powered applications, simplifying backend development, providing robust voice integration]. We value community contributions that help us achieve this vision.",
        "docsearch:version": "current",
        "scrapeId": "a8502629-d993-4844-9cb9-4e2866111925",
        "sourceURL": "https://voltagent.dev/docs/community/contributing/",
        "url": "https://voltagent.dev/docs/community/contributing/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:38.852Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/observability/overview/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nObservability is crucial for understanding, debugging, and improving the behavior of AI agents. It involves monitoring, logging, and visualizing the internal state and execution flow of your agents.\n\nWithin the VoltAgent framework, observability helps you:\n\n- **Debug complex interactions:** Trace the flow of execution, inspect messages, and understand why an agent made specific decisions or used certain tools.\n- **Monitor performance:** Identify bottlenecks or inefficiencies in your agent's logic.\n- **Improve reliability:** Catch errors and unexpected behavior during development and testing.\n- **Gain insights:** Understand how your agent interacts with tools, memory, and external systems.\n\nThe primary tool for observability in VoltAgent is the **VoltOps LLM Observability**. It provides a web-based interface to visualize and inspect your agent's activity in real-time.\n\n![VoltOps LLM Observability Platform](https://cdn.voltagent.dev/readme/demo.gif)\n\nLearn more about how to use it on the [VoltOps LLM Observability](https://voltagent.dev/docs/observability/developer-console/) page.",
      "metadata": {
        "language": "en",
        "twitter:card": "summary_large_image",
        "ogTitle": "Overview | VoltAgent",
        "ogDescription": "Observability is crucial for understanding, debugging, and improving the behavior of AI agents. It involves monitoring, logging, and visualizing the internal state and execution flow of your agents.",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "ogLocale": "en",
        "generator": "Docusaurus v3.1.1",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "og:url": "https://voltagent.dev/docs/observability/overview/",
        "docsearch:language": "en",
        "docusaurus_locale": "en",
        "docusaurus_tag": "docs-default-current",
        "docsearch:docusaurus_tag": "docs-default-current",
        "og:title": "Overview | VoltAgent",
        "og:locale": "en",
        "description": "Observability is crucial for understanding, debugging, and improving the behavior of AI agents. It involves monitoring, logging, and visualizing the internal state and execution flow of your agents.",
        "og:image": "https://voltagent.dev/img/social3.png",
        "ogUrl": "https://voltagent.dev/docs/observability/overview/",
        "docusaurus_version": "current",
        "docsearch:version": "current",
        "viewport": "width=device-width, initial-scale=1.0",
        "og:description": "Observability is crucial for understanding, debugging, and improving the behavior of AI agents. It involves monitoring, logging, and visualizing the internal state and execution flow of your agents.",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "title": "Overview | VoltAgent",
        "scrapeId": "22636afa-1c2b-4c1c-9de8-e4bf772e2aa2",
        "sourceURL": "https://voltagent.dev/docs/observability/overview/",
        "url": "https://voltagent.dev/docs/observability/overview/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:33.509Z",
        "creditsUsed": 1
      }
    },
    {
      "markdown": "[Skip to main content](https://voltagent.dev/docs/integrations/vercel-ai/#__docusaurus_skipToContent_fallback)\n\n[â­ï¸ Join our GitHub community!](https://github.com/VoltAgent/voltagent/stargazers)\n\nOn this page\n\nVoltAgent now works framework-agnostic and provides direct integration with [Vercel AI SDK](https://ai-sdk.dev/docs/introduction). This allows you to add observability to your existing Vercel AI applications with minimal changes.\n\n![Vercel AI SDK Integration](https://cdn.voltagent.dev/docs/vercel-ai-observability-demo/vercel-ai-demo-with-multi-agent.gif)\n\n## Installation [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#installation \"Direct link to Installation\")\n\nFirst, install the required packages:\n\n- npm\n- pnpm\n- yarn\n\n```codeBlockLines_e6Vv\nnpm install @voltagent/vercel-ai-exporter @opentelemetry/sdk-node @opentelemetry/auto-instrumentations-node\n\n```\n\n## Configuration [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#configuration \"Direct link to Configuration\")\n\n### Get Your API Keys [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#get-your-api-keys \"Direct link to Get Your API Keys\")\n\nYou'll need to get your API keys from VoltOps LLM Observability Platform:\n\n1. **Sign up** at [console.voltagent.dev](https://console.voltagent.dev/)\n2. **Create an organization** for your team/company\n3. **Create a project** within your organization\n4. **Get your keys** from the project settings:\n\n   - `VOLTAGENT_PUBLIC_KEY` \\- For client identification\n   - `VOLTAGENT_SECRET_KEY` \\- For secure server communication\n\n### Setup VoltAgent Exporter [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#setup-voltagent-exporter \"Direct link to Setup VoltAgent Exporter\")\n\nSet up VoltAgent exporter in your application (typically in your main file):\n\n```codeBlockLines_e6Vv\nimport { VoltAgentExporter } from \"@voltagent/vercel-ai-exporter\";\nimport { NodeSDK } from \"@opentelemetry/sdk-node\";\nimport { getNodeAutoInstrumentations } from \"@opentelemetry/auto-instrumentations-node\";\n\n// Create VoltAgent exporter\nconst voltAgentExporter = new VoltAgentExporter({\n  publicKey: process.env.VOLTAGENT_PUBLIC_KEY,\n  secretKey: process.env.VOLTAGENT_SECRET_KEY,\n  baseUrl: \"https://api.voltagent.dev\", // default\n  debug: true, // set to true for development\n});\n\n// Initialize OpenTelemetry SDK\nconst sdk = new NodeSDK({\n  traceExporter: voltAgentExporter,\n  instrumentations: [getNodeAutoInstrumentations()],\n});\n\nsdk.start();\n\n```\n\n## Basic Telemetry [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#basic-telemetry \"Direct link to Basic Telemetry\")\n\nStart with the minimal setup - just enable telemetry in your existing Vercel AI calls:\n\n```codeBlockLines_e6Vv\nimport { generateText } from \"ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst result = await generateText({\n  model: openai(\"gpt-4o-mini\"),\n  prompt: \"Hello, how are you?\",\n  experimental_telemetry: {\n    isEnabled: true,\n    // That's it! VoltAgent will track this with a default agent\n  },\n});\n\nconsole.log(\"Assistant:\", result.text);\n\n```\n\n![Vercel AI SDK Integration Basic Exampla](https://cdn.voltagent.dev/docs/vercel-ai-observability-demo/vercel-ai-demo-basic.gif)\n\n**âœ… What you get:**\n\n- AI calls tracked in VoltOps LLM Observability Platform\n- Basic execution flow visibility\n- All activities grouped under \"ai-assistant\" (default)\n\nYou'll see this helpful message\n\n```codeBlockLines_e6Vv\nðŸ“‹ VoltAgent: Using default agent for tracking.\nðŸ’¡ For better tracking, add agentId to your metadata:\n   experimental_telemetry: {\n     isEnabled: true,\n     metadata: { agentId: 'my-agent' }\n   }\n\n```\n\nThis is completely normal! VoltAgent automatically uses a default agent when no `agentId` is provided. We'll show you how to customize this in the next sections.\n\n## With Tools [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#with-tools \"Direct link to With Tools\")\n\nSame minimal setup, but now with tools to see how tool usage is tracked:\n\n```codeBlockLines_e6Vv\nimport { generateText } from \"ai\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { z } from \"zod\";\n\nconst result = await generateText({\n  model: openai(\"gpt-4o-mini\"),\n  prompt: \"What's the weather like in Tokyo?\",\n  tools: {\n    weather: {\n      description: \"Get the weather in a location\",\n      parameters: z.object({\n        location: z.string().describe(\"The location to get the weather for\"),\n      }),\n      execute: async ({ location }) => {\n        // Simulate API call\n        await new Promise((resolve) => setTimeout(resolve, 1000));\n        return {\n          location,\n          temperature: 72 + Math.floor(Math.random() * 21) - 10,\n        };\n      },\n    },\n  },\n  maxSteps: 5,\n  experimental_telemetry: {\n    isEnabled: true,\n    // Still using default agent, but now with tools\n  },\n});\n\nconsole.log(\"Assistant:\", result.text);\n\n```\n\n**âœ… What you get additionally:**\n\n- Tool calls tracked and visualized\n- Tool inputs and outputs visible\n- Tool execution timeline\n- Still grouped under default agent\n\n![Vercel AI SDK Integration Basic Exampla](https://cdn.voltagent.dev/docs/vercel-ai-observability-demo/vercel-ai-demo-with-tools.gif)\n\n## With Metadata [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#with-metadata \"Direct link to With Metadata\")\n\nNow make tracking much more powerful by adding an agent identifier:\n\n```codeBlockLines_e6Vv\nimport { generateText } from \"ai\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { z } from \"zod\";\n\nconst result = await generateText({\n  model: openai(\"gpt-4o-mini\"),\n  prompt: \"What's the weather like in Paris?\",\n  tools: {\n    weather: {\n      description: \"Get the weather in a location\",\n      parameters: z.object({\n        location: z.string().describe(\"The location to get the weather for\"),\n      }),\n      execute: async ({ location }) => {\n        await new Promise((resolve) => setTimeout(resolve, 1000));\n        return {\n          location,\n          temperature: 18 + Math.floor(Math.random() * 21) - 10,\n        };\n      },\n    },\n  },\n  maxSteps: 5,\n  experimental_telemetry: {\n    isEnabled: true,\n    metadata: {\n      agentId: \"weather-assistant\",\n      instructions: \"You are a helpful weather assistant\",\n    },\n  },\n});\n\nconsole.log(\"Assistant:\", result.text);\n\n```\n\n![Vercel AI SDK Integration Basic Exampla](https://cdn.voltagent.dev/docs/vercel-ai-observability-demo/vercel-ai-demo-with-agentid.gif)\n\n**âœ… What you get additionally:**\n\n- Your agent is now tracked under \"weather-assistant\" name\n- Instructions are visible in the console\n- Better organized execution history\n- More meaningful tracking data\n\n## With Additional Metadata [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#with-additional-metadata \"Direct link to With Additional Metadata\")\n\nYou can provide additional context about the execution:\n\n```codeBlockLines_e6Vv\nimport { generateText } from \"ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst result = await generateText({\n  model: openai(\"gpt-4o-mini\"),\n  prompt: \"Tell me a joke\",\n  experimental_telemetry: {\n    isEnabled: true,\n    metadata: {\n      agentId: \"comedy-assistant\",\n      instructions: \"You are a fun comedian assistant\",\n      userId: \"user123\",\n      sessionId: \"session456\",\n      // Any additional context you want to track\n      environment: \"production\",\n      version: \"1.2.0\",\n    },\n  },\n});\n\nconsole.log(\"Assistant:\", result.text);\n\n```\n\n![Vercel AI SDK Integration Basic Exampla](https://cdn.voltagent.dev/docs/vercel-ai-observability-demo/vercel-ai-demo-with-metadata.gif)\n\n**âœ… What you get additionally:**\n\n- User and session tracking\n- Environment context\n- Version information\n- Custom metadata for filtering and analysis\n\n## Multi-Agent Workflows [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#multi-agent-workflows \"Direct link to Multi-Agent Workflows\")\n\nTrack different agent roles within the same application:\n\n```codeBlockLines_e6Vv\nimport { generateText } from \"ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Research agent\nconst researchResult = await generateText({\n  model: openai(\"gpt-4o-mini\"),\n  prompt: \"Research information about renewable energy trends\",\n  experimental_telemetry: {\n    isEnabled: true,\n    metadata: {\n      agentId: \"research-agent\",\n      instructions: \"You are a research specialist focused on gathering factual information\",\n      role: \"researcher\",\n    },\n  },\n});\n\n// Writing agent\nconst articleResult = await generateText({\n  model: openai(\"gpt-4o-mini\"),\n  prompt: `Write an article based on this research: ${researchResult.text}`,\n  experimental_telemetry: {\n    isEnabled: true,\n    metadata: {\n      agentId: \"writing-agent\",\n      instructions: \"You are a professional writer who creates engaging articles\",\n      role: \"writer\",\n    },\n  },\n});\n\n// Review agent\nconst reviewResult = await generateText({\n  model: openai(\"gpt-4o-mini\"),\n  prompt: `Review and improve this article: ${articleResult.text}`,\n  experimental_telemetry: {\n    isEnabled: true,\n    metadata: {\n      agentId: \"review-agent\",\n      instructions: \"You are an editor who reviews and improves content\",\n      role: \"editor\",\n    },\n  },\n});\n\nconsole.log(\"Final article:\", reviewResult.text);\n\n```\n\n![Vercel AI SDK Integration Basic Exampla](https://cdn.voltagent.dev/docs/vercel-ai-observability-demo/vercel-ai-demo-with-multi-agent.gif)\n\n**âœ… What you get with multi-agent tracking:**\n\n- Each agent tracked separately in the console\n- Clear visualization of agent interactions\n- Role-based organization\n- Workflow understanding across agents\n\n## Advanced Features [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#advanced-features \"Direct link to Advanced Features\")\n\n### Custom Spans [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#custom-spans \"Direct link to Custom Spans\")\n\nAdd custom spans to track specific operations:\n\n```codeBlockLines_e6Vv\nimport { trace } from \"@opentelemetry/api\";\n\nconst tracer = trace.getTracer(\"my-app\");\n\nconst result = await tracer.startActiveSpan(\"user-request-processing\", async (span) => {\n  span.setAttributes({\n    \"user.id\": \"user123\",\n    \"request.type\": \"question\",\n  });\n\n  const response = await generateText({\n    model: openai(\"gpt-4o-mini\"),\n    prompt: \"What's the capital of France?\",\n    experimental_telemetry: {\n      isEnabled: true,\n      metadata: { agentId: \"geography-assistant\" },\n    },\n  });\n\n  span.setAttributes({\n    \"response.length\": response.text.length,\n  });\n\n  span.end();\n  return response;\n});\n\n```\n\n### Error Tracking [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#error-tracking \"Direct link to Error Tracking\")\n\nAutomatically track errors in your AI workflows:\n\n```codeBlockLines_e6Vv\nimport { trace } from \"@opentelemetry/api\";\n\ntry {\n  const result = await generateText({\n    model: openai(\"gpt-4o-mini\"),\n    prompt: \"Some prompt that might fail\",\n    experimental_telemetry: {\n      isEnabled: true,\n      metadata: { agentId: \"error-prone-agent\" },\n    },\n  });\n} catch (error) {\n  const span = trace.getActiveSpan();\n  if (span) {\n    span.recordException(error);\n    span.setStatus({ code: 2, message: error.message });\n  }\n  throw error;\n}\n\n```\n\n## Best Practices [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#best-practices \"Direct link to Best Practices\")\n\n### 1\\. Use Meaningful Agent IDs [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#1-use-meaningful-agent-ids \"Direct link to 1. Use Meaningful Agent IDs\")\n\n```codeBlockLines_e6Vv\n// âŒ Not helpful\nmetadata: {\n  agentId: \"agent1\";\n}\n\n// âœ… Descriptive and helpful\nmetadata: {\n  agentId: \"customer-support-agent\";\n}\nmetadata: {\n  agentId: \"product-recommendation-agent\";\n}\nmetadata: {\n  agentId: \"content-writer-agent\";\n}\n\n```\n\n### 2\\. Include Context [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#2-include-context \"Direct link to 2. Include Context\")\n\n```codeBlockLines_e6Vv\n// âœ… Rich context for better tracking\nmetadata: {\n  agentId: 'support-agent',\n  instructions: 'Help customers with technical issues',\n  userId: userId,\n  sessionId: sessionId,\n  category: 'technical-support',\n  priority: 'high'\n}\n\n```\n\n### 3\\. Environment Variables [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#3-environment-variables \"Direct link to 3. Environment Variables\")\n\n```codeBlockLines_e6Vv\n# .env\nVOLTAGENT_PUBLIC_KEY=your_public_key\nVOLTAGENT_SECRET_KEY=your_secret_key\nVOLTAGENT_BASE_URL=https://api.voltagent.dev\n\n```\n\n### 4\\. Development vs Production [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#4-development-vs-production \"Direct link to 4. Development vs Production\")\n\n```codeBlockLines_e6Vv\nconst voltAgentExporter = new VoltAgentExporter({\n  publicKey: process.env.VOLTAGENT_PUBLIC_KEY,\n  secretKey: process.env.VOLTAGENT_SECRET_KEY,\n  debug: process.env.NODE_ENV === \"development\", // Only debug in development\n});\n\n```\n\n## Troubleshooting [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#troubleshooting \"Direct link to Troubleshooting\")\n\n### Common Issues [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#common-issues \"Direct link to Common Issues\")\n\n1. **No data showing in console**: Verify your API keys and network connectivity\n2. **Missing spans**: Ensure telemetry is enabled and SDK is initialized\n3. **Performance impact**: Use batch processing in production\n\n### Debug Mode [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#debug-mode \"Direct link to Debug Mode\")\n\nEnable debug mode to see detailed logs:\n\n```codeBlockLines_e6Vv\nconst voltAgentExporter = new VoltAgentExporter({\n  // ... config\n  debug: true, // Enable detailed logging\n});\n\n```\n\nYou'll see helpful logs like:\n\n```codeBlockLines_e6Vv\n[VoltAgent] Exporting span: ai.generateText\n[VoltAgent] Metadata: {\"agentId\":\"my-agent\"}\n[VoltAgent] Successfully exported to VoltAgent\n\n```\n\n## Next Steps [â€‹](https://voltagent.dev/docs/integrations/vercel-ai/\\#next-steps \"Direct link to Next Steps\")\n\n- **[VoltOps Platform](https://voltagent.dev/docs/observability/developer-console/)** \\- Learn about real-time debugging\n- **[Langfuse Integration](https://voltagent.dev/docs/observability/langfuse/)** \\- Advanced analytics platform\n- **[Production Deployment](https://voltagent.dev/docs/integrations/vercel-ai/#)** \\- Best practices for production use\n\nNeed help? Join our [Discord community](https://s.voltagent.dev/discord) or check out our [GitHub discussions](https://github.com/voltagent/voltagent/discussions).\n\n### Table of Contents\n\n- [Installation](https://voltagent.dev/docs/integrations/vercel-ai/#installation)\n- [Configuration](https://voltagent.dev/docs/integrations/vercel-ai/#configuration)\n  - [Get Your API Keys](https://voltagent.dev/docs/integrations/vercel-ai/#get-your-api-keys)\n  - [Setup VoltAgent Exporter](https://voltagent.dev/docs/integrations/vercel-ai/#setup-voltagent-exporter)\n- [Basic Telemetry](https://voltagent.dev/docs/integrations/vercel-ai/#basic-telemetry)\n- [With Tools](https://voltagent.dev/docs/integrations/vercel-ai/#with-tools)\n- [With Metadata](https://voltagent.dev/docs/integrations/vercel-ai/#with-metadata)\n- [With Additional Metadata](https://voltagent.dev/docs/integrations/vercel-ai/#with-additional-metadata)\n- [Multi-Agent Workflows](https://voltagent.dev/docs/integrations/vercel-ai/#multi-agent-workflows)\n- [Advanced Features](https://voltagent.dev/docs/integrations/vercel-ai/#advanced-features)\n  - [Custom Spans](https://voltagent.dev/docs/integrations/vercel-ai/#custom-spans)\n  - [Error Tracking](https://voltagent.dev/docs/integrations/vercel-ai/#error-tracking)\n- [Best Practices](https://voltagent.dev/docs/integrations/vercel-ai/#best-practices)\n  - [1\\. Use Meaningful Agent IDs](https://voltagent.dev/docs/integrations/vercel-ai/#1-use-meaningful-agent-ids)\n  - [2\\. Include Context](https://voltagent.dev/docs/integrations/vercel-ai/#2-include-context)\n  - [3\\. Environment Variables](https://voltagent.dev/docs/integrations/vercel-ai/#3-environment-variables)\n  - [4\\. Development vs Production](https://voltagent.dev/docs/integrations/vercel-ai/#4-development-vs-production)\n- [Troubleshooting](https://voltagent.dev/docs/integrations/vercel-ai/#troubleshooting)\n  - [Common Issues](https://voltagent.dev/docs/integrations/vercel-ai/#common-issues)\n  - [Debug Mode](https://voltagent.dev/docs/integrations/vercel-ai/#debug-mode)\n- [Next Steps](https://voltagent.dev/docs/integrations/vercel-ai/#next-steps)",
      "metadata": {
        "docsearch:language": "en",
        "description": "VoltAgent now works framework-agnostic and provides direct integration with Vercel AI SDK. This allows you to add observability to your existing Vercel AI applications with minimal changes.",
        "ogTitle": "Vercel AI SDK Integration | VoltAgent",
        "og:locale": "en",
        "ogUrl": "https://voltagent.dev/docs/integrations/vercel-ai/",
        "ogDescription": "VoltAgent now works framework-agnostic and provides direct integration with Vercel AI SDK. This allows you to add observability to your existing Vercel AI applications with minimal changes.",
        "ogLocale": "en",
        "docusaurus_version": "current",
        "title": "Vercel AI SDK Integration | VoltAgent",
        "twitter:image": "https://voltagent.dev/img/social3.png",
        "docsearch:version": "current",
        "og:description": "VoltAgent now works framework-agnostic and provides direct integration with Vercel AI SDK. This allows you to add observability to your existing Vercel AI applications with minimal changes.",
        "docsearch:docusaurus_tag": "docs-default-current",
        "viewport": "width=device-width, initial-scale=1.0",
        "docusaurus_tag": "docs-default-current",
        "favicon": "https://voltagent.dev/img/favicon.ico",
        "language": "en",
        "ogImage": "https://voltagent.dev/img/social3.png",
        "og:image": "https://voltagent.dev/img/social3.png",
        "generator": "Docusaurus v3.1.1",
        "docusaurus_locale": "en",
        "og:title": "Vercel AI SDK Integration | VoltAgent",
        "og:url": "https://voltagent.dev/docs/integrations/vercel-ai/",
        "twitter:card": "summary_large_image",
        "scrapeId": "bbefd10d-0f18-42a8-b589-39bc03c6ccc2",
        "sourceURL": "https://voltagent.dev/docs/integrations/vercel-ai/",
        "url": "https://voltagent.dev/docs/integrations/vercel-ai/",
        "statusCode": 200,
        "contentType": "text/html; charset=utf-8",
        "proxyUsed": "basic",
        "cacheState": "hit",
        "cachedAt": "2025-08-23T20:40:59.334Z",
        "creditsUsed": 1
      }
    }
  ],
  "success": true,
  "completed": 62,
  "total": 62,
  "creditsUsed": 62,
  "expiresAt": "2025-08-24T20:41:36.000Z",
  "next": "https://api.firecrawl.dev/v2/crawl/e248af91-8430-4c20-bb56-11fa88dc1ed9?skip=53"
}